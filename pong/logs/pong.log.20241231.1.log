2024-12-31 21:01:11.514 Could not detect default configuration classes for test class [com.demo.controller.PongControllerSpec]: PongControllerSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:01:11.667 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.controller.PongControllerSpec
2024-12-31 21:01:11.859 Could not detect default configuration classes for test class [com.demo.dao.MessageRepositorySpec]: MessageRepositorySpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:01:11.873 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.dao.MessageRepositorySpec
2024-12-31 21:01:11.890 Could not detect default configuration classes for test class [com.demo.kafka.KafkaSpec]: KafkaSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:01:11.918 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.kafka.KafkaSpec
2024-12-31 21:01:11.955 Could not detect default configuration classes for test class [com.demo.controller.PongControllerSpec]: PongControllerSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:01:11.958 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.controller.PongControllerSpec
2024-12-31 21:01:11.964 Could not detect default configuration classes for test class [com.demo.dao.MessageRepositorySpec]: MessageRepositorySpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:01:11.967 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.dao.MessageRepositorySpec
2024-12-31 21:01:11.971 Could not detect default configuration classes for test class [com.demo.kafka.KafkaSpec]: KafkaSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:01:11.973 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.kafka.KafkaSpec
2024-12-31 21:01:12.360 Registered kafka:type=kafka.Log4jController MBean
2024-12-31 21:01:12.444 
2024-12-31 21:01:12.445   ______                  _                                          
2024-12-31 21:01:12.445  |___  /                 | |                                         
2024-12-31 21:01:12.445     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __   
2024-12-31 21:01:12.445    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__|
2024-12-31 21:01:12.445   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |    
2024-12-31 21:01:12.445  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_|
2024-12-31 21:01:12.445                                               | |                     
2024-12-31 21:01:12.445                                               |_|                     
2024-12-31 21:01:12.445 
2024-12-31 21:01:17.683 Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT
2024-12-31 21:01:17.684 Server environment:host.name=Joe
2024-12-31 21:01:17.684 Server environment:java.version=17.0.12
2024-12-31 21:01:17.684 Server environment:java.vendor=Oracle Corporation
2024-12-31 21:01:17.684 Server environment:java.home=C:\work\jdk-17
2024-12-31 21:01:17.684 Server environment:java.class.path=C:\code\hsbc\demo\pong\target\test-classes;C:\code\hsbc\demo\pong\target\classes;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-webflux\3.1.4\spring-boot-starter-webflux-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter\3.1.4\spring-boot-starter-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot\3.1.4\spring-boot-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-autoconfigure\3.1.4\spring-boot-autoconfigure-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-logging\3.1.4\spring-boot-starter-logging-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\ch\qos\logback\logback-classic\1.4.11\logback-classic-1.4.11.jar;C:\work\apache-maven-3.8.8\repo\ch\qos\logback\logback-core\1.4.11\logback-core-1.4.11.jar;C:\work\apache-maven-3.8.8\repo\org\apache\logging\log4j\log4j-to-slf4j\2.20.0\log4j-to-slf4j-2.20.0.jar;C:\work\apache-maven-3.8.8\repo\org\apache\logging\log4j\log4j-api\2.20.0\log4j-api-2.20.0.jar;C:\work\apache-maven-3.8.8\repo\org\slf4j\jul-to-slf4j\2.0.9\jul-to-slf4j-2.0.9.jar;C:\work\apache-maven-3.8.8\repo\jakarta\annotation\jakarta.annotation-api\2.1.1\jakarta.annotation-api-2.1.1.jar;C:\work\apache-maven-3.8.8\repo\org\yaml\snakeyaml\1.33\snakeyaml-1.33.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-json\3.1.4\spring-boot-starter-json-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-databind\2.15.2\jackson-databind-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-annotations\2.15.2\jackson-annotations-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-core\2.15.2\jackson-core-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.15.2\jackson-datatype-jdk8-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.15.2\jackson-datatype-jsr310-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\module\jackson-module-parameter-names\2.15.2\jackson-module-parameter-names-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-reactor-netty\3.1.4\spring-boot-starter-reactor-netty-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\netty\reactor-netty-http\1.1.11\reactor-netty-http-1.1.11.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-http\4.1.97.Final\netty-codec-http-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-http2\4.1.97.Final\netty-codec-http2-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns\4.1.97.Final\netty-resolver-dns-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-dns\4.1.97.Final\netty-codec-dns-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns-native-macos\4.1.97.Final\netty-resolver-dns-native-macos-4.1.97.Final-osx-x86_64.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns-classes-macos\4.1.97.Final\netty-resolver-dns-classes-macos-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final-linux-x86_64.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\netty\reactor-netty-core\1.1.11\reactor-netty-core-1.1.11.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-handler-proxy\4.1.97.Final\netty-handler-proxy-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-socks\4.1.97.Final\netty-codec-socks-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-web\6.0.12\spring-web-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-beans\6.0.12\spring-beans-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-webflux\6.0.12\spring-webflux-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\reactor-core\3.5.10\reactor-core-3.5.10.jar;C:\work\apache-maven-3.8.8\repo\org\reactivestreams\reactive-streams\1.0.4\reactive-streams-1.0.4.jar;C:\work\apache-maven-3.8.8\repo\com\google\guava\guava\19.0\guava-19.0.jar;C:\work\apache-maven-3.8.8\repo\commons-io\commons-io\2.11.0\commons-io-2.11.0.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-data-redis\3.1.4\spring-boot-starter-data-redis-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-redis\3.1.4\spring-data-redis-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-keyvalue\3.1.4\spring-data-keyvalue-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-oxm\6.0.12\spring-oxm-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-aop\6.0.12\spring-aop-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-context-support\6.0.12\spring-context-support-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\io\lettuce\lettuce-core\6.2.6.RELEASE\lettuce-core-6.2.6.RELEASE.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-common\4.1.97.Final\netty-common-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-handler\4.1.97.Final\netty-handler-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver\4.1.97.Final\netty-resolver-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-buffer\4.1.97.Final\netty-buffer-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-unix-common\4.1.97.Final\netty-transport-native-unix-common-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec\4.1.97.Final\netty-codec-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport\4.1.97.Final\netty-transport-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-data-jpa\3.1.4\spring-boot-starter-data-jpa-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-aop\3.1.4\spring-boot-starter-aop-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\aspectj\aspectjweaver\1.9.20\aspectjweaver-1.9.20.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-jdbc\3.1.4\spring-boot-starter-jdbc-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\zaxxer\HikariCP\5.0.1\HikariCP-5.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-jdbc\6.0.12\spring-jdbc-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\hibernate\orm\hibernate-core\6.2.9.Final\hibernate-core-6.2.9.Final.jar;C:\work\apache-maven-3.8.8\repo\jakarta\persistence\jakarta.persistence-api\3.1.0\jakarta.persistence-api-3.1.0.jar;C:\work\apache-maven-3.8.8\repo\jakarta\transaction\jakarta.transaction-api\2.0.1\jakarta.transaction-api-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\jboss\logging\jboss-logging\3.5.3.Final\jboss-logging-3.5.3.Final.jar;C:\work\apache-maven-3.8.8\repo\org\hibernate\common\hibernate-commons-annotations\6.0.6.Final\hibernate-commons-annotations-6.0.6.Final.jar;C:\work\apache-maven-3.8.8\repo\io\smallrye\jandex\3.0.5\jandex-3.0.5.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\classmate\1.5.1\classmate-1.5.1.jar;C:\work\apache-maven-3.8.8\repo\net\bytebuddy\byte-buddy\1.14.8\byte-buddy-1.14.8.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\jaxb-runtime\4.0.3\jaxb-runtime-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\jaxb-core\4.0.3\jaxb-core-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\eclipse\angus\angus-activation\2.0.1\angus-activation-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\txw2\4.0.3\txw2-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\com\sun\istack\istack-commons-runtime\4.1.2\istack-commons-runtime-4.1.2.jar;C:\work\apache-maven-3.8.8\repo\jakarta\inject\jakarta.inject-api\2.0.1\jakarta.inject-api-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\antlr\antlr4-runtime\4.10.1\antlr4-runtime-4.10.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-jpa\3.1.4\spring-data-jpa-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-commons\3.1.4\spring-data-commons-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-orm\6.0.12\spring-orm-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-aspects\6.0.12\spring-aspects-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\postgresql\postgresql\42.6.0\postgresql-42.6.0.jar;C:\work\apache-maven-3.8.8\repo\org\checkerframework\checker-qual\3.31.0\checker-qual-3.31.0.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\kafka\spring-kafka\3.0.11\spring-kafka-3.0.11.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-context\6.0.12\spring-context-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-expression\6.0.12\spring-expression-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-messaging\6.0.12\spring-messaging-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-tx\6.0.12\spring-tx-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\retry\spring-retry\2.0.3\spring-retry-2.0.3.jar;C:\work\apache-maven-3.8.8\repo\io\micrometer\micrometer-observation\1.11.4\micrometer-observation-1.11.4.jar;C:\work\apache-maven-3.8.8\repo\io\micrometer\micrometer-commons\1.11.4\micrometer-commons-1.11.4.jar;C:\work\apache-maven-3.8.8\repo\com\google\code\findbugs\jsr305\3.0.2\jsr305-3.0.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\com\github\luben\zstd-jni\1.5.2-1\zstd-jni-1.5.2-1.jar;C:\work\apache-maven-3.8.8\repo\org\lz4\lz4-java\1.8.0\lz4-java-1.8.0.jar;C:\work\apache-maven-3.8.8\repo\org\xerial\snappy\snappy-java\1.1.8.4\snappy-java-1.1.8.4.jar;C:\work\apache-maven-3.8.8\repo\org\slf4j\slf4j-api\2.0.9\slf4j-api-2.0.9.jar;C:\work\apache-maven-3.8.8\repo\com\h2database\h2\1.4.200\h2-1.4.200.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-test\3.1.4\spring-boot-starter-test-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-test\3.1.4\spring-boot-test-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-test-autoconfigure\3.1.4\spring-boot-test-autoconfigure-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\jayway\jsonpath\json-path\2.8.0\json-path-2.8.0.jar;C:\work\apache-maven-3.8.8\repo\jakarta\xml\bind\jakarta.xml.bind-api\4.0.1\jakarta.xml.bind-api-4.0.1.jar;C:\work\apache-maven-3.8.8\repo\jakarta\activation\jakarta.activation-api\2.1.2\jakarta.activation-api-2.1.2.jar;C:\work\apache-maven-3.8.8\repo\net\minidev\json-smart\2.4.11\json-smart-2.4.11.jar;C:\work\apache-maven-3.8.8\repo\net\minidev\accessors-smart\2.4.11\accessors-smart-2.4.11.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm\9.3\asm-9.3.jar;C:\work\apache-maven-3.8.8\repo\org\assertj\assertj-core\3.24.2\assertj-core-3.24.2.jar;C:\work\apache-maven-3.8.8\repo\org\hamcrest\hamcrest\2.2\hamcrest-2.2.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter\5.9.3\junit-jupiter-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-params\5.9.3\junit-jupiter-params-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-engine\5.9.3\junit-jupiter-engine-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\mockito\mockito-core\5.3.1\mockito-core-5.3.1.jar;C:\work\apache-maven-3.8.8\repo\net\bytebuddy\byte-buddy-agent\1.14.8\byte-buddy-agent-1.14.8.jar;C:\work\apache-maven-3.8.8\repo\org\objenesis\objenesis\3.3\objenesis-3.3.jar;C:\work\apache-maven-3.8.8\repo\org\mockito\mockito-junit-jupiter\5.3.1\mockito-junit-jupiter-5.3.1.jar;C:\work\apache-maven-3.8.8\repo\org\skyscreamer\jsonassert\1.5.1\jsonassert-1.5.1.jar;C:\work\apache-maven-3.8.8\repo\com\vaadin\external\google\android-json\0.0.20131108.vaadin1\android-json-0.0.20131108.vaadin1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-core\6.0.12\spring-core-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-jcl\6.0.12\spring-jcl-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-test\6.0.12\spring-test-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\xmlunit\xmlunit-core\2.9.1\xmlunit-core-2.9.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy\4.0.15\groovy-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-ant\4.0.15\groovy-ant-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant\1.10.14\ant-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-junit\1.10.14\ant-junit-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-launcher\1.10.14\ant-launcher-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-antlr\1.10.14\ant-antlr-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-cli-picocli\4.0.15\groovy-cli-picocli-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\info\picocli\picocli\4.7.5\picocli-4.7.5.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-console\4.0.15\groovy-console-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\github\javaparser\javaparser-core\3.25.5\javaparser-core-3.25.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-util\9.5\asm-util-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-tree\9.5\asm-tree-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-analysis\9.5\asm-analysis-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\abego\treelayout\org.abego.treelayout.core\1.0.3\org.abego.treelayout.core-1.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ivy\ivy\2.5.2\ivy-2.5.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-datetime\4.0.15\groovy-datetime-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-docgenerator\4.0.15\groovy-docgenerator-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\thoughtworks\qdox\qdox\1.12.1\qdox-1.12.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-groovydoc\4.0.15\groovy-groovydoc-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-groovysh\4.0.15\groovy-groovysh-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\jline\jline\2.14.6\jline-2.14.6.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-jmx\4.0.15\groovy-jmx-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-json\4.0.15\groovy-json-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-jsr223\4.0.15\groovy-jsr223-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-macro\4.0.15\groovy-macro-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-nio\4.0.15\groovy-nio-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-servlet\4.0.15\groovy-servlet-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-sql\4.0.15\groovy-sql-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-swing\4.0.15\groovy-swing-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-templates\4.0.15\groovy-templates-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-test\4.0.15\groovy-test-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\junit\junit\4.13.2\junit-4.13.2.jar;C:\work\apache-maven-3.8.8\repo\org\hamcrest\hamcrest-core\2.2\hamcrest-core-2.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-test-junit5\4.0.15\groovy-test-junit5-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-xml\4.0.15\groovy-xml-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-yaml\4.0.15\groovy-yaml-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\dataformat\jackson-dataformat-yaml\2.15.2\jackson-dataformat-yaml-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\org\spockframework\spock-core\2.4-M1-groovy-4.0\spock-core-2.4-M1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-engine\1.9.3\junit-platform-engine-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\opentest4j\opentest4j\1.2.0\opentest4j-1.2.0.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-commons\1.9.3\junit-platform-commons-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\apiguardian\apiguardian-api\1.1.2\apiguardian-api-1.1.2.jar;C:\work\apache-maven-3.8.8\repo\org\spockframework\spock-spring\2.4-M1-groovy-4.0\spock-spring-2.4-M1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\com\athaydes\spock-reports\2.5.1-groovy-4.0\spock-reports-2.5.1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\com\github\codemonstur\embedded-redis\1.4.2\embedded-redis-1.4.2.jar;C:\work\apache-maven-3.8.8\repo\redis\clients\jedis\4.3.2\jedis-4.3.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\commons\commons-pool2\2.11.1\commons-pool2-2.11.1.jar;C:\work\apache-maven-3.8.8\repo\org\json\json\20220320\json-20220320.jar;C:\work\apache-maven-3.8.8\repo\com\google\code\gson\gson\2.10.1\gson-2.10.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\kafka\spring-kafka-test\3.0.11\spring-kafka-test-3.0.11.jar;C:\work\apache-maven-3.8.8\repo\org\apache\zookeeper\zookeeper\3.6.3\zookeeper-3.6.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\zookeeper\zookeeper-jute\3.6.3\zookeeper-jute-3.6.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-classes-epoll\4.1.97.Final\netty-transport-classes-epoll-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1-test.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-metadata\3.4.1\kafka-metadata-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-server-common\3.4.1\kafka-server-common-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-raft\3.4.1\kafka-raft-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-streams-test-utils\3.4.1\kafka-streams-test-utils-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-streams\3.4.1\kafka-streams-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\rocksdb\rocksdbjni\7.1.2\rocksdbjni-7.1.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\scala-library\2.13.10\scala-library-2.13.10.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-group-coordinator\3.4.1\kafka-group-coordinator-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-storage\3.4.1\kafka-storage-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-storage-api\3.4.1\kafka-storage-api-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\net\sourceforge\argparse4j\argparse4j\0.7.0\argparse4j-0.7.0.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\module\jackson-module-scala_2.13\2.15.2\jackson-module-scala_2.13-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\thoughtworks\paranamer\paranamer\2.8\paranamer-2.8.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\dataformat\jackson-dataformat-csv\2.15.2\jackson-dataformat-csv-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\net\sf\jopt-simple\jopt-simple\5.0.4\jopt-simple-5.0.4.jar;C:\work\apache-maven-3.8.8\repo\org\bitbucket\b_c\jose4j\0.9.3\jose4j-0.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\modules\scala-collection-compat_2.13\2.10.0\scala-collection-compat_2.13-2.10.0.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\modules\scala-java8-compat_2.13\1.0.2\scala-java8-compat_2.13-1.0.2.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\scala-reflect\2.13.10\scala-reflect-2.13.10.jar;C:\work\apache-maven-3.8.8\repo\com\typesafe\scala-logging\scala-logging_2.13\3.9.4\scala-logging_2.13-3.9.4.jar;C:\work\apache-maven-3.8.8\repo\io\dropwizard\metrics\metrics-core\4.2.19\metrics-core-4.2.19.jar;C:\work\apache-maven-3.8.8\repo\commons-cli\commons-cli\1.4\commons-cli-1.4.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1-test.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-api\5.9.3\junit-jupiter-api-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-launcher\1.9.3\junit-platform-launcher-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\awaitility\awaitility\4.2.0\awaitility-4.2.0.jar;
2024-12-31 21:01:17.687 Server environment:java.library.path=C:\work\jdk-17\bin;C:\windows\Sun\Java\bin;C:\windows\system32;C:\windows;C:\work\python312\Scripts\;C:\work\python312\;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program\Git\cmd;C:\Program\PowerShell\7\;C:\Program Files\dotnet\;C:\Users\joech\AppData\Local\Microsoft\WindowsApps;C:\Users\joech\AppData\Local\GitHubDesktop\bin;C:\Program\Microsoft VS Code\bin;C:\work\apache-maven-3.8.8\bin;C:\Program Files\Tesseract-OCR;C:\work\jdk-17\bin;;.
2024-12-31 21:01:17.688 Server environment:java.io.tmpdir=C:\Users\joech\AppData\Local\Temp\
2024-12-31 21:01:17.688 Server environment:java.compiler=<NA>
2024-12-31 21:01:17.688 Server environment:os.name=Windows 11
2024-12-31 21:01:17.688 Server environment:os.arch=amd64
2024-12-31 21:01:17.688 Server environment:os.version=10.0
2024-12-31 21:01:17.688 Server environment:user.name=joech
2024-12-31 21:01:17.688 Server environment:user.home=C:\Users\joech
2024-12-31 21:01:17.688 Server environment:user.dir=C:\code\hsbc\demo\pong
2024-12-31 21:01:17.688 Server environment:os.memory.free=443MB
2024-12-31 21:01:17.688 Server environment:os.memory.max=15816MB
2024-12-31 21:01:17.688 Server environment:os.memory.total=568MB
2024-12-31 21:01:17.688 zookeeper.enableEagerACLCheck = false
2024-12-31 21:01:17.693 zookeeper.digest.enabled = true
2024-12-31 21:01:17.693 zookeeper.closeSessionTxn.enabled = true
2024-12-31 21:01:17.693 zookeeper.flushDelay=0
2024-12-31 21:01:17.693 zookeeper.maxWriteQueuePollTime=0
2024-12-31 21:01:17.693 zookeeper.maxBatchSize=1000
2024-12-31 21:01:17.694 zookeeper.intBufferStartingSizeBytes = 1024
2024-12-31 21:01:17.698 zookeeper.snapshot.trust.empty : false
2024-12-31 21:01:17.735 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:01:17.735 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:01:17.735 zookeeper.snapshotSizeFactor = 0.33
2024-12-31 21:01:17.735 zookeeper.commitLogCount=500
2024-12-31 21:01:17.743 Weighed connection throttling is disabled
2024-12-31 21:01:17.748 minSessionTimeout set to 1600
2024-12-31 21:01:17.749 maxSessionTimeout set to 16000
2024-12-31 21:01:17.752 Response cache size is initialized with value 400.
2024-12-31 21:01:17.753 Response cache size is initialized with value 400.
2024-12-31 21:01:17.756 zookeeper.pathStats.slotCapacity = 60
2024-12-31 21:01:17.757 zookeeper.pathStats.slotDuration = 15
2024-12-31 21:01:17.757 zookeeper.pathStats.maxDepth = 6
2024-12-31 21:01:17.757 zookeeper.pathStats.initialDelay = 5
2024-12-31 21:01:17.757 zookeeper.pathStats.delay = 5
2024-12-31 21:01:17.757 zookeeper.pathStats.enabled = false
2024-12-31 21:01:17.761 The max bytes for all large requests are set to 104857600
2024-12-31 21:01:17.761 The large request threshold is set to -1
2024-12-31 21:01:17.763 Created server with tickTime 800 minSessionTimeout 1600 maxSessionTimeout 16000 clientPortListenBacklog -1 datadir C:\Users\joech\AppData\Local\Temp\kafka-12828211453116232502\version-2 snapdir C:\Users\joech\AppData\Local\Temp\kafka-7403850049415395993\version-2
2024-12-31 21:01:17.832 maxCnxns is not configured, using default value 0.
2024-12-31 21:01:17.836 Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers.
2024-12-31 21:01:17.846 binding to port /127.0.0.1:0
2024-12-31 21:01:17.881 zookeeper.snapshot.compression.method = CHECKED
2024-12-31 21:01:17.882 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-7403850049415395993\version-2\snapshot.0
2024-12-31 21:01:17.890 Snapshot loaded in 35 ms, highest zxid is 0x0, digest is 1371985504
2024-12-31 21:01:17.890 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-7403850049415395993\version-2\snapshot.0
2024-12-31 21:01:17.891 Snapshot taken in 1 ms
2024-12-31 21:01:17.912 PrepRequestProcessor (sid:0) started, reconfigEnabled=false
2024-12-31 21:01:17.912 zookeeper.request_throttler.shutdownTimeout = 10000
2024-12-31 21:01:18.341 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.ec524e2d-dbef-471d-ac43-d3e355abcc851781581959491201383
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59323
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:01:18.386 Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
2024-12-31 21:01:18.484 starting
2024-12-31 21:01:18.485 Connecting to zookeeper on 127.0.0.1:59323
2024-12-31 21:01:18.511 [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:59323.
2024-12-31 21:01:23.827 Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT
2024-12-31 21:01:23.828 Client environment:host.name=Joe
2024-12-31 21:01:23.828 Client environment:java.version=17.0.12
2024-12-31 21:01:23.828 Client environment:java.vendor=Oracle Corporation
2024-12-31 21:01:23.828 Client environment:java.home=C:\work\jdk-17
2024-12-31 21:01:23.828 Client environment:java.class.path=C:\code\hsbc\demo\pong\target\test-classes;C:\code\hsbc\demo\pong\target\classes;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-webflux\3.1.4\spring-boot-starter-webflux-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter\3.1.4\spring-boot-starter-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot\3.1.4\spring-boot-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-autoconfigure\3.1.4\spring-boot-autoconfigure-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-logging\3.1.4\spring-boot-starter-logging-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\ch\qos\logback\logback-classic\1.4.11\logback-classic-1.4.11.jar;C:\work\apache-maven-3.8.8\repo\ch\qos\logback\logback-core\1.4.11\logback-core-1.4.11.jar;C:\work\apache-maven-3.8.8\repo\org\apache\logging\log4j\log4j-to-slf4j\2.20.0\log4j-to-slf4j-2.20.0.jar;C:\work\apache-maven-3.8.8\repo\org\apache\logging\log4j\log4j-api\2.20.0\log4j-api-2.20.0.jar;C:\work\apache-maven-3.8.8\repo\org\slf4j\jul-to-slf4j\2.0.9\jul-to-slf4j-2.0.9.jar;C:\work\apache-maven-3.8.8\repo\jakarta\annotation\jakarta.annotation-api\2.1.1\jakarta.annotation-api-2.1.1.jar;C:\work\apache-maven-3.8.8\repo\org\yaml\snakeyaml\1.33\snakeyaml-1.33.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-json\3.1.4\spring-boot-starter-json-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-databind\2.15.2\jackson-databind-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-annotations\2.15.2\jackson-annotations-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-core\2.15.2\jackson-core-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.15.2\jackson-datatype-jdk8-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.15.2\jackson-datatype-jsr310-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\module\jackson-module-parameter-names\2.15.2\jackson-module-parameter-names-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-reactor-netty\3.1.4\spring-boot-starter-reactor-netty-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\netty\reactor-netty-http\1.1.11\reactor-netty-http-1.1.11.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-http\4.1.97.Final\netty-codec-http-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-http2\4.1.97.Final\netty-codec-http2-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns\4.1.97.Final\netty-resolver-dns-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-dns\4.1.97.Final\netty-codec-dns-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns-native-macos\4.1.97.Final\netty-resolver-dns-native-macos-4.1.97.Final-osx-x86_64.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns-classes-macos\4.1.97.Final\netty-resolver-dns-classes-macos-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final-linux-x86_64.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\netty\reactor-netty-core\1.1.11\reactor-netty-core-1.1.11.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-handler-proxy\4.1.97.Final\netty-handler-proxy-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-socks\4.1.97.Final\netty-codec-socks-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-web\6.0.12\spring-web-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-beans\6.0.12\spring-beans-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-webflux\6.0.12\spring-webflux-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\reactor-core\3.5.10\reactor-core-3.5.10.jar;C:\work\apache-maven-3.8.8\repo\org\reactivestreams\reactive-streams\1.0.4\reactive-streams-1.0.4.jar;C:\work\apache-maven-3.8.8\repo\com\google\guava\guava\19.0\guava-19.0.jar;C:\work\apache-maven-3.8.8\repo\commons-io\commons-io\2.11.0\commons-io-2.11.0.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-data-redis\3.1.4\spring-boot-starter-data-redis-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-redis\3.1.4\spring-data-redis-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-keyvalue\3.1.4\spring-data-keyvalue-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-oxm\6.0.12\spring-oxm-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-aop\6.0.12\spring-aop-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-context-support\6.0.12\spring-context-support-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\io\lettuce\lettuce-core\6.2.6.RELEASE\lettuce-core-6.2.6.RELEASE.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-common\4.1.97.Final\netty-common-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-handler\4.1.97.Final\netty-handler-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver\4.1.97.Final\netty-resolver-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-buffer\4.1.97.Final\netty-buffer-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-unix-common\4.1.97.Final\netty-transport-native-unix-common-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec\4.1.97.Final\netty-codec-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport\4.1.97.Final\netty-transport-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-data-jpa\3.1.4\spring-boot-starter-data-jpa-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-aop\3.1.4\spring-boot-starter-aop-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\aspectj\aspectjweaver\1.9.20\aspectjweaver-1.9.20.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-jdbc\3.1.4\spring-boot-starter-jdbc-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\zaxxer\HikariCP\5.0.1\HikariCP-5.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-jdbc\6.0.12\spring-jdbc-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\hibernate\orm\hibernate-core\6.2.9.Final\hibernate-core-6.2.9.Final.jar;C:\work\apache-maven-3.8.8\repo\jakarta\persistence\jakarta.persistence-api\3.1.0\jakarta.persistence-api-3.1.0.jar;C:\work\apache-maven-3.8.8\repo\jakarta\transaction\jakarta.transaction-api\2.0.1\jakarta.transaction-api-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\jboss\logging\jboss-logging\3.5.3.Final\jboss-logging-3.5.3.Final.jar;C:\work\apache-maven-3.8.8\repo\org\hibernate\common\hibernate-commons-annotations\6.0.6.Final\hibernate-commons-annotations-6.0.6.Final.jar;C:\work\apache-maven-3.8.8\repo\io\smallrye\jandex\3.0.5\jandex-3.0.5.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\classmate\1.5.1\classmate-1.5.1.jar;C:\work\apache-maven-3.8.8\repo\net\bytebuddy\byte-buddy\1.14.8\byte-buddy-1.14.8.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\jaxb-runtime\4.0.3\jaxb-runtime-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\jaxb-core\4.0.3\jaxb-core-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\eclipse\angus\angus-activation\2.0.1\angus-activation-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\txw2\4.0.3\txw2-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\com\sun\istack\istack-commons-runtime\4.1.2\istack-commons-runtime-4.1.2.jar;C:\work\apache-maven-3.8.8\repo\jakarta\inject\jakarta.inject-api\2.0.1\jakarta.inject-api-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\antlr\antlr4-runtime\4.10.1\antlr4-runtime-4.10.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-jpa\3.1.4\spring-data-jpa-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-commons\3.1.4\spring-data-commons-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-orm\6.0.12\spring-orm-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-aspects\6.0.12\spring-aspects-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\postgresql\postgresql\42.6.0\postgresql-42.6.0.jar;C:\work\apache-maven-3.8.8\repo\org\checkerframework\checker-qual\3.31.0\checker-qual-3.31.0.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\kafka\spring-kafka\3.0.11\spring-kafka-3.0.11.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-context\6.0.12\spring-context-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-expression\6.0.12\spring-expression-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-messaging\6.0.12\spring-messaging-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-tx\6.0.12\spring-tx-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\retry\spring-retry\2.0.3\spring-retry-2.0.3.jar;C:\work\apache-maven-3.8.8\repo\io\micrometer\micrometer-observation\1.11.4\micrometer-observation-1.11.4.jar;C:\work\apache-maven-3.8.8\repo\io\micrometer\micrometer-commons\1.11.4\micrometer-commons-1.11.4.jar;C:\work\apache-maven-3.8.8\repo\com\google\code\findbugs\jsr305\3.0.2\jsr305-3.0.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\com\github\luben\zstd-jni\1.5.2-1\zstd-jni-1.5.2-1.jar;C:\work\apache-maven-3.8.8\repo\org\lz4\lz4-java\1.8.0\lz4-java-1.8.0.jar;C:\work\apache-maven-3.8.8\repo\org\xerial\snappy\snappy-java\1.1.8.4\snappy-java-1.1.8.4.jar;C:\work\apache-maven-3.8.8\repo\org\slf4j\slf4j-api\2.0.9\slf4j-api-2.0.9.jar;C:\work\apache-maven-3.8.8\repo\com\h2database\h2\1.4.200\h2-1.4.200.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-test\3.1.4\spring-boot-starter-test-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-test\3.1.4\spring-boot-test-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-test-autoconfigure\3.1.4\spring-boot-test-autoconfigure-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\jayway\jsonpath\json-path\2.8.0\json-path-2.8.0.jar;C:\work\apache-maven-3.8.8\repo\jakarta\xml\bind\jakarta.xml.bind-api\4.0.1\jakarta.xml.bind-api-4.0.1.jar;C:\work\apache-maven-3.8.8\repo\jakarta\activation\jakarta.activation-api\2.1.2\jakarta.activation-api-2.1.2.jar;C:\work\apache-maven-3.8.8\repo\net\minidev\json-smart\2.4.11\json-smart-2.4.11.jar;C:\work\apache-maven-3.8.8\repo\net\minidev\accessors-smart\2.4.11\accessors-smart-2.4.11.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm\9.3\asm-9.3.jar;C:\work\apache-maven-3.8.8\repo\org\assertj\assertj-core\3.24.2\assertj-core-3.24.2.jar;C:\work\apache-maven-3.8.8\repo\org\hamcrest\hamcrest\2.2\hamcrest-2.2.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter\5.9.3\junit-jupiter-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-params\5.9.3\junit-jupiter-params-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-engine\5.9.3\junit-jupiter-engine-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\mockito\mockito-core\5.3.1\mockito-core-5.3.1.jar;C:\work\apache-maven-3.8.8\repo\net\bytebuddy\byte-buddy-agent\1.14.8\byte-buddy-agent-1.14.8.jar;C:\work\apache-maven-3.8.8\repo\org\objenesis\objenesis\3.3\objenesis-3.3.jar;C:\work\apache-maven-3.8.8\repo\org\mockito\mockito-junit-jupiter\5.3.1\mockito-junit-jupiter-5.3.1.jar;C:\work\apache-maven-3.8.8\repo\org\skyscreamer\jsonassert\1.5.1\jsonassert-1.5.1.jar;C:\work\apache-maven-3.8.8\repo\com\vaadin\external\google\android-json\0.0.20131108.vaadin1\android-json-0.0.20131108.vaadin1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-core\6.0.12\spring-core-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-jcl\6.0.12\spring-jcl-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-test\6.0.12\spring-test-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\xmlunit\xmlunit-core\2.9.1\xmlunit-core-2.9.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy\4.0.15\groovy-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-ant\4.0.15\groovy-ant-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant\1.10.14\ant-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-junit\1.10.14\ant-junit-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-launcher\1.10.14\ant-launcher-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-antlr\1.10.14\ant-antlr-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-cli-picocli\4.0.15\groovy-cli-picocli-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\info\picocli\picocli\4.7.5\picocli-4.7.5.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-console\4.0.15\groovy-console-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\github\javaparser\javaparser-core\3.25.5\javaparser-core-3.25.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-util\9.5\asm-util-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-tree\9.5\asm-tree-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-analysis\9.5\asm-analysis-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\abego\treelayout\org.abego.treelayout.core\1.0.3\org.abego.treelayout.core-1.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ivy\ivy\2.5.2\ivy-2.5.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-datetime\4.0.15\groovy-datetime-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-docgenerator\4.0.15\groovy-docgenerator-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\thoughtworks\qdox\qdox\1.12.1\qdox-1.12.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-groovydoc\4.0.15\groovy-groovydoc-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-groovysh\4.0.15\groovy-groovysh-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\jline\jline\2.14.6\jline-2.14.6.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-jmx\4.0.15\groovy-jmx-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-json\4.0.15\groovy-json-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-jsr223\4.0.15\groovy-jsr223-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-macro\4.0.15\groovy-macro-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-nio\4.0.15\groovy-nio-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-servlet\4.0.15\groovy-servlet-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-sql\4.0.15\groovy-sql-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-swing\4.0.15\groovy-swing-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-templates\4.0.15\groovy-templates-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-test\4.0.15\groovy-test-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\junit\junit\4.13.2\junit-4.13.2.jar;C:\work\apache-maven-3.8.8\repo\org\hamcrest\hamcrest-core\2.2\hamcrest-core-2.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-test-junit5\4.0.15\groovy-test-junit5-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-xml\4.0.15\groovy-xml-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-yaml\4.0.15\groovy-yaml-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\dataformat\jackson-dataformat-yaml\2.15.2\jackson-dataformat-yaml-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\org\spockframework\spock-core\2.4-M1-groovy-4.0\spock-core-2.4-M1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-engine\1.9.3\junit-platform-engine-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\opentest4j\opentest4j\1.2.0\opentest4j-1.2.0.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-commons\1.9.3\junit-platform-commons-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\apiguardian\apiguardian-api\1.1.2\apiguardian-api-1.1.2.jar;C:\work\apache-maven-3.8.8\repo\org\spockframework\spock-spring\2.4-M1-groovy-4.0\spock-spring-2.4-M1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\com\athaydes\spock-reports\2.5.1-groovy-4.0\spock-reports-2.5.1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\com\github\codemonstur\embedded-redis\1.4.2\embedded-redis-1.4.2.jar;C:\work\apache-maven-3.8.8\repo\redis\clients\jedis\4.3.2\jedis-4.3.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\commons\commons-pool2\2.11.1\commons-pool2-2.11.1.jar;C:\work\apache-maven-3.8.8\repo\org\json\json\20220320\json-20220320.jar;C:\work\apache-maven-3.8.8\repo\com\google\code\gson\gson\2.10.1\gson-2.10.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\kafka\spring-kafka-test\3.0.11\spring-kafka-test-3.0.11.jar;C:\work\apache-maven-3.8.8\repo\org\apache\zookeeper\zookeeper\3.6.3\zookeeper-3.6.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\zookeeper\zookeeper-jute\3.6.3\zookeeper-jute-3.6.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-classes-epoll\4.1.97.Final\netty-transport-classes-epoll-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1-test.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-metadata\3.4.1\kafka-metadata-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-server-common\3.4.1\kafka-server-common-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-raft\3.4.1\kafka-raft-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-streams-test-utils\3.4.1\kafka-streams-test-utils-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-streams\3.4.1\kafka-streams-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\rocksdb\rocksdbjni\7.1.2\rocksdbjni-7.1.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\scala-library\2.13.10\scala-library-2.13.10.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-group-coordinator\3.4.1\kafka-group-coordinator-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-storage\3.4.1\kafka-storage-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-storage-api\3.4.1\kafka-storage-api-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\net\sourceforge\argparse4j\argparse4j\0.7.0\argparse4j-0.7.0.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\module\jackson-module-scala_2.13\2.15.2\jackson-module-scala_2.13-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\thoughtworks\paranamer\paranamer\2.8\paranamer-2.8.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\dataformat\jackson-dataformat-csv\2.15.2\jackson-dataformat-csv-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\net\sf\jopt-simple\jopt-simple\5.0.4\jopt-simple-5.0.4.jar;C:\work\apache-maven-3.8.8\repo\org\bitbucket\b_c\jose4j\0.9.3\jose4j-0.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\modules\scala-collection-compat_2.13\2.10.0\scala-collection-compat_2.13-2.10.0.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\modules\scala-java8-compat_2.13\1.0.2\scala-java8-compat_2.13-1.0.2.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\scala-reflect\2.13.10\scala-reflect-2.13.10.jar;C:\work\apache-maven-3.8.8\repo\com\typesafe\scala-logging\scala-logging_2.13\3.9.4\scala-logging_2.13-3.9.4.jar;C:\work\apache-maven-3.8.8\repo\io\dropwizard\metrics\metrics-core\4.2.19\metrics-core-4.2.19.jar;C:\work\apache-maven-3.8.8\repo\commons-cli\commons-cli\1.4\commons-cli-1.4.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1-test.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-api\5.9.3\junit-jupiter-api-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-launcher\1.9.3\junit-platform-launcher-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\awaitility\awaitility\4.2.0\awaitility-4.2.0.jar;
2024-12-31 21:01:23.830 Client environment:java.library.path=C:\work\jdk-17\bin;C:\windows\Sun\Java\bin;C:\windows\system32;C:\windows;C:\work\python312\Scripts\;C:\work\python312\;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program\Git\cmd;C:\Program\PowerShell\7\;C:\Program Files\dotnet\;C:\Users\joech\AppData\Local\Microsoft\WindowsApps;C:\Users\joech\AppData\Local\GitHubDesktop\bin;C:\Program\Microsoft VS Code\bin;C:\work\apache-maven-3.8.8\bin;C:\Program Files\Tesseract-OCR;C:\work\jdk-17\bin;;.
2024-12-31 21:01:23.830 Client environment:java.io.tmpdir=C:\Users\joech\AppData\Local\Temp\
2024-12-31 21:01:23.830 Client environment:java.compiler=<NA>
2024-12-31 21:01:23.830 Client environment:os.name=Windows 11
2024-12-31 21:01:23.830 Client environment:os.arch=amd64
2024-12-31 21:01:23.830 Client environment:os.version=10.0
2024-12-31 21:01:23.830 Client environment:user.name=joech
2024-12-31 21:01:23.831 Client environment:user.home=C:\Users\joech
2024-12-31 21:01:23.831 Client environment:user.dir=C:\code\hsbc\demo\pong
2024-12-31 21:01:23.831 Client environment:os.memory.free=84MB
2024-12-31 21:01:23.831 Client environment:os.memory.max=15816MB
2024-12-31 21:01:23.831 Client environment:os.memory.total=136MB
2024-12-31 21:01:23.836 Initiating client connection, connectString=127.0.0.1:59323 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@72139933
2024-12-31 21:01:23.843 jute.maxbuffer value is 4194304 Bytes
2024-12-31 21:01:23.851 zookeeper.request.timeout value is 0. feature enabled=false
2024-12-31 21:01:23.852 [ZooKeeperClient Kafka server] Waiting until connected.
2024-12-31 21:01:23.853 Opening socket connection to server /127.0.0.1:59323.
2024-12-31 21:01:23.856 Socket connection established, initiating session, client: /127.0.0.1:59324, server: /127.0.0.1:59323
2024-12-31 21:01:23.865 Creating new log file: log.1
2024-12-31 21:01:23.878 ZooKeeper audit is disabled.
2024-12-31 21:01:23.882 Session establishment complete on server /127.0.0.1:59323, session id = 0x100176981860000, negotiated timeout = 16000
2024-12-31 21:01:23.888 [ZooKeeperClient Kafka server] Connected.
2024-12-31 21:01:24.353 Cluster ID = GNRQBkKdS0uklp-lPgX4ew
2024-12-31 21:01:24.358 No meta.properties file under dir C:\Users\joech\AppData\Local\Temp\spring.kafka.ec524e2d-dbef-471d-ac43-d3e355abcc851781581959491201383\meta.properties
2024-12-31 21:01:24.426 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.ec524e2d-dbef-471d-ac43-d3e355abcc851781581959491201383
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59323
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:01:24.468 [ThrottledChannelReaper-Fetch]: Starting
2024-12-31 21:01:24.468 [ThrottledChannelReaper-Produce]: Starting
2024-12-31 21:01:24.469 [ThrottledChannelReaper-Request]: Starting
2024-12-31 21:01:24.473 [ThrottledChannelReaper-ControllerMutation]: Starting
2024-12-31 21:01:24.517 Loading logs from log dirs ArraySeq(C:\Users\joech\AppData\Local\Temp\spring.kafka.ec524e2d-dbef-471d-ac43-d3e355abcc851781581959491201383)
2024-12-31 21:01:24.521 Attempting recovery for all logs in C:\Users\joech\AppData\Local\Temp\spring.kafka.ec524e2d-dbef-471d-ac43-d3e355abcc851781581959491201383 since no clean shutdown file was found
2024-12-31 21:01:24.533 Loaded 0 logs in 16ms.
2024-12-31 21:01:24.534 Starting log cleanup with a period of 300000 ms.
2024-12-31 21:01:24.537 Starting log flusher with a default period of 9223372036854775807 ms.
2024-12-31 21:01:24.554 Starting the log cleaner
2024-12-31 21:01:24.567 [kafka-log-cleaner-thread-0]: Starting
2024-12-31 21:01:24.589 [feature-zk-node-event-process-thread]: Starting
2024-12-31 21:01:24.604 Feature ZK node at path: /feature does not exist
2024-12-31 21:01:24.646 [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting
2024-12-31 21:01:25.164 Updated connection-accept-rate max connection creation rate to 2147483647
2024-12-31 21:01:25.177 Awaiting socket connections on localhost:59325.
2024-12-31 21:01:25.215 [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT)
2024-12-31 21:01:25.227 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Starting
2024-12-31 21:01:25.253 [ExpirationReaper-0-Produce]: Starting
2024-12-31 21:01:25.254 [ExpirationReaper-0-Fetch]: Starting
2024-12-31 21:01:25.255 [ExpirationReaper-0-DeleteRecords]: Starting
2024-12-31 21:01:25.256 [ExpirationReaper-0-ElectLeader]: Starting
2024-12-31 21:01:25.274 [LogDirFailureHandler]: Starting
2024-12-31 21:01:25.300 Creating /brokers/ids/0 (is it secure? false)
2024-12-31 21:01:25.326 Stat of the created znode at /brokers/ids/0 is: 25,25,1735650085315,1735650085315,1,0,0,72083335949975552,204,0,25

2024-12-31 21:01:25.327 Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:59325, czxid (broker epoch): 25
2024-12-31 21:01:25.413 [ControllerEventThread controllerId=0] Starting
2024-12-31 21:01:25.419 [ExpirationReaper-0-topic]: Starting
2024-12-31 21:01:25.430 [ExpirationReaper-0-Heartbeat]: Starting
2024-12-31 21:01:25.431 [ExpirationReaper-0-Rebalance]: Starting
2024-12-31 21:01:25.439 Successfully created /controller_epoch with initial epoch 0
2024-12-31 21:01:25.447 [Controller id=0] 0 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1
2024-12-31 21:01:25.453 [Controller id=0] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map())
2024-12-31 21:01:25.457 Feature ZK node created at path: /feature
2024-12-31 21:01:25.459 [GroupCoordinator 0]: Starting up.
2024-12-31 21:01:25.466 [GroupCoordinator 0]: Startup complete.
2024-12-31 21:01:25.495 [TransactionCoordinator id=0] Starting up.
2024-12-31 21:01:25.501 [Transaction Marker Channel Manager 0]: Starting
2024-12-31 21:01:25.500 [TransactionCoordinator id=0] Startup complete.
2024-12-31 21:01:25.503 [Controller id=0] Registering handlers
2024-12-31 21:01:25.504 [MetadataCache brokerId=0] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0).
2024-12-31 21:01:25.508 [Controller id=0] Deleting log dir event notifications
2024-12-31 21:01:25.511 [Controller id=0] Deleting isr change notifications
2024-12-31 21:01:25.513 [Controller id=0] Initializing controller context
2024-12-31 21:01:25.533 [Controller id=0] Initialized broker epochs cache: HashMap(0 -> 25)
2024-12-31 21:01:25.545 [ExpirationReaper-0-AlterAcls]: Starting
2024-12-31 21:01:25.552 [RequestSendThread controllerId=0] Starting
2024-12-31 21:01:25.554 [Controller id=0] Currently active brokers in the cluster: Set(0)
2024-12-31 21:01:25.554 [Controller id=0] Currently shutting brokers in the cluster: HashSet()
2024-12-31 21:01:25.555 [Controller id=0] Current list of topics in the cluster: HashSet()
2024-12-31 21:01:25.555 [Controller id=0] Fetching topic deletions in progress
2024-12-31 21:01:25.558 [Controller id=0] List of topics to be deleted: 
2024-12-31 21:01:25.558 [Controller id=0] List of topics ineligible for deletion: 
2024-12-31 21:01:25.559 [Controller id=0] Initializing topic deletion manager
2024-12-31 21:01:25.559 [Topic Deletion Manager 0] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet()
2024-12-31 21:01:25.562 [Controller id=0] Sending update metadata request
2024-12-31 21:01:25.566 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions
2024-12-31 21:01:25.577 [ReplicaStateMachine controllerId=0] Initializing replica state
2024-12-31 21:01:25.578 [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2024-12-31 21:01:25.584 [ReplicaStateMachine controllerId=0] Triggering offline replica state changes
2024-12-31 21:01:25.585 [PartitionStateMachine controllerId=0] Initializing partition state
2024-12-31 21:01:25.586 [PartitionStateMachine controllerId=0] Triggering online partition state changes
2024-12-31 21:01:25.586 [/config/changes-event-process-thread]: Starting
2024-12-31 21:01:25.589 [RequestSendThread controllerId=0] Controller 0 connected to localhost:59325 (id: 0 rack: null) for sending state change requests
2024-12-31 21:01:25.590 [Controller id=0] Ready to serve as the new controller with epoch 1
2024-12-31 21:01:25.596 [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing.
2024-12-31 21:01:25.598 [Controller id=0] Partitions undergoing preferred replica election: 
2024-12-31 21:01:25.598 [Controller id=0] Partitions that completed preferred replica election: 
2024-12-31 21:01:25.599 [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2024-12-31 21:01:25.599 [Controller id=0] Resuming preferred replica election for partitions: 
2024-12-31 21:01:25.600 [Controller id=0] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered
2024-12-31 21:01:25.602 Kafka version: 3.4.1
2024-12-31 21:01:25.602 Kafka commitId: 8a516edc2755df89
2024-12-31 21:01:25.602 Kafka startTimeMs: 1735650085600
2024-12-31 21:01:25.603 [KafkaServer id=0] started
2024-12-31 21:01:25.610 AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [127.0.0.1:59325]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-31 21:01:25.613 [Controller id=0] Starting the controller scheduler
2024-12-31 21:01:25.650 Kafka version: 3.4.1
2024-12-31 21:01:25.650 Kafka commitId: 8a516edc2755df89
2024-12-31 21:01:25.651 Kafka startTimeMs: 1735650085650
2024-12-31 21:01:25.661 [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use node localhost:59325 (id: 0 rack: null)
2024-12-31 21:01:25.729 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Recorded new controller, from now on will use node localhost:59325 (id: 0 rack: null)
2024-12-31 21:01:25.754 Creating topic pong-message-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0))
2024-12-31 21:01:25.774 [Controller id=0] New topics: [Set(pong-message-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(pong-message-topic,Some(bkreKMhATjWbLBJmX1gFPQ),Map(pong-message-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), pong-message-topic-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:01:25.775 [Controller id=0] New partition creation callback for pong-message-topic-0,pong-message-topic-1
2024-12-31 21:01:25.777 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:01:25.779 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:01:25.779 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:01:25.782 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:01:25.805 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:01:25.805 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:01:25.806 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2024-12-31 21:01:25.808 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2024-12-31 21:01:25.809 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:01:25.813 [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 for 2 partitions
2024-12-31 21:01:25.844 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(pong-message-topic-0, pong-message-topic-1)
2024-12-31 21:01:25.847 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2024-12-31 21:01:25.932 [LogLoader partition=pong-message-topic-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.ec524e2d-dbef-471d-ac43-d3e355abcc851781581959491201383] Loading producer state till offset 0 with message format version 2
2024-12-31 21:01:25.947 Created log for partition pong-message-topic-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.ec524e2d-dbef-471d-ac43-d3e355abcc851781581959491201383\pong-message-topic-0 with properties {}
2024-12-31 21:01:25.948 [Partition pong-message-topic-0 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-0
2024-12-31 21:01:25.949 [Partition pong-message-topic-0 broker=0] Log loaded for partition pong-message-topic-0 with initial high watermark 0
2024-12-31 21:01:25.950 [Broker id=0] Leader pong-message-topic-0 with topic id Some(bkreKMhATjWbLBJmX1gFPQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:01:25.961 [LogLoader partition=pong-message-topic-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.ec524e2d-dbef-471d-ac43-d3e355abcc851781581959491201383] Loading producer state till offset 0 with message format version 2
2024-12-31 21:01:25.962 Created log for partition pong-message-topic-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.ec524e2d-dbef-471d-ac43-d3e355abcc851781581959491201383\pong-message-topic-1 with properties {}
2024-12-31 21:01:25.962 [Partition pong-message-topic-1 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-1
2024-12-31 21:01:25.962 [Partition pong-message-topic-1 broker=0] Log loaded for partition pong-message-topic-1 with initial high watermark 0
2024-12-31 21:01:25.964 [Broker id=0] Leader pong-message-topic-1 with topic id Some(bkreKMhATjWbLBJmX1gFPQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:01:25.971 [Broker id=0] Finished LeaderAndIsr request in 161ms correlationId 1 from controller 0 for 2 partitions
2024-12-31 21:01:25.978 [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2
2024-12-31 21:01:25.984 App info kafka.admin.client for adminclient-1 unregistered
2024-12-31 21:01:25.988 Metrics scheduler closed
2024-12-31 21:01:25.988 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:01:25.988 Metrics reporters closed
2024-12-31 21:01:26.308 

Found multiple occurrences of org.json.JSONObject on the class path:

	jar:file:/C:/work/apache-maven-3.8.8/repo/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar!/org/json/JSONObject.class
	jar:file:/C:/work/apache-maven-3.8.8/repo/org/json/json/20220320/json-20220320.jar!/org/json/JSONObject.class

You may wish to exclude one of them to ensure predictable runtime behavior

2024-12-31 21:01:26.323 zookeeper.snapshot.trust.empty : false
2024-12-31 21:01:26.324 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:01:26.324 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:01:26.324 zookeeper.snapshotSizeFactor = 0.33
2024-12-31 21:01:26.324 zookeeper.commitLogCount=500
2024-12-31 21:01:26.324 minSessionTimeout set to 1600
2024-12-31 21:01:26.324 maxSessionTimeout set to 16000
2024-12-31 21:01:26.324 Response cache size is initialized with value 400.
2024-12-31 21:01:26.325 Response cache size is initialized with value 400.
2024-12-31 21:01:26.325 zookeeper.pathStats.slotCapacity = 60
2024-12-31 21:01:26.325 zookeeper.pathStats.slotDuration = 15
2024-12-31 21:01:26.325 zookeeper.pathStats.maxDepth = 6
2024-12-31 21:01:26.325 zookeeper.pathStats.initialDelay = 5
2024-12-31 21:01:26.325 zookeeper.pathStats.delay = 5
2024-12-31 21:01:26.325 zookeeper.pathStats.enabled = false
2024-12-31 21:01:26.325 The max bytes for all large requests are set to 104857600
2024-12-31 21:01:26.325 The large request threshold is set to -1
2024-12-31 21:01:26.325 Created server with tickTime 800 minSessionTimeout 1600 maxSessionTimeout 16000 clientPortListenBacklog -1 datadir C:\Users\joech\AppData\Local\Temp\kafka-9700927980914091392\version-2 snapdir C:\Users\joech\AppData\Local\Temp\kafka-18297339401436143376\version-2
2024-12-31 21:01:26.325 maxCnxns is not configured, using default value 0.
2024-12-31 21:01:26.325 Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers.
2024-12-31 21:01:26.328 binding to port /127.0.0.1:0
2024-12-31 21:01:26.330 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-18297339401436143376\version-2\snapshot.0
2024-12-31 21:01:26.330 Snapshot loaded in 1 ms, highest zxid is 0x0, digest is 1371985504
2024-12-31 21:01:26.330 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-18297339401436143376\version-2\snapshot.0
2024-12-31 21:01:26.332 Snapshot taken in 0 ms
2024-12-31 21:01:26.332 PrepRequestProcessor (sid:0) started, reconfigEnabled=false
2024-12-31 21:01:26.334 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.16b09487-492e-47e3-8377-3ca56ec70503660252083721109126
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59329
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:01:26.338 starting
2024-12-31 21:01:26.338 Connecting to zookeeper on 127.0.0.1:59329
2024-12-31 21:01:26.338 [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:59329.
2024-12-31 21:01:26.338 Initiating client connection, connectString=127.0.0.1:59329 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4e0f805c
2024-12-31 21:01:26.341 jute.maxbuffer value is 4194304 Bytes
2024-12-31 21:01:26.341 zookeeper.request.timeout value is 0. feature enabled=false
2024-12-31 21:01:26.341 [ZooKeeperClient Kafka server] Waiting until connected.
2024-12-31 21:01:26.341 Opening socket connection to server /127.0.0.1:59329.
2024-12-31 21:01:26.341 Socket connection established, initiating session, client: /127.0.0.1:59330, server: /127.0.0.1:59329
2024-12-31 21:01:26.342 Creating new log file: log.1
2024-12-31 21:01:26.349 Session establishment complete on server /127.0.0.1:59329, session id = 0x1001769a27b0000, negotiated timeout = 16000
2024-12-31 21:01:26.349 [ZooKeeperClient Kafka server] Connected.
2024-12-31 21:01:26.379 Cluster ID = 52zN14B9SqOycPBKupPq7A
2024-12-31 21:01:26.380 No meta.properties file under dir C:\Users\joech\AppData\Local\Temp\spring.kafka.16b09487-492e-47e3-8377-3ca56ec70503660252083721109126\meta.properties
2024-12-31 21:01:26.388 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.16b09487-492e-47e3-8377-3ca56ec70503660252083721109126
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59329
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:01:26.400 [ThrottledChannelReaper-Produce]: Starting
2024-12-31 21:01:26.400 [ThrottledChannelReaper-Fetch]: Starting
2024-12-31 21:01:26.400 [ThrottledChannelReaper-Request]: Starting
2024-12-31 21:01:26.401 [ThrottledChannelReaper-ControllerMutation]: Starting
2024-12-31 21:01:26.410 Loading logs from log dirs ArraySeq(C:\Users\joech\AppData\Local\Temp\spring.kafka.16b09487-492e-47e3-8377-3ca56ec70503660252083721109126)
2024-12-31 21:01:26.410 Attempting recovery for all logs in C:\Users\joech\AppData\Local\Temp\spring.kafka.16b09487-492e-47e3-8377-3ca56ec70503660252083721109126 since no clean shutdown file was found
2024-12-31 21:01:26.412 Loaded 0 logs in 2ms.
2024-12-31 21:01:26.412 Starting log cleanup with a period of 300000 ms.
2024-12-31 21:01:26.412 Starting log flusher with a default period of 9223372036854775807 ms.
2024-12-31 21:01:26.413 Starting the log cleaner
2024-12-31 21:01:26.415 [kafka-log-cleaner-thread-0]: Starting
2024-12-31 21:01:26.415 [feature-zk-node-event-process-thread]: Starting
2024-12-31 21:01:26.417 Feature ZK node at path: /feature does not exist
2024-12-31 21:01:26.419 [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting
2024-12-31 21:01:26.434 Updated connection-accept-rate max connection creation rate to 2147483647
2024-12-31 21:01:26.436 Awaiting socket connections on localhost:59331.
2024-12-31 21:01:26.443 [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT)
2024-12-31 21:01:26.444 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Starting
2024-12-31 21:01:26.446 [ExpirationReaper-0-Produce]: Starting
2024-12-31 21:01:26.446 [ExpirationReaper-0-Fetch]: Starting
2024-12-31 21:01:26.447 [ExpirationReaper-0-DeleteRecords]: Starting
2024-12-31 21:01:26.447 [ExpirationReaper-0-ElectLeader]: Starting
2024-12-31 21:01:26.449 [LogDirFailureHandler]: Starting
2024-12-31 21:01:26.451 Creating /brokers/ids/0 (is it secure? false)
2024-12-31 21:01:26.455 Stat of the created znode at /brokers/ids/0 is: 25,25,1735650086452,1735650086452,1,0,0,72083336502902784,204,0,25

2024-12-31 21:01:26.455 Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:59331, czxid (broker epoch): 25
2024-12-31 21:01:26.463 [ControllerEventThread controllerId=0] Starting
2024-12-31 21:01:26.464 [ExpirationReaper-0-topic]: Starting
2024-12-31 21:01:26.464 [ExpirationReaper-0-Heartbeat]: Starting
2024-12-31 21:01:26.464 [ExpirationReaper-0-Rebalance]: Starting
2024-12-31 21:01:26.465 [GroupCoordinator 0]: Starting up.
2024-12-31 21:01:26.467 [GroupCoordinator 0]: Startup complete.
2024-12-31 21:01:26.467 Successfully created /controller_epoch with initial epoch 0
2024-12-31 21:01:26.469 [TransactionCoordinator id=0] Starting up.
2024-12-31 21:01:26.469 [Controller id=0] 0 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1
2024-12-31 21:01:26.469 [Controller id=0] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map())
2024-12-31 21:01:26.469 [TransactionCoordinator id=0] Startup complete.
2024-12-31 21:01:26.471 [Transaction Marker Channel Manager 0]: Starting
2024-12-31 21:01:26.471 [ExpirationReaper-0-AlterAcls]: Starting
2024-12-31 21:01:26.471 Feature ZK node created at path: /feature
2024-12-31 21:01:26.472 [MetadataCache brokerId=0] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0).
2024-12-31 21:01:26.472 [Controller id=0] Registering handlers
2024-12-31 21:01:26.474 [Controller id=0] Deleting log dir event notifications
2024-12-31 21:01:26.475 [/config/changes-event-process-thread]: Starting
2024-12-31 21:01:26.475 [Controller id=0] Deleting isr change notifications
2024-12-31 21:01:26.476 [Controller id=0] Initializing controller context
2024-12-31 21:01:26.479 [Controller id=0] Initialized broker epochs cache: HashMap(0 -> 25)
2024-12-31 21:01:26.480 [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing.
2024-12-31 21:01:26.481 Kafka version: 3.4.1
2024-12-31 21:01:26.481 Kafka commitId: 8a516edc2755df89
2024-12-31 21:01:26.481 Kafka startTimeMs: 1735650086481
2024-12-31 21:01:26.484 [RequestSendThread controllerId=0] Starting
2024-12-31 21:01:26.484 [Controller id=0] Currently active brokers in the cluster: Set(0)
2024-12-31 21:01:26.484 [Controller id=0] Currently shutting brokers in the cluster: HashSet()
2024-12-31 21:01:26.484 [Controller id=0] Current list of topics in the cluster: HashSet()
2024-12-31 21:01:26.484 [Controller id=0] Fetching topic deletions in progress
2024-12-31 21:01:26.486 [Controller id=0] List of topics to be deleted: 
2024-12-31 21:01:26.486 [Controller id=0] List of topics ineligible for deletion: 
2024-12-31 21:01:26.486 [Controller id=0] Initializing topic deletion manager
2024-12-31 21:01:26.486 [Topic Deletion Manager 0] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet()
2024-12-31 21:01:26.486 [Controller id=0] Sending update metadata request
2024-12-31 21:01:26.486 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions
2024-12-31 21:01:26.486 [ReplicaStateMachine controllerId=0] Initializing replica state
2024-12-31 21:01:26.486 [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2024-12-31 21:01:26.486 [ReplicaStateMachine controllerId=0] Triggering offline replica state changes
2024-12-31 21:01:26.486 [PartitionStateMachine controllerId=0] Initializing partition state
2024-12-31 21:01:26.486 [PartitionStateMachine controllerId=0] Triggering online partition state changes
2024-12-31 21:01:26.486 [Controller id=0] Ready to serve as the new controller with epoch 1
2024-12-31 21:01:26.481 Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.server:type=app-info,id=0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1865)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:960)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:895)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:523)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:563)
	at kafka.utils.TestUtils$.createServer(TestUtils.scala:188)
	at kafka.utils.TestUtils$.createServer(TestUtils.scala:182)
	at kafka.utils.TestUtils.createServer(TestUtils.scala)
	at org.springframework.kafka.test.EmbeddedKafkaBroker.afterPropertiesSet(EmbeddedKafkaBroker.java:369)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1817)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1766)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:410)
	at org.springframework.kafka.test.context.EmbeddedKafkaContextCustomizer.customizeContext(EmbeddedKafkaContextCustomizer.java:116)
	at org.springframework.boot.test.context.SpringBootContextLoader$ContextCustomizerAdapter.initialize(SpringBootContextLoader.java:435)
	at org.springframework.boot.SpringApplication.applyInitializers(SpringApplication.java:610)
	at org.springframework.boot.SpringApplication.prepareContext(SpringApplication.java:390)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:314)
	at org.springframework.boot.test.context.SpringBootContextLoader.lambda$loadContext$3(SpringBootContextLoader.java:137)
	at org.springframework.util.function.ThrowingSupplier.get(ThrowingSupplier.java:58)
	at org.springframework.util.function.ThrowingSupplier.get(ThrowingSupplier.java:46)
	at org.springframework.boot.SpringApplication.withHook(SpringApplication.java:1409)
	at org.springframework.boot.test.context.SpringBootContextLoader$ContextLoaderHook.run(SpringBootContextLoader.java:545)
	at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:137)
	at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:108)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:187)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:119)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:127)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:141)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:97)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:241)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:56)
	at org.spockframework.spring.SpringInterceptor.interceptInitializerMethod(SpringInterceptor.java:46)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:24)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:101)
	at org.spockframework.runtime.PlatformSpecRunner.invoke(PlatformSpecRunner.java:398)
	at org.spockframework.runtime.PlatformSpecRunner.runInitializer(PlatformSpecRunner.java:259)
	at org.spockframework.runtime.PlatformSpecRunner.runInitializer(PlatformSpecRunner.java:254)
	at org.spockframework.runtime.IterationNode.prepare(IterationNode.java:31)
	at org.spockframework.runtime.IterationNode.prepare(IterationNode.java:13)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$prepare$2(NodeTestTask.java:123)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.prepare(NodeTestTask.java:123)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:90)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:226)
	at org.spockframework.runtime.ParameterizedFeatureChildExecutor.execute(ParameterizedFeatureChildExecutor.java:104)
	at org.spockframework.runtime.PlatformParameterizedSpecRunner$1.runIteration(PlatformParameterizedSpecRunner.java:72)
	at org.spockframework.runtime.extension.IDataDriver.lambda$static$0(IDataDriver.java:37)
	at org.spockframework.runtime.PlatformParameterizedSpecRunner.runParameterizedFeature(PlatformParameterizedSpecRunner.java:47)
	at org.spockframework.runtime.ParameterizedFeatureNode.execute(ParameterizedFeatureNode.java:40)
	at org.spockframework.runtime.ParameterizedFeatureNode.execute(ParameterizedFeatureNode.java:16)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.spockframework.runtime.SpockNode.sneakyInvoke(SpockNode.java:40)
	at org.spockframework.runtime.FeatureNode.lambda$around$0(FeatureNode.java:41)
	at org.spockframework.runtime.PlatformSpecRunner.lambda$createMethodInfoForDoRunFeature$4(PlatformSpecRunner.java:199)
	at org.spockframework.runtime.model.MethodInfo.invoke(MethodInfo.java:156)
	at org.spockframework.runtime.PlatformSpecRunner.invokeRaw(PlatformSpecRunner.java:407)
	at org.spockframework.runtime.PlatformSpecRunner.invoke(PlatformSpecRunner.java:390)
	at org.spockframework.runtime.PlatformSpecRunner.runFeature(PlatformSpecRunner.java:192)
	at org.spockframework.runtime.FeatureNode.around(FeatureNode.java:41)
	at org.spockframework.runtime.FeatureNode.around(FeatureNode.java:12)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1511)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.spockframework.runtime.SpockNode.sneakyInvoke(SpockNode.java:40)
	at org.spockframework.runtime.SpecNode.lambda$around$0(SpecNode.java:63)
	at org.spockframework.runtime.PlatformSpecRunner.lambda$createMethodInfoForDoRunSpec$0(PlatformSpecRunner.java:61)
	at org.spockframework.runtime.model.MethodInfo.invoke(MethodInfo.java:156)
	at org.spockframework.runtime.PlatformSpecRunner.invokeRaw(PlatformSpecRunner.java:407)
	at org.spockframework.runtime.PlatformSpecRunner.invoke(PlatformSpecRunner.java:390)
	at org.spockframework.runtime.PlatformSpecRunner.runSpec(PlatformSpecRunner.java:55)
	at org.spockframework.runtime.SpecNode.around(SpecNode.java:63)
	at org.spockframework.runtime.SpecNode.around(SpecNode.java:11)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1511)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:147)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:127)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:90)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:55)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:102)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:150)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2024-12-31 21:01:26.488 [KafkaServer id=0] started
2024-12-31 21:01:26.488 [RequestSendThread controllerId=0] Controller 0 connected to localhost:59331 (id: 0 rack: null) for sending state change requests
2024-12-31 21:01:26.489 AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [127.0.0.1:59331]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-31 21:01:26.489 [Controller id=0] Partitions undergoing preferred replica election: 
2024-12-31 21:01:26.489 [Controller id=0] Partitions that completed preferred replica election: 
2024-12-31 21:01:26.489 [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2024-12-31 21:01:26.489 [Controller id=0] Resuming preferred replica election for partitions: 
2024-12-31 21:01:26.489 [Controller id=0] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered
2024-12-31 21:01:26.491 [Controller id=0] Starting the controller scheduler
2024-12-31 21:01:26.492 Kafka version: 3.4.1
2024-12-31 21:01:26.492 Kafka commitId: 8a516edc2755df89
2024-12-31 21:01:26.492 Kafka startTimeMs: 1735650086492
2024-12-31 21:01:26.505 Creating topic pong-message-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2024-12-31 21:01:26.511 [Controller id=0] New topics: [Set(pong-message-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(pong-message-topic,Some(1FhysHYXSmmWO7-LZexYdg),Map(pong-message-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:01:26.511 [Controller id=0] New partition creation callback for pong-message-topic-0
2024-12-31 21:01:26.511 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:01:26.511 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:01:26.511 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:01:26.516 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:01:26.516 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions
2024-12-31 21:01:26.516 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 1 partitions
2024-12-31 21:01:26.517 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:01:26.517 [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 for 1 partitions
2024-12-31 21:01:26.518 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(pong-message-topic-0)
2024-12-31 21:01:26.518 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions
2024-12-31 21:01:26.520 [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use node localhost:59331 (id: 0 rack: null)
2024-12-31 21:01:26.528 [LogLoader partition=pong-message-topic-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.16b09487-492e-47e3-8377-3ca56ec70503660252083721109126] Loading producer state till offset 0 with message format version 2
2024-12-31 21:01:26.529 Created log for partition pong-message-topic-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.16b09487-492e-47e3-8377-3ca56ec70503660252083721109126\pong-message-topic-0 with properties {}
2024-12-31 21:01:26.529 [Partition pong-message-topic-0 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-0
2024-12-31 21:01:26.529 [Partition pong-message-topic-0 broker=0] Log loaded for partition pong-message-topic-0 with initial high watermark 0
2024-12-31 21:01:26.529 [Broker id=0] Leader pong-message-topic-0 with topic id Some(1FhysHYXSmmWO7-LZexYdg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:01:26.534 [Broker id=0] Finished LeaderAndIsr request in 16ms correlationId 1 from controller 0 for 1 partitions
2024-12-31 21:01:26.535 [Broker id=0] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2
2024-12-31 21:01:26.537 App info kafka.admin.client for adminclient-2 unregistered
2024-12-31 21:01:26.538 Metrics scheduler closed
2024-12-31 21:01:26.538 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:01:26.538 Metrics reporters closed
2024-12-31 21:01:26.547 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Recorded new controller, from now on will use node localhost:59331 (id: 0 rack: null)
2024-12-31 21:01:26.547 Starting PongControllerSpec using Java 17.0.12 with PID 392 (started by joech in C:\code\hsbc\demo\pong)
2024-12-31 21:01:26.548 No active profile set, falling back to 1 default profile: "default"
2024-12-31 21:01:27.179 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:01:27.182 Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2024-12-31 21:01:27.324 Finished Spring Data repository scanning in 131 ms. Found 1 JPA repository interfaces.
2024-12-31 21:01:27.350 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:01:27.351 Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2024-12-31 21:01:27.370 Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.demo.dao.MessageRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2024-12-31 21:01:27.370 Finished Spring Data repository scanning in 7 ms. Found 0 Redis repository interfaces.
2024-12-31 21:01:28.095 HHH000204: Processing PersistenceUnitInfo [name: default]
2024-12-31 21:01:28.171 HHH000412: Hibernate ORM core version 6.2.9.Final
2024-12-31 21:01:28.176 HHH000406: Using bytecode reflection optimizer
2024-12-31 21:01:28.352 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:01:28.546 No LoadTimeWeaver setup: ignoring JPA class transformer
2024-12-31 21:01:28.573 HikariPool-1 - Starting...
2024-12-31 21:01:28.890 HikariPool-1 - Added connection conn0: url=jdbc:h2:mem:testdb user=SA
2024-12-31 21:01:28.893 HikariPool-1 - Start completed.
2024-12-31 21:01:29.250 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:01:30.012 HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2024-12-31 21:01:30.104 Initialized JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:01:30.615 [Controller id=0] Processing automatic preferred replica leader election
2024-12-31 21:01:31.489 Netty started on port 59335
2024-12-31 21:01:31.491 [Controller id=0] Processing automatic preferred replica leader election
2024-12-31 21:01:31.525 ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:59325]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-pong-service-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = pong-service
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2024-12-31 21:01:31.570 These configurations '[spring.json.trusted.packages]' were supplied but are not used yet.
2024-12-31 21:01:31.570 Kafka version: 3.4.1
2024-12-31 21:01:31.570 Kafka commitId: 8a516edc2755df89
2024-12-31 21:01:31.570 Kafka startTimeMs: 1735650091570
2024-12-31 21:01:31.572 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Subscribed to topic(s): pong-message-topic
2024-12-31 21:01:31.590 Started PongControllerSpec in 5.536 seconds (process running for 22.159)
2024-12-31 21:01:31.602 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting the last seen epoch of partition pong-message-topic-0 to 0 since the associated topicId changed from null to bkreKMhATjWbLBJmX1gFPQ
2024-12-31 21:01:31.602 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting the last seen epoch of partition pong-message-topic-1 to 0 since the associated topicId changed from null to bkreKMhATjWbLBJmX1gFPQ
2024-12-31 21:01:31.604 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Cluster ID: GNRQBkKdS0uklp-lPgX4ew
2024-12-31 21:01:31.605 Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0))
2024-12-31 21:01:31.611 [Controller id=0] New topics: [Set(__consumer_offsets)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(__consumer_offsets,Some(oiZBuCgRQ8yspEwYv_MUQg),HashMap(__consumer_offsets-4 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-3 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-2 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:01:31.611 [Controller id=0] New partition creation callback for __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2024-12-31 21:01:31.611 [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:01:31.611 [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:01:31.611 [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:01:31.611 [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:01:31.611 [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:01:31.611 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:01:31.612 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:01:31.620 [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:01:31.620 [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:01:31.621 [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:01:31.621 [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:01:31.621 [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:01:31.621 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 5 become-leader and 0 become-follower partitions
2024-12-31 21:01:31.621 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 5 partitions
2024-12-31 21:01:31.621 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:01:31.622 [Broker id=0] Handling LeaderAndIsr request correlationId 3 from controller 0 for 5 partitions
2024-12-31 21:01:31.624 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-4, __consumer_offsets-3, __consumer_offsets-2, __consumer_offsets-0, __consumer_offsets-1)
2024-12-31 21:01:31.624 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 3 from controller 0 epoch 1 as part of the become-leader transition for 5 partitions
2024-12-31 21:01:31.635 [LogLoader partition=__consumer_offsets-3, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.ec524e2d-dbef-471d-ac43-d3e355abcc851781581959491201383] Loading producer state till offset 0 with message format version 2
2024-12-31 21:01:31.636 Created log for partition __consumer_offsets-3 in C:\Users\joech\AppData\Local\Temp\spring.kafka.ec524e2d-dbef-471d-ac43-d3e355abcc851781581959491201383\__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:01:31.647 [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
2024-12-31 21:01:31.648 [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0
2024-12-31 21:01:31.648 [Broker id=0] Leader __consumer_offsets-3 with topic id Some(oiZBuCgRQ8yspEwYv_MUQg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:01:31.656 [LogLoader partition=__consumer_offsets-2, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.ec524e2d-dbef-471d-ac43-d3e355abcc851781581959491201383] Loading producer state till offset 0 with message format version 2
2024-12-31 21:01:31.657 Created log for partition __consumer_offsets-2 in C:\Users\joech\AppData\Local\Temp\spring.kafka.ec524e2d-dbef-471d-ac43-d3e355abcc851781581959491201383\__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:01:31.657 [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
2024-12-31 21:01:31.657 [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0
2024-12-31 21:01:31.657 [Broker id=0] Leader __consumer_offsets-2 with topic id Some(oiZBuCgRQ8yspEwYv_MUQg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:01:31.666 [LogLoader partition=__consumer_offsets-4, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.ec524e2d-dbef-471d-ac43-d3e355abcc851781581959491201383] Loading producer state till offset 0 with message format version 2
2024-12-31 21:01:31.667 Created log for partition __consumer_offsets-4 in C:\Users\joech\AppData\Local\Temp\spring.kafka.ec524e2d-dbef-471d-ac43-d3e355abcc851781581959491201383\__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:01:31.667 [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
2024-12-31 21:01:31.667 [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0
2024-12-31 21:01:31.667 [Broker id=0] Leader __consumer_offsets-4 with topic id Some(oiZBuCgRQ8yspEwYv_MUQg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:01:31.675 [LogLoader partition=__consumer_offsets-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.ec524e2d-dbef-471d-ac43-d3e355abcc851781581959491201383] Loading producer state till offset 0 with message format version 2
2024-12-31 21:01:31.676 Created log for partition __consumer_offsets-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.ec524e2d-dbef-471d-ac43-d3e355abcc851781581959491201383\__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:01:31.677 [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
2024-12-31 21:01:31.677 [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0
2024-12-31 21:01:31.677 [Broker id=0] Leader __consumer_offsets-1 with topic id Some(oiZBuCgRQ8yspEwYv_MUQg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:01:31.686 [LogLoader partition=__consumer_offsets-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.ec524e2d-dbef-471d-ac43-d3e355abcc851781581959491201383] Loading producer state till offset 0 with message format version 2
2024-12-31 21:01:31.687 Created log for partition __consumer_offsets-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.ec524e2d-dbef-471d-ac43-d3e355abcc851781581959491201383\__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:01:31.687 [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
2024-12-31 21:01:31.687 [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0
2024-12-31 21:01:31.687 [Broker id=0] Leader __consumer_offsets-0 with topic id Some(oiZBuCgRQ8yspEwYv_MUQg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:01:31.690 [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 0
2024-12-31 21:01:31.691 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0
2024-12-31 21:01:31.692 [GroupCoordinator 0]: Elected as the group coordinator for partition 2 in epoch 0
2024-12-31 21:01:31.692 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0
2024-12-31 21:01:31.692 [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 0
2024-12-31 21:01:31.692 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0
2024-12-31 21:01:31.692 [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 0
2024-12-31 21:01:31.692 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0
2024-12-31 21:01:31.692 [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 0
2024-12-31 21:01:31.692 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0
2024-12-31 21:01:31.692 [Broker id=0] Finished LeaderAndIsr request in 70ms correlationId 3 from controller 0 for 5 partitions
2024-12-31 21:01:31.694 [Broker id=0] Add 5 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 4
2024-12-31 21:01:31.696 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 4 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler.
2024-12-31 21:01:31.697 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler.
2024-12-31 21:01:31.697 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler.
2024-12-31 21:01:31.697 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler.
2024-12-31 21:01:31.697 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler.
2024-12-31 21:01:31.705 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Discovered group coordinator localhost:59325 (id: 2147483647 rack: null)
2024-12-31 21:01:31.708 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] (Re-)joining group
2024-12-31 21:01:31.727 [GroupCoordinator 0]: Dynamic member with unknown member id joins group pong-service in Empty state. Created a new member id consumer-pong-service-1-54538f04-38fe-4ebe-a16a-c3d5c30ef592 and request the member to rejoin with this id.
2024-12-31 21:01:31.730 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: need to re-join with the given member-id: consumer-pong-service-1-54538f04-38fe-4ebe-a16a-c3d5c30ef592
2024-12-31 21:01:31.731 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2024-12-31 21:01:31.731 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] (Re-)joining group
2024-12-31 21:01:31.738 [GroupCoordinator 0]: Preparing to rebalance group pong-service in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-pong-service-1-54538f04-38fe-4ebe-a16a-c3d5c30ef592 with group instance id None; client reason: rebalance failed due to MemberIdRequiredException)
2024-12-31 21:01:31.743 [GroupCoordinator 0]: Stabilized group pong-service generation 1 (__consumer_offsets-2) with 1 members
2024-12-31 21:01:31.744 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Successfully joined group with generation Generation{generationId=1, memberId='consumer-pong-service-1-54538f04-38fe-4ebe-a16a-c3d5c30ef592', protocol='range'}
2024-12-31 21:01:31.746 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Finished assignment for group at generation 1: {consumer-pong-service-1-54538f04-38fe-4ebe-a16a-c3d5c30ef592=Assignment(partitions=[pong-message-topic-0, pong-message-topic-1])}
2024-12-31 21:01:31.753 [GroupCoordinator 0]: Assignment received from leader consumer-pong-service-1-54538f04-38fe-4ebe-a16a-c3d5c30ef592 for group pong-service for generation 1. The group has 1 members, 0 of which are static.
2024-12-31 21:01:31.805 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Successfully synced group in generation Generation{generationId=1, memberId='consumer-pong-service-1-54538f04-38fe-4ebe-a16a-c3d5c30ef592', protocol='range'}
2024-12-31 21:01:31.806 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Notifying assignor about the new Assignment(partitions=[pong-message-topic-0, pong-message-topic-1])
2024-12-31 21:01:31.809 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Adding newly assigned partitions: pong-message-topic-0, pong-message-topic-1
2024-12-31 21:01:31.818 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-0
2024-12-31 21:01:31.819 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-1
2024-12-31 21:01:31.822 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-0
2024-12-31 21:01:31.822 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-1
2024-12-31 21:01:31.836 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting offset for partition pong-message-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:59325 (id: 0 rack: null)], epoch=0}}.
2024-12-31 21:01:31.837 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting offset for partition pong-message-topic-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:59325 (id: 0 rack: null)], epoch=0}}.
2024-12-31 21:01:31.853 pong-service: partitions assigned: [pong-message-topic-0, pong-message-topic-1]
2024-12-31 21:01:32.481 Received ping message: Hello
2024-12-31 21:01:32.492 Idempotence will be disabled because acks is set to 0, not set to 'all'.
2024-12-31 21:01:32.492 ProducerConfig values: 
	acks = 0
	auto.include.jmx.reporter = true
	batch.size = 10
	bootstrap.servers = [127.0.0.1:59325]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2024-12-31 21:01:32.516 Kafka version: 3.4.1
2024-12-31 21:01:32.516 Kafka commitId: 8a516edc2755df89
2024-12-31 21:01:32.516 Kafka startTimeMs: 1735650092516
2024-12-31 21:01:32.520 [Producer clientId=producer-1] Cluster ID: GNRQBkKdS0uklp-lPgX4ew
2024-12-31 21:01:32.525 [Producer clientId=producer-1] Resetting the last seen epoch of partition pong-message-topic-0 to 0 since the associated topicId changed from null to bkreKMhATjWbLBJmX1gFPQ
2024-12-31 21:01:32.525 [Producer clientId=producer-1] Resetting the last seen epoch of partition pong-message-topic-1 to 0 since the associated topicId changed from null to bkreKMhATjWbLBJmX1gFPQ
2024-12-31 21:01:33.931 Received ping message: Hello
2024-12-31 21:01:33.940 Throttling request as too many requests in the same second
2024-12-31 21:01:33.940 Received ping message: Hello
2024-12-31 21:01:34.315 [KafkaServer id=0] shutting down
2024-12-31 21:01:34.317 [KafkaServer id=0] Starting controlled shutdown
2024-12-31 21:01:34.326 [Controller id=0] Shutting down broker 0
2024-12-31 21:01:34.331 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:01:34.336 [KafkaServer id=0] Controlled shutdown request returned successfully after 14ms
2024-12-31 21:01:34.339 [/config/changes-event-process-thread]: Shutting down
2024-12-31 21:01:34.339 [/config/changes-event-process-thread]: Stopped
2024-12-31 21:01:34.340 [/config/changes-event-process-thread]: Shutdown completed
2024-12-31 21:01:34.340 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
2024-12-31 21:01:34.344 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:01:34.344 [Producer clientId=producer-1] Node 0 disconnected.
2024-12-31 21:01:34.345 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Cancelled in-flight FETCH request with correlation id 22 due to node 0 being disconnected (elapsed time since creation: 394ms, elapsed time since send: 394ms, request timeout: 30000ms)
2024-12-31 21:01:34.345 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 2147483647 disconnected.
2024-12-31 21:01:34.346 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:01:34.346 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:01:34.346 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Error sending fetch request (sessionId=2059664013, epoch=6) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2024-12-31 21:01:34.346 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Group coordinator localhost:59325 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
2024-12-31 21:01:34.347 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors
2024-12-31 21:01:34.347 [data-plane Kafka Request Handler on Broker 0], shutting down
2024-12-31 21:01:34.349 [data-plane Kafka Request Handler on Broker 0], shut down completely
2024-12-31 21:01:34.351 [ExpirationReaper-0-AlterAcls]: Shutting down
2024-12-31 21:01:34.355 [ExpirationReaper-0-AlterAcls]: Shutdown completed
2024-12-31 21:01:34.355 [ExpirationReaper-0-AlterAcls]: Stopped
2024-12-31 21:01:34.356 [KafkaApi-0] Shutdown complete.
2024-12-31 21:01:34.357 [ExpirationReaper-0-topic]: Shutting down
2024-12-31 21:01:34.357 [ExpirationReaper-0-topic]: Stopped
2024-12-31 21:01:34.357 [ExpirationReaper-0-topic]: Shutdown completed
2024-12-31 21:01:34.360 [TransactionCoordinator id=0] Shutting down.
2024-12-31 21:01:34.360 [Transaction State Manager 0]: Shutdown complete
2024-12-31 21:01:34.360 [Transaction Marker Channel Manager 0]: Shutting down
2024-12-31 21:01:34.360 [Transaction Marker Channel Manager 0]: Stopped
2024-12-31 21:01:34.360 [Transaction Marker Channel Manager 0]: Shutdown completed
2024-12-31 21:01:34.361 [TransactionCoordinator id=0] Shutdown complete.
2024-12-31 21:01:34.361 [GroupCoordinator 0]: Shutting down.
2024-12-31 21:01:34.362 [ExpirationReaper-0-Heartbeat]: Shutting down
2024-12-31 21:01:34.362 [ExpirationReaper-0-Heartbeat]: Stopped
2024-12-31 21:01:34.362 [ExpirationReaper-0-Heartbeat]: Shutdown completed
2024-12-31 21:01:34.362 [ExpirationReaper-0-Rebalance]: Shutting down
2024-12-31 21:01:34.363 [ExpirationReaper-0-Rebalance]: Stopped
2024-12-31 21:01:34.363 [ExpirationReaper-0-Rebalance]: Shutdown completed
2024-12-31 21:01:34.363 [GroupCoordinator 0]: Shutdown complete.
2024-12-31 21:01:34.364 [ReplicaManager broker=0] Shutting down
2024-12-31 21:01:34.364 [LogDirFailureHandler]: Shutting down
2024-12-31 21:01:34.364 [LogDirFailureHandler]: Stopped
2024-12-31 21:01:34.364 [LogDirFailureHandler]: Shutdown completed
2024-12-31 21:01:34.365 [ReplicaFetcherManager on broker 0] shutting down
2024-12-31 21:01:34.367 [ReplicaFetcherManager on broker 0] shutdown completed
2024-12-31 21:01:34.367 [ReplicaAlterLogDirsManager on broker 0] shutting down
2024-12-31 21:01:34.367 [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2024-12-31 21:01:34.367 [ExpirationReaper-0-Fetch]: Shutting down
2024-12-31 21:01:34.367 [ExpirationReaper-0-Fetch]: Stopped
2024-12-31 21:01:34.367 [ExpirationReaper-0-Fetch]: Shutdown completed
2024-12-31 21:01:34.368 [ExpirationReaper-0-Produce]: Shutting down
2024-12-31 21:01:34.368 [ExpirationReaper-0-Produce]: Stopped
2024-12-31 21:01:34.368 [ExpirationReaper-0-Produce]: Shutdown completed
2024-12-31 21:01:34.369 [ExpirationReaper-0-DeleteRecords]: Shutting down
2024-12-31 21:01:34.369 [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2024-12-31 21:01:34.369 [ExpirationReaper-0-DeleteRecords]: Stopped
2024-12-31 21:01:34.369 [ExpirationReaper-0-ElectLeader]: Shutting down
2024-12-31 21:01:34.369 [ExpirationReaper-0-ElectLeader]: Shutdown completed
2024-12-31 21:01:34.369 [ExpirationReaper-0-ElectLeader]: Stopped
2024-12-31 21:01:34.379 [ReplicaManager broker=0] Shut down completely
2024-12-31 21:01:34.380 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutting down
2024-12-31 21:01:34.380 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutdown completed
2024-12-31 21:01:34.380 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Stopped
2024-12-31 21:01:34.382 Broker to controller channel manager for alterPartition shutdown
2024-12-31 21:01:34.382 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down
2024-12-31 21:01:34.382 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed
2024-12-31 21:01:34.382 [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped
2024-12-31 21:01:34.383 Broker to controller channel manager for forwarding shutdown
2024-12-31 21:01:34.383 Shutting down.
2024-12-31 21:01:34.385 Shutting down the log cleaner.
2024-12-31 21:01:34.386 [kafka-log-cleaner-thread-0]: Shutting down
2024-12-31 21:01:34.387 [kafka-log-cleaner-thread-0]: Shutdown completed
2024-12-31 21:01:34.387 [kafka-log-cleaner-thread-0]: Stopped
2024-12-31 21:01:34.425 [ProducerStateManager partition=pong-message-topic-0] Wrote producer snapshot at offset 2 with 0 producer ids in 5 ms.
2024-12-31 21:01:34.434 [ProducerStateManager partition=pong-message-topic-1] Wrote producer snapshot at offset 1 with 0 producer ids in 3 ms.
2024-12-31 21:01:34.444 [ProducerStateManager partition=__consumer_offsets-2] Wrote producer snapshot at offset 6 with 0 producer ids in 2 ms.
2024-12-31 21:01:34.445 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:01:34.445 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node 0 (localhost/127.0.0.1:59325) could not be established. Broker may not be available.
2024-12-31 21:01:34.446 [Producer clientId=producer-1] Node 0 disconnected.
2024-12-31 21:01:34.446 [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:59325) could not be established. Broker may not be available.
2024-12-31 21:01:34.459 Shutdown complete.
2024-12-31 21:01:34.459 [ControllerEventThread controllerId=0] Shutting down
2024-12-31 21:01:34.460 [ControllerEventThread controllerId=0] Shutdown completed
2024-12-31 21:01:34.460 [ControllerEventThread controllerId=0] Stopped
2024-12-31 21:01:34.461 [PartitionStateMachine controllerId=0] Stopped partition state machine
2024-12-31 21:01:34.461 [ReplicaStateMachine controllerId=0] Stopped replica state machine
2024-12-31 21:01:34.463 [RequestSendThread controllerId=0] Shutting down
2024-12-31 21:01:34.463 [RequestSendThread controllerId=0] Stopped
2024-12-31 21:01:34.463 [RequestSendThread controllerId=0] Shutdown completed
2024-12-31 21:01:34.464 [Controller id=0] Resigned
2024-12-31 21:01:34.464 [feature-zk-node-event-process-thread]: Shutting down
2024-12-31 21:01:34.464 [feature-zk-node-event-process-thread]: Stopped
2024-12-31 21:01:34.464 [feature-zk-node-event-process-thread]: Shutdown completed
2024-12-31 21:01:34.465 [ZooKeeperClient Kafka server] Closing.
2024-12-31 21:01:34.547 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:01:34.547 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node 0 (localhost/127.0.0.1:59325) could not be established. Broker may not be available.
2024-12-31 21:01:34.574 Session: 0x100176981860000 closed
2024-12-31 21:01:34.574 EventThread shut down for session: 0x100176981860000
2024-12-31 21:01:34.575 [ZooKeeperClient Kafka server] Closed.
2024-12-31 21:01:34.576 [ThrottledChannelReaper-Fetch]: Shutting down
2024-12-31 21:01:34.578 [ThrottledChannelReaper-Fetch]: Stopped
2024-12-31 21:01:34.578 [ThrottledChannelReaper-Fetch]: Shutdown completed
2024-12-31 21:01:34.578 [ThrottledChannelReaper-Produce]: Shutting down
2024-12-31 21:01:34.578 [ThrottledChannelReaper-Produce]: Shutdown completed
2024-12-31 21:01:34.578 [ThrottledChannelReaper-Produce]: Stopped
2024-12-31 21:01:34.578 [ThrottledChannelReaper-Request]: Shutting down
2024-12-31 21:01:34.578 [ThrottledChannelReaper-Request]: Stopped
2024-12-31 21:01:34.578 [ThrottledChannelReaper-Request]: Shutdown completed
2024-12-31 21:01:34.578 [ThrottledChannelReaper-ControllerMutation]: Shutting down
2024-12-31 21:01:34.578 [ThrottledChannelReaper-ControllerMutation]: Stopped
2024-12-31 21:01:34.578 [ThrottledChannelReaper-ControllerMutation]: Shutdown completed
2024-12-31 21:01:34.579 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server
2024-12-31 21:01:34.594 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed
2024-12-31 21:01:34.595 Metrics scheduler closed
2024-12-31 21:01:34.595 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:01:34.595 Metrics reporters closed
2024-12-31 21:01:34.596 Broker and topic stats closed
2024-12-31 21:01:34.596 App info kafka.server for 0 unregistered
2024-12-31 21:01:34.597 [KafkaServer id=0] shut down completed
2024-12-31 21:01:34.599 [Producer clientId=producer-1] Node 0 disconnected.
2024-12-31 21:01:34.599 [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:59325) could not be established. Broker may not be available.
2024-12-31 21:01:34.612 ConnnectionExpirerThread interrupted
2024-12-31 21:01:34.613 selector thread exitted run method
2024-12-31 21:01:34.613 selector thread exitted run method
2024-12-31 21:01:34.613 accept thread exitted run method
2024-12-31 21:01:34.613 shutting down
2024-12-31 21:01:34.613 Shutting down
2024-12-31 21:01:34.613 Draining request throttler queue
2024-12-31 21:01:34.613 RequestThrottler shutdown. Dropped 0 requests
2024-12-31 21:01:34.613 Shutting down
2024-12-31 21:01:34.613 Shutting down
2024-12-31 21:01:34.613 Shutting down
2024-12-31 21:01:34.613 PrepRequestProcessor exited loop!
2024-12-31 21:01:34.613 SyncRequestProcessor exited!
2024-12-31 21:01:34.613 shutdown of request processor complete
2024-12-31 21:01:34.642 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Revoke previously assigned partitions pong-message-topic-0, pong-message-topic-1
2024-12-31 21:01:34.643 pong-service: partitions revoked: [pong-message-topic-0, pong-message-topic-1]
2024-12-31 21:01:34.643 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:01:34.643 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:01:34.643 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Unsubscribed all topics or patterns and assigned partitions
2024-12-31 21:01:34.644 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:01:34.644 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:01:34.644 Metrics scheduler closed
2024-12-31 21:01:34.644 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:01:34.644 Metrics reporters closed
2024-12-31 21:01:34.645 App info kafka.consumer for consumer-pong-service-1 unregistered
2024-12-31 21:01:34.645 pong-service: Consumer stopped
2024-12-31 21:01:34.650 [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2024-12-31 21:01:34.651 Metrics scheduler closed
2024-12-31 21:01:34.651 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:01:34.651 Metrics reporters closed
2024-12-31 21:01:34.652 App info kafka.producer for producer-1 unregistered
2024-12-31 21:01:34.669 Closing JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:01:34.673 HikariPool-1 - Shutdown initiated...
2024-12-31 21:01:34.676 HikariPool-1 - Shutdown completed.
2024-12-31 21:01:34.690 SessionTrackerImpl exited loop!
2024-12-31 21:01:36.701 [KafkaServer id=0] shutting down
2024-12-31 21:01:36.701 [/config/changes-event-process-thread]: Shutting down
2024-12-31 21:01:36.701 [/config/changes-event-process-thread]: Shutdown completed
2024-12-31 21:01:36.701 [/config/changes-event-process-thread]: Stopped
2024-12-31 21:01:36.701 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
2024-12-31 21:01:36.706 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors
2024-12-31 21:01:36.706 [data-plane Kafka Request Handler on Broker 0], shutting down
2024-12-31 21:01:36.708 [data-plane Kafka Request Handler on Broker 0], shut down completely
2024-12-31 21:01:36.710 [ExpirationReaper-0-AlterAcls]: Shutting down
2024-12-31 21:01:36.710 [ExpirationReaper-0-AlterAcls]: Stopped
2024-12-31 21:01:36.710 [ExpirationReaper-0-AlterAcls]: Shutdown completed
2024-12-31 21:01:36.710 [KafkaApi-0] Shutdown complete.
2024-12-31 21:01:36.710 [ExpirationReaper-0-topic]: Shutting down
2024-12-31 21:01:36.710 [ExpirationReaper-0-topic]: Stopped
2024-12-31 21:01:36.710 [ExpirationReaper-0-topic]: Shutdown completed
2024-12-31 21:01:36.711 [TransactionCoordinator id=0] Shutting down.
2024-12-31 21:01:36.711 [Transaction State Manager 0]: Shutdown complete
2024-12-31 21:01:36.711 [Transaction Marker Channel Manager 0]: Shutting down
2024-12-31 21:01:36.711 [Transaction Marker Channel Manager 0]: Shutdown completed
2024-12-31 21:01:36.711 [Transaction Marker Channel Manager 0]: Stopped
2024-12-31 21:01:36.713 [TransactionCoordinator id=0] Shutdown complete.
2024-12-31 21:01:36.713 [GroupCoordinator 0]: Shutting down.
2024-12-31 21:01:36.713 [ExpirationReaper-0-Heartbeat]: Shutting down
2024-12-31 21:01:36.713 [ExpirationReaper-0-Heartbeat]: Shutdown completed
2024-12-31 21:01:36.713 [ExpirationReaper-0-Heartbeat]: Stopped
2024-12-31 21:01:36.713 [ExpirationReaper-0-Rebalance]: Shutting down
2024-12-31 21:01:36.714 [ExpirationReaper-0-Rebalance]: Shutdown completed
2024-12-31 21:01:36.714 [ExpirationReaper-0-Rebalance]: Stopped
2024-12-31 21:01:36.714 [GroupCoordinator 0]: Shutdown complete.
2024-12-31 21:01:36.714 [ReplicaManager broker=0] Shutting down
2024-12-31 21:01:36.714 [LogDirFailureHandler]: Shutting down
2024-12-31 21:01:36.714 [LogDirFailureHandler]: Shutdown completed
2024-12-31 21:01:36.714 [LogDirFailureHandler]: Stopped
2024-12-31 21:01:36.714 [ReplicaFetcherManager on broker 0] shutting down
2024-12-31 21:01:36.714 [ReplicaFetcherManager on broker 0] shutdown completed
2024-12-31 21:01:36.714 [ReplicaAlterLogDirsManager on broker 0] shutting down
2024-12-31 21:01:36.714 [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2024-12-31 21:01:36.714 [ExpirationReaper-0-Fetch]: Shutting down
2024-12-31 21:01:36.714 [ExpirationReaper-0-Fetch]: Stopped
2024-12-31 21:01:36.714 [ExpirationReaper-0-Fetch]: Shutdown completed
2024-12-31 21:01:36.714 [ExpirationReaper-0-Produce]: Shutting down
2024-12-31 21:01:36.715 [ExpirationReaper-0-Produce]: Stopped
2024-12-31 21:01:36.715 [ExpirationReaper-0-Produce]: Shutdown completed
2024-12-31 21:01:36.715 [ExpirationReaper-0-DeleteRecords]: Shutting down
2024-12-31 21:01:36.715 [ExpirationReaper-0-DeleteRecords]: Stopped
2024-12-31 21:01:36.716 [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2024-12-31 21:01:36.716 [ExpirationReaper-0-ElectLeader]: Shutting down
2024-12-31 21:01:36.716 [ExpirationReaper-0-ElectLeader]: Stopped
2024-12-31 21:01:36.716 [ExpirationReaper-0-ElectLeader]: Shutdown completed
2024-12-31 21:01:36.724 [ReplicaManager broker=0] Shut down completely
2024-12-31 21:01:36.725 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutting down
2024-12-31 21:01:36.725 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Stopped
2024-12-31 21:01:36.725 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutdown completed
2024-12-31 21:01:36.726 Broker to controller channel manager for alterPartition shutdown
2024-12-31 21:01:36.726 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down
2024-12-31 21:01:36.726 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed
2024-12-31 21:01:36.726 [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped
2024-12-31 21:01:36.726 Broker to controller channel manager for forwarding shutdown
2024-12-31 21:01:36.726 Shutting down.
2024-12-31 21:01:36.727 Shutting down the log cleaner.
2024-12-31 21:01:36.727 [kafka-log-cleaner-thread-0]: Shutting down
2024-12-31 21:01:36.727 [kafka-log-cleaner-thread-0]: Stopped
2024-12-31 21:01:36.727 [kafka-log-cleaner-thread-0]: Shutdown completed
2024-12-31 21:01:36.736 Shutdown complete.
2024-12-31 21:01:36.736 [ControllerEventThread controllerId=0] Shutting down
2024-12-31 21:01:36.736 [ControllerEventThread controllerId=0] Shutdown completed
2024-12-31 21:01:36.736 [ControllerEventThread controllerId=0] Stopped
2024-12-31 21:01:36.738 [PartitionStateMachine controllerId=0] Stopped partition state machine
2024-12-31 21:01:36.738 [ReplicaStateMachine controllerId=0] Stopped replica state machine
2024-12-31 21:01:36.738 [RequestSendThread controllerId=0] Shutting down
2024-12-31 21:01:36.738 [RequestSendThread controllerId=0] Stopped
2024-12-31 21:01:36.738 [RequestSendThread controllerId=0] Shutdown completed
2024-12-31 21:01:36.739 [Controller id=0] Resigned
2024-12-31 21:01:36.739 [feature-zk-node-event-process-thread]: Shutting down
2024-12-31 21:01:36.739 [feature-zk-node-event-process-thread]: Shutdown completed
2024-12-31 21:01:36.739 [feature-zk-node-event-process-thread]: Stopped
2024-12-31 21:01:36.739 [ZooKeeperClient Kafka server] Closing.
2024-12-31 21:01:36.842 Session: 0x1001769a27b0000 closed
2024-12-31 21:01:36.842 EventThread shut down for session: 0x1001769a27b0000
2024-12-31 21:01:36.843 [ZooKeeperClient Kafka server] Closed.
2024-12-31 21:01:36.843 [ThrottledChannelReaper-Fetch]: Shutting down
2024-12-31 21:01:36.843 [ThrottledChannelReaper-Fetch]: Stopped
2024-12-31 21:01:36.843 [ThrottledChannelReaper-Fetch]: Shutdown completed
2024-12-31 21:01:36.843 [ThrottledChannelReaper-Produce]: Shutting down
2024-12-31 21:01:36.843 [ThrottledChannelReaper-Produce]: Stopped
2024-12-31 21:01:36.843 [ThrottledChannelReaper-Produce]: Shutdown completed
2024-12-31 21:01:36.843 [ThrottledChannelReaper-Request]: Shutting down
2024-12-31 21:01:36.843 [ThrottledChannelReaper-Request]: Stopped
2024-12-31 21:01:36.843 [ThrottledChannelReaper-Request]: Shutdown completed
2024-12-31 21:01:36.843 [ThrottledChannelReaper-ControllerMutation]: Shutting down
2024-12-31 21:01:36.843 [ThrottledChannelReaper-ControllerMutation]: Stopped
2024-12-31 21:01:36.843 [ThrottledChannelReaper-ControllerMutation]: Shutdown completed
2024-12-31 21:01:36.843 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server
2024-12-31 21:01:36.856 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed
2024-12-31 21:01:36.856 Metrics scheduler closed
2024-12-31 21:01:36.856 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:01:36.856 Metrics reporters closed
2024-12-31 21:01:36.857 Broker and topic stats closed
2024-12-31 21:01:36.857 App info kafka.server for 0 unregistered
2024-12-31 21:01:36.857 [KafkaServer id=0] shut down completed
2024-12-31 21:01:36.862 ConnnectionExpirerThread interrupted
2024-12-31 21:01:36.862 selector thread exitted run method
2024-12-31 21:01:36.862 accept thread exitted run method
2024-12-31 21:01:36.862 selector thread exitted run method
2024-12-31 21:01:36.864 shutting down
2024-12-31 21:01:36.864 Shutting down
2024-12-31 21:01:36.864 Draining request throttler queue
2024-12-31 21:01:36.864 RequestThrottler shutdown. Dropped 0 requests
2024-12-31 21:01:36.865 Shutting down
2024-12-31 21:01:36.865 Shutting down
2024-12-31 21:01:36.865 Shutting down
2024-12-31 21:01:36.865 PrepRequestProcessor exited loop!
2024-12-31 21:01:36.865 SyncRequestProcessor exited!
2024-12-31 21:01:36.865 shutdown of request processor complete
2024-12-31 21:01:37.089 SessionTrackerImpl exited loop!
2024-12-31 21:01:37.358 

Found multiple occurrences of org.json.JSONObject on the class path:

	jar:file:/C:/work/apache-maven-3.8.8/repo/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar!/org/json/JSONObject.class
	jar:file:/C:/work/apache-maven-3.8.8/repo/org/json/json/20220320/json-20220320.jar!/org/json/JSONObject.class

You may wish to exclude one of them to ensure predictable runtime behavior

2024-12-31 21:01:37.358 Starting MessageRepositorySpec using Java 17.0.12 with PID 392 (started by joech in C:\code\hsbc\demo\pong)
2024-12-31 21:01:37.358 No active profile set, falling back to 1 default profile: "default"
2024-12-31 21:01:37.521 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:01:37.521 Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2024-12-31 21:01:37.538 Finished Spring Data repository scanning in 14 ms. Found 1 JPA repository interfaces.
2024-12-31 21:01:37.543 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:01:37.543 Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2024-12-31 21:01:37.545 Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.demo.dao.MessageRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2024-12-31 21:01:37.545 Finished Spring Data repository scanning in 4 ms. Found 0 Redis repository interfaces.
2024-12-31 21:01:37.655 HHH000204: Processing PersistenceUnitInfo [name: default]
2024-12-31 21:01:37.664 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:01:37.664 No LoadTimeWeaver setup: ignoring JPA class transformer
2024-12-31 21:01:37.664 HikariPool-2 - Starting...
2024-12-31 21:01:37.667 HikariPool-2 - Added connection conn10: url=jdbc:h2:mem:testdb user=SA
2024-12-31 21:01:37.667 HikariPool-2 - Start completed.
2024-12-31 21:01:37.680 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:01:37.711 HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2024-12-31 21:01:37.734 Initialized JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:01:37.982 ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:59325]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-pong-service-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = pong-service
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2024-12-31 21:01:37.990 These configurations '[spring.json.trusted.packages]' were supplied but are not used yet.
2024-12-31 21:01:37.990 Kafka version: 3.4.1
2024-12-31 21:01:37.990 Kafka commitId: 8a516edc2755df89
2024-12-31 21:01:37.990 Kafka startTimeMs: 1735650097990
2024-12-31 21:01:37.990 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Subscribed to topic(s): pong-message-topic
2024-12-31 21:01:37.994 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:01:37.994 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Connection to node -1 (/127.0.0.1:59325) could not be established. Broker may not be available.
2024-12-31 21:01:37.994 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Bootstrap broker 127.0.0.1:59325 (id: -1 rack: null) disconnected
2024-12-31 21:01:37.995 Started MessageRepositorySpec in 0.668 seconds (process running for 28.564)
2024-12-31 21:01:38.052 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:01:38.052 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:01:38.052 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Unsubscribed all topics or patterns and assigned partitions
2024-12-31 21:01:38.052 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:01:38.052 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:01:38.052 Metrics scheduler closed
2024-12-31 21:01:38.052 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:01:38.052 Metrics reporters closed
2024-12-31 21:01:38.052 App info kafka.consumer for consumer-pong-service-2 unregistered
2024-12-31 21:01:38.052 pong-service: Consumer stopped
2024-12-31 21:01:38.061 Closing JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:01:38.061 HikariPool-2 - Shutdown initiated...
2024-12-31 21:01:38.066 HikariPool-2 - Shutdown completed.
2024-12-31 21:01:38.086 zookeeper.snapshot.trust.empty : false
2024-12-31 21:01:38.086 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:01:38.086 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:01:38.086 zookeeper.snapshotSizeFactor = 0.33
2024-12-31 21:01:38.086 zookeeper.commitLogCount=500
2024-12-31 21:01:38.086 minSessionTimeout set to 1600
2024-12-31 21:01:38.086 maxSessionTimeout set to 16000
2024-12-31 21:01:38.086 Response cache size is initialized with value 400.
2024-12-31 21:01:38.093 Response cache size is initialized with value 400.
2024-12-31 21:01:38.093 zookeeper.pathStats.slotCapacity = 60
2024-12-31 21:01:38.093 zookeeper.pathStats.slotDuration = 15
2024-12-31 21:01:38.093 zookeeper.pathStats.maxDepth = 6
2024-12-31 21:01:38.093 zookeeper.pathStats.initialDelay = 5
2024-12-31 21:01:38.093 zookeeper.pathStats.delay = 5
2024-12-31 21:01:38.093 zookeeper.pathStats.enabled = false
2024-12-31 21:01:38.093 The max bytes for all large requests are set to 104857600
2024-12-31 21:01:38.093 The large request threshold is set to -1
2024-12-31 21:01:38.093 Created server with tickTime 800 minSessionTimeout 1600 maxSessionTimeout 16000 clientPortListenBacklog -1 datadir C:\Users\joech\AppData\Local\Temp\kafka-14330522262193990038\version-2 snapdir C:\Users\joech\AppData\Local\Temp\kafka-5469709465376863093\version-2
2024-12-31 21:01:38.094 maxCnxns is not configured, using default value 0.
2024-12-31 21:01:38.094 Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers.
2024-12-31 21:01:38.097 binding to port /127.0.0.1:0
2024-12-31 21:01:38.102 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-5469709465376863093\version-2\snapshot.0
2024-12-31 21:01:38.103 Snapshot loaded in 2 ms, highest zxid is 0x0, digest is 1371985504
2024-12-31 21:01:38.103 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-5469709465376863093\version-2\snapshot.0
2024-12-31 21:01:38.104 Snapshot taken in 1 ms
2024-12-31 21:01:38.104 PrepRequestProcessor (sid:0) started, reconfigEnabled=false
2024-12-31 21:01:38.107 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.65722cd2-db14-42e2-99a7-6c723ecdf45d4770093949029589497
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59352
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:01:38.111 starting
2024-12-31 21:01:38.111 Connecting to zookeeper on 127.0.0.1:59352
2024-12-31 21:01:38.112 [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:59352.
2024-12-31 21:01:38.112 Initiating client connection, connectString=127.0.0.1:59352 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@dc48606
2024-12-31 21:01:38.115 jute.maxbuffer value is 4194304 Bytes
2024-12-31 21:01:38.115 zookeeper.request.timeout value is 0. feature enabled=false
2024-12-31 21:01:38.116 [ZooKeeperClient Kafka server] Waiting until connected.
2024-12-31 21:01:38.116 Opening socket connection to server /127.0.0.1:59352.
2024-12-31 21:01:38.117 Socket connection established, initiating session, client: /127.0.0.1:59353, server: /127.0.0.1:59352
2024-12-31 21:01:38.118 Creating new log file: log.1
2024-12-31 21:01:38.126 Session establishment complete on server /127.0.0.1:59352, session id = 0x1001769d0780000, negotiated timeout = 16000
2024-12-31 21:01:38.127 [ZooKeeperClient Kafka server] Connected.
2024-12-31 21:01:38.168 Cluster ID = K3Ve5ER1QAqxbOzPTQqjQQ
2024-12-31 21:01:38.168 No meta.properties file under dir C:\Users\joech\AppData\Local\Temp\spring.kafka.65722cd2-db14-42e2-99a7-6c723ecdf45d4770093949029589497\meta.properties
2024-12-31 21:01:38.178 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.65722cd2-db14-42e2-99a7-6c723ecdf45d4770093949029589497
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59352
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:01:38.183 [ThrottledChannelReaper-Produce]: Starting
2024-12-31 21:01:38.183 [ThrottledChannelReaper-Fetch]: Starting
2024-12-31 21:01:38.184 [ThrottledChannelReaper-Request]: Starting
2024-12-31 21:01:38.184 [ThrottledChannelReaper-ControllerMutation]: Starting
2024-12-31 21:01:38.193 Loading logs from log dirs ArraySeq(C:\Users\joech\AppData\Local\Temp\spring.kafka.65722cd2-db14-42e2-99a7-6c723ecdf45d4770093949029589497)
2024-12-31 21:01:38.194 Attempting recovery for all logs in C:\Users\joech\AppData\Local\Temp\spring.kafka.65722cd2-db14-42e2-99a7-6c723ecdf45d4770093949029589497 since no clean shutdown file was found
2024-12-31 21:01:38.195 Loaded 0 logs in 1ms.
2024-12-31 21:01:38.195 Starting log cleanup with a period of 300000 ms.
2024-12-31 21:01:38.196 Starting log flusher with a default period of 9223372036854775807 ms.
2024-12-31 21:01:38.198 Starting the log cleaner
2024-12-31 21:01:38.199 [kafka-log-cleaner-thread-0]: Starting
2024-12-31 21:01:38.199 [feature-zk-node-event-process-thread]: Starting
2024-12-31 21:01:38.201 Feature ZK node at path: /feature does not exist
2024-12-31 21:01:38.205 [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting
2024-12-31 21:01:38.222 Updated connection-accept-rate max connection creation rate to 2147483647
2024-12-31 21:01:38.225 Awaiting socket connections on localhost:59354.
2024-12-31 21:01:38.233 [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT)
2024-12-31 21:01:38.236 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Starting
2024-12-31 21:01:38.237 [ExpirationReaper-0-Produce]: Starting
2024-12-31 21:01:38.237 [ExpirationReaper-0-Fetch]: Starting
2024-12-31 21:01:38.237 [ExpirationReaper-0-DeleteRecords]: Starting
2024-12-31 21:01:38.239 [ExpirationReaper-0-ElectLeader]: Starting
2024-12-31 21:01:38.240 [LogDirFailureHandler]: Starting
2024-12-31 21:01:38.243 Creating /brokers/ids/0 (is it secure? false)
2024-12-31 21:01:38.246 Stat of the created znode at /brokers/ids/0 is: 25,25,1735650098245,1735650098245,1,0,0,72083337274458112,204,0,25

2024-12-31 21:01:38.246 Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:59354, czxid (broker epoch): 25
2024-12-31 21:01:38.258 [ControllerEventThread controllerId=0] Starting
2024-12-31 21:01:38.258 [ExpirationReaper-0-topic]: Starting
2024-12-31 21:01:38.258 [ExpirationReaper-0-Heartbeat]: Starting
2024-12-31 21:01:38.260 [ExpirationReaper-0-Rebalance]: Starting
2024-12-31 21:01:38.260 [GroupCoordinator 0]: Starting up.
2024-12-31 21:01:38.261 [GroupCoordinator 0]: Startup complete.
2024-12-31 21:01:38.263 Successfully created /controller_epoch with initial epoch 0
2024-12-31 21:01:38.263 [TransactionCoordinator id=0] Starting up.
2024-12-31 21:01:38.265 [Controller id=0] 0 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1
2024-12-31 21:01:38.265 [TransactionCoordinator id=0] Startup complete.
2024-12-31 21:01:38.265 [Transaction Marker Channel Manager 0]: Starting
2024-12-31 21:01:38.266 [Controller id=0] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map())
2024-12-31 21:01:38.266 [ExpirationReaper-0-AlterAcls]: Starting
2024-12-31 21:01:38.269 Feature ZK node created at path: /feature
2024-12-31 21:01:38.270 [/config/changes-event-process-thread]: Starting
2024-12-31 21:01:38.271 [Controller id=0] Registering handlers
2024-12-31 21:01:38.271 [MetadataCache brokerId=0] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0).
2024-12-31 21:01:38.272 [Controller id=0] Deleting log dir event notifications
2024-12-31 21:01:38.273 [Controller id=0] Deleting isr change notifications
2024-12-31 21:01:38.274 [Controller id=0] Initializing controller context
2024-12-31 21:01:38.275 [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing.
2024-12-31 21:01:38.276 Kafka version: 3.4.1
2024-12-31 21:01:38.276 Kafka commitId: 8a516edc2755df89
2024-12-31 21:01:38.276 Kafka startTimeMs: 1735650098276
2024-12-31 21:01:38.277 [KafkaServer id=0] started
2024-12-31 21:01:38.277 AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [127.0.0.1:59354]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-31 21:01:38.278 [Controller id=0] Initialized broker epochs cache: HashMap(0 -> 25)
2024-12-31 21:01:38.281 Kafka version: 3.4.1
2024-12-31 21:01:38.281 Kafka commitId: 8a516edc2755df89
2024-12-31 21:01:38.281 Kafka startTimeMs: 1735650098281
2024-12-31 21:01:38.286 [Controller id=0] Currently active brokers in the cluster: Set(0)
2024-12-31 21:01:38.286 [RequestSendThread controllerId=0] Starting
2024-12-31 21:01:38.286 [Controller id=0] Currently shutting brokers in the cluster: HashSet()
2024-12-31 21:01:38.286 [Controller id=0] Current list of topics in the cluster: HashSet()
2024-12-31 21:01:38.286 [Controller id=0] Fetching topic deletions in progress
2024-12-31 21:01:38.288 [Controller id=0] List of topics to be deleted: 
2024-12-31 21:01:38.288 [Controller id=0] List of topics ineligible for deletion: 
2024-12-31 21:01:38.288 [Controller id=0] Initializing topic deletion manager
2024-12-31 21:01:38.288 [Topic Deletion Manager 0] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet()
2024-12-31 21:01:38.288 [Controller id=0] Sending update metadata request
2024-12-31 21:01:38.288 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions
2024-12-31 21:01:38.290 [ReplicaStateMachine controllerId=0] Initializing replica state
2024-12-31 21:01:38.290 [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2024-12-31 21:01:38.290 [ReplicaStateMachine controllerId=0] Triggering offline replica state changes
2024-12-31 21:01:38.290 [PartitionStateMachine controllerId=0] Initializing partition state
2024-12-31 21:01:38.290 [PartitionStateMachine controllerId=0] Triggering online partition state changes
2024-12-31 21:01:38.290 [Controller id=0] Ready to serve as the new controller with epoch 1
2024-12-31 21:01:38.291 [RequestSendThread controllerId=0] Controller 0 connected to localhost:59354 (id: 0 rack: null) for sending state change requests
2024-12-31 21:01:38.292 [Controller id=0] Partitions undergoing preferred replica election: 
2024-12-31 21:01:38.292 [Controller id=0] Partitions that completed preferred replica election: 
2024-12-31 21:01:38.292 [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2024-12-31 21:01:38.292 [Controller id=0] Resuming preferred replica election for partitions: 
2024-12-31 21:01:38.292 [Controller id=0] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered
2024-12-31 21:01:38.294 [Controller id=0] Starting the controller scheduler
2024-12-31 21:01:38.305 [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use node localhost:59354 (id: 0 rack: null)
2024-12-31 21:01:38.337 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Recorded new controller, from now on will use node localhost:59354 (id: 0 rack: null)
2024-12-31 21:01:38.395 Creating topic pong-message-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0))
2024-12-31 21:01:38.406 [Controller id=0] New topics: [Set(pong-message-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(pong-message-topic,Some(7UIYtsZqRAq49sQp6SAqWQ),Map(pong-message-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), pong-message-topic-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:01:38.406 [Controller id=0] New partition creation callback for pong-message-topic-0,pong-message-topic-1
2024-12-31 21:01:38.406 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:01:38.406 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:01:38.406 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:01:38.407 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:01:38.413 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:01:38.414 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:01:38.414 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2024-12-31 21:01:38.414 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2024-12-31 21:01:38.414 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:01:38.416 [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 for 2 partitions
2024-12-31 21:01:38.417 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(pong-message-topic-0, pong-message-topic-1)
2024-12-31 21:01:38.417 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2024-12-31 21:01:38.430 [LogLoader partition=pong-message-topic-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.65722cd2-db14-42e2-99a7-6c723ecdf45d4770093949029589497] Loading producer state till offset 0 with message format version 2
2024-12-31 21:01:38.433 Created log for partition pong-message-topic-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.65722cd2-db14-42e2-99a7-6c723ecdf45d4770093949029589497\pong-message-topic-0 with properties {}
2024-12-31 21:01:38.433 [Partition pong-message-topic-0 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-0
2024-12-31 21:01:38.433 [Partition pong-message-topic-0 broker=0] Log loaded for partition pong-message-topic-0 with initial high watermark 0
2024-12-31 21:01:38.433 [Broker id=0] Leader pong-message-topic-0 with topic id Some(7UIYtsZqRAq49sQp6SAqWQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:01:38.444 [LogLoader partition=pong-message-topic-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.65722cd2-db14-42e2-99a7-6c723ecdf45d4770093949029589497] Loading producer state till offset 0 with message format version 2
2024-12-31 21:01:38.445 Created log for partition pong-message-topic-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.65722cd2-db14-42e2-99a7-6c723ecdf45d4770093949029589497\pong-message-topic-1 with properties {}
2024-12-31 21:01:38.445 [Partition pong-message-topic-1 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-1
2024-12-31 21:01:38.445 [Partition pong-message-topic-1 broker=0] Log loaded for partition pong-message-topic-1 with initial high watermark 0
2024-12-31 21:01:38.445 [Broker id=0] Leader pong-message-topic-1 with topic id Some(7UIYtsZqRAq49sQp6SAqWQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:01:38.449 [Broker id=0] Finished LeaderAndIsr request in 33ms correlationId 1 from controller 0 for 2 partitions
2024-12-31 21:01:38.452 [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2
2024-12-31 21:01:38.455 App info kafka.admin.client for adminclient-3 unregistered
2024-12-31 21:01:38.456 Metrics scheduler closed
2024-12-31 21:01:38.456 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:01:38.456 Metrics reporters closed
2024-12-31 21:01:38.501 

Found multiple occurrences of org.json.JSONObject on the class path:

	jar:file:/C:/work/apache-maven-3.8.8/repo/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar!/org/json/JSONObject.class
	jar:file:/C:/work/apache-maven-3.8.8/repo/org/json/json/20220320/json-20220320.jar!/org/json/JSONObject.class

You may wish to exclude one of them to ensure predictable runtime behavior

2024-12-31 21:01:38.505 Starting KafkaSpec using Java 17.0.12 with PID 392 (started by joech in C:\code\hsbc\demo\pong)
2024-12-31 21:01:38.505 No active profile set, falling back to 1 default profile: "default"
2024-12-31 21:01:38.690 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:01:38.690 Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2024-12-31 21:01:38.716 Finished Spring Data repository scanning in 24 ms. Found 1 JPA repository interfaces.
2024-12-31 21:01:38.729 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:01:38.729 Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2024-12-31 21:01:38.735 Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.demo.dao.MessageRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2024-12-31 21:01:38.735 Finished Spring Data repository scanning in 5 ms. Found 0 Redis repository interfaces.
2024-12-31 21:01:38.827 HHH000204: Processing PersistenceUnitInfo [name: default]
2024-12-31 21:01:38.837 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:01:38.838 No LoadTimeWeaver setup: ignoring JPA class transformer
2024-12-31 21:01:38.839 HikariPool-3 - Starting...
2024-12-31 21:01:38.843 HikariPool-3 - Added connection conn20: url=jdbc:h2:mem:testdb user=SA
2024-12-31 21:01:38.844 HikariPool-3 - Start completed.
2024-12-31 21:01:38.856 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:01:38.887 HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2024-12-31 21:01:38.910 Initialized JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:01:39.084 ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:59354]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-pong-service-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = pong-service
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2024-12-31 21:01:39.090 These configurations '[spring.json.trusted.packages]' were supplied but are not used yet.
2024-12-31 21:01:39.090 Kafka version: 3.4.1
2024-12-31 21:01:39.090 Kafka commitId: 8a516edc2755df89
2024-12-31 21:01:39.090 Kafka startTimeMs: 1735650099090
2024-12-31 21:01:39.090 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Subscribed to topic(s): pong-message-topic
2024-12-31 21:01:39.095 Started KafkaSpec in 0.635 seconds (process running for 29.664)
2024-12-31 21:01:39.101 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting the last seen epoch of partition pong-message-topic-0 to 0 since the associated topicId changed from null to 7UIYtsZqRAq49sQp6SAqWQ
2024-12-31 21:01:39.101 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting the last seen epoch of partition pong-message-topic-1 to 0 since the associated topicId changed from null to 7UIYtsZqRAq49sQp6SAqWQ
2024-12-31 21:01:39.101 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Cluster ID: K3Ve5ER1QAqxbOzPTQqjQQ
2024-12-31 21:01:39.105 Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0))
2024-12-31 21:01:39.108 Idempotence will be disabled because acks is set to 0, not set to 'all'.
2024-12-31 21:01:39.109 ProducerConfig values: 
	acks = 0
	auto.include.jmx.reporter = true
	batch.size = 10
	bootstrap.servers = [127.0.0.1:59354]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2024-12-31 21:01:39.114 Kafka version: 3.4.1
2024-12-31 21:01:39.114 Kafka commitId: 8a516edc2755df89
2024-12-31 21:01:39.114 Kafka startTimeMs: 1735650099114
2024-12-31 21:01:39.114 [Controller id=0] New topics: [Set(__consumer_offsets)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(__consumer_offsets,Some(WSspNx8OQR6OwmvPCnXNZg),HashMap(__consumer_offsets-4 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-3 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-2 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:01:39.115 [Controller id=0] New partition creation callback for __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2024-12-31 21:01:39.115 [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:01:39.115 [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:01:39.115 [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:01:39.115 [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:01:39.115 [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:01:39.115 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:01:39.116 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:01:39.121 [Producer clientId=producer-2] Resetting the last seen epoch of partition pong-message-topic-0 to 0 since the associated topicId changed from null to 7UIYtsZqRAq49sQp6SAqWQ
2024-12-31 21:01:39.121 [Producer clientId=producer-2] Resetting the last seen epoch of partition pong-message-topic-1 to 0 since the associated topicId changed from null to 7UIYtsZqRAq49sQp6SAqWQ
2024-12-31 21:01:39.121 [Producer clientId=producer-2] Cluster ID: K3Ve5ER1QAqxbOzPTQqjQQ
2024-12-31 21:01:39.128 [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:01:39.128 [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:01:39.128 [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:01:39.128 [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:01:39.128 [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:01:39.128 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 5 become-leader and 0 become-follower partitions
2024-12-31 21:01:39.130 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 5 partitions
2024-12-31 21:01:39.130 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:01:39.130 [Broker id=0] Handling LeaderAndIsr request correlationId 3 from controller 0 for 5 partitions
2024-12-31 21:01:39.131 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-4, __consumer_offsets-3, __consumer_offsets-2, __consumer_offsets-0, __consumer_offsets-1)
2024-12-31 21:01:39.132 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 3 from controller 0 epoch 1 as part of the become-leader transition for 5 partitions
2024-12-31 21:01:39.147 [LogLoader partition=__consumer_offsets-3, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.65722cd2-db14-42e2-99a7-6c723ecdf45d4770093949029589497] Loading producer state till offset 0 with message format version 2
2024-12-31 21:01:39.148 Created log for partition __consumer_offsets-3 in C:\Users\joech\AppData\Local\Temp\spring.kafka.65722cd2-db14-42e2-99a7-6c723ecdf45d4770093949029589497\__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:01:39.151 [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
2024-12-31 21:01:39.151 [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0
2024-12-31 21:01:39.151 [Broker id=0] Leader __consumer_offsets-3 with topic id Some(WSspNx8OQR6OwmvPCnXNZg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:01:39.164 [LogLoader partition=__consumer_offsets-2, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.65722cd2-db14-42e2-99a7-6c723ecdf45d4770093949029589497] Loading producer state till offset 0 with message format version 2
2024-12-31 21:01:39.165 Created log for partition __consumer_offsets-2 in C:\Users\joech\AppData\Local\Temp\spring.kafka.65722cd2-db14-42e2-99a7-6c723ecdf45d4770093949029589497\__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:01:39.165 [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
2024-12-31 21:01:39.165 [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0
2024-12-31 21:01:39.165 [Broker id=0] Leader __consumer_offsets-2 with topic id Some(WSspNx8OQR6OwmvPCnXNZg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:01:39.177 [LogLoader partition=__consumer_offsets-4, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.65722cd2-db14-42e2-99a7-6c723ecdf45d4770093949029589497] Loading producer state till offset 0 with message format version 2
2024-12-31 21:01:39.178 Created log for partition __consumer_offsets-4 in C:\Users\joech\AppData\Local\Temp\spring.kafka.65722cd2-db14-42e2-99a7-6c723ecdf45d4770093949029589497\__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:01:39.178 [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
2024-12-31 21:01:39.178 [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0
2024-12-31 21:01:39.179 [Broker id=0] Leader __consumer_offsets-4 with topic id Some(WSspNx8OQR6OwmvPCnXNZg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:01:39.191 [LogLoader partition=__consumer_offsets-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.65722cd2-db14-42e2-99a7-6c723ecdf45d4770093949029589497] Loading producer state till offset 0 with message format version 2
2024-12-31 21:01:39.191 Created log for partition __consumer_offsets-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.65722cd2-db14-42e2-99a7-6c723ecdf45d4770093949029589497\__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:01:39.193 [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
2024-12-31 21:01:39.193 [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0
2024-12-31 21:01:39.193 [Broker id=0] Leader __consumer_offsets-1 with topic id Some(WSspNx8OQR6OwmvPCnXNZg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:01:39.203 [LogLoader partition=__consumer_offsets-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.65722cd2-db14-42e2-99a7-6c723ecdf45d4770093949029589497] Loading producer state till offset 0 with message format version 2
2024-12-31 21:01:39.204 Created log for partition __consumer_offsets-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.65722cd2-db14-42e2-99a7-6c723ecdf45d4770093949029589497\__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:01:39.204 [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
2024-12-31 21:01:39.204 [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0
2024-12-31 21:01:39.204 [Broker id=0] Leader __consumer_offsets-0 with topic id Some(WSspNx8OQR6OwmvPCnXNZg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:01:39.207 [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 0
2024-12-31 21:01:39.208 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0
2024-12-31 21:01:39.208 [GroupCoordinator 0]: Elected as the group coordinator for partition 2 in epoch 0
2024-12-31 21:01:39.208 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0
2024-12-31 21:01:39.208 [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 0
2024-12-31 21:01:39.208 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0
2024-12-31 21:01:39.208 [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 0
2024-12-31 21:01:39.208 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0
2024-12-31 21:01:39.208 [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 0
2024-12-31 21:01:39.208 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0
2024-12-31 21:01:39.208 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler.
2024-12-31 21:01:39.208 [Broker id=0] Finished LeaderAndIsr request in 78ms correlationId 3 from controller 0 for 5 partitions
2024-12-31 21:01:39.208 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler.
2024-12-31 21:01:39.208 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler.
2024-12-31 21:01:39.208 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler.
2024-12-31 21:01:39.208 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler.
2024-12-31 21:01:39.209 [Broker id=0] Add 5 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 4
2024-12-31 21:01:39.308 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Discovered group coordinator localhost:59354 (id: 2147483647 rack: null)
2024-12-31 21:01:39.309 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] (Re-)joining group
2024-12-31 21:01:39.313 [GroupCoordinator 0]: Dynamic member with unknown member id joins group pong-service in Empty state. Created a new member id consumer-pong-service-3-68ca9c81-514c-49cb-9f72-000f212b0d29 and request the member to rejoin with this id.
2024-12-31 21:01:39.313 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Request joining group due to: need to re-join with the given member-id: consumer-pong-service-3-68ca9c81-514c-49cb-9f72-000f212b0d29
2024-12-31 21:01:39.314 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2024-12-31 21:01:39.314 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] (Re-)joining group
2024-12-31 21:01:39.315 [GroupCoordinator 0]: Preparing to rebalance group pong-service in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-pong-service-3-68ca9c81-514c-49cb-9f72-000f212b0d29 with group instance id None; client reason: rebalance failed due to MemberIdRequiredException)
2024-12-31 21:01:39.316 [GroupCoordinator 0]: Stabilized group pong-service generation 1 (__consumer_offsets-2) with 1 members
2024-12-31 21:01:39.317 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Successfully joined group with generation Generation{generationId=1, memberId='consumer-pong-service-3-68ca9c81-514c-49cb-9f72-000f212b0d29', protocol='range'}
2024-12-31 21:01:39.317 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Finished assignment for group at generation 1: {consumer-pong-service-3-68ca9c81-514c-49cb-9f72-000f212b0d29=Assignment(partitions=[pong-message-topic-0, pong-message-topic-1])}
2024-12-31 21:01:39.319 [GroupCoordinator 0]: Assignment received from leader consumer-pong-service-3-68ca9c81-514c-49cb-9f72-000f212b0d29 for group pong-service for generation 1. The group has 1 members, 0 of which are static.
2024-12-31 21:01:39.321 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Successfully synced group in generation Generation{generationId=1, memberId='consumer-pong-service-3-68ca9c81-514c-49cb-9f72-000f212b0d29', protocol='range'}
2024-12-31 21:01:39.322 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Notifying assignor about the new Assignment(partitions=[pong-message-topic-0, pong-message-topic-1])
2024-12-31 21:01:39.322 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Adding newly assigned partitions: pong-message-topic-0, pong-message-topic-1
2024-12-31 21:01:39.323 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Found no committed offset for partition pong-message-topic-0
2024-12-31 21:01:39.323 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Found no committed offset for partition pong-message-topic-1
2024-12-31 21:01:39.324 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Found no committed offset for partition pong-message-topic-0
2024-12-31 21:01:39.325 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Found no committed offset for partition pong-message-topic-1
2024-12-31 21:01:39.326 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting offset for partition pong-message-topic-0 to position FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:59354 (id: 0 rack: null)], epoch=0}}.
2024-12-31 21:01:39.326 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting offset for partition pong-message-topic-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:59354 (id: 0 rack: null)], epoch=0}}.
2024-12-31 21:01:39.334 pong-service: partitions assigned: [pong-message-topic-0, pong-message-topic-1]
2024-12-31 21:01:39.455 [KafkaServer id=0] shutting down
2024-12-31 21:01:39.455 [KafkaServer id=0] Starting controlled shutdown
2024-12-31 21:01:39.460 [Controller id=0] Shutting down broker 0
2024-12-31 21:01:39.461 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:01:39.461 [KafkaServer id=0] Controlled shutdown request returned successfully after 1ms
2024-12-31 21:01:39.462 [/config/changes-event-process-thread]: Shutting down
2024-12-31 21:01:39.462 [/config/changes-event-process-thread]: Stopped
2024-12-31 21:01:39.462 [/config/changes-event-process-thread]: Shutdown completed
2024-12-31 21:01:39.462 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
2024-12-31 21:01:39.463 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:01:39.463 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:01:39.463 [Producer clientId=producer-2] Node 0 disconnected.
2024-12-31 21:01:39.463 [Producer clientId=producer-2] Cancelled in-flight METADATA request with correlation id 4 due to node 0 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 30000ms)
2024-12-31 21:01:39.463 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:01:39.463 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Cancelled in-flight FETCH request with correlation id 16 due to node 0 being disconnected (elapsed time since creation: 128ms, elapsed time since send: 128ms, request timeout: 30000ms)
2024-12-31 21:01:39.463 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Cancelled in-flight METADATA request with correlation id 17 due to node 0 being disconnected (elapsed time since creation: 44ms, elapsed time since send: 44ms, request timeout: 30000ms)
2024-12-31 21:01:39.463 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node 2147483647 disconnected.
2024-12-31 21:01:39.465 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors
2024-12-31 21:01:39.465 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2024-12-31 21:01:39.465 [data-plane Kafka Request Handler on Broker 0], shutting down
2024-12-31 21:01:39.465 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Group coordinator localhost:59354 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
2024-12-31 21:01:39.465 [data-plane Kafka Request Handler on Broker 0], shut down completely
2024-12-31 21:01:39.465 [ExpirationReaper-0-AlterAcls]: Shutting down
2024-12-31 21:01:39.466 [ExpirationReaper-0-AlterAcls]: Stopped
2024-12-31 21:01:39.466 [ExpirationReaper-0-AlterAcls]: Shutdown completed
2024-12-31 21:01:39.466 [KafkaApi-0] Shutdown complete.
2024-12-31 21:01:39.466 [ExpirationReaper-0-topic]: Shutting down
2024-12-31 21:01:39.466 [ExpirationReaper-0-topic]: Stopped
2024-12-31 21:01:39.466 [ExpirationReaper-0-topic]: Shutdown completed
2024-12-31 21:01:39.466 [TransactionCoordinator id=0] Shutting down.
2024-12-31 21:01:39.466 [Transaction State Manager 0]: Shutdown complete
2024-12-31 21:01:39.466 [Transaction Marker Channel Manager 0]: Shutting down
2024-12-31 21:01:39.466 [Transaction Marker Channel Manager 0]: Shutdown completed
2024-12-31 21:01:39.466 [Transaction Marker Channel Manager 0]: Stopped
2024-12-31 21:01:39.466 [TransactionCoordinator id=0] Shutdown complete.
2024-12-31 21:01:39.467 [GroupCoordinator 0]: Shutting down.
2024-12-31 21:01:39.467 [ExpirationReaper-0-Heartbeat]: Shutting down
2024-12-31 21:01:39.467 [ExpirationReaper-0-Heartbeat]: Shutdown completed
2024-12-31 21:01:39.467 [ExpirationReaper-0-Heartbeat]: Stopped
2024-12-31 21:01:39.467 [ExpirationReaper-0-Rebalance]: Shutting down
2024-12-31 21:01:39.467 [ExpirationReaper-0-Rebalance]: Stopped
2024-12-31 21:01:39.467 [ExpirationReaper-0-Rebalance]: Shutdown completed
2024-12-31 21:01:39.467 [GroupCoordinator 0]: Shutdown complete.
2024-12-31 21:01:39.467 [ReplicaManager broker=0] Shutting down
2024-12-31 21:01:39.467 [LogDirFailureHandler]: Shutting down
2024-12-31 21:01:39.467 [LogDirFailureHandler]: Stopped
2024-12-31 21:01:39.467 [LogDirFailureHandler]: Shutdown completed
2024-12-31 21:01:39.467 [ReplicaFetcherManager on broker 0] shutting down
2024-12-31 21:01:39.467 [ReplicaFetcherManager on broker 0] shutdown completed
2024-12-31 21:01:39.467 [ReplicaAlterLogDirsManager on broker 0] shutting down
2024-12-31 21:01:39.467 [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2024-12-31 21:01:39.467 [ExpirationReaper-0-Fetch]: Shutting down
2024-12-31 21:01:39.467 [ExpirationReaper-0-Fetch]: Stopped
2024-12-31 21:01:39.467 [ExpirationReaper-0-Fetch]: Shutdown completed
2024-12-31 21:01:39.467 [ExpirationReaper-0-Produce]: Shutting down
2024-12-31 21:01:39.468 [ExpirationReaper-0-Produce]: Stopped
2024-12-31 21:01:39.468 [ExpirationReaper-0-Produce]: Shutdown completed
2024-12-31 21:01:39.468 [ExpirationReaper-0-DeleteRecords]: Shutting down
2024-12-31 21:01:39.468 [ExpirationReaper-0-DeleteRecords]: Stopped
2024-12-31 21:01:39.468 [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2024-12-31 21:01:39.468 [ExpirationReaper-0-ElectLeader]: Shutting down
2024-12-31 21:01:39.468 [ExpirationReaper-0-ElectLeader]: Shutdown completed
2024-12-31 21:01:39.468 [ExpirationReaper-0-ElectLeader]: Stopped
2024-12-31 21:01:39.477 [ReplicaManager broker=0] Shut down completely
2024-12-31 21:01:39.477 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutting down
2024-12-31 21:01:39.478 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Stopped
2024-12-31 21:01:39.478 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutdown completed
2024-12-31 21:01:39.478 Broker to controller channel manager for alterPartition shutdown
2024-12-31 21:01:39.478 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down
2024-12-31 21:01:39.478 [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped
2024-12-31 21:01:39.478 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed
2024-12-31 21:01:39.478 Broker to controller channel manager for forwarding shutdown
2024-12-31 21:01:39.478 Shutting down.
2024-12-31 21:01:39.478 Shutting down the log cleaner.
2024-12-31 21:01:39.478 [kafka-log-cleaner-thread-0]: Shutting down
2024-12-31 21:01:39.478 [kafka-log-cleaner-thread-0]: Stopped
2024-12-31 21:01:39.478 [kafka-log-cleaner-thread-0]: Shutdown completed
2024-12-31 21:01:39.493 [ProducerStateManager partition=pong-message-topic-0] Wrote producer snapshot at offset 1 with 0 producer ids in 2 ms.
2024-12-31 21:01:39.504 [ProducerStateManager partition=__consumer_offsets-2] Wrote producer snapshot at offset 3 with 0 producer ids in 2 ms.
2024-12-31 21:01:39.512 Shutdown complete.
2024-12-31 21:01:39.512 [ControllerEventThread controllerId=0] Shutting down
2024-12-31 21:01:39.512 [ControllerEventThread controllerId=0] Stopped
2024-12-31 21:01:39.512 [ControllerEventThread controllerId=0] Shutdown completed
2024-12-31 21:01:39.513 [PartitionStateMachine controllerId=0] Stopped partition state machine
2024-12-31 21:01:39.513 [ReplicaStateMachine controllerId=0] Stopped replica state machine
2024-12-31 21:01:39.513 [RequestSendThread controllerId=0] Shutting down
2024-12-31 21:01:39.513 [RequestSendThread controllerId=0] Shutdown completed
2024-12-31 21:01:39.513 [RequestSendThread controllerId=0] Stopped
2024-12-31 21:01:39.513 [Controller id=0] Resigned
2024-12-31 21:01:39.513 [feature-zk-node-event-process-thread]: Shutting down
2024-12-31 21:01:39.513 [feature-zk-node-event-process-thread]: Shutdown completed
2024-12-31 21:01:39.513 [feature-zk-node-event-process-thread]: Stopped
2024-12-31 21:01:39.514 [ZooKeeperClient Kafka server] Closing.
2024-12-31 21:01:39.563 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:01:39.563 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node 0 (localhost/127.0.0.1:59354) could not be established. Broker may not be available.
2024-12-31 21:01:39.564 [Producer clientId=producer-2] Node 0 disconnected.
2024-12-31 21:01:39.564 [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:59354) could not be established. Broker may not be available.
2024-12-31 21:01:39.617 EventThread shut down for session: 0x1001769d0780000
2024-12-31 21:01:39.617 Session: 0x1001769d0780000 closed
2024-12-31 21:01:39.617 [ZooKeeperClient Kafka server] Closed.
2024-12-31 21:01:39.617 [ThrottledChannelReaper-Fetch]: Shutting down
2024-12-31 21:01:39.617 [ThrottledChannelReaper-Fetch]: Stopped
2024-12-31 21:01:39.617 [ThrottledChannelReaper-Fetch]: Shutdown completed
2024-12-31 21:01:39.618 [ThrottledChannelReaper-Produce]: Shutting down
2024-12-31 21:01:39.618 [ThrottledChannelReaper-Produce]: Shutdown completed
2024-12-31 21:01:39.618 [ThrottledChannelReaper-Produce]: Stopped
2024-12-31 21:01:39.618 [ThrottledChannelReaper-Request]: Shutting down
2024-12-31 21:01:39.618 [ThrottledChannelReaper-Request]: Stopped
2024-12-31 21:01:39.618 [ThrottledChannelReaper-Request]: Shutdown completed
2024-12-31 21:01:39.618 [ThrottledChannelReaper-ControllerMutation]: Shutting down
2024-12-31 21:01:39.618 [ThrottledChannelReaper-ControllerMutation]: Stopped
2024-12-31 21:01:39.618 [ThrottledChannelReaper-ControllerMutation]: Shutdown completed
2024-12-31 21:01:39.618 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server
2024-12-31 21:01:39.626 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed
2024-12-31 21:01:39.626 Metrics scheduler closed
2024-12-31 21:01:39.626 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:01:39.626 Metrics reporters closed
2024-12-31 21:01:39.626 Broker and topic stats closed
2024-12-31 21:01:39.626 App info kafka.server for 0 unregistered
2024-12-31 21:01:39.626 [KafkaServer id=0] shut down completed
2024-12-31 21:01:39.637 ConnnectionExpirerThread interrupted
2024-12-31 21:01:39.637 selector thread exitted run method
2024-12-31 21:01:39.637 accept thread exitted run method
2024-12-31 21:01:39.637 selector thread exitted run method
2024-12-31 21:01:39.637 shutting down
2024-12-31 21:01:39.638 Shutting down
2024-12-31 21:01:39.638 Draining request throttler queue
2024-12-31 21:01:39.638 RequestThrottler shutdown. Dropped 0 requests
2024-12-31 21:01:39.638 Shutting down
2024-12-31 21:01:39.638 Shutting down
2024-12-31 21:01:39.638 Shutting down
2024-12-31 21:01:39.638 PrepRequestProcessor exited loop!
2024-12-31 21:01:39.638 SyncRequestProcessor exited!
2024-12-31 21:01:39.638 shutdown of request processor complete
2024-12-31 21:01:39.653 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Revoke previously assigned partitions pong-message-topic-0, pong-message-topic-1
2024-12-31 21:01:39.653 pong-service: partitions revoked: [pong-message-topic-0, pong-message-topic-1]
2024-12-31 21:01:39.653 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:01:39.653 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:01:39.653 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Unsubscribed all topics or patterns and assigned partitions
2024-12-31 21:01:39.653 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:01:39.653 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:01:39.653 Metrics scheduler closed
2024-12-31 21:01:39.653 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:01:39.653 Metrics reporters closed
2024-12-31 21:01:39.653 App info kafka.consumer for consumer-pong-service-3 unregistered
2024-12-31 21:01:39.653 pong-service: Consumer stopped
2024-12-31 21:01:39.655 [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 30000 ms.
2024-12-31 21:01:39.655 Metrics scheduler closed
2024-12-31 21:01:39.655 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:01:39.655 Metrics reporters closed
2024-12-31 21:01:39.655 App info kafka.producer for producer-2 unregistered
2024-12-31 21:01:39.659 Closing JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:01:39.659 HikariPool-3 - Shutdown initiated...
2024-12-31 21:01:39.660 HikariPool-3 - Shutdown completed.
2024-12-31 21:01:57.157 Could not detect default configuration classes for test class [com.demo.kafka.KafkaSpec]: KafkaSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:01:57.242 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.kafka.KafkaSpec
2024-12-31 21:01:57.602 Registered kafka:type=kafka.Log4jController MBean
2024-12-31 21:01:57.670 
2024-12-31 21:01:57.671   ______                  _                                          
2024-12-31 21:01:57.671  |___  /                 | |                                         
2024-12-31 21:01:57.671     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __   
2024-12-31 21:01:57.671    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__|
2024-12-31 21:01:57.671   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |    
2024-12-31 21:01:57.671  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_|
2024-12-31 21:01:57.671                                               | |                     
2024-12-31 21:01:57.671                                               |_|                     
2024-12-31 21:01:57.671 
2024-12-31 21:02:02.964 Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT
2024-12-31 21:02:02.965 Server environment:host.name=Joe
2024-12-31 21:02:02.965 Server environment:java.version=17.0.12
2024-12-31 21:02:02.965 Server environment:java.vendor=Oracle Corporation
2024-12-31 21:02:02.965 Server environment:java.home=C:\work\jdk-17
2024-12-31 21:02:02.965 Server environment:java.class.path=C:\work\ideaIC-2024.2.0.2.win\lib\idea_rt.jar;C:\work\ideaIC-2024.2.0.2.win\plugins\junit\lib\junit5-rt.jar;C:\work\ideaIC-2024.2.0.2.win\plugins\junit\lib\junit-rt.jar;C:\code\hsbc\demo\pong\target\test-classes;C:\code\hsbc\demo\pong\target\classes;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-webflux\3.1.4\spring-boot-starter-webflux-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter\3.1.4\spring-boot-starter-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot\3.1.4\spring-boot-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-autoconfigure\3.1.4\spring-boot-autoconfigure-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-logging\3.1.4\spring-boot-starter-logging-3.1.4.jar;C:\Users\joech\.m2\repository\ch\qos\logback\logback-classic\1.4.11\logback-classic-1.4.11.jar;C:\Users\joech\.m2\repository\ch\qos\logback\logback-core\1.4.11\logback-core-1.4.11.jar;C:\Users\joech\.m2\repository\org\apache\logging\log4j\log4j-to-slf4j\2.20.0\log4j-to-slf4j-2.20.0.jar;C:\Users\joech\.m2\repository\org\apache\logging\log4j\log4j-api\2.20.0\log4j-api-2.20.0.jar;C:\Users\joech\.m2\repository\org\slf4j\jul-to-slf4j\2.0.9\jul-to-slf4j-2.0.9.jar;C:\Users\joech\.m2\repository\jakarta\annotation\jakarta.annotation-api\2.1.1\jakarta.annotation-api-2.1.1.jar;C:\Users\joech\.m2\repository\org\yaml\snakeyaml\1.33\snakeyaml-1.33.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-json\3.1.4\spring-boot-starter-json-3.1.4.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\core\jackson-databind\2.15.2\jackson-databind-2.15.2.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\core\jackson-annotations\2.15.2\jackson-annotations-2.15.2.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\core\jackson-core\2.15.2\jackson-core-2.15.2.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.15.2\jackson-datatype-jdk8-2.15.2.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.15.2\jackson-datatype-jsr310-2.15.2.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\module\jackson-module-parameter-names\2.15.2\jackson-module-parameter-names-2.15.2.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-reactor-netty\3.1.4\spring-boot-starter-reactor-netty-3.1.4.jar;C:\Users\joech\.m2\repository\io\projectreactor\netty\reactor-netty-http\1.1.11\reactor-netty-http-1.1.11.jar;C:\Users\joech\.m2\repository\io\netty\netty-codec-http\4.1.97.Final\netty-codec-http-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-codec-http2\4.1.97.Final\netty-codec-http2-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-resolver-dns\4.1.97.Final\netty-resolver-dns-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-codec-dns\4.1.97.Final\netty-codec-dns-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-resolver-dns-native-macos\4.1.97.Final\netty-resolver-dns-native-macos-4.1.97.Final-osx-x86_64.jar;C:\Users\joech\.m2\repository\io\netty\netty-resolver-dns-classes-macos\4.1.97.Final\netty-resolver-dns-classes-macos-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final-linux-x86_64.jar;C:\Users\joech\.m2\repository\io\projectreactor\netty\reactor-netty-core\1.1.11\reactor-netty-core-1.1.11.jar;C:\Users\joech\.m2\repository\io\netty\netty-handler-proxy\4.1.97.Final\netty-handler-proxy-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-codec-socks\4.1.97.Final\netty-codec-socks-4.1.97.Final.jar;C:\Users\joech\.m2\repository\org\springframework\spring-web\6.0.12\spring-web-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-beans\6.0.12\spring-beans-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-webflux\6.0.12\spring-webflux-6.0.12.jar;C:\Users\joech\.m2\repository\io\projectreactor\reactor-core\3.5.10\reactor-core-3.5.10.jar;C:\Users\joech\.m2\repository\org\reactivestreams\reactive-streams\1.0.4\reactive-streams-1.0.4.jar;C:\Users\joech\.m2\repository\com\google\guava\guava\19.0\guava-19.0.jar;C:\Users\joech\.m2\repository\commons-io\commons-io\2.11.0\commons-io-2.11.0.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-data-redis\3.1.4\spring-boot-starter-data-redis-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\data\spring-data-redis\3.1.4\spring-data-redis-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\data\spring-data-keyvalue\3.1.4\spring-data-keyvalue-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\spring-oxm\6.0.12\spring-oxm-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-aop\6.0.12\spring-aop-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-context-support\6.0.12\spring-context-support-6.0.12.jar;C:\Users\joech\.m2\repository\io\lettuce\lettuce-core\6.2.6.RELEASE\lettuce-core-6.2.6.RELEASE.jar;C:\Users\joech\.m2\repository\io\netty\netty-common\4.1.97.Final\netty-common-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-handler\4.1.97.Final\netty-handler-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-resolver\4.1.97.Final\netty-resolver-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-buffer\4.1.97.Final\netty-buffer-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-transport-native-unix-common\4.1.97.Final\netty-transport-native-unix-common-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-codec\4.1.97.Final\netty-codec-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-transport\4.1.97.Final\netty-transport-4.1.97.Final.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-data-jpa\3.1.4\spring-boot-starter-data-jpa-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-aop\3.1.4\spring-boot-starter-aop-3.1.4.jar;C:\Users\joech\.m2\repository\org\aspectj\aspectjweaver\1.9.20\aspectjweaver-1.9.20.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-jdbc\3.1.4\spring-boot-starter-jdbc-3.1.4.jar;C:\Users\joech\.m2\repository\com\zaxxer\HikariCP\5.0.1\HikariCP-5.0.1.jar;C:\Users\joech\.m2\repository\org\springframework\spring-jdbc\6.0.12\spring-jdbc-6.0.12.jar;C:\Users\joech\.m2\repository\org\hibernate\orm\hibernate-core\6.2.9.Final\hibernate-core-6.2.9.Final.jar;C:\Users\joech\.m2\repository\jakarta\persistence\jakarta.persistence-api\3.1.0\jakarta.persistence-api-3.1.0.jar;C:\Users\joech\.m2\repository\jakarta\transaction\jakarta.transaction-api\2.0.1\jakarta.transaction-api-2.0.1.jar;C:\Users\joech\.m2\repository\org\jboss\logging\jboss-logging\3.5.3.Final\jboss-logging-3.5.3.Final.jar;C:\Users\joech\.m2\repository\org\hibernate\common\hibernate-commons-annotations\6.0.6.Final\hibernate-commons-annotations-6.0.6.Final.jar;C:\Users\joech\.m2\repository\io\smallrye\jandex\3.0.5\jandex-3.0.5.jar;C:\Users\joech\.m2\repository\com\fasterxml\classmate\1.5.1\classmate-1.5.1.jar;C:\Users\joech\.m2\repository\net\bytebuddy\byte-buddy\1.14.8\byte-buddy-1.14.8.jar;C:\Users\joech\.m2\repository\org\glassfish\jaxb\jaxb-runtime\4.0.3\jaxb-runtime-4.0.3.jar;C:\Users\joech\.m2\repository\org\glassfish\jaxb\jaxb-core\4.0.3\jaxb-core-4.0.3.jar;C:\Users\joech\.m2\repository\org\eclipse\angus\angus-activation\2.0.1\angus-activation-2.0.1.jar;C:\Users\joech\.m2\repository\org\glassfish\jaxb\txw2\4.0.3\txw2-4.0.3.jar;C:\Users\joech\.m2\repository\com\sun\istack\istack-commons-runtime\4.1.2\istack-commons-runtime-4.1.2.jar;C:\Users\joech\.m2\repository\jakarta\inject\jakarta.inject-api\2.0.1\jakarta.inject-api-2.0.1.jar;C:\Users\joech\.m2\repository\org\antlr\antlr4-runtime\4.10.1\antlr4-runtime-4.10.1.jar;C:\Users\joech\.m2\repository\org\springframework\data\spring-data-jpa\3.1.4\spring-data-jpa-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\data\spring-data-commons\3.1.4\spring-data-commons-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\spring-orm\6.0.12\spring-orm-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-aspects\6.0.12\spring-aspects-6.0.12.jar;C:\Users\joech\.m2\repository\org\postgresql\postgresql\42.6.0\postgresql-42.6.0.jar;C:\Users\joech\.m2\repository\org\checkerframework\checker-qual\3.31.0\checker-qual-3.31.0.jar;C:\Users\joech\.m2\repository\org\springframework\kafka\spring-kafka\3.0.11\spring-kafka-3.0.11.jar;C:\Users\joech\.m2\repository\org\springframework\spring-context\6.0.12\spring-context-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-expression\6.0.12\spring-expression-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-messaging\6.0.12\spring-messaging-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-tx\6.0.12\spring-tx-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\retry\spring-retry\2.0.3\spring-retry-2.0.3.jar;C:\Users\joech\.m2\repository\io\micrometer\micrometer-observation\1.11.4\micrometer-observation-1.11.4.jar;C:\Users\joech\.m2\repository\io\micrometer\micrometer-commons\1.11.4\micrometer-commons-1.11.4.jar;C:\Users\joech\.m2\repository\com\google\code\findbugs\jsr305\3.0.2\jsr305-3.0.2.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1.jar;C:\Users\joech\.m2\repository\com\github\luben\zstd-jni\1.5.2-1\zstd-jni-1.5.2-1.jar;C:\Users\joech\.m2\repository\org\lz4\lz4-java\1.8.0\lz4-java-1.8.0.jar;C:\Users\joech\.m2\repository\org\xerial\snappy\snappy-java\1.1.8.4\snappy-java-1.1.8.4.jar;C:\Users\joech\.m2\repository\org\slf4j\slf4j-api\2.0.9\slf4j-api-2.0.9.jar;C:\Users\joech\.m2\repository\com\h2database\h2\1.4.200\h2-1.4.200.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-test\3.1.4\spring-boot-starter-test-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-test\3.1.4\spring-boot-test-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-test-autoconfigure\3.1.4\spring-boot-test-autoconfigure-3.1.4.jar;C:\Users\joech\.m2\repository\com\jayway\jsonpath\json-path\2.8.0\json-path-2.8.0.jar;C:\Users\joech\.m2\repository\jakarta\xml\bind\jakarta.xml.bind-api\4.0.1\jakarta.xml.bind-api-4.0.1.jar;C:\Users\joech\.m2\repository\jakarta\activation\jakarta.activation-api\2.1.2\jakarta.activation-api-2.1.2.jar;C:\Users\joech\.m2\repository\net\minidev\json-smart\2.4.11\json-smart-2.4.11.jar;C:\Users\joech\.m2\repository\net\minidev\accessors-smart\2.4.11\accessors-smart-2.4.11.jar;C:\Users\joech\.m2\repository\org\ow2\asm\asm\9.3\asm-9.3.jar;C:\Users\joech\.m2\repository\org\assertj\assertj-core\3.24.2\assertj-core-3.24.2.jar;C:\Users\joech\.m2\repository\org\hamcrest\hamcrest\2.2\hamcrest-2.2.jar;C:\Users\joech\.m2\repository\org\junit\jupiter\junit-jupiter\5.9.3\junit-jupiter-5.9.3.jar;C:\Users\joech\.m2\repository\org\junit\jupiter\junit-jupiter-params\5.9.3\junit-jupiter-params-5.9.3.jar;C:\Users\joech\.m2\repository\org\junit\jupiter\junit-jupiter-engine\5.9.3\junit-jupiter-engine-5.9.3.jar;C:\Users\joech\.m2\repository\org\mockito\mockito-core\5.3.1\mockito-core-5.3.1.jar;C:\Users\joech\.m2\repository\net\bytebuddy\byte-buddy-agent\1.14.8\byte-buddy-agent-1.14.8.jar;C:\Users\joech\.m2\repository\org\objenesis\objenesis\3.3\objenesis-3.3.jar;C:\Users\joech\.m2\repository\org\mockito\mockito-junit-jupiter\5.3.1\mockito-junit-jupiter-5.3.1.jar;C:\Users\joech\.m2\repository\org\skyscreamer\jsonassert\1.5.1\jsonassert-1.5.1.jar;C:\Users\joech\.m2\repository\com\vaadin\external\google\android-json\0.0.20131108.vaadin1\android-json-0.0.20131108.vaadin1.jar;C:\Users\joech\.m2\repository\org\springframework\spring-core\6.0.12\spring-core-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-jcl\6.0.12\spring-jcl-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-test\6.0.12\spring-test-6.0.12.jar;C:\Users\joech\.m2\repository\org\xmlunit\xmlunit-core\2.9.1\xmlunit-core-2.9.1.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy\4.0.15\groovy-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-ant\4.0.15\groovy-ant-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\ant\ant\1.10.14\ant-1.10.14.jar;C:\Users\joech\.m2\repository\org\apache\ant\ant-junit\1.10.14\ant-junit-1.10.14.jar;C:\Users\joech\.m2\repository\org\apache\ant\ant-launcher\1.10.14\ant-launcher-1.10.14.jar;C:\Users\joech\.m2\repository\org\apache\ant\ant-antlr\1.10.14\ant-antlr-1.10.14.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-cli-picocli\4.0.15\groovy-cli-picocli-4.0.15.jar;C:\Users\joech\.m2\repository\info\picocli\picocli\4.7.5\picocli-4.7.5.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-console\4.0.15\groovy-console-4.0.15.jar;C:\Users\joech\.m2\repository\com\github\javaparser\javaparser-core\3.25.5\javaparser-core-3.25.5.jar;C:\Users\joech\.m2\repository\org\ow2\asm\asm-util\9.5\asm-util-9.5.jar;C:\Users\joech\.m2\repository\org\ow2\asm\asm-tree\9.5\asm-tree-9.5.jar;C:\Users\joech\.m2\repository\org\ow2\asm\asm-analysis\9.5\asm-analysis-9.5.jar;C:\Users\joech\.m2\repository\org\abego\treelayout\org.abego.treelayout.core\1.0.3\org.abego.treelayout.core-1.0.3.jar;C:\Users\joech\.m2\repository\org\apache\ivy\ivy\2.5.2\ivy-2.5.2.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-datetime\4.0.15\groovy-datetime-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-docgenerator\4.0.15\groovy-docgenerator-4.0.15.jar;C:\Users\joech\.m2\repository\com\thoughtworks\qdox\qdox\1.12.1\qdox-1.12.1.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-groovydoc\4.0.15\groovy-groovydoc-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-groovysh\4.0.15\groovy-groovysh-4.0.15.jar;C:\Users\joech\.m2\repository\jline\jline\2.14.6\jline-2.14.6.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-jmx\4.0.15\groovy-jmx-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-json\4.0.15\groovy-json-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-jsr223\4.0.15\groovy-jsr223-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-macro\4.0.15\groovy-macro-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-nio\4.0.15\groovy-nio-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-servlet\4.0.15\groovy-servlet-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-sql\4.0.15\groovy-sql-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-swing\4.0.15\groovy-swing-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-templates\4.0.15\groovy-templates-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-test\4.0.15\groovy-test-4.0.15.jar;C:\Users\joech\.m2\repository\junit\junit\4.13.2\junit-4.13.2.jar;C:\Users\joech\.m2\repository\org\hamcrest\hamcrest-core\2.2\hamcrest-core-2.2.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-test-junit5\4.0.15\groovy-test-junit5-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-xml\4.0.15\groovy-xml-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-yaml\4.0.15\groovy-yaml-4.0.15.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\dataformat\jackson-dataformat-yaml\2.15.2\jackson-dataformat-yaml-2.15.2.jar;C:\Users\joech\.m2\repository\org\spockframework\spock-core\2.4-M1-groovy-4.0\spock-core-2.4-M1-groovy-4.0.jar;C:\Users\joech\.m2\repository\org\junit\platform\junit-platform-engine\1.9.3\junit-platform-engine-1.9.3.jar;C:\Users\joech\.m2\repository\org\opentest4j\opentest4j\1.2.0\opentest4j-1.2.0.jar;C:\Users\joech\.m2\repository\org\junit\platform\junit-platform-commons\1.9.3\junit-platform-commons-1.9.3.jar;C:\Users\joech\.m2\repository\org\apiguardian\apiguardian-api\1.1.2\apiguardian-api-1.1.2.jar;C:\Users\joech\.m2\repository\org\spockframework\spock-spring\2.4-M1-groovy-4.0\spock-spring-2.4-M1-groovy-4.0.jar;C:\Users\joech\.m2\repository\com\athaydes\spock-reports\2.5.1-groovy-4.0\spock-reports-2.5.1-groovy-4.0.jar;C:\Users\joech\.m2\repository\com\github\codemonstur\embedded-redis\1.4.2\embedded-redis-1.4.2.jar;C:\Users\joech\.m2\repository\redis\clients\jedis\4.3.2\jedis-4.3.2.jar;C:\Users\joech\.m2\repository\org\apache\commons\commons-pool2\2.11.1\commons-pool2-2.11.1.jar;C:\Users\joech\.m2\repository\org\json\json\20220320\json-20220320.jar;C:\Users\joech\.m2\repository\com\google\code\gson\gson\2.10.1\gson-2.10.1.jar;C:\Users\joech\.m2\repository\org\springframework\kafka\spring-kafka-test\3.0.11\spring-kafka-test-3.0.11.jar;C:\Users\joech\.m2\repository\org\apache\zookeeper\zookeeper\3.6.3\zookeeper-3.6.3.jar;C:\Users\joech\.m2\repository\org\apache\zookeeper\zookeeper-jute\3.6.3\zookeeper-jute-3.6.3.jar;C:\Users\joech\.m2\repository\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;C:\Users\joech\.m2\repository\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-transport-classes-epoll\4.1.97.Final\netty-transport-classes-epoll-4.1.97.Final.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1-test.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-metadata\3.4.1\kafka-metadata-3.4.1.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-server-common\3.4.1\kafka-server-common-3.4.1.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-raft\3.4.1\kafka-raft-3.4.1.jar;C:\Users\joech\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-streams-test-utils\3.4.1\kafka-streams-test-utils-3.4.1.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-streams\3.4.1\kafka-streams-3.4.1.jar;C:\Users\joech\.m2\repository\org\rocksdb\rocksdbjni\7.1.2\rocksdbjni-7.1.2.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1.jar;C:\Users\joech\.m2\repository\org\scala-lang\scala-library\2.13.10\scala-library-2.13.10.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-group-coordinator\3.4.1\kafka-group-coordinator-3.4.1.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-storage\3.4.1\kafka-storage-3.4.1.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-storage-api\3.4.1\kafka-storage-api-3.4.1.jar;C:\Users\joech\.m2\repository\net\sourceforge\argparse4j\argparse4j\0.7.0\argparse4j-0.7.0.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\module\jackson-module-scala_2.13\2.15.2\jackson-module-scala_2.13-2.15.2.jar;C:\Users\joech\.m2\repository\com\thoughtworks\paranamer\paranamer\2.8\paranamer-2.8.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\dataformat\jackson-dataformat-csv\2.15.2\jackson-dataformat-csv-2.15.2.jar;C:\Users\joech\.m2\repository\net\sf\jopt-simple\jopt-simple\5.0.4\jopt-simple-5.0.4.jar;C:\Users\joech\.m2\repository\org\bitbucket\b_c\jose4j\0.9.3\jose4j-0.9.3.jar;C:\Users\joech\.m2\repository\org\scala-lang\modules\scala-collection-compat_2.13\2.10.0\scala-collection-compat_2.13-2.10.0.jar;C:\Users\joech\.m2\repository\org\scala-lang\modules\scala-java8-compat_2.13\1.0.2\scala-java8-compat_2.13-1.0.2.jar;C:\Users\joech\.m2\repository\org\scala-lang\scala-reflect\2.13.10\scala-reflect-2.13.10.jar;C:\Users\joech\.m2\repository\com\typesafe\scala-logging\scala-logging_2.13\3.9.4\scala-logging_2.13-3.9.4.jar;C:\Users\joech\.m2\repository\io\dropwizard\metrics\metrics-core\4.2.19\metrics-core-4.2.19.jar;C:\Users\joech\.m2\repository\commons-cli\commons-cli\1.4\commons-cli-1.4.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1-test.jar;C:\Users\joech\.m2\repository\org\junit\jupiter\junit-jupiter-api\5.9.3\junit-jupiter-api-5.9.3.jar;C:\Users\joech\.m2\repository\org\junit\platform\junit-platform-launcher\1.9.3\junit-platform-launcher-1.9.3.jar;C:\Users\joech\.m2\repository\org\awaitility\awaitility\4.2.0\awaitility-4.2.0.jar
2024-12-31 21:02:02.966 Server environment:java.library.path=C:\work\jdk-17\bin;C:\windows\Sun\Java\bin;C:\windows\system32;C:\windows;C:\work\python312\Scripts\;C:\work\python312\;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program\Git\cmd;C:\Program\PowerShell\7\;C:\Program Files\dotnet\;C:\Users\joech\AppData\Local\Microsoft\WindowsApps;C:\Users\joech\AppData\Local\GitHubDesktop\bin;C:\Program\Microsoft VS Code\bin;C:\work\apache-maven-3.8.8\bin;C:\Program Files\Tesseract-OCR;C:\work\jdk-17\bin;;.
2024-12-31 21:02:02.966 Server environment:java.io.tmpdir=C:\Users\joech\AppData\Local\Temp\
2024-12-31 21:02:02.966 Server environment:java.compiler=<NA>
2024-12-31 21:02:02.966 Server environment:os.name=Windows 11
2024-12-31 21:02:02.966 Server environment:os.arch=amd64
2024-12-31 21:02:02.966 Server environment:os.version=10.0
2024-12-31 21:02:02.966 Server environment:user.name=joech
2024-12-31 21:02:02.966 Server environment:user.home=C:\Users\joech
2024-12-31 21:02:02.966 Server environment:user.dir=C:\code\hsbc\demo\pong
2024-12-31 21:02:02.966 Server environment:os.memory.free=82MB
2024-12-31 21:02:02.966 Server environment:os.memory.max=15816MB
2024-12-31 21:02:02.966 Server environment:os.memory.total=136MB
2024-12-31 21:02:02.966 zookeeper.enableEagerACLCheck = false
2024-12-31 21:02:02.968 zookeeper.digest.enabled = true
2024-12-31 21:02:02.968 zookeeper.closeSessionTxn.enabled = true
2024-12-31 21:02:02.968 zookeeper.flushDelay=0
2024-12-31 21:02:02.969 zookeeper.maxWriteQueuePollTime=0
2024-12-31 21:02:02.969 zookeeper.maxBatchSize=1000
2024-12-31 21:02:02.969 zookeeper.intBufferStartingSizeBytes = 1024
2024-12-31 21:02:02.971 zookeeper.snapshot.trust.empty : false
2024-12-31 21:02:02.989 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:02:02.990 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:02:02.991 zookeeper.snapshotSizeFactor = 0.33
2024-12-31 21:02:02.991 zookeeper.commitLogCount=500
2024-12-31 21:02:02.995 Weighed connection throttling is disabled
2024-12-31 21:02:02.997 minSessionTimeout set to 1600
2024-12-31 21:02:02.997 maxSessionTimeout set to 16000
2024-12-31 21:02:02.999 Response cache size is initialized with value 400.
2024-12-31 21:02:02.999 Response cache size is initialized with value 400.
2024-12-31 21:02:03.000 zookeeper.pathStats.slotCapacity = 60
2024-12-31 21:02:03.000 zookeeper.pathStats.slotDuration = 15
2024-12-31 21:02:03.000 zookeeper.pathStats.maxDepth = 6
2024-12-31 21:02:03.000 zookeeper.pathStats.initialDelay = 5
2024-12-31 21:02:03.000 zookeeper.pathStats.delay = 5
2024-12-31 21:02:03.000 zookeeper.pathStats.enabled = false
2024-12-31 21:02:03.002 The max bytes for all large requests are set to 104857600
2024-12-31 21:02:03.002 The large request threshold is set to -1
2024-12-31 21:02:03.002 Created server with tickTime 800 minSessionTimeout 1600 maxSessionTimeout 16000 clientPortListenBacklog -1 datadir C:\Users\joech\AppData\Local\Temp\kafka-6089678770009383965\version-2 snapdir C:\Users\joech\AppData\Local\Temp\kafka-17207506098324438319\version-2
2024-12-31 21:02:03.044 maxCnxns is not configured, using default value 0.
2024-12-31 21:02:03.046 Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers.
2024-12-31 21:02:03.053 binding to port /127.0.0.1:0
2024-12-31 21:02:03.073 zookeeper.snapshot.compression.method = CHECKED
2024-12-31 21:02:03.074 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-17207506098324438319\version-2\snapshot.0
2024-12-31 21:02:03.079 Snapshot loaded in 21 ms, highest zxid is 0x0, digest is 1371985504
2024-12-31 21:02:03.079 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-17207506098324438319\version-2\snapshot.0
2024-12-31 21:02:03.080 Snapshot taken in 1 ms
2024-12-31 21:02:03.090 PrepRequestProcessor (sid:0) started, reconfigEnabled=false
2024-12-31 21:02:03.090 zookeeper.request_throttler.shutdownTimeout = 10000
2024-12-31 21:02:03.334 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.98f117fd-c496-4f55-9831-73f1a793f0bf3668178615976838553
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59381
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:02:03.356 Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
2024-12-31 21:02:03.426 starting
2024-12-31 21:02:03.428 Connecting to zookeeper on 127.0.0.1:59381
2024-12-31 21:02:03.444 [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:59381.
2024-12-31 21:02:08.685 Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT
2024-12-31 21:02:08.686 Client environment:host.name=Joe
2024-12-31 21:02:08.686 Client environment:java.version=17.0.12
2024-12-31 21:02:08.686 Client environment:java.vendor=Oracle Corporation
2024-12-31 21:02:08.686 Client environment:java.home=C:\work\jdk-17
2024-12-31 21:02:08.686 Client environment:java.class.path=C:\work\ideaIC-2024.2.0.2.win\lib\idea_rt.jar;C:\work\ideaIC-2024.2.0.2.win\plugins\junit\lib\junit5-rt.jar;C:\work\ideaIC-2024.2.0.2.win\plugins\junit\lib\junit-rt.jar;C:\code\hsbc\demo\pong\target\test-classes;C:\code\hsbc\demo\pong\target\classes;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-webflux\3.1.4\spring-boot-starter-webflux-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter\3.1.4\spring-boot-starter-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot\3.1.4\spring-boot-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-autoconfigure\3.1.4\spring-boot-autoconfigure-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-logging\3.1.4\spring-boot-starter-logging-3.1.4.jar;C:\Users\joech\.m2\repository\ch\qos\logback\logback-classic\1.4.11\logback-classic-1.4.11.jar;C:\Users\joech\.m2\repository\ch\qos\logback\logback-core\1.4.11\logback-core-1.4.11.jar;C:\Users\joech\.m2\repository\org\apache\logging\log4j\log4j-to-slf4j\2.20.0\log4j-to-slf4j-2.20.0.jar;C:\Users\joech\.m2\repository\org\apache\logging\log4j\log4j-api\2.20.0\log4j-api-2.20.0.jar;C:\Users\joech\.m2\repository\org\slf4j\jul-to-slf4j\2.0.9\jul-to-slf4j-2.0.9.jar;C:\Users\joech\.m2\repository\jakarta\annotation\jakarta.annotation-api\2.1.1\jakarta.annotation-api-2.1.1.jar;C:\Users\joech\.m2\repository\org\yaml\snakeyaml\1.33\snakeyaml-1.33.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-json\3.1.4\spring-boot-starter-json-3.1.4.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\core\jackson-databind\2.15.2\jackson-databind-2.15.2.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\core\jackson-annotations\2.15.2\jackson-annotations-2.15.2.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\core\jackson-core\2.15.2\jackson-core-2.15.2.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.15.2\jackson-datatype-jdk8-2.15.2.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.15.2\jackson-datatype-jsr310-2.15.2.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\module\jackson-module-parameter-names\2.15.2\jackson-module-parameter-names-2.15.2.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-reactor-netty\3.1.4\spring-boot-starter-reactor-netty-3.1.4.jar;C:\Users\joech\.m2\repository\io\projectreactor\netty\reactor-netty-http\1.1.11\reactor-netty-http-1.1.11.jar;C:\Users\joech\.m2\repository\io\netty\netty-codec-http\4.1.97.Final\netty-codec-http-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-codec-http2\4.1.97.Final\netty-codec-http2-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-resolver-dns\4.1.97.Final\netty-resolver-dns-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-codec-dns\4.1.97.Final\netty-codec-dns-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-resolver-dns-native-macos\4.1.97.Final\netty-resolver-dns-native-macos-4.1.97.Final-osx-x86_64.jar;C:\Users\joech\.m2\repository\io\netty\netty-resolver-dns-classes-macos\4.1.97.Final\netty-resolver-dns-classes-macos-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final-linux-x86_64.jar;C:\Users\joech\.m2\repository\io\projectreactor\netty\reactor-netty-core\1.1.11\reactor-netty-core-1.1.11.jar;C:\Users\joech\.m2\repository\io\netty\netty-handler-proxy\4.1.97.Final\netty-handler-proxy-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-codec-socks\4.1.97.Final\netty-codec-socks-4.1.97.Final.jar;C:\Users\joech\.m2\repository\org\springframework\spring-web\6.0.12\spring-web-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-beans\6.0.12\spring-beans-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-webflux\6.0.12\spring-webflux-6.0.12.jar;C:\Users\joech\.m2\repository\io\projectreactor\reactor-core\3.5.10\reactor-core-3.5.10.jar;C:\Users\joech\.m2\repository\org\reactivestreams\reactive-streams\1.0.4\reactive-streams-1.0.4.jar;C:\Users\joech\.m2\repository\com\google\guava\guava\19.0\guava-19.0.jar;C:\Users\joech\.m2\repository\commons-io\commons-io\2.11.0\commons-io-2.11.0.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-data-redis\3.1.4\spring-boot-starter-data-redis-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\data\spring-data-redis\3.1.4\spring-data-redis-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\data\spring-data-keyvalue\3.1.4\spring-data-keyvalue-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\spring-oxm\6.0.12\spring-oxm-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-aop\6.0.12\spring-aop-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-context-support\6.0.12\spring-context-support-6.0.12.jar;C:\Users\joech\.m2\repository\io\lettuce\lettuce-core\6.2.6.RELEASE\lettuce-core-6.2.6.RELEASE.jar;C:\Users\joech\.m2\repository\io\netty\netty-common\4.1.97.Final\netty-common-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-handler\4.1.97.Final\netty-handler-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-resolver\4.1.97.Final\netty-resolver-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-buffer\4.1.97.Final\netty-buffer-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-transport-native-unix-common\4.1.97.Final\netty-transport-native-unix-common-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-codec\4.1.97.Final\netty-codec-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-transport\4.1.97.Final\netty-transport-4.1.97.Final.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-data-jpa\3.1.4\spring-boot-starter-data-jpa-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-aop\3.1.4\spring-boot-starter-aop-3.1.4.jar;C:\Users\joech\.m2\repository\org\aspectj\aspectjweaver\1.9.20\aspectjweaver-1.9.20.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-jdbc\3.1.4\spring-boot-starter-jdbc-3.1.4.jar;C:\Users\joech\.m2\repository\com\zaxxer\HikariCP\5.0.1\HikariCP-5.0.1.jar;C:\Users\joech\.m2\repository\org\springframework\spring-jdbc\6.0.12\spring-jdbc-6.0.12.jar;C:\Users\joech\.m2\repository\org\hibernate\orm\hibernate-core\6.2.9.Final\hibernate-core-6.2.9.Final.jar;C:\Users\joech\.m2\repository\jakarta\persistence\jakarta.persistence-api\3.1.0\jakarta.persistence-api-3.1.0.jar;C:\Users\joech\.m2\repository\jakarta\transaction\jakarta.transaction-api\2.0.1\jakarta.transaction-api-2.0.1.jar;C:\Users\joech\.m2\repository\org\jboss\logging\jboss-logging\3.5.3.Final\jboss-logging-3.5.3.Final.jar;C:\Users\joech\.m2\repository\org\hibernate\common\hibernate-commons-annotations\6.0.6.Final\hibernate-commons-annotations-6.0.6.Final.jar;C:\Users\joech\.m2\repository\io\smallrye\jandex\3.0.5\jandex-3.0.5.jar;C:\Users\joech\.m2\repository\com\fasterxml\classmate\1.5.1\classmate-1.5.1.jar;C:\Users\joech\.m2\repository\net\bytebuddy\byte-buddy\1.14.8\byte-buddy-1.14.8.jar;C:\Users\joech\.m2\repository\org\glassfish\jaxb\jaxb-runtime\4.0.3\jaxb-runtime-4.0.3.jar;C:\Users\joech\.m2\repository\org\glassfish\jaxb\jaxb-core\4.0.3\jaxb-core-4.0.3.jar;C:\Users\joech\.m2\repository\org\eclipse\angus\angus-activation\2.0.1\angus-activation-2.0.1.jar;C:\Users\joech\.m2\repository\org\glassfish\jaxb\txw2\4.0.3\txw2-4.0.3.jar;C:\Users\joech\.m2\repository\com\sun\istack\istack-commons-runtime\4.1.2\istack-commons-runtime-4.1.2.jar;C:\Users\joech\.m2\repository\jakarta\inject\jakarta.inject-api\2.0.1\jakarta.inject-api-2.0.1.jar;C:\Users\joech\.m2\repository\org\antlr\antlr4-runtime\4.10.1\antlr4-runtime-4.10.1.jar;C:\Users\joech\.m2\repository\org\springframework\data\spring-data-jpa\3.1.4\spring-data-jpa-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\data\spring-data-commons\3.1.4\spring-data-commons-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\spring-orm\6.0.12\spring-orm-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-aspects\6.0.12\spring-aspects-6.0.12.jar;C:\Users\joech\.m2\repository\org\postgresql\postgresql\42.6.0\postgresql-42.6.0.jar;C:\Users\joech\.m2\repository\org\checkerframework\checker-qual\3.31.0\checker-qual-3.31.0.jar;C:\Users\joech\.m2\repository\org\springframework\kafka\spring-kafka\3.0.11\spring-kafka-3.0.11.jar;C:\Users\joech\.m2\repository\org\springframework\spring-context\6.0.12\spring-context-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-expression\6.0.12\spring-expression-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-messaging\6.0.12\spring-messaging-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-tx\6.0.12\spring-tx-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\retry\spring-retry\2.0.3\spring-retry-2.0.3.jar;C:\Users\joech\.m2\repository\io\micrometer\micrometer-observation\1.11.4\micrometer-observation-1.11.4.jar;C:\Users\joech\.m2\repository\io\micrometer\micrometer-commons\1.11.4\micrometer-commons-1.11.4.jar;C:\Users\joech\.m2\repository\com\google\code\findbugs\jsr305\3.0.2\jsr305-3.0.2.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1.jar;C:\Users\joech\.m2\repository\com\github\luben\zstd-jni\1.5.2-1\zstd-jni-1.5.2-1.jar;C:\Users\joech\.m2\repository\org\lz4\lz4-java\1.8.0\lz4-java-1.8.0.jar;C:\Users\joech\.m2\repository\org\xerial\snappy\snappy-java\1.1.8.4\snappy-java-1.1.8.4.jar;C:\Users\joech\.m2\repository\org\slf4j\slf4j-api\2.0.9\slf4j-api-2.0.9.jar;C:\Users\joech\.m2\repository\com\h2database\h2\1.4.200\h2-1.4.200.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-test\3.1.4\spring-boot-starter-test-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-test\3.1.4\spring-boot-test-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-test-autoconfigure\3.1.4\spring-boot-test-autoconfigure-3.1.4.jar;C:\Users\joech\.m2\repository\com\jayway\jsonpath\json-path\2.8.0\json-path-2.8.0.jar;C:\Users\joech\.m2\repository\jakarta\xml\bind\jakarta.xml.bind-api\4.0.1\jakarta.xml.bind-api-4.0.1.jar;C:\Users\joech\.m2\repository\jakarta\activation\jakarta.activation-api\2.1.2\jakarta.activation-api-2.1.2.jar;C:\Users\joech\.m2\repository\net\minidev\json-smart\2.4.11\json-smart-2.4.11.jar;C:\Users\joech\.m2\repository\net\minidev\accessors-smart\2.4.11\accessors-smart-2.4.11.jar;C:\Users\joech\.m2\repository\org\ow2\asm\asm\9.3\asm-9.3.jar;C:\Users\joech\.m2\repository\org\assertj\assertj-core\3.24.2\assertj-core-3.24.2.jar;C:\Users\joech\.m2\repository\org\hamcrest\hamcrest\2.2\hamcrest-2.2.jar;C:\Users\joech\.m2\repository\org\junit\jupiter\junit-jupiter\5.9.3\junit-jupiter-5.9.3.jar;C:\Users\joech\.m2\repository\org\junit\jupiter\junit-jupiter-params\5.9.3\junit-jupiter-params-5.9.3.jar;C:\Users\joech\.m2\repository\org\junit\jupiter\junit-jupiter-engine\5.9.3\junit-jupiter-engine-5.9.3.jar;C:\Users\joech\.m2\repository\org\mockito\mockito-core\5.3.1\mockito-core-5.3.1.jar;C:\Users\joech\.m2\repository\net\bytebuddy\byte-buddy-agent\1.14.8\byte-buddy-agent-1.14.8.jar;C:\Users\joech\.m2\repository\org\objenesis\objenesis\3.3\objenesis-3.3.jar;C:\Users\joech\.m2\repository\org\mockito\mockito-junit-jupiter\5.3.1\mockito-junit-jupiter-5.3.1.jar;C:\Users\joech\.m2\repository\org\skyscreamer\jsonassert\1.5.1\jsonassert-1.5.1.jar;C:\Users\joech\.m2\repository\com\vaadin\external\google\android-json\0.0.20131108.vaadin1\android-json-0.0.20131108.vaadin1.jar;C:\Users\joech\.m2\repository\org\springframework\spring-core\6.0.12\spring-core-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-jcl\6.0.12\spring-jcl-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-test\6.0.12\spring-test-6.0.12.jar;C:\Users\joech\.m2\repository\org\xmlunit\xmlunit-core\2.9.1\xmlunit-core-2.9.1.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy\4.0.15\groovy-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-ant\4.0.15\groovy-ant-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\ant\ant\1.10.14\ant-1.10.14.jar;C:\Users\joech\.m2\repository\org\apache\ant\ant-junit\1.10.14\ant-junit-1.10.14.jar;C:\Users\joech\.m2\repository\org\apache\ant\ant-launcher\1.10.14\ant-launcher-1.10.14.jar;C:\Users\joech\.m2\repository\org\apache\ant\ant-antlr\1.10.14\ant-antlr-1.10.14.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-cli-picocli\4.0.15\groovy-cli-picocli-4.0.15.jar;C:\Users\joech\.m2\repository\info\picocli\picocli\4.7.5\picocli-4.7.5.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-console\4.0.15\groovy-console-4.0.15.jar;C:\Users\joech\.m2\repository\com\github\javaparser\javaparser-core\3.25.5\javaparser-core-3.25.5.jar;C:\Users\joech\.m2\repository\org\ow2\asm\asm-util\9.5\asm-util-9.5.jar;C:\Users\joech\.m2\repository\org\ow2\asm\asm-tree\9.5\asm-tree-9.5.jar;C:\Users\joech\.m2\repository\org\ow2\asm\asm-analysis\9.5\asm-analysis-9.5.jar;C:\Users\joech\.m2\repository\org\abego\treelayout\org.abego.treelayout.core\1.0.3\org.abego.treelayout.core-1.0.3.jar;C:\Users\joech\.m2\repository\org\apache\ivy\ivy\2.5.2\ivy-2.5.2.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-datetime\4.0.15\groovy-datetime-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-docgenerator\4.0.15\groovy-docgenerator-4.0.15.jar;C:\Users\joech\.m2\repository\com\thoughtworks\qdox\qdox\1.12.1\qdox-1.12.1.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-groovydoc\4.0.15\groovy-groovydoc-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-groovysh\4.0.15\groovy-groovysh-4.0.15.jar;C:\Users\joech\.m2\repository\jline\jline\2.14.6\jline-2.14.6.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-jmx\4.0.15\groovy-jmx-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-json\4.0.15\groovy-json-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-jsr223\4.0.15\groovy-jsr223-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-macro\4.0.15\groovy-macro-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-nio\4.0.15\groovy-nio-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-servlet\4.0.15\groovy-servlet-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-sql\4.0.15\groovy-sql-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-swing\4.0.15\groovy-swing-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-templates\4.0.15\groovy-templates-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-test\4.0.15\groovy-test-4.0.15.jar;C:\Users\joech\.m2\repository\junit\junit\4.13.2\junit-4.13.2.jar;C:\Users\joech\.m2\repository\org\hamcrest\hamcrest-core\2.2\hamcrest-core-2.2.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-test-junit5\4.0.15\groovy-test-junit5-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-xml\4.0.15\groovy-xml-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-yaml\4.0.15\groovy-yaml-4.0.15.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\dataformat\jackson-dataformat-yaml\2.15.2\jackson-dataformat-yaml-2.15.2.jar;C:\Users\joech\.m2\repository\org\spockframework\spock-core\2.4-M1-groovy-4.0\spock-core-2.4-M1-groovy-4.0.jar;C:\Users\joech\.m2\repository\org\junit\platform\junit-platform-engine\1.9.3\junit-platform-engine-1.9.3.jar;C:\Users\joech\.m2\repository\org\opentest4j\opentest4j\1.2.0\opentest4j-1.2.0.jar;C:\Users\joech\.m2\repository\org\junit\platform\junit-platform-commons\1.9.3\junit-platform-commons-1.9.3.jar;C:\Users\joech\.m2\repository\org\apiguardian\apiguardian-api\1.1.2\apiguardian-api-1.1.2.jar;C:\Users\joech\.m2\repository\org\spockframework\spock-spring\2.4-M1-groovy-4.0\spock-spring-2.4-M1-groovy-4.0.jar;C:\Users\joech\.m2\repository\com\athaydes\spock-reports\2.5.1-groovy-4.0\spock-reports-2.5.1-groovy-4.0.jar;C:\Users\joech\.m2\repository\com\github\codemonstur\embedded-redis\1.4.2\embedded-redis-1.4.2.jar;C:\Users\joech\.m2\repository\redis\clients\jedis\4.3.2\jedis-4.3.2.jar;C:\Users\joech\.m2\repository\org\apache\commons\commons-pool2\2.11.1\commons-pool2-2.11.1.jar;C:\Users\joech\.m2\repository\org\json\json\20220320\json-20220320.jar;C:\Users\joech\.m2\repository\com\google\code\gson\gson\2.10.1\gson-2.10.1.jar;C:\Users\joech\.m2\repository\org\springframework\kafka\spring-kafka-test\3.0.11\spring-kafka-test-3.0.11.jar;C:\Users\joech\.m2\repository\org\apache\zookeeper\zookeeper\3.6.3\zookeeper-3.6.3.jar;C:\Users\joech\.m2\repository\org\apache\zookeeper\zookeeper-jute\3.6.3\zookeeper-jute-3.6.3.jar;C:\Users\joech\.m2\repository\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;C:\Users\joech\.m2\repository\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-transport-classes-epoll\4.1.97.Final\netty-transport-classes-epoll-4.1.97.Final.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1-test.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-metadata\3.4.1\kafka-metadata-3.4.1.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-server-common\3.4.1\kafka-server-common-3.4.1.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-raft\3.4.1\kafka-raft-3.4.1.jar;C:\Users\joech\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-streams-test-utils\3.4.1\kafka-streams-test-utils-3.4.1.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-streams\3.4.1\kafka-streams-3.4.1.jar;C:\Users\joech\.m2\repository\org\rocksdb\rocksdbjni\7.1.2\rocksdbjni-7.1.2.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1.jar;C:\Users\joech\.m2\repository\org\scala-lang\scala-library\2.13.10\scala-library-2.13.10.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-group-coordinator\3.4.1\kafka-group-coordinator-3.4.1.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-storage\3.4.1\kafka-storage-3.4.1.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-storage-api\3.4.1\kafka-storage-api-3.4.1.jar;C:\Users\joech\.m2\repository\net\sourceforge\argparse4j\argparse4j\0.7.0\argparse4j-0.7.0.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\module\jackson-module-scala_2.13\2.15.2\jackson-module-scala_2.13-2.15.2.jar;C:\Users\joech\.m2\repository\com\thoughtworks\paranamer\paranamer\2.8\paranamer-2.8.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\dataformat\jackson-dataformat-csv\2.15.2\jackson-dataformat-csv-2.15.2.jar;C:\Users\joech\.m2\repository\net\sf\jopt-simple\jopt-simple\5.0.4\jopt-simple-5.0.4.jar;C:\Users\joech\.m2\repository\org\bitbucket\b_c\jose4j\0.9.3\jose4j-0.9.3.jar;C:\Users\joech\.m2\repository\org\scala-lang\modules\scala-collection-compat_2.13\2.10.0\scala-collection-compat_2.13-2.10.0.jar;C:\Users\joech\.m2\repository\org\scala-lang\modules\scala-java8-compat_2.13\1.0.2\scala-java8-compat_2.13-1.0.2.jar;C:\Users\joech\.m2\repository\org\scala-lang\scala-reflect\2.13.10\scala-reflect-2.13.10.jar;C:\Users\joech\.m2\repository\com\typesafe\scala-logging\scala-logging_2.13\3.9.4\scala-logging_2.13-3.9.4.jar;C:\Users\joech\.m2\repository\io\dropwizard\metrics\metrics-core\4.2.19\metrics-core-4.2.19.jar;C:\Users\joech\.m2\repository\commons-cli\commons-cli\1.4\commons-cli-1.4.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1-test.jar;C:\Users\joech\.m2\repository\org\junit\jupiter\junit-jupiter-api\5.9.3\junit-jupiter-api-5.9.3.jar;C:\Users\joech\.m2\repository\org\junit\platform\junit-platform-launcher\1.9.3\junit-platform-launcher-1.9.3.jar;C:\Users\joech\.m2\repository\org\awaitility\awaitility\4.2.0\awaitility-4.2.0.jar
2024-12-31 21:02:08.686 Client environment:java.library.path=C:\work\jdk-17\bin;C:\windows\Sun\Java\bin;C:\windows\system32;C:\windows;C:\work\python312\Scripts\;C:\work\python312\;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program\Git\cmd;C:\Program\PowerShell\7\;C:\Program Files\dotnet\;C:\Users\joech\AppData\Local\Microsoft\WindowsApps;C:\Users\joech\AppData\Local\GitHubDesktop\bin;C:\Program\Microsoft VS Code\bin;C:\work\apache-maven-3.8.8\bin;C:\Program Files\Tesseract-OCR;C:\work\jdk-17\bin;;.
2024-12-31 21:02:08.686 Client environment:java.io.tmpdir=C:\Users\joech\AppData\Local\Temp\
2024-12-31 21:02:08.686 Client environment:java.compiler=<NA>
2024-12-31 21:02:08.686 Client environment:os.name=Windows 11
2024-12-31 21:02:08.686 Client environment:os.arch=amd64
2024-12-31 21:02:08.686 Client environment:os.version=10.0
2024-12-31 21:02:08.686 Client environment:user.name=joech
2024-12-31 21:02:08.687 Client environment:user.home=C:\Users\joech
2024-12-31 21:02:08.687 Client environment:user.dir=C:\code\hsbc\demo\pong
2024-12-31 21:02:08.687 Client environment:os.memory.free=107MB
2024-12-31 21:02:08.687 Client environment:os.memory.max=15816MB
2024-12-31 21:02:08.687 Client environment:os.memory.total=136MB
2024-12-31 21:02:08.690 Initiating client connection, connectString=127.0.0.1:59381 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@5ac53c06
2024-12-31 21:02:08.694 jute.maxbuffer value is 4194304 Bytes
2024-12-31 21:02:08.701 zookeeper.request.timeout value is 0. feature enabled=false
2024-12-31 21:02:08.703 [ZooKeeperClient Kafka server] Waiting until connected.
2024-12-31 21:02:08.704 Opening socket connection to server /127.0.0.1:59381.
2024-12-31 21:02:08.705 Socket connection established, initiating session, client: /127.0.0.1:59382, server: /127.0.0.1:59381
2024-12-31 21:02:08.713 Creating new log file: log.1
2024-12-31 21:02:08.727 ZooKeeper audit is disabled.
2024-12-31 21:02:08.732 Session establishment complete on server /127.0.0.1:59381, session id = 0x100176a320a0000, negotiated timeout = 16000
2024-12-31 21:02:08.735 [ZooKeeperClient Kafka server] Connected.
2024-12-31 21:02:09.005 Cluster ID = DyapT7fHSx2XjJAiIj_pxQ
2024-12-31 21:02:09.008 No meta.properties file under dir C:\Users\joech\AppData\Local\Temp\spring.kafka.98f117fd-c496-4f55-9831-73f1a793f0bf3668178615976838553\meta.properties
2024-12-31 21:02:09.049 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.98f117fd-c496-4f55-9831-73f1a793f0bf3668178615976838553
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59381
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:02:09.083 [ThrottledChannelReaper-Fetch]: Starting
2024-12-31 21:02:09.083 [ThrottledChannelReaper-Produce]: Starting
2024-12-31 21:02:09.084 [ThrottledChannelReaper-Request]: Starting
2024-12-31 21:02:09.087 [ThrottledChannelReaper-ControllerMutation]: Starting
2024-12-31 21:02:09.123 Loading logs from log dirs ArraySeq(C:\Users\joech\AppData\Local\Temp\spring.kafka.98f117fd-c496-4f55-9831-73f1a793f0bf3668178615976838553)
2024-12-31 21:02:09.126 Attempting recovery for all logs in C:\Users\joech\AppData\Local\Temp\spring.kafka.98f117fd-c496-4f55-9831-73f1a793f0bf3668178615976838553 since no clean shutdown file was found
2024-12-31 21:02:09.138 Loaded 0 logs in 15ms.
2024-12-31 21:02:09.138 Starting log cleanup with a period of 300000 ms.
2024-12-31 21:02:09.142 Starting log flusher with a default period of 9223372036854775807 ms.
2024-12-31 21:02:09.155 Starting the log cleaner
2024-12-31 21:02:09.165 [kafka-log-cleaner-thread-0]: Starting
2024-12-31 21:02:09.179 [feature-zk-node-event-process-thread]: Starting
2024-12-31 21:02:09.188 Feature ZK node at path: /feature does not exist
2024-12-31 21:02:09.215 [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting
2024-12-31 21:02:09.546 Updated connection-accept-rate max connection creation rate to 2147483647
2024-12-31 21:02:09.553 Awaiting socket connections on localhost:59383.
2024-12-31 21:02:09.580 [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT)
2024-12-31 21:02:09.588 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Starting
2024-12-31 21:02:09.603 [ExpirationReaper-0-Produce]: Starting
2024-12-31 21:02:09.605 [ExpirationReaper-0-Fetch]: Starting
2024-12-31 21:02:09.605 [ExpirationReaper-0-DeleteRecords]: Starting
2024-12-31 21:02:09.606 [ExpirationReaper-0-ElectLeader]: Starting
2024-12-31 21:02:09.619 [LogDirFailureHandler]: Starting
2024-12-31 21:02:09.640 Creating /brokers/ids/0 (is it secure? false)
2024-12-31 21:02:09.658 Stat of the created znode at /brokers/ids/0 is: 25,25,1735650129650,1735650129650,1,0,0,72083338911416320,204,0,25

2024-12-31 21:02:09.659 Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:59383, czxid (broker epoch): 25
2024-12-31 21:02:09.712 [ControllerEventThread controllerId=0] Starting
2024-12-31 21:02:09.716 [ExpirationReaper-0-topic]: Starting
2024-12-31 21:02:09.724 [ExpirationReaper-0-Heartbeat]: Starting
2024-12-31 21:02:09.725 [ExpirationReaper-0-Rebalance]: Starting
2024-12-31 21:02:09.734 Successfully created /controller_epoch with initial epoch 0
2024-12-31 21:02:09.739 [Controller id=0] 0 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1
2024-12-31 21:02:09.743 [GroupCoordinator 0]: Starting up.
2024-12-31 21:02:09.744 [Controller id=0] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map())
2024-12-31 21:02:09.746 Feature ZK node created at path: /feature
2024-12-31 21:02:09.749 [GroupCoordinator 0]: Startup complete.
2024-12-31 21:02:09.774 [TransactionCoordinator id=0] Starting up.
2024-12-31 21:02:09.777 [TransactionCoordinator id=0] Startup complete.
2024-12-31 21:02:09.777 [Transaction Marker Channel Manager 0]: Starting
2024-12-31 21:02:09.780 [Controller id=0] Registering handlers
2024-12-31 21:02:09.780 [MetadataCache brokerId=0] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0).
2024-12-31 21:02:09.784 [Controller id=0] Deleting log dir event notifications
2024-12-31 21:02:09.788 [Controller id=0] Deleting isr change notifications
2024-12-31 21:02:09.790 [Controller id=0] Initializing controller context
2024-12-31 21:02:09.807 [Controller id=0] Initialized broker epochs cache: HashMap(0 -> 25)
2024-12-31 21:02:09.810 [ExpirationReaper-0-AlterAcls]: Starting
2024-12-31 21:02:09.829 [RequestSendThread controllerId=0] Starting
2024-12-31 21:02:09.830 [Controller id=0] Currently active brokers in the cluster: Set(0)
2024-12-31 21:02:09.832 [Controller id=0] Currently shutting brokers in the cluster: HashSet()
2024-12-31 21:02:09.832 [Controller id=0] Current list of topics in the cluster: HashSet()
2024-12-31 21:02:09.833 [Controller id=0] Fetching topic deletions in progress
2024-12-31 21:02:09.836 [Controller id=0] List of topics to be deleted: 
2024-12-31 21:02:09.836 [Controller id=0] List of topics ineligible for deletion: 
2024-12-31 21:02:09.837 [Controller id=0] Initializing topic deletion manager
2024-12-31 21:02:09.837 [Topic Deletion Manager 0] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet()
2024-12-31 21:02:09.839 [Controller id=0] Sending update metadata request
2024-12-31 21:02:09.841 [/config/changes-event-process-thread]: Starting
2024-12-31 21:02:09.842 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions
2024-12-31 21:02:09.850 [ReplicaStateMachine controllerId=0] Initializing replica state
2024-12-31 21:02:09.850 [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing.
2024-12-31 21:02:09.851 [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2024-12-31 21:02:09.858 Kafka version: 3.4.1
2024-12-31 21:02:09.858 Kafka commitId: 8a516edc2755df89
2024-12-31 21:02:09.858 Kafka startTimeMs: 1735650129853
2024-12-31 21:02:09.858 [ReplicaStateMachine controllerId=0] Triggering offline replica state changes
2024-12-31 21:02:09.859 [PartitionStateMachine controllerId=0] Initializing partition state
2024-12-31 21:02:09.859 [KafkaServer id=0] started
2024-12-31 21:02:09.860 [PartitionStateMachine controllerId=0] Triggering online partition state changes
2024-12-31 21:02:09.863 [RequestSendThread controllerId=0] Controller 0 connected to localhost:59383 (id: 0 rack: null) for sending state change requests
2024-12-31 21:02:09.866 [Controller id=0] Ready to serve as the new controller with epoch 1
2024-12-31 21:02:09.869 AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [127.0.0.1:59383]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-31 21:02:09.872 [Controller id=0] Partitions undergoing preferred replica election: 
2024-12-31 21:02:09.872 [Controller id=0] Partitions that completed preferred replica election: 
2024-12-31 21:02:09.874 [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2024-12-31 21:02:09.874 [Controller id=0] Resuming preferred replica election for partitions: 
2024-12-31 21:02:09.876 [Controller id=0] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered
2024-12-31 21:02:09.888 [Controller id=0] Starting the controller scheduler
2024-12-31 21:02:09.901 Kafka version: 3.4.1
2024-12-31 21:02:09.902 Kafka commitId: 8a516edc2755df89
2024-12-31 21:02:09.902 Kafka startTimeMs: 1735650129901
2024-12-31 21:02:09.926 [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use node localhost:59383 (id: 0 rack: null)
2024-12-31 21:02:09.991 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Recorded new controller, from now on will use node localhost:59383 (id: 0 rack: null)
2024-12-31 21:02:09.995 Creating topic pong-message-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0))
2024-12-31 21:02:10.020 [Controller id=0] New topics: [Set(pong-message-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(pong-message-topic,Some(3aoccVK6TGKf3DyogOIGPQ),Map(pong-message-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), pong-message-topic-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:02:10.022 [Controller id=0] New partition creation callback for pong-message-topic-0,pong-message-topic-1
2024-12-31 21:02:10.024 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:02:10.024 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:02:10.024 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:02:10.029 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:02:10.055 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:02:10.056 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:02:10.058 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2024-12-31 21:02:10.060 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2024-12-31 21:02:10.061 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:02:10.068 [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 for 2 partitions
2024-12-31 21:02:10.097 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(pong-message-topic-0, pong-message-topic-1)
2024-12-31 21:02:10.098 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2024-12-31 21:02:10.196 [LogLoader partition=pong-message-topic-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.98f117fd-c496-4f55-9831-73f1a793f0bf3668178615976838553] Loading producer state till offset 0 with message format version 2
2024-12-31 21:02:10.220 Created log for partition pong-message-topic-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.98f117fd-c496-4f55-9831-73f1a793f0bf3668178615976838553\pong-message-topic-0 with properties {}
2024-12-31 21:02:10.223 [Partition pong-message-topic-0 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-0
2024-12-31 21:02:10.224 [Partition pong-message-topic-0 broker=0] Log loaded for partition pong-message-topic-0 with initial high watermark 0
2024-12-31 21:02:10.225 [Broker id=0] Leader pong-message-topic-0 with topic id Some(3aoccVK6TGKf3DyogOIGPQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:02:10.242 [LogLoader partition=pong-message-topic-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.98f117fd-c496-4f55-9831-73f1a793f0bf3668178615976838553] Loading producer state till offset 0 with message format version 2
2024-12-31 21:02:10.243 Created log for partition pong-message-topic-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.98f117fd-c496-4f55-9831-73f1a793f0bf3668178615976838553\pong-message-topic-1 with properties {}
2024-12-31 21:02:10.243 [Partition pong-message-topic-1 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-1
2024-12-31 21:02:10.243 [Partition pong-message-topic-1 broker=0] Log loaded for partition pong-message-topic-1 with initial high watermark 0
2024-12-31 21:02:10.243 [Broker id=0] Leader pong-message-topic-1 with topic id Some(3aoccVK6TGKf3DyogOIGPQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:02:10.253 [Broker id=0] Finished LeaderAndIsr request in 189ms correlationId 1 from controller 0 for 2 partitions
2024-12-31 21:02:10.262 [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2
2024-12-31 21:02:10.272 App info kafka.admin.client for adminclient-1 unregistered
2024-12-31 21:02:10.274 Metrics scheduler closed
2024-12-31 21:02:10.274 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:02:10.275 Metrics reporters closed
2024-12-31 21:02:10.589 

Found multiple occurrences of org.json.JSONObject on the class path:

	jar:file:/C:/Users/joech/.m2/repository/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar!/org/json/JSONObject.class
	jar:file:/C:/Users/joech/.m2/repository/org/json/json/20220320/json-20220320.jar!/org/json/JSONObject.class

You may wish to exclude one of them to ensure predictable runtime behavior

2024-12-31 21:02:10.621 Starting KafkaSpec using Java 17.0.12 with PID 28680 (started by joech in C:\code\hsbc\demo\pong)
2024-12-31 21:02:10.622 No active profile set, falling back to 1 default profile: "default"
2024-12-31 21:02:11.286 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:02:11.288 Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2024-12-31 21:02:11.410 Finished Spring Data repository scanning in 113 ms. Found 1 JPA repository interfaces.
2024-12-31 21:02:11.427 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:02:11.428 Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2024-12-31 21:02:11.441 Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.demo.dao.MessageRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2024-12-31 21:02:11.441 Finished Spring Data repository scanning in 5 ms. Found 0 Redis repository interfaces.
2024-12-31 21:02:11.879 HHH000204: Processing PersistenceUnitInfo [name: default]
2024-12-31 21:02:11.943 HHH000412: Hibernate ORM core version 6.2.9.Final
2024-12-31 21:02:11.945 HHH000406: Using bytecode reflection optimizer
2024-12-31 21:02:12.086 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:02:12.193 No LoadTimeWeaver setup: ignoring JPA class transformer
2024-12-31 21:02:12.205 HikariPool-1 - Starting...
2024-12-31 21:02:12.335 HikariPool-1 - Added connection conn0: url=jdbc:h2:mem:testdb user=SA
2024-12-31 21:02:12.336 HikariPool-1 - Start completed.
2024-12-31 21:02:12.496 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:02:12.921 HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2024-12-31 21:02:12.989 Initialized JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:02:14.192 ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:59383]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-pong-service-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = pong-service
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2024-12-31 21:02:14.223 These configurations '[spring.json.trusted.packages]' were supplied but are not used yet.
2024-12-31 21:02:14.223 Kafka version: 3.4.1
2024-12-31 21:02:14.223 Kafka commitId: 8a516edc2755df89
2024-12-31 21:02:14.223 Kafka startTimeMs: 1735650134223
2024-12-31 21:02:14.224 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Subscribed to topic(s): pong-message-topic
2024-12-31 21:02:14.239 Started KafkaSpec in 3.913 seconds (process running for 18.999)
2024-12-31 21:02:14.249 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting the last seen epoch of partition pong-message-topic-0 to 0 since the associated topicId changed from null to 3aoccVK6TGKf3DyogOIGPQ
2024-12-31 21:02:14.249 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting the last seen epoch of partition pong-message-topic-1 to 0 since the associated topicId changed from null to 3aoccVK6TGKf3DyogOIGPQ
2024-12-31 21:02:14.251 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Cluster ID: DyapT7fHSx2XjJAiIj_pxQ
2024-12-31 21:02:14.252 Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0))
2024-12-31 21:02:14.258 [Controller id=0] New topics: [Set(__consumer_offsets)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(__consumer_offsets,Some(HgQR4-prTqqsrjydCnC1UA),HashMap(__consumer_offsets-4 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-3 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-2 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:02:14.258 [Controller id=0] New partition creation callback for __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2024-12-31 21:02:14.259 [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:02:14.259 [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:02:14.259 [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:02:14.259 [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:02:14.259 [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:02:14.259 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:02:14.260 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:02:14.267 [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:02:14.267 [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:02:14.267 [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:02:14.267 [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:02:14.267 [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:02:14.267 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 5 become-leader and 0 become-follower partitions
2024-12-31 21:02:14.268 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 5 partitions
2024-12-31 21:02:14.268 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:02:14.268 [Broker id=0] Handling LeaderAndIsr request correlationId 3 from controller 0 for 5 partitions
2024-12-31 21:02:14.271 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-4, __consumer_offsets-3, __consumer_offsets-2, __consumer_offsets-0, __consumer_offsets-1)
2024-12-31 21:02:14.271 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 3 from controller 0 epoch 1 as part of the become-leader transition for 5 partitions
2024-12-31 21:02:14.281 [LogLoader partition=__consumer_offsets-3, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.98f117fd-c496-4f55-9831-73f1a793f0bf3668178615976838553] Loading producer state till offset 0 with message format version 2
2024-12-31 21:02:14.282 Created log for partition __consumer_offsets-3 in C:\Users\joech\AppData\Local\Temp\spring.kafka.98f117fd-c496-4f55-9831-73f1a793f0bf3668178615976838553\__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:02:14.283 [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
2024-12-31 21:02:14.284 [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0
2024-12-31 21:02:14.284 [Broker id=0] Leader __consumer_offsets-3 with topic id Some(HgQR4-prTqqsrjydCnC1UA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:02:14.291 [LogLoader partition=__consumer_offsets-2, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.98f117fd-c496-4f55-9831-73f1a793f0bf3668178615976838553] Loading producer state till offset 0 with message format version 2
2024-12-31 21:02:14.292 Created log for partition __consumer_offsets-2 in C:\Users\joech\AppData\Local\Temp\spring.kafka.98f117fd-c496-4f55-9831-73f1a793f0bf3668178615976838553\__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:02:14.292 [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
2024-12-31 21:02:14.292 [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0
2024-12-31 21:02:14.292 [Broker id=0] Leader __consumer_offsets-2 with topic id Some(HgQR4-prTqqsrjydCnC1UA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:02:14.307 [LogLoader partition=__consumer_offsets-4, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.98f117fd-c496-4f55-9831-73f1a793f0bf3668178615976838553] Loading producer state till offset 0 with message format version 2
2024-12-31 21:02:14.308 Created log for partition __consumer_offsets-4 in C:\Users\joech\AppData\Local\Temp\spring.kafka.98f117fd-c496-4f55-9831-73f1a793f0bf3668178615976838553\__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:02:14.308 [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
2024-12-31 21:02:14.308 [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0
2024-12-31 21:02:14.308 [Broker id=0] Leader __consumer_offsets-4 with topic id Some(HgQR4-prTqqsrjydCnC1UA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:02:14.319 [LogLoader partition=__consumer_offsets-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.98f117fd-c496-4f55-9831-73f1a793f0bf3668178615976838553] Loading producer state till offset 0 with message format version 2
2024-12-31 21:02:14.320 Created log for partition __consumer_offsets-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.98f117fd-c496-4f55-9831-73f1a793f0bf3668178615976838553\__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:02:14.320 [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
2024-12-31 21:02:14.320 [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0
2024-12-31 21:02:14.320 [Broker id=0] Leader __consumer_offsets-1 with topic id Some(HgQR4-prTqqsrjydCnC1UA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:02:14.328 [LogLoader partition=__consumer_offsets-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.98f117fd-c496-4f55-9831-73f1a793f0bf3668178615976838553] Loading producer state till offset 0 with message format version 2
2024-12-31 21:02:14.330 Created log for partition __consumer_offsets-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.98f117fd-c496-4f55-9831-73f1a793f0bf3668178615976838553\__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:02:14.330 [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
2024-12-31 21:02:14.330 [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0
2024-12-31 21:02:14.330 [Broker id=0] Leader __consumer_offsets-0 with topic id Some(HgQR4-prTqqsrjydCnC1UA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:02:14.333 [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 0
2024-12-31 21:02:14.333 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0
2024-12-31 21:02:14.334 [GroupCoordinator 0]: Elected as the group coordinator for partition 2 in epoch 0
2024-12-31 21:02:14.334 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0
2024-12-31 21:02:14.334 [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 0
2024-12-31 21:02:14.334 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0
2024-12-31 21:02:14.334 [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 0
2024-12-31 21:02:14.334 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0
2024-12-31 21:02:14.334 [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 0
2024-12-31 21:02:14.335 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0
2024-12-31 21:02:14.335 [Broker id=0] Finished LeaderAndIsr request in 67ms correlationId 3 from controller 0 for 5 partitions
2024-12-31 21:02:14.336 [Broker id=0] Add 5 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 4
2024-12-31 21:02:14.337 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 4 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler.
2024-12-31 21:02:14.339 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler.
2024-12-31 21:02:14.339 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler.
2024-12-31 21:02:14.339 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler.
2024-12-31 21:02:14.339 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler.
2024-12-31 21:02:14.353 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Discovered group coordinator localhost:59383 (id: 2147483647 rack: null)
2024-12-31 21:02:14.355 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] (Re-)joining group
2024-12-31 21:02:14.373 [GroupCoordinator 0]: Dynamic member with unknown member id joins group pong-service in Empty state. Created a new member id consumer-pong-service-1-a08f3a94-56a0-4ccb-a7df-9f723b9afa8f and request the member to rejoin with this id.
2024-12-31 21:02:14.376 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: need to re-join with the given member-id: consumer-pong-service-1-a08f3a94-56a0-4ccb-a7df-9f723b9afa8f
2024-12-31 21:02:14.376 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2024-12-31 21:02:14.376 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] (Re-)joining group
2024-12-31 21:02:14.381 [GroupCoordinator 0]: Preparing to rebalance group pong-service in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-pong-service-1-a08f3a94-56a0-4ccb-a7df-9f723b9afa8f with group instance id None; client reason: rebalance failed due to MemberIdRequiredException)
2024-12-31 21:02:14.387 [GroupCoordinator 0]: Stabilized group pong-service generation 1 (__consumer_offsets-2) with 1 members
2024-12-31 21:02:14.390 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Successfully joined group with generation Generation{generationId=1, memberId='consumer-pong-service-1-a08f3a94-56a0-4ccb-a7df-9f723b9afa8f', protocol='range'}
2024-12-31 21:02:14.391 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Finished assignment for group at generation 1: {consumer-pong-service-1-a08f3a94-56a0-4ccb-a7df-9f723b9afa8f=Assignment(partitions=[pong-message-topic-0, pong-message-topic-1])}
2024-12-31 21:02:14.398 [GroupCoordinator 0]: Assignment received from leader consumer-pong-service-1-a08f3a94-56a0-4ccb-a7df-9f723b9afa8f for group pong-service for generation 1. The group has 1 members, 0 of which are static.
2024-12-31 21:02:14.436 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Successfully synced group in generation Generation{generationId=1, memberId='consumer-pong-service-1-a08f3a94-56a0-4ccb-a7df-9f723b9afa8f', protocol='range'}
2024-12-31 21:02:14.436 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Notifying assignor about the new Assignment(partitions=[pong-message-topic-0, pong-message-topic-1])
2024-12-31 21:02:14.438 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Adding newly assigned partitions: pong-message-topic-0, pong-message-topic-1
2024-12-31 21:02:14.445 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-0
2024-12-31 21:02:14.445 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-1
2024-12-31 21:02:14.448 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-0
2024-12-31 21:02:14.448 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-1
2024-12-31 21:02:14.459 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting offset for partition pong-message-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:59383 (id: 0 rack: null)], epoch=0}}.
2024-12-31 21:02:14.459 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting offset for partition pong-message-topic-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:59383 (id: 0 rack: null)], epoch=0}}.
2024-12-31 21:02:14.478 pong-service: partitions assigned: [pong-message-topic-0, pong-message-topic-1]
2024-12-31 21:02:14.681 Idempotence will be disabled because acks is set to 0, not set to 'all'.
2024-12-31 21:02:14.681 ProducerConfig values: 
	acks = 0
	auto.include.jmx.reporter = true
	batch.size = 10
	bootstrap.servers = [127.0.0.1:59383]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2024-12-31 21:02:14.695 Kafka version: 3.4.1
2024-12-31 21:02:14.696 Kafka commitId: 8a516edc2755df89
2024-12-31 21:02:14.696 Kafka startTimeMs: 1735650134695
2024-12-31 21:02:14.699 [Producer clientId=producer-1] Resetting the last seen epoch of partition pong-message-topic-0 to 0 since the associated topicId changed from null to 3aoccVK6TGKf3DyogOIGPQ
2024-12-31 21:02:14.699 [Producer clientId=producer-1] Resetting the last seen epoch of partition pong-message-topic-1 to 0 since the associated topicId changed from null to 3aoccVK6TGKf3DyogOIGPQ
2024-12-31 21:02:14.699 [Producer clientId=producer-1] Cluster ID: DyapT7fHSx2XjJAiIj_pxQ
2024-12-31 21:02:14.890 [Controller id=0] Processing automatic preferred replica leader election
2024-12-31 21:02:14.927 [KafkaServer id=0] shutting down
2024-12-31 21:02:14.927 [KafkaServer id=0] Starting controlled shutdown
2024-12-31 21:02:14.933 [Controller id=0] Shutting down broker 0
2024-12-31 21:02:14.935 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:02:14.943 [KafkaServer id=0] Controlled shutdown request returned successfully after 13ms
2024-12-31 21:02:14.944 [/config/changes-event-process-thread]: Shutting down
2024-12-31 21:02:14.944 [/config/changes-event-process-thread]: Shutdown completed
2024-12-31 21:02:14.946 [/config/changes-event-process-thread]: Stopped
2024-12-31 21:02:14.946 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
2024-12-31 21:02:14.948 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:02:14.948 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:02:14.949 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Cancelled in-flight FETCH request with correlation id 15 due to node 0 being disconnected (elapsed time since creation: 208ms, elapsed time since send: 208ms, request timeout: 30000ms)
2024-12-31 21:02:14.949 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 2147483647 disconnected.
2024-12-31 21:02:14.949 [Producer clientId=producer-1] Node 0 disconnected.
2024-12-31 21:02:14.949 [Producer clientId=producer-1] Cancelled in-flight METADATA request with correlation id 4 due to node 0 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 30000ms)
2024-12-31 21:02:14.950 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:02:14.950 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Group coordinator localhost:59383 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
2024-12-31 21:02:14.952 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors
2024-12-31 21:02:14.952 [data-plane Kafka Request Handler on Broker 0], shutting down
2024-12-31 21:02:14.950 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Error sending fetch request (sessionId=478915947, epoch=1) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2024-12-31 21:02:14.953 [data-plane Kafka Request Handler on Broker 0], shut down completely
2024-12-31 21:02:14.954 [ExpirationReaper-0-AlterAcls]: Shutting down
2024-12-31 21:02:14.955 [ExpirationReaper-0-AlterAcls]: Shutdown completed
2024-12-31 21:02:14.955 [ExpirationReaper-0-AlterAcls]: Stopped
2024-12-31 21:02:14.956 [KafkaApi-0] Shutdown complete.
2024-12-31 21:02:14.956 [ExpirationReaper-0-topic]: Shutting down
2024-12-31 21:02:14.956 [ExpirationReaper-0-topic]: Stopped
2024-12-31 21:02:14.956 [ExpirationReaper-0-topic]: Shutdown completed
2024-12-31 21:02:14.956 [TransactionCoordinator id=0] Shutting down.
2024-12-31 21:02:14.958 [Transaction State Manager 0]: Shutdown complete
2024-12-31 21:02:14.958 [Transaction Marker Channel Manager 0]: Shutting down
2024-12-31 21:02:14.958 [Transaction Marker Channel Manager 0]: Shutdown completed
2024-12-31 21:02:14.958 [Transaction Marker Channel Manager 0]: Stopped
2024-12-31 21:02:14.958 [TransactionCoordinator id=0] Shutdown complete.
2024-12-31 21:02:14.958 [GroupCoordinator 0]: Shutting down.
2024-12-31 21:02:14.958 [ExpirationReaper-0-Heartbeat]: Shutting down
2024-12-31 21:02:14.959 [ExpirationReaper-0-Heartbeat]: Stopped
2024-12-31 21:02:14.959 [ExpirationReaper-0-Heartbeat]: Shutdown completed
2024-12-31 21:02:14.959 [ExpirationReaper-0-Rebalance]: Shutting down
2024-12-31 21:02:14.959 [ExpirationReaper-0-Rebalance]: Stopped
2024-12-31 21:02:14.959 [ExpirationReaper-0-Rebalance]: Shutdown completed
2024-12-31 21:02:14.959 [GroupCoordinator 0]: Shutdown complete.
2024-12-31 21:02:14.960 [ReplicaManager broker=0] Shutting down
2024-12-31 21:02:14.960 [LogDirFailureHandler]: Shutting down
2024-12-31 21:02:14.960 [LogDirFailureHandler]: Stopped
2024-12-31 21:02:14.960 [LogDirFailureHandler]: Shutdown completed
2024-12-31 21:02:14.960 [ReplicaFetcherManager on broker 0] shutting down
2024-12-31 21:02:14.961 [ReplicaFetcherManager on broker 0] shutdown completed
2024-12-31 21:02:14.961 [ReplicaAlterLogDirsManager on broker 0] shutting down
2024-12-31 21:02:14.961 [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2024-12-31 21:02:14.961 [ExpirationReaper-0-Fetch]: Shutting down
2024-12-31 21:02:14.961 [ExpirationReaper-0-Fetch]: Stopped
2024-12-31 21:02:14.961 [ExpirationReaper-0-Fetch]: Shutdown completed
2024-12-31 21:02:14.961 [ExpirationReaper-0-Produce]: Shutting down
2024-12-31 21:02:14.961 [ExpirationReaper-0-Produce]: Stopped
2024-12-31 21:02:14.961 [ExpirationReaper-0-Produce]: Shutdown completed
2024-12-31 21:02:14.961 [ExpirationReaper-0-DeleteRecords]: Shutting down
2024-12-31 21:02:14.961 [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2024-12-31 21:02:14.961 [ExpirationReaper-0-DeleteRecords]: Stopped
2024-12-31 21:02:14.963 [ExpirationReaper-0-ElectLeader]: Shutting down
2024-12-31 21:02:14.963 [ExpirationReaper-0-ElectLeader]: Shutdown completed
2024-12-31 21:02:14.963 [ExpirationReaper-0-ElectLeader]: Stopped
2024-12-31 21:02:14.972 [ReplicaManager broker=0] Shut down completely
2024-12-31 21:02:14.973 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutting down
2024-12-31 21:02:14.973 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Stopped
2024-12-31 21:02:14.973 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutdown completed
2024-12-31 21:02:14.973 Broker to controller channel manager for alterPartition shutdown
2024-12-31 21:02:14.974 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down
2024-12-31 21:02:14.974 [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped
2024-12-31 21:02:14.974 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed
2024-12-31 21:02:14.974 Broker to controller channel manager for forwarding shutdown
2024-12-31 21:02:14.974 Shutting down.
2024-12-31 21:02:14.974 Shutting down the log cleaner.
2024-12-31 21:02:14.975 [kafka-log-cleaner-thread-0]: Shutting down
2024-12-31 21:02:14.975 [kafka-log-cleaner-thread-0]: Stopped
2024-12-31 21:02:14.975 [kafka-log-cleaner-thread-0]: Shutdown completed
2024-12-31 21:02:14.998 [ProducerStateManager partition=pong-message-topic-0] Wrote producer snapshot at offset 1 with 0 producer ids in 2 ms.
2024-12-31 21:02:15.008 [ProducerStateManager partition=__consumer_offsets-2] Wrote producer snapshot at offset 4 with 0 producer ids in 2 ms.
2024-12-31 21:02:15.019 Shutdown complete.
2024-12-31 21:02:15.019 [ControllerEventThread controllerId=0] Shutting down
2024-12-31 21:02:15.019 [ControllerEventThread controllerId=0] Shutdown completed
2024-12-31 21:02:15.019 [ControllerEventThread controllerId=0] Stopped
2024-12-31 21:02:15.019 [PartitionStateMachine controllerId=0] Stopped partition state machine
2024-12-31 21:02:15.020 [ReplicaStateMachine controllerId=0] Stopped replica state machine
2024-12-31 21:02:15.020 [RequestSendThread controllerId=0] Shutting down
2024-12-31 21:02:15.020 [RequestSendThread controllerId=0] Shutdown completed
2024-12-31 21:02:15.020 [RequestSendThread controllerId=0] Stopped
2024-12-31 21:02:15.021 [Controller id=0] Resigned
2024-12-31 21:02:15.021 [feature-zk-node-event-process-thread]: Shutting down
2024-12-31 21:02:15.021 [feature-zk-node-event-process-thread]: Stopped
2024-12-31 21:02:15.021 [feature-zk-node-event-process-thread]: Shutdown completed
2024-12-31 21:02:15.021 [ZooKeeperClient Kafka server] Closing.
2024-12-31 21:02:15.049 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:02:15.049 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node 0 (localhost/127.0.0.1:59383) could not be established. Broker may not be available.
2024-12-31 21:02:15.050 [Producer clientId=producer-1] Node 0 disconnected.
2024-12-31 21:02:15.050 [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:59383) could not be established. Broker may not be available.
2024-12-31 21:02:15.126 EventThread shut down for session: 0x100176a320a0000
2024-12-31 21:02:15.126 Session: 0x100176a320a0000 closed
2024-12-31 21:02:15.127 [ZooKeeperClient Kafka server] Closed.
2024-12-31 21:02:15.127 [ThrottledChannelReaper-Fetch]: Shutting down
2024-12-31 21:02:15.129 [ThrottledChannelReaper-Fetch]: Stopped
2024-12-31 21:02:15.129 [ThrottledChannelReaper-Fetch]: Shutdown completed
2024-12-31 21:02:15.129 [ThrottledChannelReaper-Produce]: Shutting down
2024-12-31 21:02:15.129 [ThrottledChannelReaper-Produce]: Stopped
2024-12-31 21:02:15.129 [ThrottledChannelReaper-Produce]: Shutdown completed
2024-12-31 21:02:15.129 [ThrottledChannelReaper-Request]: Shutting down
2024-12-31 21:02:15.129 [ThrottledChannelReaper-Request]: Stopped
2024-12-31 21:02:15.129 [ThrottledChannelReaper-Request]: Shutdown completed
2024-12-31 21:02:15.129 [ThrottledChannelReaper-ControllerMutation]: Shutting down
2024-12-31 21:02:15.129 [ThrottledChannelReaper-ControllerMutation]: Stopped
2024-12-31 21:02:15.129 [ThrottledChannelReaper-ControllerMutation]: Shutdown completed
2024-12-31 21:02:15.130 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server
2024-12-31 21:02:15.138 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed
2024-12-31 21:02:15.138 Metrics scheduler closed
2024-12-31 21:02:15.138 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:02:15.138 Metrics reporters closed
2024-12-31 21:02:15.139 Broker and topic stats closed
2024-12-31 21:02:15.139 App info kafka.server for 0 unregistered
2024-12-31 21:02:15.139 [KafkaServer id=0] shut down completed
2024-12-31 21:02:15.148 ConnnectionExpirerThread interrupted
2024-12-31 21:02:15.150 accept thread exitted run method
2024-12-31 21:02:15.150 selector thread exitted run method
2024-12-31 21:02:15.150 selector thread exitted run method
2024-12-31 21:02:15.151 shutting down
2024-12-31 21:02:15.151 Shutting down
2024-12-31 21:02:15.151 Draining request throttler queue
2024-12-31 21:02:15.151 RequestThrottler shutdown. Dropped 0 requests
2024-12-31 21:02:15.151 Shutting down
2024-12-31 21:02:15.151 Shutting down
2024-12-31 21:02:15.151 Shutting down
2024-12-31 21:02:15.151 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:02:15.151 PrepRequestProcessor exited loop!
2024-12-31 21:02:15.151 SyncRequestProcessor exited!
2024-12-31 21:02:15.151 shutdown of request processor complete
2024-12-31 21:02:15.151 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node 0 (localhost/127.0.0.1:59383) could not be established. Broker may not be available.
2024-12-31 21:02:15.165 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Revoke previously assigned partitions pong-message-topic-0, pong-message-topic-1
2024-12-31 21:02:15.165 pong-service: partitions revoked: [pong-message-topic-0, pong-message-topic-1]
2024-12-31 21:02:15.165 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:02:15.165 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:02:15.165 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Unsubscribed all topics or patterns and assigned partitions
2024-12-31 21:02:15.165 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:02:15.165 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:02:15.166 Metrics scheduler closed
2024-12-31 21:02:15.166 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:02:15.166 Metrics reporters closed
2024-12-31 21:02:15.166 App info kafka.consumer for consumer-pong-service-1 unregistered
2024-12-31 21:02:15.166 pong-service: Consumer stopped
2024-12-31 21:02:15.167 [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2024-12-31 21:02:15.169 Metrics scheduler closed
2024-12-31 21:02:15.169 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:02:15.169 Metrics reporters closed
2024-12-31 21:02:15.169 App info kafka.producer for producer-1 unregistered
2024-12-31 21:02:15.183 Closing JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:02:15.184 HikariPool-1 - Shutdown initiated...
2024-12-31 21:02:15.185 HikariPool-1 - Shutdown completed.
2024-12-31 21:06:12.230 Could not detect default configuration classes for test class [com.demo.controller.PongControllerSpec]: PongControllerSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:06:12.376 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.controller.PongControllerSpec
2024-12-31 21:06:12.562 Could not detect default configuration classes for test class [com.demo.dao.MessageRepositorySpec]: MessageRepositorySpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:06:12.573 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.dao.MessageRepositorySpec
2024-12-31 21:06:12.584 Could not detect default configuration classes for test class [com.demo.kafka.KafkaSpec]: KafkaSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:06:12.611 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.kafka.KafkaSpec
2024-12-31 21:06:12.647 Could not detect default configuration classes for test class [com.demo.controller.PongControllerSpec]: PongControllerSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:06:12.649 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.controller.PongControllerSpec
2024-12-31 21:06:12.652 Could not detect default configuration classes for test class [com.demo.dao.MessageRepositorySpec]: MessageRepositorySpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:06:12.657 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.dao.MessageRepositorySpec
2024-12-31 21:06:12.661 Could not detect default configuration classes for test class [com.demo.kafka.KafkaSpec]: KafkaSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:06:12.661 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.kafka.KafkaSpec
2024-12-31 21:06:12.986 Registered kafka:type=kafka.Log4jController MBean
2024-12-31 21:06:13.067 
2024-12-31 21:06:13.070   ______                  _                                          
2024-12-31 21:06:13.070  |___  /                 | |                                         
2024-12-31 21:06:13.070     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __   
2024-12-31 21:06:13.070    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__|
2024-12-31 21:06:13.070   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |    
2024-12-31 21:06:13.071  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_|
2024-12-31 21:06:13.071                                               | |                     
2024-12-31 21:06:13.071                                               |_|                     
2024-12-31 21:06:13.071 
2024-12-31 21:06:18.341 Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT
2024-12-31 21:06:18.341 Server environment:host.name=Joe
2024-12-31 21:06:18.341 Server environment:java.version=17.0.12
2024-12-31 21:06:18.341 Server environment:java.vendor=Oracle Corporation
2024-12-31 21:06:18.341 Server environment:java.home=C:\work\jdk-17
2024-12-31 21:06:18.341 Server environment:java.class.path=C:\code\hsbc\demo\pong\target\test-classes;C:\code\hsbc\demo\pong\target\classes;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-webflux\3.1.4\spring-boot-starter-webflux-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter\3.1.4\spring-boot-starter-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot\3.1.4\spring-boot-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-autoconfigure\3.1.4\spring-boot-autoconfigure-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-logging\3.1.4\spring-boot-starter-logging-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\ch\qos\logback\logback-classic\1.4.11\logback-classic-1.4.11.jar;C:\work\apache-maven-3.8.8\repo\ch\qos\logback\logback-core\1.4.11\logback-core-1.4.11.jar;C:\work\apache-maven-3.8.8\repo\org\apache\logging\log4j\log4j-to-slf4j\2.20.0\log4j-to-slf4j-2.20.0.jar;C:\work\apache-maven-3.8.8\repo\org\apache\logging\log4j\log4j-api\2.20.0\log4j-api-2.20.0.jar;C:\work\apache-maven-3.8.8\repo\org\slf4j\jul-to-slf4j\2.0.9\jul-to-slf4j-2.0.9.jar;C:\work\apache-maven-3.8.8\repo\jakarta\annotation\jakarta.annotation-api\2.1.1\jakarta.annotation-api-2.1.1.jar;C:\work\apache-maven-3.8.8\repo\org\yaml\snakeyaml\1.33\snakeyaml-1.33.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-json\3.1.4\spring-boot-starter-json-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-databind\2.15.2\jackson-databind-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-annotations\2.15.2\jackson-annotations-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-core\2.15.2\jackson-core-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.15.2\jackson-datatype-jdk8-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.15.2\jackson-datatype-jsr310-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\module\jackson-module-parameter-names\2.15.2\jackson-module-parameter-names-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-reactor-netty\3.1.4\spring-boot-starter-reactor-netty-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\netty\reactor-netty-http\1.1.11\reactor-netty-http-1.1.11.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-http\4.1.97.Final\netty-codec-http-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-http2\4.1.97.Final\netty-codec-http2-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns\4.1.97.Final\netty-resolver-dns-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-dns\4.1.97.Final\netty-codec-dns-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns-native-macos\4.1.97.Final\netty-resolver-dns-native-macos-4.1.97.Final-osx-x86_64.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns-classes-macos\4.1.97.Final\netty-resolver-dns-classes-macos-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final-linux-x86_64.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\netty\reactor-netty-core\1.1.11\reactor-netty-core-1.1.11.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-handler-proxy\4.1.97.Final\netty-handler-proxy-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-socks\4.1.97.Final\netty-codec-socks-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-web\6.0.12\spring-web-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-beans\6.0.12\spring-beans-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-webflux\6.0.12\spring-webflux-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\reactor-core\3.5.10\reactor-core-3.5.10.jar;C:\work\apache-maven-3.8.8\repo\org\reactivestreams\reactive-streams\1.0.4\reactive-streams-1.0.4.jar;C:\work\apache-maven-3.8.8\repo\com\google\guava\guava\19.0\guava-19.0.jar;C:\work\apache-maven-3.8.8\repo\commons-io\commons-io\2.11.0\commons-io-2.11.0.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-data-redis\3.1.4\spring-boot-starter-data-redis-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-redis\3.1.4\spring-data-redis-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-keyvalue\3.1.4\spring-data-keyvalue-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-oxm\6.0.12\spring-oxm-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-aop\6.0.12\spring-aop-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-context-support\6.0.12\spring-context-support-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\io\lettuce\lettuce-core\6.2.6.RELEASE\lettuce-core-6.2.6.RELEASE.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-common\4.1.97.Final\netty-common-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-handler\4.1.97.Final\netty-handler-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver\4.1.97.Final\netty-resolver-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-buffer\4.1.97.Final\netty-buffer-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-unix-common\4.1.97.Final\netty-transport-native-unix-common-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec\4.1.97.Final\netty-codec-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport\4.1.97.Final\netty-transport-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-data-jpa\3.1.4\spring-boot-starter-data-jpa-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-aop\3.1.4\spring-boot-starter-aop-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\aspectj\aspectjweaver\1.9.20\aspectjweaver-1.9.20.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-jdbc\3.1.4\spring-boot-starter-jdbc-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\zaxxer\HikariCP\5.0.1\HikariCP-5.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-jdbc\6.0.12\spring-jdbc-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\hibernate\orm\hibernate-core\6.2.9.Final\hibernate-core-6.2.9.Final.jar;C:\work\apache-maven-3.8.8\repo\jakarta\persistence\jakarta.persistence-api\3.1.0\jakarta.persistence-api-3.1.0.jar;C:\work\apache-maven-3.8.8\repo\jakarta\transaction\jakarta.transaction-api\2.0.1\jakarta.transaction-api-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\jboss\logging\jboss-logging\3.5.3.Final\jboss-logging-3.5.3.Final.jar;C:\work\apache-maven-3.8.8\repo\org\hibernate\common\hibernate-commons-annotations\6.0.6.Final\hibernate-commons-annotations-6.0.6.Final.jar;C:\work\apache-maven-3.8.8\repo\io\smallrye\jandex\3.0.5\jandex-3.0.5.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\classmate\1.5.1\classmate-1.5.1.jar;C:\work\apache-maven-3.8.8\repo\net\bytebuddy\byte-buddy\1.14.8\byte-buddy-1.14.8.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\jaxb-runtime\4.0.3\jaxb-runtime-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\jaxb-core\4.0.3\jaxb-core-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\eclipse\angus\angus-activation\2.0.1\angus-activation-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\txw2\4.0.3\txw2-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\com\sun\istack\istack-commons-runtime\4.1.2\istack-commons-runtime-4.1.2.jar;C:\work\apache-maven-3.8.8\repo\jakarta\inject\jakarta.inject-api\2.0.1\jakarta.inject-api-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\antlr\antlr4-runtime\4.10.1\antlr4-runtime-4.10.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-jpa\3.1.4\spring-data-jpa-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-commons\3.1.4\spring-data-commons-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-orm\6.0.12\spring-orm-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-aspects\6.0.12\spring-aspects-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\postgresql\postgresql\42.6.0\postgresql-42.6.0.jar;C:\work\apache-maven-3.8.8\repo\org\checkerframework\checker-qual\3.31.0\checker-qual-3.31.0.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\kafka\spring-kafka\3.0.11\spring-kafka-3.0.11.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-context\6.0.12\spring-context-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-expression\6.0.12\spring-expression-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-messaging\6.0.12\spring-messaging-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-tx\6.0.12\spring-tx-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\retry\spring-retry\2.0.3\spring-retry-2.0.3.jar;C:\work\apache-maven-3.8.8\repo\io\micrometer\micrometer-observation\1.11.4\micrometer-observation-1.11.4.jar;C:\work\apache-maven-3.8.8\repo\io\micrometer\micrometer-commons\1.11.4\micrometer-commons-1.11.4.jar;C:\work\apache-maven-3.8.8\repo\com\google\code\findbugs\jsr305\3.0.2\jsr305-3.0.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\com\github\luben\zstd-jni\1.5.2-1\zstd-jni-1.5.2-1.jar;C:\work\apache-maven-3.8.8\repo\org\lz4\lz4-java\1.8.0\lz4-java-1.8.0.jar;C:\work\apache-maven-3.8.8\repo\org\xerial\snappy\snappy-java\1.1.8.4\snappy-java-1.1.8.4.jar;C:\work\apache-maven-3.8.8\repo\org\slf4j\slf4j-api\2.0.9\slf4j-api-2.0.9.jar;C:\work\apache-maven-3.8.8\repo\com\h2database\h2\1.4.200\h2-1.4.200.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-test\3.1.4\spring-boot-starter-test-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-test\3.1.4\spring-boot-test-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-test-autoconfigure\3.1.4\spring-boot-test-autoconfigure-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\jayway\jsonpath\json-path\2.8.0\json-path-2.8.0.jar;C:\work\apache-maven-3.8.8\repo\jakarta\xml\bind\jakarta.xml.bind-api\4.0.1\jakarta.xml.bind-api-4.0.1.jar;C:\work\apache-maven-3.8.8\repo\jakarta\activation\jakarta.activation-api\2.1.2\jakarta.activation-api-2.1.2.jar;C:\work\apache-maven-3.8.8\repo\net\minidev\json-smart\2.4.11\json-smart-2.4.11.jar;C:\work\apache-maven-3.8.8\repo\net\minidev\accessors-smart\2.4.11\accessors-smart-2.4.11.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm\9.3\asm-9.3.jar;C:\work\apache-maven-3.8.8\repo\org\assertj\assertj-core\3.24.2\assertj-core-3.24.2.jar;C:\work\apache-maven-3.8.8\repo\org\hamcrest\hamcrest\2.2\hamcrest-2.2.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter\5.9.3\junit-jupiter-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-params\5.9.3\junit-jupiter-params-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-engine\5.9.3\junit-jupiter-engine-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\mockito\mockito-core\5.3.1\mockito-core-5.3.1.jar;C:\work\apache-maven-3.8.8\repo\net\bytebuddy\byte-buddy-agent\1.14.8\byte-buddy-agent-1.14.8.jar;C:\work\apache-maven-3.8.8\repo\org\objenesis\objenesis\3.3\objenesis-3.3.jar;C:\work\apache-maven-3.8.8\repo\org\mockito\mockito-junit-jupiter\5.3.1\mockito-junit-jupiter-5.3.1.jar;C:\work\apache-maven-3.8.8\repo\org\skyscreamer\jsonassert\1.5.1\jsonassert-1.5.1.jar;C:\work\apache-maven-3.8.8\repo\com\vaadin\external\google\android-json\0.0.20131108.vaadin1\android-json-0.0.20131108.vaadin1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-core\6.0.12\spring-core-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-jcl\6.0.12\spring-jcl-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-test\6.0.12\spring-test-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\xmlunit\xmlunit-core\2.9.1\xmlunit-core-2.9.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy\4.0.15\groovy-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-ant\4.0.15\groovy-ant-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant\1.10.14\ant-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-junit\1.10.14\ant-junit-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-launcher\1.10.14\ant-launcher-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-antlr\1.10.14\ant-antlr-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-cli-picocli\4.0.15\groovy-cli-picocli-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\info\picocli\picocli\4.7.5\picocli-4.7.5.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-console\4.0.15\groovy-console-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\github\javaparser\javaparser-core\3.25.5\javaparser-core-3.25.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-util\9.5\asm-util-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-tree\9.5\asm-tree-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-analysis\9.5\asm-analysis-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\abego\treelayout\org.abego.treelayout.core\1.0.3\org.abego.treelayout.core-1.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ivy\ivy\2.5.2\ivy-2.5.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-datetime\4.0.15\groovy-datetime-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-docgenerator\4.0.15\groovy-docgenerator-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\thoughtworks\qdox\qdox\1.12.1\qdox-1.12.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-groovydoc\4.0.15\groovy-groovydoc-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-groovysh\4.0.15\groovy-groovysh-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\jline\jline\2.14.6\jline-2.14.6.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-jmx\4.0.15\groovy-jmx-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-json\4.0.15\groovy-json-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-jsr223\4.0.15\groovy-jsr223-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-macro\4.0.15\groovy-macro-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-nio\4.0.15\groovy-nio-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-servlet\4.0.15\groovy-servlet-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-sql\4.0.15\groovy-sql-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-swing\4.0.15\groovy-swing-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-templates\4.0.15\groovy-templates-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-test\4.0.15\groovy-test-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\junit\junit\4.13.2\junit-4.13.2.jar;C:\work\apache-maven-3.8.8\repo\org\hamcrest\hamcrest-core\2.2\hamcrest-core-2.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-test-junit5\4.0.15\groovy-test-junit5-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-xml\4.0.15\groovy-xml-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-yaml\4.0.15\groovy-yaml-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\dataformat\jackson-dataformat-yaml\2.15.2\jackson-dataformat-yaml-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\org\spockframework\spock-core\2.4-M1-groovy-4.0\spock-core-2.4-M1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-engine\1.9.3\junit-platform-engine-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\opentest4j\opentest4j\1.2.0\opentest4j-1.2.0.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-commons\1.9.3\junit-platform-commons-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\apiguardian\apiguardian-api\1.1.2\apiguardian-api-1.1.2.jar;C:\work\apache-maven-3.8.8\repo\org\spockframework\spock-spring\2.4-M1-groovy-4.0\spock-spring-2.4-M1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\com\athaydes\spock-reports\2.5.1-groovy-4.0\spock-reports-2.5.1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\com\github\codemonstur\embedded-redis\1.4.2\embedded-redis-1.4.2.jar;C:\work\apache-maven-3.8.8\repo\redis\clients\jedis\4.3.2\jedis-4.3.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\commons\commons-pool2\2.11.1\commons-pool2-2.11.1.jar;C:\work\apache-maven-3.8.8\repo\org\json\json\20220320\json-20220320.jar;C:\work\apache-maven-3.8.8\repo\com\google\code\gson\gson\2.10.1\gson-2.10.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\kafka\spring-kafka-test\3.0.11\spring-kafka-test-3.0.11.jar;C:\work\apache-maven-3.8.8\repo\org\apache\zookeeper\zookeeper\3.6.3\zookeeper-3.6.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\zookeeper\zookeeper-jute\3.6.3\zookeeper-jute-3.6.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-classes-epoll\4.1.97.Final\netty-transport-classes-epoll-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1-test.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-metadata\3.4.1\kafka-metadata-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-server-common\3.4.1\kafka-server-common-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-raft\3.4.1\kafka-raft-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-streams-test-utils\3.4.1\kafka-streams-test-utils-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-streams\3.4.1\kafka-streams-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\rocksdb\rocksdbjni\7.1.2\rocksdbjni-7.1.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\scala-library\2.13.10\scala-library-2.13.10.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-group-coordinator\3.4.1\kafka-group-coordinator-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-storage\3.4.1\kafka-storage-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-storage-api\3.4.1\kafka-storage-api-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\net\sourceforge\argparse4j\argparse4j\0.7.0\argparse4j-0.7.0.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\module\jackson-module-scala_2.13\2.15.2\jackson-module-scala_2.13-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\thoughtworks\paranamer\paranamer\2.8\paranamer-2.8.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\dataformat\jackson-dataformat-csv\2.15.2\jackson-dataformat-csv-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\net\sf\jopt-simple\jopt-simple\5.0.4\jopt-simple-5.0.4.jar;C:\work\apache-maven-3.8.8\repo\org\bitbucket\b_c\jose4j\0.9.3\jose4j-0.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\modules\scala-collection-compat_2.13\2.10.0\scala-collection-compat_2.13-2.10.0.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\modules\scala-java8-compat_2.13\1.0.2\scala-java8-compat_2.13-1.0.2.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\scala-reflect\2.13.10\scala-reflect-2.13.10.jar;C:\work\apache-maven-3.8.8\repo\com\typesafe\scala-logging\scala-logging_2.13\3.9.4\scala-logging_2.13-3.9.4.jar;C:\work\apache-maven-3.8.8\repo\io\dropwizard\metrics\metrics-core\4.2.19\metrics-core-4.2.19.jar;C:\work\apache-maven-3.8.8\repo\commons-cli\commons-cli\1.4\commons-cli-1.4.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1-test.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-api\5.9.3\junit-jupiter-api-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-launcher\1.9.3\junit-platform-launcher-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\awaitility\awaitility\4.2.0\awaitility-4.2.0.jar;
2024-12-31 21:06:18.341 Server environment:java.library.path=C:\work\jdk-17\bin;C:\windows\Sun\Java\bin;C:\windows\system32;C:\windows;C:\work\python312\Scripts\;C:\work\python312\;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program\Git\cmd;C:\Program\PowerShell\7\;C:\Program Files\dotnet\;C:\Users\joech\AppData\Local\Microsoft\WindowsApps;C:\Users\joech\AppData\Local\GitHubDesktop\bin;C:\Program\Microsoft VS Code\bin;C:\work\apache-maven-3.8.8\bin;C:\Program Files\Tesseract-OCR;C:\work\jdk-17\bin;;.
2024-12-31 21:06:18.341 Server environment:java.io.tmpdir=C:\Users\joech\AppData\Local\Temp\
2024-12-31 21:06:18.341 Server environment:java.compiler=<NA>
2024-12-31 21:06:18.341 Server environment:os.name=Windows 11
2024-12-31 21:06:18.341 Server environment:os.arch=amd64
2024-12-31 21:06:18.341 Server environment:os.version=10.0
2024-12-31 21:06:18.341 Server environment:user.name=joech
2024-12-31 21:06:18.341 Server environment:user.home=C:\Users\joech
2024-12-31 21:06:18.341 Server environment:user.dir=C:\code\hsbc\demo\pong
2024-12-31 21:06:18.341 Server environment:os.memory.free=89MB
2024-12-31 21:06:18.341 Server environment:os.memory.max=15816MB
2024-12-31 21:06:18.341 Server environment:os.memory.total=136MB
2024-12-31 21:06:18.341 zookeeper.enableEagerACLCheck = false
2024-12-31 21:06:18.341 zookeeper.digest.enabled = true
2024-12-31 21:06:18.341 zookeeper.closeSessionTxn.enabled = true
2024-12-31 21:06:18.341 zookeeper.flushDelay=0
2024-12-31 21:06:18.341 zookeeper.maxWriteQueuePollTime=0
2024-12-31 21:06:18.341 zookeeper.maxBatchSize=1000
2024-12-31 21:06:18.341 zookeeper.intBufferStartingSizeBytes = 1024
2024-12-31 21:06:18.341 zookeeper.snapshot.trust.empty : false
2024-12-31 21:06:18.372 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:06:18.372 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:06:18.372 zookeeper.snapshotSizeFactor = 0.33
2024-12-31 21:06:18.372 zookeeper.commitLogCount=500
2024-12-31 21:06:18.388 Weighed connection throttling is disabled
2024-12-31 21:06:18.395 minSessionTimeout set to 1600
2024-12-31 21:06:18.395 maxSessionTimeout set to 16000
2024-12-31 21:06:18.395 Response cache size is initialized with value 400.
2024-12-31 21:06:18.395 Response cache size is initialized with value 400.
2024-12-31 21:06:18.395 zookeeper.pathStats.slotCapacity = 60
2024-12-31 21:06:18.395 zookeeper.pathStats.slotDuration = 15
2024-12-31 21:06:18.395 zookeeper.pathStats.maxDepth = 6
2024-12-31 21:06:18.395 zookeeper.pathStats.initialDelay = 5
2024-12-31 21:06:18.395 zookeeper.pathStats.delay = 5
2024-12-31 21:06:18.395 zookeeper.pathStats.enabled = false
2024-12-31 21:06:18.395 The max bytes for all large requests are set to 104857600
2024-12-31 21:06:18.395 The large request threshold is set to -1
2024-12-31 21:06:18.395 Created server with tickTime 800 minSessionTimeout 1600 maxSessionTimeout 16000 clientPortListenBacklog -1 datadir C:\Users\joech\AppData\Local\Temp\kafka-5831600171073728498\version-2 snapdir C:\Users\joech\AppData\Local\Temp\kafka-2366345888803208610\version-2
2024-12-31 21:06:18.451 maxCnxns is not configured, using default value 0.
2024-12-31 21:06:18.451 Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers.
2024-12-31 21:06:18.467 binding to port /127.0.0.1:0
2024-12-31 21:06:18.490 zookeeper.snapshot.compression.method = CHECKED
2024-12-31 21:06:18.490 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-2366345888803208610\version-2\snapshot.0
2024-12-31 21:06:18.497 Snapshot loaded in 26 ms, highest zxid is 0x0, digest is 1371985504
2024-12-31 21:06:18.497 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-2366345888803208610\version-2\snapshot.0
2024-12-31 21:06:18.498 Snapshot taken in 0 ms
2024-12-31 21:06:18.513 PrepRequestProcessor (sid:0) started, reconfigEnabled=false
2024-12-31 21:06:18.514 zookeeper.request_throttler.shutdownTimeout = 10000
2024-12-31 21:06:18.850 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.f8fa9ffc-a166-42fa-9375-d6234d8183f96138590628883926380
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59413
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:06:18.883 Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
2024-12-31 21:06:18.982 starting
2024-12-31 21:06:18.983 Connecting to zookeeper on 127.0.0.1:59413
2024-12-31 21:06:19.008 [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:59413.
2024-12-31 21:06:24.279 Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT
2024-12-31 21:06:24.280 Client environment:host.name=Joe
2024-12-31 21:06:24.280 Client environment:java.version=17.0.12
2024-12-31 21:06:24.280 Client environment:java.vendor=Oracle Corporation
2024-12-31 21:06:24.280 Client environment:java.home=C:\work\jdk-17
2024-12-31 21:06:24.280 Client environment:java.class.path=C:\code\hsbc\demo\pong\target\test-classes;C:\code\hsbc\demo\pong\target\classes;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-webflux\3.1.4\spring-boot-starter-webflux-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter\3.1.4\spring-boot-starter-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot\3.1.4\spring-boot-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-autoconfigure\3.1.4\spring-boot-autoconfigure-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-logging\3.1.4\spring-boot-starter-logging-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\ch\qos\logback\logback-classic\1.4.11\logback-classic-1.4.11.jar;C:\work\apache-maven-3.8.8\repo\ch\qos\logback\logback-core\1.4.11\logback-core-1.4.11.jar;C:\work\apache-maven-3.8.8\repo\org\apache\logging\log4j\log4j-to-slf4j\2.20.0\log4j-to-slf4j-2.20.0.jar;C:\work\apache-maven-3.8.8\repo\org\apache\logging\log4j\log4j-api\2.20.0\log4j-api-2.20.0.jar;C:\work\apache-maven-3.8.8\repo\org\slf4j\jul-to-slf4j\2.0.9\jul-to-slf4j-2.0.9.jar;C:\work\apache-maven-3.8.8\repo\jakarta\annotation\jakarta.annotation-api\2.1.1\jakarta.annotation-api-2.1.1.jar;C:\work\apache-maven-3.8.8\repo\org\yaml\snakeyaml\1.33\snakeyaml-1.33.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-json\3.1.4\spring-boot-starter-json-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-databind\2.15.2\jackson-databind-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-annotations\2.15.2\jackson-annotations-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-core\2.15.2\jackson-core-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.15.2\jackson-datatype-jdk8-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.15.2\jackson-datatype-jsr310-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\module\jackson-module-parameter-names\2.15.2\jackson-module-parameter-names-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-reactor-netty\3.1.4\spring-boot-starter-reactor-netty-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\netty\reactor-netty-http\1.1.11\reactor-netty-http-1.1.11.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-http\4.1.97.Final\netty-codec-http-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-http2\4.1.97.Final\netty-codec-http2-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns\4.1.97.Final\netty-resolver-dns-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-dns\4.1.97.Final\netty-codec-dns-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns-native-macos\4.1.97.Final\netty-resolver-dns-native-macos-4.1.97.Final-osx-x86_64.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns-classes-macos\4.1.97.Final\netty-resolver-dns-classes-macos-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final-linux-x86_64.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\netty\reactor-netty-core\1.1.11\reactor-netty-core-1.1.11.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-handler-proxy\4.1.97.Final\netty-handler-proxy-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-socks\4.1.97.Final\netty-codec-socks-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-web\6.0.12\spring-web-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-beans\6.0.12\spring-beans-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-webflux\6.0.12\spring-webflux-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\reactor-core\3.5.10\reactor-core-3.5.10.jar;C:\work\apache-maven-3.8.8\repo\org\reactivestreams\reactive-streams\1.0.4\reactive-streams-1.0.4.jar;C:\work\apache-maven-3.8.8\repo\com\google\guava\guava\19.0\guava-19.0.jar;C:\work\apache-maven-3.8.8\repo\commons-io\commons-io\2.11.0\commons-io-2.11.0.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-data-redis\3.1.4\spring-boot-starter-data-redis-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-redis\3.1.4\spring-data-redis-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-keyvalue\3.1.4\spring-data-keyvalue-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-oxm\6.0.12\spring-oxm-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-aop\6.0.12\spring-aop-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-context-support\6.0.12\spring-context-support-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\io\lettuce\lettuce-core\6.2.6.RELEASE\lettuce-core-6.2.6.RELEASE.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-common\4.1.97.Final\netty-common-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-handler\4.1.97.Final\netty-handler-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver\4.1.97.Final\netty-resolver-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-buffer\4.1.97.Final\netty-buffer-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-unix-common\4.1.97.Final\netty-transport-native-unix-common-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec\4.1.97.Final\netty-codec-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport\4.1.97.Final\netty-transport-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-data-jpa\3.1.4\spring-boot-starter-data-jpa-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-aop\3.1.4\spring-boot-starter-aop-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\aspectj\aspectjweaver\1.9.20\aspectjweaver-1.9.20.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-jdbc\3.1.4\spring-boot-starter-jdbc-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\zaxxer\HikariCP\5.0.1\HikariCP-5.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-jdbc\6.0.12\spring-jdbc-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\hibernate\orm\hibernate-core\6.2.9.Final\hibernate-core-6.2.9.Final.jar;C:\work\apache-maven-3.8.8\repo\jakarta\persistence\jakarta.persistence-api\3.1.0\jakarta.persistence-api-3.1.0.jar;C:\work\apache-maven-3.8.8\repo\jakarta\transaction\jakarta.transaction-api\2.0.1\jakarta.transaction-api-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\jboss\logging\jboss-logging\3.5.3.Final\jboss-logging-3.5.3.Final.jar;C:\work\apache-maven-3.8.8\repo\org\hibernate\common\hibernate-commons-annotations\6.0.6.Final\hibernate-commons-annotations-6.0.6.Final.jar;C:\work\apache-maven-3.8.8\repo\io\smallrye\jandex\3.0.5\jandex-3.0.5.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\classmate\1.5.1\classmate-1.5.1.jar;C:\work\apache-maven-3.8.8\repo\net\bytebuddy\byte-buddy\1.14.8\byte-buddy-1.14.8.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\jaxb-runtime\4.0.3\jaxb-runtime-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\jaxb-core\4.0.3\jaxb-core-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\eclipse\angus\angus-activation\2.0.1\angus-activation-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\txw2\4.0.3\txw2-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\com\sun\istack\istack-commons-runtime\4.1.2\istack-commons-runtime-4.1.2.jar;C:\work\apache-maven-3.8.8\repo\jakarta\inject\jakarta.inject-api\2.0.1\jakarta.inject-api-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\antlr\antlr4-runtime\4.10.1\antlr4-runtime-4.10.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-jpa\3.1.4\spring-data-jpa-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-commons\3.1.4\spring-data-commons-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-orm\6.0.12\spring-orm-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-aspects\6.0.12\spring-aspects-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\postgresql\postgresql\42.6.0\postgresql-42.6.0.jar;C:\work\apache-maven-3.8.8\repo\org\checkerframework\checker-qual\3.31.0\checker-qual-3.31.0.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\kafka\spring-kafka\3.0.11\spring-kafka-3.0.11.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-context\6.0.12\spring-context-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-expression\6.0.12\spring-expression-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-messaging\6.0.12\spring-messaging-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-tx\6.0.12\spring-tx-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\retry\spring-retry\2.0.3\spring-retry-2.0.3.jar;C:\work\apache-maven-3.8.8\repo\io\micrometer\micrometer-observation\1.11.4\micrometer-observation-1.11.4.jar;C:\work\apache-maven-3.8.8\repo\io\micrometer\micrometer-commons\1.11.4\micrometer-commons-1.11.4.jar;C:\work\apache-maven-3.8.8\repo\com\google\code\findbugs\jsr305\3.0.2\jsr305-3.0.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\com\github\luben\zstd-jni\1.5.2-1\zstd-jni-1.5.2-1.jar;C:\work\apache-maven-3.8.8\repo\org\lz4\lz4-java\1.8.0\lz4-java-1.8.0.jar;C:\work\apache-maven-3.8.8\repo\org\xerial\snappy\snappy-java\1.1.8.4\snappy-java-1.1.8.4.jar;C:\work\apache-maven-3.8.8\repo\org\slf4j\slf4j-api\2.0.9\slf4j-api-2.0.9.jar;C:\work\apache-maven-3.8.8\repo\com\h2database\h2\1.4.200\h2-1.4.200.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-test\3.1.4\spring-boot-starter-test-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-test\3.1.4\spring-boot-test-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-test-autoconfigure\3.1.4\spring-boot-test-autoconfigure-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\jayway\jsonpath\json-path\2.8.0\json-path-2.8.0.jar;C:\work\apache-maven-3.8.8\repo\jakarta\xml\bind\jakarta.xml.bind-api\4.0.1\jakarta.xml.bind-api-4.0.1.jar;C:\work\apache-maven-3.8.8\repo\jakarta\activation\jakarta.activation-api\2.1.2\jakarta.activation-api-2.1.2.jar;C:\work\apache-maven-3.8.8\repo\net\minidev\json-smart\2.4.11\json-smart-2.4.11.jar;C:\work\apache-maven-3.8.8\repo\net\minidev\accessors-smart\2.4.11\accessors-smart-2.4.11.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm\9.3\asm-9.3.jar;C:\work\apache-maven-3.8.8\repo\org\assertj\assertj-core\3.24.2\assertj-core-3.24.2.jar;C:\work\apache-maven-3.8.8\repo\org\hamcrest\hamcrest\2.2\hamcrest-2.2.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter\5.9.3\junit-jupiter-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-params\5.9.3\junit-jupiter-params-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-engine\5.9.3\junit-jupiter-engine-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\mockito\mockito-core\5.3.1\mockito-core-5.3.1.jar;C:\work\apache-maven-3.8.8\repo\net\bytebuddy\byte-buddy-agent\1.14.8\byte-buddy-agent-1.14.8.jar;C:\work\apache-maven-3.8.8\repo\org\objenesis\objenesis\3.3\objenesis-3.3.jar;C:\work\apache-maven-3.8.8\repo\org\mockito\mockito-junit-jupiter\5.3.1\mockito-junit-jupiter-5.3.1.jar;C:\work\apache-maven-3.8.8\repo\org\skyscreamer\jsonassert\1.5.1\jsonassert-1.5.1.jar;C:\work\apache-maven-3.8.8\repo\com\vaadin\external\google\android-json\0.0.20131108.vaadin1\android-json-0.0.20131108.vaadin1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-core\6.0.12\spring-core-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-jcl\6.0.12\spring-jcl-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-test\6.0.12\spring-test-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\xmlunit\xmlunit-core\2.9.1\xmlunit-core-2.9.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy\4.0.15\groovy-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-ant\4.0.15\groovy-ant-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant\1.10.14\ant-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-junit\1.10.14\ant-junit-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-launcher\1.10.14\ant-launcher-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-antlr\1.10.14\ant-antlr-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-cli-picocli\4.0.15\groovy-cli-picocli-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\info\picocli\picocli\4.7.5\picocli-4.7.5.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-console\4.0.15\groovy-console-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\github\javaparser\javaparser-core\3.25.5\javaparser-core-3.25.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-util\9.5\asm-util-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-tree\9.5\asm-tree-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-analysis\9.5\asm-analysis-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\abego\treelayout\org.abego.treelayout.core\1.0.3\org.abego.treelayout.core-1.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ivy\ivy\2.5.2\ivy-2.5.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-datetime\4.0.15\groovy-datetime-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-docgenerator\4.0.15\groovy-docgenerator-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\thoughtworks\qdox\qdox\1.12.1\qdox-1.12.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-groovydoc\4.0.15\groovy-groovydoc-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-groovysh\4.0.15\groovy-groovysh-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\jline\jline\2.14.6\jline-2.14.6.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-jmx\4.0.15\groovy-jmx-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-json\4.0.15\groovy-json-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-jsr223\4.0.15\groovy-jsr223-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-macro\4.0.15\groovy-macro-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-nio\4.0.15\groovy-nio-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-servlet\4.0.15\groovy-servlet-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-sql\4.0.15\groovy-sql-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-swing\4.0.15\groovy-swing-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-templates\4.0.15\groovy-templates-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-test\4.0.15\groovy-test-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\junit\junit\4.13.2\junit-4.13.2.jar;C:\work\apache-maven-3.8.8\repo\org\hamcrest\hamcrest-core\2.2\hamcrest-core-2.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-test-junit5\4.0.15\groovy-test-junit5-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-xml\4.0.15\groovy-xml-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-yaml\4.0.15\groovy-yaml-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\dataformat\jackson-dataformat-yaml\2.15.2\jackson-dataformat-yaml-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\org\spockframework\spock-core\2.4-M1-groovy-4.0\spock-core-2.4-M1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-engine\1.9.3\junit-platform-engine-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\opentest4j\opentest4j\1.2.0\opentest4j-1.2.0.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-commons\1.9.3\junit-platform-commons-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\apiguardian\apiguardian-api\1.1.2\apiguardian-api-1.1.2.jar;C:\work\apache-maven-3.8.8\repo\org\spockframework\spock-spring\2.4-M1-groovy-4.0\spock-spring-2.4-M1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\com\athaydes\spock-reports\2.5.1-groovy-4.0\spock-reports-2.5.1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\com\github\codemonstur\embedded-redis\1.4.2\embedded-redis-1.4.2.jar;C:\work\apache-maven-3.8.8\repo\redis\clients\jedis\4.3.2\jedis-4.3.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\commons\commons-pool2\2.11.1\commons-pool2-2.11.1.jar;C:\work\apache-maven-3.8.8\repo\org\json\json\20220320\json-20220320.jar;C:\work\apache-maven-3.8.8\repo\com\google\code\gson\gson\2.10.1\gson-2.10.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\kafka\spring-kafka-test\3.0.11\spring-kafka-test-3.0.11.jar;C:\work\apache-maven-3.8.8\repo\org\apache\zookeeper\zookeeper\3.6.3\zookeeper-3.6.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\zookeeper\zookeeper-jute\3.6.3\zookeeper-jute-3.6.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-classes-epoll\4.1.97.Final\netty-transport-classes-epoll-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1-test.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-metadata\3.4.1\kafka-metadata-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-server-common\3.4.1\kafka-server-common-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-raft\3.4.1\kafka-raft-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-streams-test-utils\3.4.1\kafka-streams-test-utils-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-streams\3.4.1\kafka-streams-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\rocksdb\rocksdbjni\7.1.2\rocksdbjni-7.1.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\scala-library\2.13.10\scala-library-2.13.10.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-group-coordinator\3.4.1\kafka-group-coordinator-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-storage\3.4.1\kafka-storage-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-storage-api\3.4.1\kafka-storage-api-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\net\sourceforge\argparse4j\argparse4j\0.7.0\argparse4j-0.7.0.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\module\jackson-module-scala_2.13\2.15.2\jackson-module-scala_2.13-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\thoughtworks\paranamer\paranamer\2.8\paranamer-2.8.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\dataformat\jackson-dataformat-csv\2.15.2\jackson-dataformat-csv-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\net\sf\jopt-simple\jopt-simple\5.0.4\jopt-simple-5.0.4.jar;C:\work\apache-maven-3.8.8\repo\org\bitbucket\b_c\jose4j\0.9.3\jose4j-0.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\modules\scala-collection-compat_2.13\2.10.0\scala-collection-compat_2.13-2.10.0.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\modules\scala-java8-compat_2.13\1.0.2\scala-java8-compat_2.13-1.0.2.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\scala-reflect\2.13.10\scala-reflect-2.13.10.jar;C:\work\apache-maven-3.8.8\repo\com\typesafe\scala-logging\scala-logging_2.13\3.9.4\scala-logging_2.13-3.9.4.jar;C:\work\apache-maven-3.8.8\repo\io\dropwizard\metrics\metrics-core\4.2.19\metrics-core-4.2.19.jar;C:\work\apache-maven-3.8.8\repo\commons-cli\commons-cli\1.4\commons-cli-1.4.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1-test.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-api\5.9.3\junit-jupiter-api-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-launcher\1.9.3\junit-platform-launcher-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\awaitility\awaitility\4.2.0\awaitility-4.2.0.jar;
2024-12-31 21:06:24.284 Client environment:java.library.path=C:\work\jdk-17\bin;C:\windows\Sun\Java\bin;C:\windows\system32;C:\windows;C:\work\python312\Scripts\;C:\work\python312\;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program\Git\cmd;C:\Program\PowerShell\7\;C:\Program Files\dotnet\;C:\Users\joech\AppData\Local\Microsoft\WindowsApps;C:\Users\joech\AppData\Local\GitHubDesktop\bin;C:\Program\Microsoft VS Code\bin;C:\work\apache-maven-3.8.8\bin;C:\Program Files\Tesseract-OCR;C:\work\jdk-17\bin;;.
2024-12-31 21:06:24.284 Client environment:java.io.tmpdir=C:\Users\joech\AppData\Local\Temp\
2024-12-31 21:06:24.284 Client environment:java.compiler=<NA>
2024-12-31 21:06:24.284 Client environment:os.name=Windows 11
2024-12-31 21:06:24.284 Client environment:os.arch=amd64
2024-12-31 21:06:24.284 Client environment:os.version=10.0
2024-12-31 21:06:24.284 Client environment:user.name=joech
2024-12-31 21:06:24.284 Client environment:user.home=C:\Users\joech
2024-12-31 21:06:24.284 Client environment:user.dir=C:\code\hsbc\demo\pong
2024-12-31 21:06:24.284 Client environment:os.memory.free=95MB
2024-12-31 21:06:24.284 Client environment:os.memory.max=15816MB
2024-12-31 21:06:24.284 Client environment:os.memory.total=136MB
2024-12-31 21:06:24.290 Initiating client connection, connectString=127.0.0.1:59413 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7625bfbd
2024-12-31 21:06:24.296 jute.maxbuffer value is 4194304 Bytes
2024-12-31 21:06:24.304 zookeeper.request.timeout value is 0. feature enabled=false
2024-12-31 21:06:24.307 [ZooKeeperClient Kafka server] Waiting until connected.
2024-12-31 21:06:24.307 Opening socket connection to server /127.0.0.1:59413.
2024-12-31 21:06:24.309 Socket connection established, initiating session, client: /127.0.0.1:59414, server: /127.0.0.1:59413
2024-12-31 21:06:24.319 Creating new log file: log.1
2024-12-31 21:06:24.333 ZooKeeper audit is disabled.
2024-12-31 21:06:24.338 Session establishment complete on server /127.0.0.1:59413, session id = 0x100176e17c50000, negotiated timeout = 16000
2024-12-31 21:06:24.343 [ZooKeeperClient Kafka server] Connected.
2024-12-31 21:06:24.785 Cluster ID = cs9V3SfyRf-rMAykfxPJjg
2024-12-31 21:06:24.790 No meta.properties file under dir C:\Users\joech\AppData\Local\Temp\spring.kafka.f8fa9ffc-a166-42fa-9375-d6234d8183f96138590628883926380\meta.properties
2024-12-31 21:06:24.853 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.f8fa9ffc-a166-42fa-9375-d6234d8183f96138590628883926380
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59413
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:06:24.901 [ThrottledChannelReaper-Fetch]: Starting
2024-12-31 21:06:24.902 [ThrottledChannelReaper-Produce]: Starting
2024-12-31 21:06:24.904 [ThrottledChannelReaper-Request]: Starting
2024-12-31 21:06:24.908 [ThrottledChannelReaper-ControllerMutation]: Starting
2024-12-31 21:06:24.955 Loading logs from log dirs ArraySeq(C:\Users\joech\AppData\Local\Temp\spring.kafka.f8fa9ffc-a166-42fa-9375-d6234d8183f96138590628883926380)
2024-12-31 21:06:24.960 Attempting recovery for all logs in C:\Users\joech\AppData\Local\Temp\spring.kafka.f8fa9ffc-a166-42fa-9375-d6234d8183f96138590628883926380 since no clean shutdown file was found
2024-12-31 21:06:24.973 Loaded 0 logs in 17ms.
2024-12-31 21:06:24.974 Starting log cleanup with a period of 300000 ms.
2024-12-31 21:06:24.978 Starting log flusher with a default period of 9223372036854775807 ms.
2024-12-31 21:06:24.999 Starting the log cleaner
2024-12-31 21:06:25.015 [kafka-log-cleaner-thread-0]: Starting
2024-12-31 21:06:25.035 [feature-zk-node-event-process-thread]: Starting
2024-12-31 21:06:25.050 Feature ZK node at path: /feature does not exist
2024-12-31 21:06:25.096 [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting
2024-12-31 21:06:25.598 Updated connection-accept-rate max connection creation rate to 2147483647
2024-12-31 21:06:25.609 Awaiting socket connections on localhost:59415.
2024-12-31 21:06:25.643 [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT)
2024-12-31 21:06:25.655 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Starting
2024-12-31 21:06:25.679 [ExpirationReaper-0-Produce]: Starting
2024-12-31 21:06:25.679 [ExpirationReaper-0-Fetch]: Starting
2024-12-31 21:06:25.680 [ExpirationReaper-0-DeleteRecords]: Starting
2024-12-31 21:06:25.681 [ExpirationReaper-0-ElectLeader]: Starting
2024-12-31 21:06:25.709 [LogDirFailureHandler]: Starting
2024-12-31 21:06:25.736 Creating /brokers/ids/0 (is it secure? false)
2024-12-31 21:06:25.765 Stat of the created znode at /brokers/ids/0 is: 25,25,1735650385755,1735650385755,1,0,0,72083355650555904,204,0,25

2024-12-31 21:06:25.766 Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:59415, czxid (broker epoch): 25
2024-12-31 21:06:25.861 [ControllerEventThread controllerId=0] Starting
2024-12-31 21:06:25.868 [ExpirationReaper-0-topic]: Starting
2024-12-31 21:06:25.880 [ExpirationReaper-0-Heartbeat]: Starting
2024-12-31 21:06:25.880 [ExpirationReaper-0-Rebalance]: Starting
2024-12-31 21:06:25.889 Successfully created /controller_epoch with initial epoch 0
2024-12-31 21:06:25.896 [Controller id=0] 0 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1
2024-12-31 21:06:25.901 [Controller id=0] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map())
2024-12-31 21:06:25.907 Feature ZK node created at path: /feature
2024-12-31 21:06:25.911 [GroupCoordinator 0]: Starting up.
2024-12-31 21:06:25.919 [GroupCoordinator 0]: Startup complete.
2024-12-31 21:06:25.951 [TransactionCoordinator id=0] Starting up.
2024-12-31 21:06:25.956 [TransactionCoordinator id=0] Startup complete.
2024-12-31 21:06:25.956 [Transaction Marker Channel Manager 0]: Starting
2024-12-31 21:06:25.958 [MetadataCache brokerId=0] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0).
2024-12-31 21:06:25.959 [Controller id=0] Registering handlers
2024-12-31 21:06:25.964 [Controller id=0] Deleting log dir event notifications
2024-12-31 21:06:25.967 [Controller id=0] Deleting isr change notifications
2024-12-31 21:06:25.970 [Controller id=0] Initializing controller context
2024-12-31 21:06:25.990 [Controller id=0] Initialized broker epochs cache: HashMap(0 -> 25)
2024-12-31 21:06:26.006 [ExpirationReaper-0-AlterAcls]: Starting
2024-12-31 21:06:26.017 [RequestSendThread controllerId=0] Starting
2024-12-31 21:06:26.020 [Controller id=0] Currently active brokers in the cluster: Set(0)
2024-12-31 21:06:26.021 [Controller id=0] Currently shutting brokers in the cluster: HashSet()
2024-12-31 21:06:26.021 [Controller id=0] Current list of topics in the cluster: HashSet()
2024-12-31 21:06:26.021 [Controller id=0] Fetching topic deletions in progress
2024-12-31 21:06:26.024 [Controller id=0] List of topics to be deleted: 
2024-12-31 21:06:26.025 [Controller id=0] List of topics ineligible for deletion: 
2024-12-31 21:06:26.025 [Controller id=0] Initializing topic deletion manager
2024-12-31 21:06:26.026 [Topic Deletion Manager 0] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet()
2024-12-31 21:06:26.029 [Controller id=0] Sending update metadata request
2024-12-31 21:06:26.032 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions
2024-12-31 21:06:26.050 [ReplicaStateMachine controllerId=0] Initializing replica state
2024-12-31 21:06:26.051 [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2024-12-31 21:06:26.057 [ReplicaStateMachine controllerId=0] Triggering offline replica state changes
2024-12-31 21:06:26.057 [/config/changes-event-process-thread]: Starting
2024-12-31 21:06:26.058 [PartitionStateMachine controllerId=0] Initializing partition state
2024-12-31 21:06:26.058 [PartitionStateMachine controllerId=0] Triggering online partition state changes
2024-12-31 21:06:26.063 [RequestSendThread controllerId=0] Controller 0 connected to localhost:59415 (id: 0 rack: null) for sending state change requests
2024-12-31 21:06:26.063 [Controller id=0] Ready to serve as the new controller with epoch 1
2024-12-31 21:06:26.066 [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing.
2024-12-31 21:06:26.073 [Controller id=0] Partitions undergoing preferred replica election: 
2024-12-31 21:06:26.074 [Controller id=0] Partitions that completed preferred replica election: 
2024-12-31 21:06:26.074 [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2024-12-31 21:06:26.074 [Controller id=0] Resuming preferred replica election for partitions: 
2024-12-31 21:06:26.075 Kafka version: 3.4.1
2024-12-31 21:06:26.075 Kafka commitId: 8a516edc2755df89
2024-12-31 21:06:26.075 Kafka startTimeMs: 1735650386073
2024-12-31 21:06:26.076 [Controller id=0] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered
2024-12-31 21:06:26.077 [KafkaServer id=0] started
2024-12-31 21:06:26.085 AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [127.0.0.1:59415]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-31 21:06:26.091 [Controller id=0] Starting the controller scheduler
2024-12-31 21:06:26.135 Kafka version: 3.4.1
2024-12-31 21:06:26.135 Kafka commitId: 8a516edc2755df89
2024-12-31 21:06:26.135 Kafka startTimeMs: 1735650386135
2024-12-31 21:06:26.160 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Recorded new controller, from now on will use node localhost:59415 (id: 0 rack: null)
2024-12-31 21:06:26.211 [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use node localhost:59415 (id: 0 rack: null)
2024-12-31 21:06:26.263 Creating topic pong-message-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0))
2024-12-31 21:06:26.295 [Controller id=0] New topics: [Set(pong-message-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(pong-message-topic,Some(nl-UGCIpSrmXBiuXaAfnGg),Map(pong-message-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), pong-message-topic-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:06:26.298 [Controller id=0] New partition creation callback for pong-message-topic-0,pong-message-topic-1
2024-12-31 21:06:26.301 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:06:26.301 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:06:26.301 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:06:26.306 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:06:26.334 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:06:26.335 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:06:26.337 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2024-12-31 21:06:26.340 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2024-12-31 21:06:26.342 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:06:26.347 [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 for 2 partitions
2024-12-31 21:06:26.389 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(pong-message-topic-0, pong-message-topic-1)
2024-12-31 21:06:26.390 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2024-12-31 21:06:26.491 [LogLoader partition=pong-message-topic-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.f8fa9ffc-a166-42fa-9375-d6234d8183f96138590628883926380] Loading producer state till offset 0 with message format version 2
2024-12-31 21:06:26.516 Created log for partition pong-message-topic-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.f8fa9ffc-a166-42fa-9375-d6234d8183f96138590628883926380\pong-message-topic-0 with properties {}
2024-12-31 21:06:26.518 [Partition pong-message-topic-0 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-0
2024-12-31 21:06:26.519 [Partition pong-message-topic-0 broker=0] Log loaded for partition pong-message-topic-0 with initial high watermark 0
2024-12-31 21:06:26.521 [Broker id=0] Leader pong-message-topic-0 with topic id Some(nl-UGCIpSrmXBiuXaAfnGg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:06:26.538 [LogLoader partition=pong-message-topic-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.f8fa9ffc-a166-42fa-9375-d6234d8183f96138590628883926380] Loading producer state till offset 0 with message format version 2
2024-12-31 21:06:26.540 Created log for partition pong-message-topic-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.f8fa9ffc-a166-42fa-9375-d6234d8183f96138590628883926380\pong-message-topic-1 with properties {}
2024-12-31 21:06:26.540 [Partition pong-message-topic-1 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-1
2024-12-31 21:06:26.540 [Partition pong-message-topic-1 broker=0] Log loaded for partition pong-message-topic-1 with initial high watermark 0
2024-12-31 21:06:26.540 [Broker id=0] Leader pong-message-topic-1 with topic id Some(nl-UGCIpSrmXBiuXaAfnGg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:06:26.551 [Broker id=0] Finished LeaderAndIsr request in 207ms correlationId 1 from controller 0 for 2 partitions
2024-12-31 21:06:26.560 [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2
2024-12-31 21:06:26.568 App info kafka.admin.client for adminclient-1 unregistered
2024-12-31 21:06:26.571 Metrics scheduler closed
2024-12-31 21:06:26.571 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:06:26.571 Metrics reporters closed
2024-12-31 21:06:26.928 

Found multiple occurrences of org.json.JSONObject on the class path:

	jar:file:/C:/work/apache-maven-3.8.8/repo/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar!/org/json/JSONObject.class
	jar:file:/C:/work/apache-maven-3.8.8/repo/org/json/json/20220320/json-20220320.jar!/org/json/JSONObject.class

You may wish to exclude one of them to ensure predictable runtime behavior

2024-12-31 21:06:26.950 zookeeper.snapshot.trust.empty : false
2024-12-31 21:06:26.952 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:06:26.952 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:06:26.952 zookeeper.snapshotSizeFactor = 0.33
2024-12-31 21:06:26.952 zookeeper.commitLogCount=500
2024-12-31 21:06:26.952 minSessionTimeout set to 1600
2024-12-31 21:06:26.952 maxSessionTimeout set to 16000
2024-12-31 21:06:26.952 Response cache size is initialized with value 400.
2024-12-31 21:06:26.952 Response cache size is initialized with value 400.
2024-12-31 21:06:26.952 zookeeper.pathStats.slotCapacity = 60
2024-12-31 21:06:26.952 zookeeper.pathStats.slotDuration = 15
2024-12-31 21:06:26.952 zookeeper.pathStats.maxDepth = 6
2024-12-31 21:06:26.952 zookeeper.pathStats.initialDelay = 5
2024-12-31 21:06:26.952 zookeeper.pathStats.delay = 5
2024-12-31 21:06:26.952 zookeeper.pathStats.enabled = false
2024-12-31 21:06:26.952 The max bytes for all large requests are set to 104857600
2024-12-31 21:06:26.952 The large request threshold is set to -1
2024-12-31 21:06:26.953 Created server with tickTime 800 minSessionTimeout 1600 maxSessionTimeout 16000 clientPortListenBacklog -1 datadir C:\Users\joech\AppData\Local\Temp\kafka-6156502616001844391\version-2 snapdir C:\Users\joech\AppData\Local\Temp\kafka-870708998525614160\version-2
2024-12-31 21:06:26.953 maxCnxns is not configured, using default value 0.
2024-12-31 21:06:26.953 Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers.
2024-12-31 21:06:26.956 binding to port /127.0.0.1:0
2024-12-31 21:06:26.958 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-870708998525614160\version-2\snapshot.0
2024-12-31 21:06:26.958 Snapshot loaded in 1 ms, highest zxid is 0x0, digest is 1371985504
2024-12-31 21:06:26.959 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-870708998525614160\version-2\snapshot.0
2024-12-31 21:06:26.959 Snapshot taken in 1 ms
2024-12-31 21:06:26.960 PrepRequestProcessor (sid:0) started, reconfigEnabled=false
2024-12-31 21:06:26.963 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.ab90a101-aad0-4b02-b46c-fbe808c6e58b16290002568815701410
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59419
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:06:26.967 starting
2024-12-31 21:06:26.967 Connecting to zookeeper on 127.0.0.1:59419
2024-12-31 21:06:26.968 [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:59419.
2024-12-31 21:06:26.968 Initiating client connection, connectString=127.0.0.1:59419 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@637ae337
2024-12-31 21:06:26.970 jute.maxbuffer value is 4194304 Bytes
2024-12-31 21:06:26.970 zookeeper.request.timeout value is 0. feature enabled=false
2024-12-31 21:06:26.971 [ZooKeeperClient Kafka server] Waiting until connected.
2024-12-31 21:06:26.971 Opening socket connection to server /127.0.0.1:59419.
2024-12-31 21:06:26.972 Socket connection established, initiating session, client: /127.0.0.1:59420, server: /127.0.0.1:59419
2024-12-31 21:06:26.973 Creating new log file: log.1
2024-12-31 21:06:26.980 Session establishment complete on server /127.0.0.1:59419, session id = 0x100176e38cf0000, negotiated timeout = 16000
2024-12-31 21:06:26.980 [ZooKeeperClient Kafka server] Connected.
2024-12-31 21:06:27.013 Cluster ID = C9uTJzX5SmiY_i9yFR2l7A
2024-12-31 21:06:27.014 No meta.properties file under dir C:\Users\joech\AppData\Local\Temp\spring.kafka.ab90a101-aad0-4b02-b46c-fbe808c6e58b16290002568815701410\meta.properties
2024-12-31 21:06:27.022 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.ab90a101-aad0-4b02-b46c-fbe808c6e58b16290002568815701410
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59419
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:06:27.032 [ThrottledChannelReaper-Fetch]: Starting
2024-12-31 21:06:27.032 [ThrottledChannelReaper-ControllerMutation]: Starting
2024-12-31 21:06:27.032 [ThrottledChannelReaper-Request]: Starting
2024-12-31 21:06:27.032 [ThrottledChannelReaper-Produce]: Starting
2024-12-31 21:06:27.041 Loading logs from log dirs ArraySeq(C:\Users\joech\AppData\Local\Temp\spring.kafka.ab90a101-aad0-4b02-b46c-fbe808c6e58b16290002568815701410)
2024-12-31 21:06:27.041 Attempting recovery for all logs in C:\Users\joech\AppData\Local\Temp\spring.kafka.ab90a101-aad0-4b02-b46c-fbe808c6e58b16290002568815701410 since no clean shutdown file was found
2024-12-31 21:06:27.043 Loaded 0 logs in 1ms.
2024-12-31 21:06:27.043 Starting log cleanup with a period of 300000 ms.
2024-12-31 21:06:27.043 Starting log flusher with a default period of 9223372036854775807 ms.
2024-12-31 21:06:27.044 Starting the log cleaner
2024-12-31 21:06:27.045 [kafka-log-cleaner-thread-0]: Starting
2024-12-31 21:06:27.045 [feature-zk-node-event-process-thread]: Starting
2024-12-31 21:06:27.047 Feature ZK node at path: /feature does not exist
2024-12-31 21:06:27.049 [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting
2024-12-31 21:06:27.065 Updated connection-accept-rate max connection creation rate to 2147483647
2024-12-31 21:06:27.067 Awaiting socket connections on localhost:59421.
2024-12-31 21:06:27.074 [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT)
2024-12-31 21:06:27.076 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Starting
2024-12-31 21:06:27.077 [ExpirationReaper-0-Produce]: Starting
2024-12-31 21:06:27.078 [ExpirationReaper-0-Fetch]: Starting
2024-12-31 21:06:27.078 [ExpirationReaper-0-DeleteRecords]: Starting
2024-12-31 21:06:27.078 [ExpirationReaper-0-ElectLeader]: Starting
2024-12-31 21:06:27.080 [LogDirFailureHandler]: Starting
2024-12-31 21:06:27.082 Creating /brokers/ids/0 (is it secure? false)
2024-12-31 21:06:27.084 Stat of the created znode at /brokers/ids/0 is: 25,25,1735650387083,1735650387083,1,0,0,72083356204859392,204,0,25

2024-12-31 21:06:27.084 Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:59421, czxid (broker epoch): 25
2024-12-31 21:06:27.093 [ControllerEventThread controllerId=0] Starting
2024-12-31 21:06:27.094 [ExpirationReaper-0-topic]: Starting
2024-12-31 21:06:27.094 [ExpirationReaper-0-Heartbeat]: Starting
2024-12-31 21:06:27.095 [ExpirationReaper-0-Rebalance]: Starting
2024-12-31 21:06:27.096 [GroupCoordinator 0]: Starting up.
2024-12-31 21:06:27.097 [GroupCoordinator 0]: Startup complete.
2024-12-31 21:06:27.097 Successfully created /controller_epoch with initial epoch 0
2024-12-31 21:06:27.098 [TransactionCoordinator id=0] Starting up.
2024-12-31 21:06:27.098 [Controller id=0] 0 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1
2024-12-31 21:06:27.099 [Controller id=0] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map())
2024-12-31 21:06:27.099 [TransactionCoordinator id=0] Startup complete.
2024-12-31 21:06:27.100 [Transaction Marker Channel Manager 0]: Starting
2024-12-31 21:06:27.101 Feature ZK node created at path: /feature
2024-12-31 21:06:27.101 [ExpirationReaper-0-AlterAcls]: Starting
2024-12-31 21:06:27.102 [Controller id=0] Registering handlers
2024-12-31 21:06:27.102 [MetadataCache brokerId=0] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0).
2024-12-31 21:06:27.103 [Controller id=0] Deleting log dir event notifications
2024-12-31 21:06:27.104 [Controller id=0] Deleting isr change notifications
2024-12-31 21:06:27.104 [/config/changes-event-process-thread]: Starting
2024-12-31 21:06:27.105 [Controller id=0] Initializing controller context
2024-12-31 21:06:27.107 [Controller id=0] Initialized broker epochs cache: HashMap(0 -> 25)
2024-12-31 21:06:27.108 [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing.
2024-12-31 21:06:27.109 Kafka version: 3.4.1
2024-12-31 21:06:27.109 Kafka commitId: 8a516edc2755df89
2024-12-31 21:06:27.109 Kafka startTimeMs: 1735650387109
2024-12-31 21:06:27.113 [Controller id=0] Currently active brokers in the cluster: Set(0)
2024-12-31 21:06:27.113 [Controller id=0] Currently shutting brokers in the cluster: HashSet()
2024-12-31 21:06:27.113 [RequestSendThread controllerId=0] Starting
2024-12-31 21:06:27.113 [Controller id=0] Current list of topics in the cluster: HashSet()
2024-12-31 21:06:27.113 [Controller id=0] Fetching topic deletions in progress
2024-12-31 21:06:27.114 [Controller id=0] List of topics to be deleted: 
2024-12-31 21:06:27.114 [Controller id=0] List of topics ineligible for deletion: 
2024-12-31 21:06:27.114 [Controller id=0] Initializing topic deletion manager
2024-12-31 21:06:27.115 [Topic Deletion Manager 0] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet()
2024-12-31 21:06:27.115 [Controller id=0] Sending update metadata request
2024-12-31 21:06:27.115 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions
2024-12-31 21:06:27.110 Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.server:type=app-info,id=0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1865)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:960)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:895)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:523)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:563)
	at kafka.utils.TestUtils$.createServer(TestUtils.scala:188)
	at kafka.utils.TestUtils$.createServer(TestUtils.scala:182)
	at kafka.utils.TestUtils.createServer(TestUtils.scala)
	at org.springframework.kafka.test.EmbeddedKafkaBroker.afterPropertiesSet(EmbeddedKafkaBroker.java:369)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1817)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1766)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:410)
	at org.springframework.kafka.test.context.EmbeddedKafkaContextCustomizer.customizeContext(EmbeddedKafkaContextCustomizer.java:116)
	at org.springframework.boot.test.context.SpringBootContextLoader$ContextCustomizerAdapter.initialize(SpringBootContextLoader.java:435)
	at org.springframework.boot.SpringApplication.applyInitializers(SpringApplication.java:610)
	at org.springframework.boot.SpringApplication.prepareContext(SpringApplication.java:390)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:314)
	at org.springframework.boot.test.context.SpringBootContextLoader.lambda$loadContext$3(SpringBootContextLoader.java:137)
	at org.springframework.util.function.ThrowingSupplier.get(ThrowingSupplier.java:58)
	at org.springframework.util.function.ThrowingSupplier.get(ThrowingSupplier.java:46)
	at org.springframework.boot.SpringApplication.withHook(SpringApplication.java:1409)
	at org.springframework.boot.test.context.SpringBootContextLoader$ContextLoaderHook.run(SpringBootContextLoader.java:545)
	at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:137)
	at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:108)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:187)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:119)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:127)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:141)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:97)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:241)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:56)
	at org.spockframework.spring.SpringInterceptor.interceptInitializerMethod(SpringInterceptor.java:46)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:24)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:101)
	at org.spockframework.runtime.PlatformSpecRunner.invoke(PlatformSpecRunner.java:398)
	at org.spockframework.runtime.PlatformSpecRunner.runInitializer(PlatformSpecRunner.java:259)
	at org.spockframework.runtime.PlatformSpecRunner.runInitializer(PlatformSpecRunner.java:254)
	at org.spockframework.runtime.IterationNode.prepare(IterationNode.java:31)
	at org.spockframework.runtime.IterationNode.prepare(IterationNode.java:13)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$prepare$2(NodeTestTask.java:123)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.prepare(NodeTestTask.java:123)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:90)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:226)
	at org.spockframework.runtime.ParameterizedFeatureChildExecutor.execute(ParameterizedFeatureChildExecutor.java:104)
	at org.spockframework.runtime.PlatformParameterizedSpecRunner$1.runIteration(PlatformParameterizedSpecRunner.java:72)
	at org.spockframework.runtime.extension.IDataDriver.lambda$static$0(IDataDriver.java:37)
	at org.spockframework.runtime.PlatformParameterizedSpecRunner.runParameterizedFeature(PlatformParameterizedSpecRunner.java:47)
	at org.spockframework.runtime.ParameterizedFeatureNode.execute(ParameterizedFeatureNode.java:40)
	at org.spockframework.runtime.ParameterizedFeatureNode.execute(ParameterizedFeatureNode.java:16)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.spockframework.runtime.SpockNode.sneakyInvoke(SpockNode.java:40)
	at org.spockframework.runtime.FeatureNode.lambda$around$0(FeatureNode.java:41)
	at org.spockframework.runtime.PlatformSpecRunner.lambda$createMethodInfoForDoRunFeature$4(PlatformSpecRunner.java:199)
	at org.spockframework.runtime.model.MethodInfo.invoke(MethodInfo.java:156)
	at org.spockframework.runtime.PlatformSpecRunner.invokeRaw(PlatformSpecRunner.java:407)
	at org.spockframework.runtime.PlatformSpecRunner.invoke(PlatformSpecRunner.java:390)
	at org.spockframework.runtime.PlatformSpecRunner.runFeature(PlatformSpecRunner.java:192)
	at org.spockframework.runtime.FeatureNode.around(FeatureNode.java:41)
	at org.spockframework.runtime.FeatureNode.around(FeatureNode.java:12)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1511)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.spockframework.runtime.SpockNode.sneakyInvoke(SpockNode.java:40)
	at org.spockframework.runtime.SpecNode.lambda$around$0(SpecNode.java:63)
	at org.spockframework.runtime.PlatformSpecRunner.lambda$createMethodInfoForDoRunSpec$0(PlatformSpecRunner.java:61)
	at org.spockframework.runtime.model.MethodInfo.invoke(MethodInfo.java:156)
	at org.spockframework.runtime.PlatformSpecRunner.invokeRaw(PlatformSpecRunner.java:407)
	at org.spockframework.runtime.PlatformSpecRunner.invoke(PlatformSpecRunner.java:390)
	at org.spockframework.runtime.PlatformSpecRunner.runSpec(PlatformSpecRunner.java:55)
	at org.spockframework.runtime.SpecNode.around(SpecNode.java:63)
	at org.spockframework.runtime.SpecNode.around(SpecNode.java:11)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1511)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:147)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:127)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:90)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:55)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:102)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:150)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2024-12-31 21:06:27.115 [KafkaServer id=0] started
2024-12-31 21:06:27.115 [ReplicaStateMachine controllerId=0] Initializing replica state
2024-12-31 21:06:27.115 [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2024-12-31 21:06:27.115 [ReplicaStateMachine controllerId=0] Triggering offline replica state changes
2024-12-31 21:06:27.115 [PartitionStateMachine controllerId=0] Initializing partition state
2024-12-31 21:06:27.115 [PartitionStateMachine controllerId=0] Triggering online partition state changes
2024-12-31 21:06:27.116 [Controller id=0] Ready to serve as the new controller with epoch 1
2024-12-31 21:06:27.116 AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [127.0.0.1:59421]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-31 21:06:27.116 [RequestSendThread controllerId=0] Controller 0 connected to localhost:59421 (id: 0 rack: null) for sending state change requests
2024-12-31 21:06:27.117 [Controller id=0] Partitions undergoing preferred replica election: 
2024-12-31 21:06:27.118 [Controller id=0] Partitions that completed preferred replica election: 
2024-12-31 21:06:27.118 [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2024-12-31 21:06:27.118 [Controller id=0] Resuming preferred replica election for partitions: 
2024-12-31 21:06:27.118 [Controller id=0] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered
2024-12-31 21:06:27.119 Kafka version: 3.4.1
2024-12-31 21:06:27.119 Kafka commitId: 8a516edc2755df89
2024-12-31 21:06:27.119 Kafka startTimeMs: 1735650387119
2024-12-31 21:06:27.119 [Controller id=0] Starting the controller scheduler
2024-12-31 21:06:27.131 Creating topic pong-message-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2024-12-31 21:06:27.138 [Controller id=0] New topics: [Set(pong-message-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(pong-message-topic,Some(IOVrqR7ARSeq9i7WuD9Y3w),Map(pong-message-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:06:27.138 [Controller id=0] New partition creation callback for pong-message-topic-0
2024-12-31 21:06:27.138 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:06:27.138 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:06:27.138 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:06:27.142 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:06:27.142 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions
2024-12-31 21:06:27.143 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 1 partitions
2024-12-31 21:06:27.144 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:06:27.144 [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 for 1 partitions
2024-12-31 21:06:27.144 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(pong-message-topic-0)
2024-12-31 21:06:27.144 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions
2024-12-31 21:06:27.149 [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use node localhost:59421 (id: 0 rack: null)
2024-12-31 21:06:27.155 [LogLoader partition=pong-message-topic-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.ab90a101-aad0-4b02-b46c-fbe808c6e58b16290002568815701410] Loading producer state till offset 0 with message format version 2
2024-12-31 21:06:27.156 Created log for partition pong-message-topic-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.ab90a101-aad0-4b02-b46c-fbe808c6e58b16290002568815701410\pong-message-topic-0 with properties {}
2024-12-31 21:06:27.156 [Partition pong-message-topic-0 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-0
2024-12-31 21:06:27.156 [Partition pong-message-topic-0 broker=0] Log loaded for partition pong-message-topic-0 with initial high watermark 0
2024-12-31 21:06:27.156 [Broker id=0] Leader pong-message-topic-0 with topic id Some(IOVrqR7ARSeq9i7WuD9Y3w) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:06:27.159 [Broker id=0] Finished LeaderAndIsr request in 15ms correlationId 1 from controller 0 for 1 partitions
2024-12-31 21:06:27.161 [Broker id=0] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2
2024-12-31 21:06:27.163 App info kafka.admin.client for adminclient-2 unregistered
2024-12-31 21:06:27.164 Metrics scheduler closed
2024-12-31 21:06:27.164 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:06:27.164 Metrics reporters closed
2024-12-31 21:06:27.172 Starting PongControllerSpec using Java 17.0.12 with PID 11052 (started by joech in C:\code\hsbc\demo\pong)
2024-12-31 21:06:27.173 No active profile set, falling back to 1 default profile: "default"
2024-12-31 21:06:27.178 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Recorded new controller, from now on will use node localhost:59421 (id: 0 rack: null)
2024-12-31 21:06:27.808 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:06:27.812 Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2024-12-31 21:06:27.963 Finished Spring Data repository scanning in 143 ms. Found 1 JPA repository interfaces.
2024-12-31 21:06:27.984 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:06:27.985 Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2024-12-31 21:06:28.003 Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.demo.dao.MessageRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2024-12-31 21:06:28.004 Finished Spring Data repository scanning in 6 ms. Found 0 Redis repository interfaces.
2024-12-31 21:06:28.724 HHH000204: Processing PersistenceUnitInfo [name: default]
2024-12-31 21:06:28.810 HHH000412: Hibernate ORM core version 6.2.9.Final
2024-12-31 21:06:28.814 HHH000406: Using bytecode reflection optimizer
2024-12-31 21:06:29.010 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:06:29.202 No LoadTimeWeaver setup: ignoring JPA class transformer
2024-12-31 21:06:29.231 HikariPool-1 - Starting...
2024-12-31 21:06:29.536 HikariPool-1 - Added connection conn0: url=jdbc:h2:mem:testdb user=SA
2024-12-31 21:06:29.539 HikariPool-1 - Start completed.
2024-12-31 21:06:29.876 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:06:30.658 HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2024-12-31 21:06:30.773 Initialized JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:06:31.093 [Controller id=0] Processing automatic preferred replica leader election
2024-12-31 21:06:32.121 [Controller id=0] Processing automatic preferred replica leader election
2024-12-31 21:06:32.260 Netty started on port 59425
2024-12-31 21:06:32.292 ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:59415]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-pong-service-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = pong-service
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2024-12-31 21:06:32.337 These configurations '[spring.json.trusted.packages]' were supplied but are not used yet.
2024-12-31 21:06:32.337 Kafka version: 3.4.1
2024-12-31 21:06:32.337 Kafka commitId: 8a516edc2755df89
2024-12-31 21:06:32.337 Kafka startTimeMs: 1735650392337
2024-12-31 21:06:32.339 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Subscribed to topic(s): pong-message-topic
2024-12-31 21:06:32.356 Started PongControllerSpec in 5.709 seconds (process running for 22.252)
2024-12-31 21:06:32.367 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting the last seen epoch of partition pong-message-topic-0 to 0 since the associated topicId changed from null to nl-UGCIpSrmXBiuXaAfnGg
2024-12-31 21:06:32.367 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting the last seen epoch of partition pong-message-topic-1 to 0 since the associated topicId changed from null to nl-UGCIpSrmXBiuXaAfnGg
2024-12-31 21:06:32.369 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Cluster ID: cs9V3SfyRf-rMAykfxPJjg
2024-12-31 21:06:32.371 Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0))
2024-12-31 21:06:32.377 [Controller id=0] New topics: [Set(__consumer_offsets)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(__consumer_offsets,Some(pTGZKKdyT2yCeKJNN7YNGQ),HashMap(__consumer_offsets-4 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-3 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-2 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:06:32.377 [Controller id=0] New partition creation callback for __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2024-12-31 21:06:32.377 [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:06:32.377 [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:06:32.377 [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:06:32.377 [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:06:32.377 [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:06:32.377 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:06:32.379 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:06:32.386 [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:06:32.386 [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:06:32.386 [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:06:32.386 [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:06:32.386 [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:06:32.386 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 5 become-leader and 0 become-follower partitions
2024-12-31 21:06:32.386 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 5 partitions
2024-12-31 21:06:32.386 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:06:32.388 [Broker id=0] Handling LeaderAndIsr request correlationId 3 from controller 0 for 5 partitions
2024-12-31 21:06:32.389 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-4, __consumer_offsets-3, __consumer_offsets-2, __consumer_offsets-0, __consumer_offsets-1)
2024-12-31 21:06:32.389 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 3 from controller 0 epoch 1 as part of the become-leader transition for 5 partitions
2024-12-31 21:06:32.400 [LogLoader partition=__consumer_offsets-3, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.f8fa9ffc-a166-42fa-9375-d6234d8183f96138590628883926380] Loading producer state till offset 0 with message format version 2
2024-12-31 21:06:32.402 Created log for partition __consumer_offsets-3 in C:\Users\joech\AppData\Local\Temp\spring.kafka.f8fa9ffc-a166-42fa-9375-d6234d8183f96138590628883926380\__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:06:32.410 [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
2024-12-31 21:06:32.410 [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0
2024-12-31 21:06:32.410 [Broker id=0] Leader __consumer_offsets-3 with topic id Some(pTGZKKdyT2yCeKJNN7YNGQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:06:32.418 [LogLoader partition=__consumer_offsets-2, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.f8fa9ffc-a166-42fa-9375-d6234d8183f96138590628883926380] Loading producer state till offset 0 with message format version 2
2024-12-31 21:06:32.420 Created log for partition __consumer_offsets-2 in C:\Users\joech\AppData\Local\Temp\spring.kafka.f8fa9ffc-a166-42fa-9375-d6234d8183f96138590628883926380\__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:06:32.420 [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
2024-12-31 21:06:32.420 [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0
2024-12-31 21:06:32.421 [Broker id=0] Leader __consumer_offsets-2 with topic id Some(pTGZKKdyT2yCeKJNN7YNGQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:06:32.429 [LogLoader partition=__consumer_offsets-4, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.f8fa9ffc-a166-42fa-9375-d6234d8183f96138590628883926380] Loading producer state till offset 0 with message format version 2
2024-12-31 21:06:32.430 Created log for partition __consumer_offsets-4 in C:\Users\joech\AppData\Local\Temp\spring.kafka.f8fa9ffc-a166-42fa-9375-d6234d8183f96138590628883926380\__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:06:32.430 [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
2024-12-31 21:06:32.430 [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0
2024-12-31 21:06:32.430 [Broker id=0] Leader __consumer_offsets-4 with topic id Some(pTGZKKdyT2yCeKJNN7YNGQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:06:32.439 [LogLoader partition=__consumer_offsets-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.f8fa9ffc-a166-42fa-9375-d6234d8183f96138590628883926380] Loading producer state till offset 0 with message format version 2
2024-12-31 21:06:32.440 Created log for partition __consumer_offsets-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.f8fa9ffc-a166-42fa-9375-d6234d8183f96138590628883926380\__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:06:32.440 [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
2024-12-31 21:06:32.440 [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0
2024-12-31 21:06:32.440 [Broker id=0] Leader __consumer_offsets-1 with topic id Some(pTGZKKdyT2yCeKJNN7YNGQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:06:32.449 [LogLoader partition=__consumer_offsets-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.f8fa9ffc-a166-42fa-9375-d6234d8183f96138590628883926380] Loading producer state till offset 0 with message format version 2
2024-12-31 21:06:32.450 Created log for partition __consumer_offsets-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.f8fa9ffc-a166-42fa-9375-d6234d8183f96138590628883926380\__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:06:32.451 [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
2024-12-31 21:06:32.451 [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0
2024-12-31 21:06:32.451 [Broker id=0] Leader __consumer_offsets-0 with topic id Some(pTGZKKdyT2yCeKJNN7YNGQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:06:32.455 [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 0
2024-12-31 21:06:32.456 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0
2024-12-31 21:06:32.457 [GroupCoordinator 0]: Elected as the group coordinator for partition 2 in epoch 0
2024-12-31 21:06:32.457 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0
2024-12-31 21:06:32.457 [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 0
2024-12-31 21:06:32.457 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0
2024-12-31 21:06:32.457 [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 0
2024-12-31 21:06:32.457 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0
2024-12-31 21:06:32.457 [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 0
2024-12-31 21:06:32.457 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0
2024-12-31 21:06:32.457 [Broker id=0] Finished LeaderAndIsr request in 69ms correlationId 3 from controller 0 for 5 partitions
2024-12-31 21:06:32.459 [Broker id=0] Add 5 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 4
2024-12-31 21:06:32.461 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 5 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler.
2024-12-31 21:06:32.462 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler.
2024-12-31 21:06:32.462 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler.
2024-12-31 21:06:32.462 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler.
2024-12-31 21:06:32.462 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler.
2024-12-31 21:06:32.471 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Discovered group coordinator localhost:59415 (id: 2147483647 rack: null)
2024-12-31 21:06:32.473 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] (Re-)joining group
2024-12-31 21:06:32.491 [GroupCoordinator 0]: Dynamic member with unknown member id joins group pong-service in Empty state. Created a new member id consumer-pong-service-1-f64eb8f9-5cf0-456c-bfa2-6554e928a6a4 and request the member to rejoin with this id.
2024-12-31 21:06:32.494 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: need to re-join with the given member-id: consumer-pong-service-1-f64eb8f9-5cf0-456c-bfa2-6554e928a6a4
2024-12-31 21:06:32.495 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2024-12-31 21:06:32.495 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] (Re-)joining group
2024-12-31 21:06:32.501 [GroupCoordinator 0]: Preparing to rebalance group pong-service in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-pong-service-1-f64eb8f9-5cf0-456c-bfa2-6554e928a6a4 with group instance id None; client reason: rebalance failed due to MemberIdRequiredException)
2024-12-31 21:06:32.505 [GroupCoordinator 0]: Stabilized group pong-service generation 1 (__consumer_offsets-2) with 1 members
2024-12-31 21:06:32.507 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Successfully joined group with generation Generation{generationId=1, memberId='consumer-pong-service-1-f64eb8f9-5cf0-456c-bfa2-6554e928a6a4', protocol='range'}
2024-12-31 21:06:32.509 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Finished assignment for group at generation 1: {consumer-pong-service-1-f64eb8f9-5cf0-456c-bfa2-6554e928a6a4=Assignment(partitions=[pong-message-topic-0, pong-message-topic-1])}
2024-12-31 21:06:32.516 [GroupCoordinator 0]: Assignment received from leader consumer-pong-service-1-f64eb8f9-5cf0-456c-bfa2-6554e928a6a4 for group pong-service for generation 1. The group has 1 members, 0 of which are static.
2024-12-31 21:06:32.577 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Successfully synced group in generation Generation{generationId=1, memberId='consumer-pong-service-1-f64eb8f9-5cf0-456c-bfa2-6554e928a6a4', protocol='range'}
2024-12-31 21:06:32.577 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Notifying assignor about the new Assignment(partitions=[pong-message-topic-0, pong-message-topic-1])
2024-12-31 21:06:32.581 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Adding newly assigned partitions: pong-message-topic-0, pong-message-topic-1
2024-12-31 21:06:32.588 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-0
2024-12-31 21:06:32.588 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-1
2024-12-31 21:06:32.591 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-0
2024-12-31 21:06:32.591 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-1
2024-12-31 21:06:32.603 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting offset for partition pong-message-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:59415 (id: 0 rack: null)], epoch=0}}.
2024-12-31 21:06:32.603 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting offset for partition pong-message-topic-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:59415 (id: 0 rack: null)], epoch=0}}.
2024-12-31 21:06:32.623 pong-service: partitions assigned: [pong-message-topic-0, pong-message-topic-1]
2024-12-31 21:06:33.213 Received ping message: Hello
2024-12-31 21:06:33.225 Idempotence will be disabled because acks is set to 0, not set to 'all'.
2024-12-31 21:06:33.225 ProducerConfig values: 
	acks = 0
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:59415]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2024-12-31 21:06:33.255 Kafka version: 3.4.1
2024-12-31 21:06:33.255 Kafka commitId: 8a516edc2755df89
2024-12-31 21:06:33.257 Kafka startTimeMs: 1735650393255
2024-12-31 21:06:33.261 [Producer clientId=producer-1] Resetting the last seen epoch of partition pong-message-topic-0 to 0 since the associated topicId changed from null to nl-UGCIpSrmXBiuXaAfnGg
2024-12-31 21:06:33.261 [Producer clientId=producer-1] Resetting the last seen epoch of partition pong-message-topic-1 to 0 since the associated topicId changed from null to nl-UGCIpSrmXBiuXaAfnGg
2024-12-31 21:06:33.262 [Producer clientId=producer-1] Cluster ID: cs9V3SfyRf-rMAykfxPJjg
2024-12-31 21:06:34.660 Received ping message: Hello
2024-12-31 21:06:34.667 Received ping message: Hello
2024-12-31 21:06:34.670 Throttling request as too many requests in the same second
2024-12-31 21:06:35.130 [KafkaServer id=0] shutting down
2024-12-31 21:06:35.131 [KafkaServer id=0] Starting controlled shutdown
2024-12-31 21:06:35.142 [Controller id=0] Shutting down broker 0
2024-12-31 21:06:35.147 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:06:35.153 [KafkaServer id=0] Controlled shutdown request returned successfully after 14ms
2024-12-31 21:06:35.155 [/config/changes-event-process-thread]: Shutting down
2024-12-31 21:06:35.156 [/config/changes-event-process-thread]: Stopped
2024-12-31 21:06:35.156 [/config/changes-event-process-thread]: Shutdown completed
2024-12-31 21:06:35.156 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
2024-12-31 21:06:35.160 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:06:35.160 [Producer clientId=producer-1] Node 0 disconnected.
2024-12-31 21:06:35.163 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Cancelled in-flight FETCH request with correlation id 22 due to node 0 being disconnected (elapsed time since creation: 480ms, elapsed time since send: 480ms, request timeout: 30000ms)
2024-12-31 21:06:35.164 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:06:35.164 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Error sending fetch request (sessionId=1464510888, epoch=6) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2024-12-31 21:06:35.165 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 2147483647 disconnected.
2024-12-31 21:06:35.165 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:06:35.165 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Group coordinator localhost:59415 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
2024-12-31 21:06:35.166 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors
2024-12-31 21:06:35.166 [data-plane Kafka Request Handler on Broker 0], shutting down
2024-12-31 21:06:35.168 [data-plane Kafka Request Handler on Broker 0], shut down completely
2024-12-31 21:06:35.170 [ExpirationReaper-0-AlterAcls]: Shutting down
2024-12-31 21:06:35.174 [ExpirationReaper-0-AlterAcls]: Stopped
2024-12-31 21:06:35.174 [ExpirationReaper-0-AlterAcls]: Shutdown completed
2024-12-31 21:06:35.177 [KafkaApi-0] Shutdown complete.
2024-12-31 21:06:35.178 [ExpirationReaper-0-topic]: Shutting down
2024-12-31 21:06:35.179 [ExpirationReaper-0-topic]: Shutdown completed
2024-12-31 21:06:35.179 [ExpirationReaper-0-topic]: Stopped
2024-12-31 21:06:35.181 [TransactionCoordinator id=0] Shutting down.
2024-12-31 21:06:35.181 [Transaction State Manager 0]: Shutdown complete
2024-12-31 21:06:35.181 [Transaction Marker Channel Manager 0]: Shutting down
2024-12-31 21:06:35.182 [Transaction Marker Channel Manager 0]: Shutdown completed
2024-12-31 21:06:35.182 [Transaction Marker Channel Manager 0]: Stopped
2024-12-31 21:06:35.182 [TransactionCoordinator id=0] Shutdown complete.
2024-12-31 21:06:35.183 [GroupCoordinator 0]: Shutting down.
2024-12-31 21:06:35.183 [ExpirationReaper-0-Heartbeat]: Shutting down
2024-12-31 21:06:35.183 [ExpirationReaper-0-Heartbeat]: Shutdown completed
2024-12-31 21:06:35.183 [ExpirationReaper-0-Heartbeat]: Stopped
2024-12-31 21:06:35.184 [ExpirationReaper-0-Rebalance]: Shutting down
2024-12-31 21:06:35.184 [ExpirationReaper-0-Rebalance]: Stopped
2024-12-31 21:06:35.184 [ExpirationReaper-0-Rebalance]: Shutdown completed
2024-12-31 21:06:35.184 [GroupCoordinator 0]: Shutdown complete.
2024-12-31 21:06:35.185 [ReplicaManager broker=0] Shutting down
2024-12-31 21:06:35.185 [LogDirFailureHandler]: Shutting down
2024-12-31 21:06:35.185 [LogDirFailureHandler]: Stopped
2024-12-31 21:06:35.185 [LogDirFailureHandler]: Shutdown completed
2024-12-31 21:06:35.185 [ReplicaFetcherManager on broker 0] shutting down
2024-12-31 21:06:35.187 [ReplicaFetcherManager on broker 0] shutdown completed
2024-12-31 21:06:35.188 [ReplicaAlterLogDirsManager on broker 0] shutting down
2024-12-31 21:06:35.188 [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2024-12-31 21:06:35.188 [ExpirationReaper-0-Fetch]: Shutting down
2024-12-31 21:06:35.188 [ExpirationReaper-0-Fetch]: Stopped
2024-12-31 21:06:35.188 [ExpirationReaper-0-Fetch]: Shutdown completed
2024-12-31 21:06:35.188 [ExpirationReaper-0-Produce]: Shutting down
2024-12-31 21:06:35.189 [ExpirationReaper-0-Produce]: Shutdown completed
2024-12-31 21:06:35.189 [ExpirationReaper-0-Produce]: Stopped
2024-12-31 21:06:35.189 [ExpirationReaper-0-DeleteRecords]: Shutting down
2024-12-31 21:06:35.189 [ExpirationReaper-0-DeleteRecords]: Stopped
2024-12-31 21:06:35.189 [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2024-12-31 21:06:35.190 [ExpirationReaper-0-ElectLeader]: Shutting down
2024-12-31 21:06:35.190 [ExpirationReaper-0-ElectLeader]: Stopped
2024-12-31 21:06:35.190 [ExpirationReaper-0-ElectLeader]: Shutdown completed
2024-12-31 21:06:35.202 [ReplicaManager broker=0] Shut down completely
2024-12-31 21:06:35.203 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutting down
2024-12-31 21:06:35.203 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutdown completed
2024-12-31 21:06:35.203 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Stopped
2024-12-31 21:06:35.204 Broker to controller channel manager for alterPartition shutdown
2024-12-31 21:06:35.204 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down
2024-12-31 21:06:35.204 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed
2024-12-31 21:06:35.204 [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped
2024-12-31 21:06:35.206 Broker to controller channel manager for forwarding shutdown
2024-12-31 21:06:35.206 Shutting down.
2024-12-31 21:06:35.208 Shutting down the log cleaner.
2024-12-31 21:06:35.209 [kafka-log-cleaner-thread-0]: Shutting down
2024-12-31 21:06:35.210 [kafka-log-cleaner-thread-0]: Shutdown completed
2024-12-31 21:06:35.210 [kafka-log-cleaner-thread-0]: Stopped
2024-12-31 21:06:35.252 [ProducerStateManager partition=pong-message-topic-1] Wrote producer snapshot at offset 3 with 0 producer ids in 3 ms.
2024-12-31 21:06:35.265 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:06:35.265 [Producer clientId=producer-1] Node 0 disconnected.
2024-12-31 21:06:35.265 [ProducerStateManager partition=__consumer_offsets-2] Wrote producer snapshot at offset 6 with 0 producer ids in 3 ms.
2024-12-31 21:06:35.266 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node 0 (localhost/127.0.0.1:59415) could not be established. Broker may not be available.
2024-12-31 21:06:35.266 [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:59415) could not be established. Broker may not be available.
2024-12-31 21:06:35.283 Shutdown complete.
2024-12-31 21:06:35.283 [ControllerEventThread controllerId=0] Shutting down
2024-12-31 21:06:35.283 [ControllerEventThread controllerId=0] Stopped
2024-12-31 21:06:35.283 [ControllerEventThread controllerId=0] Shutdown completed
2024-12-31 21:06:35.285 [PartitionStateMachine controllerId=0] Stopped partition state machine
2024-12-31 21:06:35.286 [ReplicaStateMachine controllerId=0] Stopped replica state machine
2024-12-31 21:06:35.286 [RequestSendThread controllerId=0] Shutting down
2024-12-31 21:06:35.286 [RequestSendThread controllerId=0] Shutdown completed
2024-12-31 21:06:35.286 [RequestSendThread controllerId=0] Stopped
2024-12-31 21:06:35.288 [Controller id=0] Resigned
2024-12-31 21:06:35.288 [feature-zk-node-event-process-thread]: Shutting down
2024-12-31 21:06:35.289 [feature-zk-node-event-process-thread]: Stopped
2024-12-31 21:06:35.289 [feature-zk-node-event-process-thread]: Shutdown completed
2024-12-31 21:06:35.289 [ZooKeeperClient Kafka server] Closing.
2024-12-31 21:06:35.367 [Producer clientId=producer-1] Node 0 disconnected.
2024-12-31 21:06:35.368 [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:59415) could not be established. Broker may not be available.
2024-12-31 21:06:35.400 EventThread shut down for session: 0x100176e17c50000
2024-12-31 21:06:35.400 Session: 0x100176e17c50000 closed
2024-12-31 21:06:35.401 [ZooKeeperClient Kafka server] Closed.
2024-12-31 21:06:35.402 [ThrottledChannelReaper-Fetch]: Shutting down
2024-12-31 21:06:35.403 [ThrottledChannelReaper-Fetch]: Stopped
2024-12-31 21:06:35.403 [ThrottledChannelReaper-Fetch]: Shutdown completed
2024-12-31 21:06:35.403 [ThrottledChannelReaper-Produce]: Shutting down
2024-12-31 21:06:35.404 [ThrottledChannelReaper-Produce]: Shutdown completed
2024-12-31 21:06:35.404 [ThrottledChannelReaper-Produce]: Stopped
2024-12-31 21:06:35.404 [ThrottledChannelReaper-Request]: Shutting down
2024-12-31 21:06:35.404 [ThrottledChannelReaper-Request]: Stopped
2024-12-31 21:06:35.404 [ThrottledChannelReaper-Request]: Shutdown completed
2024-12-31 21:06:35.404 [ThrottledChannelReaper-ControllerMutation]: Shutting down
2024-12-31 21:06:35.404 [ThrottledChannelReaper-ControllerMutation]: Stopped
2024-12-31 21:06:35.404 [ThrottledChannelReaper-ControllerMutation]: Shutdown completed
2024-12-31 21:06:35.405 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server
2024-12-31 21:06:35.418 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:06:35.418 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node 0 (localhost/127.0.0.1:59415) could not be established. Broker may not be available.
2024-12-31 21:06:35.421 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed
2024-12-31 21:06:35.422 Metrics scheduler closed
2024-12-31 21:06:35.422 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:06:35.422 Metrics reporters closed
2024-12-31 21:06:35.424 Broker and topic stats closed
2024-12-31 21:06:35.424 App info kafka.server for 0 unregistered
2024-12-31 21:06:35.424 [KafkaServer id=0] shut down completed
2024-12-31 21:06:35.441 ConnnectionExpirerThread interrupted
2024-12-31 21:06:35.441 selector thread exitted run method
2024-12-31 21:06:35.441 selector thread exitted run method
2024-12-31 21:06:35.441 accept thread exitted run method
2024-12-31 21:06:35.442 shutting down
2024-12-31 21:06:35.442 Shutting down
2024-12-31 21:06:35.442 Draining request throttler queue
2024-12-31 21:06:35.442 RequestThrottler shutdown. Dropped 0 requests
2024-12-31 21:06:35.442 Shutting down
2024-12-31 21:06:35.442 Shutting down
2024-12-31 21:06:35.442 Shutting down
2024-12-31 21:06:35.442 SyncRequestProcessor exited!
2024-12-31 21:06:35.442 PrepRequestProcessor exited loop!
2024-12-31 21:06:35.443 shutdown of request processor complete
2024-12-31 21:06:35.477 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Revoke previously assigned partitions pong-message-topic-0, pong-message-topic-1
2024-12-31 21:06:35.478 pong-service: partitions revoked: [pong-message-topic-0, pong-message-topic-1]
2024-12-31 21:06:35.478 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:06:35.478 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:06:35.478 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Unsubscribed all topics or patterns and assigned partitions
2024-12-31 21:06:35.479 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:06:35.479 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:06:35.479 Metrics scheduler closed
2024-12-31 21:06:35.479 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:06:35.480 Metrics reporters closed
2024-12-31 21:06:35.481 App info kafka.consumer for consumer-pong-service-1 unregistered
2024-12-31 21:06:35.481 pong-service: Consumer stopped
2024-12-31 21:06:35.487 [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2024-12-31 21:06:35.488 SessionTrackerImpl exited loop!
2024-12-31 21:06:35.489 Metrics scheduler closed
2024-12-31 21:06:35.489 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:06:35.489 Metrics reporters closed
2024-12-31 21:06:35.489 App info kafka.producer for producer-1 unregistered
2024-12-31 21:06:35.509 Closing JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:06:35.512 HikariPool-1 - Shutdown initiated...
2024-12-31 21:06:35.515 HikariPool-1 - Shutdown completed.
2024-12-31 21:06:37.542 [KafkaServer id=0] shutting down
2024-12-31 21:06:37.543 [/config/changes-event-process-thread]: Shutting down
2024-12-31 21:06:37.543 [/config/changes-event-process-thread]: Shutdown completed
2024-12-31 21:06:37.543 [/config/changes-event-process-thread]: Stopped
2024-12-31 21:06:37.543 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
2024-12-31 21:06:37.546 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors
2024-12-31 21:06:37.546 [data-plane Kafka Request Handler on Broker 0], shutting down
2024-12-31 21:06:37.548 [data-plane Kafka Request Handler on Broker 0], shut down completely
2024-12-31 21:06:37.548 [ExpirationReaper-0-AlterAcls]: Shutting down
2024-12-31 21:06:37.549 [ExpirationReaper-0-AlterAcls]: Stopped
2024-12-31 21:06:37.549 [ExpirationReaper-0-AlterAcls]: Shutdown completed
2024-12-31 21:06:37.549 [KafkaApi-0] Shutdown complete.
2024-12-31 21:06:37.549 [ExpirationReaper-0-topic]: Shutting down
2024-12-31 21:06:37.549 [ExpirationReaper-0-topic]: Shutdown completed
2024-12-31 21:06:37.549 [ExpirationReaper-0-topic]: Stopped
2024-12-31 21:06:37.550 [TransactionCoordinator id=0] Shutting down.
2024-12-31 21:06:37.550 [Transaction State Manager 0]: Shutdown complete
2024-12-31 21:06:37.550 [Transaction Marker Channel Manager 0]: Shutting down
2024-12-31 21:06:37.550 [Transaction Marker Channel Manager 0]: Stopped
2024-12-31 21:06:37.550 [Transaction Marker Channel Manager 0]: Shutdown completed
2024-12-31 21:06:37.551 [TransactionCoordinator id=0] Shutdown complete.
2024-12-31 21:06:37.551 [GroupCoordinator 0]: Shutting down.
2024-12-31 21:06:37.551 [ExpirationReaper-0-Heartbeat]: Shutting down
2024-12-31 21:06:37.551 [ExpirationReaper-0-Heartbeat]: Stopped
2024-12-31 21:06:37.551 [ExpirationReaper-0-Heartbeat]: Shutdown completed
2024-12-31 21:06:37.552 [ExpirationReaper-0-Rebalance]: Shutting down
2024-12-31 21:06:37.552 [ExpirationReaper-0-Rebalance]: Stopped
2024-12-31 21:06:37.552 [ExpirationReaper-0-Rebalance]: Shutdown completed
2024-12-31 21:06:37.552 [GroupCoordinator 0]: Shutdown complete.
2024-12-31 21:06:37.552 [ReplicaManager broker=0] Shutting down
2024-12-31 21:06:37.552 [LogDirFailureHandler]: Shutting down
2024-12-31 21:06:37.552 [LogDirFailureHandler]: Shutdown completed
2024-12-31 21:06:37.552 [LogDirFailureHandler]: Stopped
2024-12-31 21:06:37.552 [ReplicaFetcherManager on broker 0] shutting down
2024-12-31 21:06:37.552 [ReplicaFetcherManager on broker 0] shutdown completed
2024-12-31 21:06:37.552 [ReplicaAlterLogDirsManager on broker 0] shutting down
2024-12-31 21:06:37.552 [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2024-12-31 21:06:37.552 [ExpirationReaper-0-Fetch]: Shutting down
2024-12-31 21:06:37.552 [ExpirationReaper-0-Fetch]: Stopped
2024-12-31 21:06:37.552 [ExpirationReaper-0-Fetch]: Shutdown completed
2024-12-31 21:06:37.554 [ExpirationReaper-0-Produce]: Shutting down
2024-12-31 21:06:37.554 [ExpirationReaper-0-Produce]: Stopped
2024-12-31 21:06:37.554 [ExpirationReaper-0-Produce]: Shutdown completed
2024-12-31 21:06:37.554 [ExpirationReaper-0-DeleteRecords]: Shutting down
2024-12-31 21:06:37.554 [ExpirationReaper-0-DeleteRecords]: Stopped
2024-12-31 21:06:37.554 [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2024-12-31 21:06:37.554 [ExpirationReaper-0-ElectLeader]: Shutting down
2024-12-31 21:06:37.555 [ExpirationReaper-0-ElectLeader]: Shutdown completed
2024-12-31 21:06:37.555 [ExpirationReaper-0-ElectLeader]: Stopped
2024-12-31 21:06:37.563 [ReplicaManager broker=0] Shut down completely
2024-12-31 21:06:37.563 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutting down
2024-12-31 21:06:37.563 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutdown completed
2024-12-31 21:06:37.563 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Stopped
2024-12-31 21:06:37.563 Broker to controller channel manager for alterPartition shutdown
2024-12-31 21:06:37.563 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down
2024-12-31 21:06:37.565 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed
2024-12-31 21:06:37.565 [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped
2024-12-31 21:06:37.565 Broker to controller channel manager for forwarding shutdown
2024-12-31 21:06:37.565 Shutting down.
2024-12-31 21:06:37.565 Shutting down the log cleaner.
2024-12-31 21:06:37.565 [kafka-log-cleaner-thread-0]: Shutting down
2024-12-31 21:06:37.565 [kafka-log-cleaner-thread-0]: Stopped
2024-12-31 21:06:37.565 [kafka-log-cleaner-thread-0]: Shutdown completed
2024-12-31 21:06:37.575 Shutdown complete.
2024-12-31 21:06:37.575 [ControllerEventThread controllerId=0] Shutting down
2024-12-31 21:06:37.575 [ControllerEventThread controllerId=0] Stopped
2024-12-31 21:06:37.575 [ControllerEventThread controllerId=0] Shutdown completed
2024-12-31 21:06:37.575 [PartitionStateMachine controllerId=0] Stopped partition state machine
2024-12-31 21:06:37.575 [ReplicaStateMachine controllerId=0] Stopped replica state machine
2024-12-31 21:06:37.575 [RequestSendThread controllerId=0] Shutting down
2024-12-31 21:06:37.575 [RequestSendThread controllerId=0] Shutdown completed
2024-12-31 21:06:37.575 [RequestSendThread controllerId=0] Stopped
2024-12-31 21:06:37.578 [Controller id=0] Resigned
2024-12-31 21:06:37.578 [feature-zk-node-event-process-thread]: Shutting down
2024-12-31 21:06:37.578 [feature-zk-node-event-process-thread]: Shutdown completed
2024-12-31 21:06:37.578 [feature-zk-node-event-process-thread]: Stopped
2024-12-31 21:06:37.578 [ZooKeeperClient Kafka server] Closing.
2024-12-31 21:06:37.581 An exception was thrown while closing send thread for session 0x100176e38cf0000.
org.apache.zookeeper.ClientCnxn$EndOfStreamException: Unable to read additional data from server sessionid 0x100176e38cf0000, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2024-12-31 21:06:37.682 EventThread shut down for session: 0x100176e38cf0000
2024-12-31 21:06:37.682 Session: 0x100176e38cf0000 closed
2024-12-31 21:06:37.683 [ZooKeeperClient Kafka server] Closed.
2024-12-31 21:06:37.683 [ThrottledChannelReaper-Fetch]: Shutting down
2024-12-31 21:06:37.683 [ThrottledChannelReaper-Fetch]: Stopped
2024-12-31 21:06:37.683 [ThrottledChannelReaper-Fetch]: Shutdown completed
2024-12-31 21:06:37.683 [ThrottledChannelReaper-Produce]: Shutting down
2024-12-31 21:06:37.683 [ThrottledChannelReaper-Produce]: Stopped
2024-12-31 21:06:37.683 [ThrottledChannelReaper-Produce]: Shutdown completed
2024-12-31 21:06:37.683 [ThrottledChannelReaper-Request]: Shutting down
2024-12-31 21:06:37.684 [ThrottledChannelReaper-Request]: Stopped
2024-12-31 21:06:37.684 [ThrottledChannelReaper-Request]: Shutdown completed
2024-12-31 21:06:37.684 [ThrottledChannelReaper-ControllerMutation]: Shutting down
2024-12-31 21:06:37.684 [ThrottledChannelReaper-ControllerMutation]: Stopped
2024-12-31 21:06:37.684 [ThrottledChannelReaper-ControllerMutation]: Shutdown completed
2024-12-31 21:06:37.684 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server
2024-12-31 21:06:37.693 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed
2024-12-31 21:06:37.694 Metrics scheduler closed
2024-12-31 21:06:37.694 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:06:37.695 Metrics reporters closed
2024-12-31 21:06:37.695 Broker and topic stats closed
2024-12-31 21:06:37.695 App info kafka.server for 0 unregistered
2024-12-31 21:06:37.695 [KafkaServer id=0] shut down completed
2024-12-31 21:06:37.702 ConnnectionExpirerThread interrupted
2024-12-31 21:06:37.702 selector thread exitted run method
2024-12-31 21:06:37.702 selector thread exitted run method
2024-12-31 21:06:37.702 accept thread exitted run method
2024-12-31 21:06:37.704 shutting down
2024-12-31 21:06:37.705 Shutting down
2024-12-31 21:06:37.705 Draining request throttler queue
2024-12-31 21:06:37.705 RequestThrottler shutdown. Dropped 0 requests
2024-12-31 21:06:37.705 Shutting down
2024-12-31 21:06:37.705 Shutting down
2024-12-31 21:06:37.705 Shutting down
2024-12-31 21:06:37.705 PrepRequestProcessor exited loop!
2024-12-31 21:06:37.705 SyncRequestProcessor exited!
2024-12-31 21:06:37.705 shutdown of request processor complete
2024-12-31 21:06:37.892 SessionTrackerImpl exited loop!
2024-12-31 21:06:38.185 

Found multiple occurrences of org.json.JSONObject on the class path:

	jar:file:/C:/work/apache-maven-3.8.8/repo/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar!/org/json/JSONObject.class
	jar:file:/C:/work/apache-maven-3.8.8/repo/org/json/json/20220320/json-20220320.jar!/org/json/JSONObject.class

You may wish to exclude one of them to ensure predictable runtime behavior

2024-12-31 21:06:38.190 Starting MessageRepositorySpec using Java 17.0.12 with PID 11052 (started by joech in C:\code\hsbc\demo\pong)
2024-12-31 21:06:38.190 No active profile set, falling back to 1 default profile: "default"
2024-12-31 21:06:38.342 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:06:38.342 Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2024-12-31 21:06:38.357 Finished Spring Data repository scanning in 14 ms. Found 1 JPA repository interfaces.
2024-12-31 21:06:38.357 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:06:38.357 Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2024-12-31 21:06:38.367 Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.demo.dao.MessageRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2024-12-31 21:06:38.367 Finished Spring Data repository scanning in 4 ms. Found 0 Redis repository interfaces.
2024-12-31 21:06:38.463 HHH000204: Processing PersistenceUnitInfo [name: default]
2024-12-31 21:06:38.479 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:06:38.479 No LoadTimeWeaver setup: ignoring JPA class transformer
2024-12-31 21:06:38.479 HikariPool-2 - Starting...
2024-12-31 21:06:38.486 HikariPool-2 - Added connection conn10: url=jdbc:h2:mem:testdb user=SA
2024-12-31 21:06:38.486 HikariPool-2 - Start completed.
2024-12-31 21:06:38.494 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:06:38.526 HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2024-12-31 21:06:38.541 Initialized JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:06:38.814 ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:59415]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-pong-service-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = pong-service
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2024-12-31 21:06:38.818 These configurations '[spring.json.trusted.packages]' were supplied but are not used yet.
2024-12-31 21:06:38.818 Kafka version: 3.4.1
2024-12-31 21:06:38.818 Kafka commitId: 8a516edc2755df89
2024-12-31 21:06:38.818 Kafka startTimeMs: 1735650398818
2024-12-31 21:06:38.818 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Subscribed to topic(s): pong-message-topic
2024-12-31 21:06:38.822 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:06:38.822 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Connection to node -1 (/127.0.0.1:59415) could not be established. Broker may not be available.
2024-12-31 21:06:38.822 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Bootstrap broker 127.0.0.1:59415 (id: -1 rack: null) disconnected
2024-12-31 21:06:38.822 Started MessageRepositorySpec in 0.675 seconds (process running for 28.722)
2024-12-31 21:06:38.881 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:06:38.881 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:06:38.881 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Unsubscribed all topics or patterns and assigned partitions
2024-12-31 21:06:38.881 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:06:38.881 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:06:38.881 Metrics scheduler closed
2024-12-31 21:06:38.881 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:06:38.881 Metrics reporters closed
2024-12-31 21:06:38.881 App info kafka.consumer for consumer-pong-service-2 unregistered
2024-12-31 21:06:38.881 pong-service: Consumer stopped
2024-12-31 21:06:38.894 Closing JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:06:38.894 HikariPool-2 - Shutdown initiated...
2024-12-31 21:06:38.894 HikariPool-2 - Shutdown completed.
2024-12-31 21:06:38.922 zookeeper.snapshot.trust.empty : false
2024-12-31 21:06:38.922 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:06:38.922 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:06:38.922 zookeeper.snapshotSizeFactor = 0.33
2024-12-31 21:06:38.922 zookeeper.commitLogCount=500
2024-12-31 21:06:38.922 minSessionTimeout set to 1600
2024-12-31 21:06:38.922 maxSessionTimeout set to 16000
2024-12-31 21:06:38.922 Response cache size is initialized with value 400.
2024-12-31 21:06:38.922 Response cache size is initialized with value 400.
2024-12-31 21:06:38.922 zookeeper.pathStats.slotCapacity = 60
2024-12-31 21:06:38.922 zookeeper.pathStats.slotDuration = 15
2024-12-31 21:06:38.922 zookeeper.pathStats.maxDepth = 6
2024-12-31 21:06:38.922 zookeeper.pathStats.initialDelay = 5
2024-12-31 21:06:38.922 zookeeper.pathStats.delay = 5
2024-12-31 21:06:38.922 zookeeper.pathStats.enabled = false
2024-12-31 21:06:38.922 The max bytes for all large requests are set to 104857600
2024-12-31 21:06:38.922 The large request threshold is set to -1
2024-12-31 21:06:38.922 Created server with tickTime 800 minSessionTimeout 1600 maxSessionTimeout 16000 clientPortListenBacklog -1 datadir C:\Users\joech\AppData\Local\Temp\kafka-7003387613503057056\version-2 snapdir C:\Users\joech\AppData\Local\Temp\kafka-15379513172416782496\version-2
2024-12-31 21:06:38.922 maxCnxns is not configured, using default value 0.
2024-12-31 21:06:38.922 Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers.
2024-12-31 21:06:38.922 binding to port /127.0.0.1:0
2024-12-31 21:06:38.934 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-15379513172416782496\version-2\snapshot.0
2024-12-31 21:06:38.935 Snapshot loaded in 2 ms, highest zxid is 0x0, digest is 1371985504
2024-12-31 21:06:38.935 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-15379513172416782496\version-2\snapshot.0
2024-12-31 21:06:38.936 Snapshot taken in 1 ms
2024-12-31 21:06:38.937 PrepRequestProcessor (sid:0) started, reconfigEnabled=false
2024-12-31 21:06:38.939 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.85af7a06-a837-4887-82d9-4a83d63dc0272257300898709522066
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59442
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:06:38.944 starting
2024-12-31 21:06:38.944 Connecting to zookeeper on 127.0.0.1:59442
2024-12-31 21:06:38.945 [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:59442.
2024-12-31 21:06:38.945 Initiating client connection, connectString=127.0.0.1:59442 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@18d9d102
2024-12-31 21:06:38.947 jute.maxbuffer value is 4194304 Bytes
2024-12-31 21:06:38.948 zookeeper.request.timeout value is 0. feature enabled=false
2024-12-31 21:06:38.948 [ZooKeeperClient Kafka server] Waiting until connected.
2024-12-31 21:06:38.948 Opening socket connection to server /127.0.0.1:59442.
2024-12-31 21:06:38.949 Socket connection established, initiating session, client: /127.0.0.1:59443, server: /127.0.0.1:59442
2024-12-31 21:06:38.950 Creating new log file: log.1
2024-12-31 21:06:38.958 Session establishment complete on server /127.0.0.1:59442, session id = 0x100176e67980000, negotiated timeout = 16000
2024-12-31 21:06:38.958 [ZooKeeperClient Kafka server] Connected.
2024-12-31 21:06:38.998 Cluster ID = WMwKN4ZzSiGUnYfQ0x7N5Q
2024-12-31 21:06:38.998 No meta.properties file under dir C:\Users\joech\AppData\Local\Temp\spring.kafka.85af7a06-a837-4887-82d9-4a83d63dc0272257300898709522066\meta.properties
2024-12-31 21:06:39.007 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.85af7a06-a837-4887-82d9-4a83d63dc0272257300898709522066
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59442
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:06:39.014 [ThrottledChannelReaper-Fetch]: Starting
2024-12-31 21:06:39.014 [ThrottledChannelReaper-Produce]: Starting
2024-12-31 21:06:39.014 [ThrottledChannelReaper-Request]: Starting
2024-12-31 21:06:39.014 [ThrottledChannelReaper-ControllerMutation]: Starting
2024-12-31 21:06:39.025 Loading logs from log dirs ArraySeq(C:\Users\joech\AppData\Local\Temp\spring.kafka.85af7a06-a837-4887-82d9-4a83d63dc0272257300898709522066)
2024-12-31 21:06:39.025 Attempting recovery for all logs in C:\Users\joech\AppData\Local\Temp\spring.kafka.85af7a06-a837-4887-82d9-4a83d63dc0272257300898709522066 since no clean shutdown file was found
2024-12-31 21:06:39.027 Loaded 0 logs in 2ms.
2024-12-31 21:06:39.027 Starting log cleanup with a period of 300000 ms.
2024-12-31 21:06:39.028 Starting log flusher with a default period of 9223372036854775807 ms.
2024-12-31 21:06:39.029 Starting the log cleaner
2024-12-31 21:06:39.030 [kafka-log-cleaner-thread-0]: Starting
2024-12-31 21:06:39.030 [feature-zk-node-event-process-thread]: Starting
2024-12-31 21:06:39.033 Feature ZK node at path: /feature does not exist
2024-12-31 21:06:39.036 [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting
2024-12-31 21:06:39.056 Updated connection-accept-rate max connection creation rate to 2147483647
2024-12-31 21:06:39.060 Awaiting socket connections on localhost:59444.
2024-12-31 21:06:39.070 [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT)
2024-12-31 21:06:39.073 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Starting
2024-12-31 21:06:39.074 [ExpirationReaper-0-Produce]: Starting
2024-12-31 21:06:39.075 [ExpirationReaper-0-Fetch]: Starting
2024-12-31 21:06:39.075 [ExpirationReaper-0-DeleteRecords]: Starting
2024-12-31 21:06:39.075 [ExpirationReaper-0-ElectLeader]: Starting
2024-12-31 21:06:39.078 [LogDirFailureHandler]: Starting
2024-12-31 21:06:39.082 Creating /brokers/ids/0 (is it secure? false)
2024-12-31 21:06:39.084 Stat of the created znode at /brokers/ids/0 is: 25,25,1735650399083,1735650399083,1,0,0,72083356989784064,204,0,25

2024-12-31 21:06:39.085 Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:59444, czxid (broker epoch): 25
2024-12-31 21:06:39.095 [ControllerEventThread controllerId=0] Starting
2024-12-31 21:06:39.097 [ExpirationReaper-0-topic]: Starting
2024-12-31 21:06:39.097 [ExpirationReaper-0-Heartbeat]: Starting
2024-12-31 21:06:39.097 [ExpirationReaper-0-Rebalance]: Starting
2024-12-31 21:06:39.097 [GroupCoordinator 0]: Starting up.
2024-12-31 21:06:39.099 [GroupCoordinator 0]: Startup complete.
2024-12-31 21:06:39.100 Successfully created /controller_epoch with initial epoch 0
2024-12-31 21:06:39.101 [TransactionCoordinator id=0] Starting up.
2024-12-31 21:06:39.103 [Controller id=0] 0 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1
2024-12-31 21:06:39.103 [TransactionCoordinator id=0] Startup complete.
2024-12-31 21:06:39.104 [Transaction Marker Channel Manager 0]: Starting
2024-12-31 21:06:39.104 [Controller id=0] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map())
2024-12-31 21:06:39.105 [ExpirationReaper-0-AlterAcls]: Starting
2024-12-31 21:06:39.107 Feature ZK node created at path: /feature
2024-12-31 21:06:39.108 [MetadataCache brokerId=0] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0).
2024-12-31 21:06:39.108 [Controller id=0] Registering handlers
2024-12-31 21:06:39.109 [/config/changes-event-process-thread]: Starting
2024-12-31 21:06:39.110 [Controller id=0] Deleting log dir event notifications
2024-12-31 21:06:39.112 [Controller id=0] Deleting isr change notifications
2024-12-31 21:06:39.112 [Controller id=0] Initializing controller context
2024-12-31 21:06:39.114 [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing.
2024-12-31 21:06:39.115 Kafka version: 3.4.1
2024-12-31 21:06:39.115 Kafka commitId: 8a516edc2755df89
2024-12-31 21:06:39.115 Kafka startTimeMs: 1735650399115
2024-12-31 21:06:39.115 [KafkaServer id=0] started
2024-12-31 21:06:39.116 [Controller id=0] Initialized broker epochs cache: HashMap(0 -> 25)
2024-12-31 21:06:39.116 AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [127.0.0.1:59444]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-31 21:06:39.119 Kafka version: 3.4.1
2024-12-31 21:06:39.120 Kafka commitId: 8a516edc2755df89
2024-12-31 21:06:39.120 Kafka startTimeMs: 1735650399119
2024-12-31 21:06:39.121 [RequestSendThread controllerId=0] Starting
2024-12-31 21:06:39.121 [Controller id=0] Currently active brokers in the cluster: Set(0)
2024-12-31 21:06:39.121 [Controller id=0] Currently shutting brokers in the cluster: HashSet()
2024-12-31 21:06:39.121 [Controller id=0] Current list of topics in the cluster: HashSet()
2024-12-31 21:06:39.121 [Controller id=0] Fetching topic deletions in progress
2024-12-31 21:06:39.122 [Controller id=0] List of topics to be deleted: 
2024-12-31 21:06:39.122 [Controller id=0] List of topics ineligible for deletion: 
2024-12-31 21:06:39.122 [Controller id=0] Initializing topic deletion manager
2024-12-31 21:06:39.122 [Topic Deletion Manager 0] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet()
2024-12-31 21:06:39.122 [Controller id=0] Sending update metadata request
2024-12-31 21:06:39.124 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions
2024-12-31 21:06:39.124 [ReplicaStateMachine controllerId=0] Initializing replica state
2024-12-31 21:06:39.124 [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2024-12-31 21:06:39.124 [ReplicaStateMachine controllerId=0] Triggering offline replica state changes
2024-12-31 21:06:39.124 [PartitionStateMachine controllerId=0] Initializing partition state
2024-12-31 21:06:39.124 [PartitionStateMachine controllerId=0] Triggering online partition state changes
2024-12-31 21:06:39.124 [Controller id=0] Ready to serve as the new controller with epoch 1
2024-12-31 21:06:39.125 [RequestSendThread controllerId=0] Controller 0 connected to localhost:59444 (id: 0 rack: null) for sending state change requests
2024-12-31 21:06:39.126 [Controller id=0] Partitions undergoing preferred replica election: 
2024-12-31 21:06:39.127 [Controller id=0] Partitions that completed preferred replica election: 
2024-12-31 21:06:39.127 [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2024-12-31 21:06:39.127 [Controller id=0] Resuming preferred replica election for partitions: 
2024-12-31 21:06:39.127 [Controller id=0] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered
2024-12-31 21:06:39.129 [Controller id=0] Starting the controller scheduler
2024-12-31 21:06:39.137 [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use node localhost:59444 (id: 0 rack: null)
2024-12-31 21:06:39.175 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Recorded new controller, from now on will use node localhost:59444 (id: 0 rack: null)
2024-12-31 21:06:39.232 Creating topic pong-message-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0))
2024-12-31 21:06:39.241 [Controller id=0] New topics: [Set(pong-message-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(pong-message-topic,Some(TECWJp-bQVa-1cbCXiiw7A),Map(pong-message-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), pong-message-topic-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:06:39.241 [Controller id=0] New partition creation callback for pong-message-topic-0,pong-message-topic-1
2024-12-31 21:06:39.241 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:06:39.241 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:06:39.241 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:06:39.241 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:06:39.249 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:06:39.249 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:06:39.249 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2024-12-31 21:06:39.250 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2024-12-31 21:06:39.250 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:06:39.251 [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 for 2 partitions
2024-12-31 21:06:39.251 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(pong-message-topic-0, pong-message-topic-1)
2024-12-31 21:06:39.251 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2024-12-31 21:06:39.266 [LogLoader partition=pong-message-topic-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.85af7a06-a837-4887-82d9-4a83d63dc0272257300898709522066] Loading producer state till offset 0 with message format version 2
2024-12-31 21:06:39.267 Created log for partition pong-message-topic-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.85af7a06-a837-4887-82d9-4a83d63dc0272257300898709522066\pong-message-topic-0 with properties {}
2024-12-31 21:06:39.267 [Partition pong-message-topic-0 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-0
2024-12-31 21:06:39.267 [Partition pong-message-topic-0 broker=0] Log loaded for partition pong-message-topic-0 with initial high watermark 0
2024-12-31 21:06:39.268 [Broker id=0] Leader pong-message-topic-0 with topic id Some(TECWJp-bQVa-1cbCXiiw7A) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:06:39.280 [LogLoader partition=pong-message-topic-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.85af7a06-a837-4887-82d9-4a83d63dc0272257300898709522066] Loading producer state till offset 0 with message format version 2
2024-12-31 21:06:39.281 Created log for partition pong-message-topic-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.85af7a06-a837-4887-82d9-4a83d63dc0272257300898709522066\pong-message-topic-1 with properties {}
2024-12-31 21:06:39.281 [Partition pong-message-topic-1 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-1
2024-12-31 21:06:39.281 [Partition pong-message-topic-1 broker=0] Log loaded for partition pong-message-topic-1 with initial high watermark 0
2024-12-31 21:06:39.281 [Broker id=0] Leader pong-message-topic-1 with topic id Some(TECWJp-bQVa-1cbCXiiw7A) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:06:39.284 [Broker id=0] Finished LeaderAndIsr request in 33ms correlationId 1 from controller 0 for 2 partitions
2024-12-31 21:06:39.289 [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2
2024-12-31 21:06:39.291 App info kafka.admin.client for adminclient-3 unregistered
2024-12-31 21:06:39.291 Metrics scheduler closed
2024-12-31 21:06:39.293 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:06:39.293 Metrics reporters closed
2024-12-31 21:06:39.338 

Found multiple occurrences of org.json.JSONObject on the class path:

	jar:file:/C:/work/apache-maven-3.8.8/repo/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar!/org/json/JSONObject.class
	jar:file:/C:/work/apache-maven-3.8.8/repo/org/json/json/20220320/json-20220320.jar!/org/json/JSONObject.class

You may wish to exclude one of them to ensure predictable runtime behavior

2024-12-31 21:06:39.341 Starting KafkaSpec using Java 17.0.12 with PID 11052 (started by joech in C:\code\hsbc\demo\pong)
2024-12-31 21:06:39.341 No active profile set, falling back to 1 default profile: "default"
2024-12-31 21:06:39.502 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:06:39.503 Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2024-12-31 21:06:39.525 Finished Spring Data repository scanning in 21 ms. Found 1 JPA repository interfaces.
2024-12-31 21:06:39.530 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:06:39.530 Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2024-12-31 21:06:39.536 Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.demo.dao.MessageRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2024-12-31 21:06:39.537 Finished Spring Data repository scanning in 5 ms. Found 0 Redis repository interfaces.
2024-12-31 21:06:39.622 HHH000204: Processing PersistenceUnitInfo [name: default]
2024-12-31 21:06:39.633 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:06:39.634 No LoadTimeWeaver setup: ignoring JPA class transformer
2024-12-31 21:06:39.635 HikariPool-3 - Starting...
2024-12-31 21:06:39.638 HikariPool-3 - Added connection conn20: url=jdbc:h2:mem:testdb user=SA
2024-12-31 21:06:39.638 HikariPool-3 - Start completed.
2024-12-31 21:06:39.650 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:06:39.681 HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2024-12-31 21:06:39.704 Initialized JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:06:39.901 ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:59444]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-pong-service-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = pong-service
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2024-12-31 21:06:39.907 These configurations '[spring.json.trusted.packages]' were supplied but are not used yet.
2024-12-31 21:06:39.907 Kafka version: 3.4.1
2024-12-31 21:06:39.908 Kafka commitId: 8a516edc2755df89
2024-12-31 21:06:39.908 Kafka startTimeMs: 1735650399907
2024-12-31 21:06:39.908 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Subscribed to topic(s): pong-message-topic
2024-12-31 21:06:39.913 Started KafkaSpec in 0.616 seconds (process running for 29.809)
2024-12-31 21:06:39.915 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting the last seen epoch of partition pong-message-topic-0 to 0 since the associated topicId changed from null to TECWJp-bQVa-1cbCXiiw7A
2024-12-31 21:06:39.916 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting the last seen epoch of partition pong-message-topic-1 to 0 since the associated topicId changed from null to TECWJp-bQVa-1cbCXiiw7A
2024-12-31 21:06:39.916 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Cluster ID: WMwKN4ZzSiGUnYfQ0x7N5Q
2024-12-31 21:06:39.920 Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0))
2024-12-31 21:06:39.926 Idempotence will be disabled because acks is set to 0, not set to 'all'.
2024-12-31 21:06:39.926 ProducerConfig values: 
	acks = 0
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:59444]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2024-12-31 21:06:39.932 Kafka version: 3.4.1
2024-12-31 21:06:39.932 [Controller id=0] New topics: [Set(__consumer_offsets)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(__consumer_offsets,Some(SYacCyLNRjuHqH0VaSVIGw),HashMap(__consumer_offsets-4 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-3 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-2 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:06:39.932 Kafka commitId: 8a516edc2755df89
2024-12-31 21:06:39.932 Kafka startTimeMs: 1735650399932
2024-12-31 21:06:39.932 [Controller id=0] New partition creation callback for __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2024-12-31 21:06:39.933 [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:06:39.933 [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:06:39.933 [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:06:39.933 [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:06:39.933 [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:06:39.933 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:06:39.933 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:06:39.939 [Producer clientId=producer-2] Resetting the last seen epoch of partition pong-message-topic-0 to 0 since the associated topicId changed from null to TECWJp-bQVa-1cbCXiiw7A
2024-12-31 21:06:39.939 [Producer clientId=producer-2] Resetting the last seen epoch of partition pong-message-topic-1 to 0 since the associated topicId changed from null to TECWJp-bQVa-1cbCXiiw7A
2024-12-31 21:06:39.939 [Producer clientId=producer-2] Cluster ID: WMwKN4ZzSiGUnYfQ0x7N5Q
2024-12-31 21:06:39.946 [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:06:39.946 [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:06:39.946 [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:06:39.946 [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:06:39.946 [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:06:39.946 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 5 become-leader and 0 become-follower partitions
2024-12-31 21:06:39.946 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 5 partitions
2024-12-31 21:06:39.947 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:06:39.947 [Broker id=0] Handling LeaderAndIsr request correlationId 3 from controller 0 for 5 partitions
2024-12-31 21:06:39.948 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-4, __consumer_offsets-3, __consumer_offsets-2, __consumer_offsets-0, __consumer_offsets-1)
2024-12-31 21:06:39.948 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 3 from controller 0 epoch 1 as part of the become-leader transition for 5 partitions
2024-12-31 21:06:39.964 [LogLoader partition=__consumer_offsets-3, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.85af7a06-a837-4887-82d9-4a83d63dc0272257300898709522066] Loading producer state till offset 0 with message format version 2
2024-12-31 21:06:39.965 Created log for partition __consumer_offsets-3 in C:\Users\joech\AppData\Local\Temp\spring.kafka.85af7a06-a837-4887-82d9-4a83d63dc0272257300898709522066\__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:06:39.967 [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
2024-12-31 21:06:39.968 [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0
2024-12-31 21:06:39.968 [Broker id=0] Leader __consumer_offsets-3 with topic id Some(SYacCyLNRjuHqH0VaSVIGw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:06:39.981 [LogLoader partition=__consumer_offsets-2, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.85af7a06-a837-4887-82d9-4a83d63dc0272257300898709522066] Loading producer state till offset 0 with message format version 2
2024-12-31 21:06:39.982 Created log for partition __consumer_offsets-2 in C:\Users\joech\AppData\Local\Temp\spring.kafka.85af7a06-a837-4887-82d9-4a83d63dc0272257300898709522066\__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:06:39.982 [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
2024-12-31 21:06:39.982 [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0
2024-12-31 21:06:39.983 [Broker id=0] Leader __consumer_offsets-2 with topic id Some(SYacCyLNRjuHqH0VaSVIGw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:06:39.996 [LogLoader partition=__consumer_offsets-4, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.85af7a06-a837-4887-82d9-4a83d63dc0272257300898709522066] Loading producer state till offset 0 with message format version 2
2024-12-31 21:06:39.998 Created log for partition __consumer_offsets-4 in C:\Users\joech\AppData\Local\Temp\spring.kafka.85af7a06-a837-4887-82d9-4a83d63dc0272257300898709522066\__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:06:39.998 [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
2024-12-31 21:06:39.998 [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0
2024-12-31 21:06:39.999 [Broker id=0] Leader __consumer_offsets-4 with topic id Some(SYacCyLNRjuHqH0VaSVIGw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:06:40.011 [LogLoader partition=__consumer_offsets-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.85af7a06-a837-4887-82d9-4a83d63dc0272257300898709522066] Loading producer state till offset 0 with message format version 2
2024-12-31 21:06:40.012 Created log for partition __consumer_offsets-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.85af7a06-a837-4887-82d9-4a83d63dc0272257300898709522066\__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:06:40.012 [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
2024-12-31 21:06:40.012 [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0
2024-12-31 21:06:40.012 [Broker id=0] Leader __consumer_offsets-1 with topic id Some(SYacCyLNRjuHqH0VaSVIGw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:06:40.027 [LogLoader partition=__consumer_offsets-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.85af7a06-a837-4887-82d9-4a83d63dc0272257300898709522066] Loading producer state till offset 0 with message format version 2
2024-12-31 21:06:40.028 Created log for partition __consumer_offsets-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.85af7a06-a837-4887-82d9-4a83d63dc0272257300898709522066\__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:06:40.028 [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
2024-12-31 21:06:40.028 [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0
2024-12-31 21:06:40.028 [Broker id=0] Leader __consumer_offsets-0 with topic id Some(SYacCyLNRjuHqH0VaSVIGw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:06:40.032 [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 0
2024-12-31 21:06:40.032 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0
2024-12-31 21:06:40.032 [GroupCoordinator 0]: Elected as the group coordinator for partition 2 in epoch 0
2024-12-31 21:06:40.032 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0
2024-12-31 21:06:40.032 [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 0
2024-12-31 21:06:40.032 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0
2024-12-31 21:06:40.032 [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 0
2024-12-31 21:06:40.032 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0
2024-12-31 21:06:40.032 [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 0
2024-12-31 21:06:40.032 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0
2024-12-31 21:06:40.032 [Broker id=0] Finished LeaderAndIsr request in 85ms correlationId 3 from controller 0 for 5 partitions
2024-12-31 21:06:40.032 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler.
2024-12-31 21:06:40.032 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler.
2024-12-31 21:06:40.032 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler.
2024-12-31 21:06:40.032 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler.
2024-12-31 21:06:40.032 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler.
2024-12-31 21:06:40.035 [Broker id=0] Add 5 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 4
2024-12-31 21:06:40.122 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Discovered group coordinator localhost:59444 (id: 2147483647 rack: null)
2024-12-31 21:06:40.122 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] (Re-)joining group
2024-12-31 21:06:40.127 [GroupCoordinator 0]: Dynamic member with unknown member id joins group pong-service in Empty state. Created a new member id consumer-pong-service-3-55b45bdc-b3bf-4086-98ec-3a4dbb9445d0 and request the member to rejoin with this id.
2024-12-31 21:06:40.129 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Request joining group due to: need to re-join with the given member-id: consumer-pong-service-3-55b45bdc-b3bf-4086-98ec-3a4dbb9445d0
2024-12-31 21:06:40.129 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2024-12-31 21:06:40.129 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] (Re-)joining group
2024-12-31 21:06:40.130 [GroupCoordinator 0]: Preparing to rebalance group pong-service in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-pong-service-3-55b45bdc-b3bf-4086-98ec-3a4dbb9445d0 with group instance id None; client reason: rebalance failed due to MemberIdRequiredException)
2024-12-31 21:06:40.131 [GroupCoordinator 0]: Stabilized group pong-service generation 1 (__consumer_offsets-2) with 1 members
2024-12-31 21:06:40.132 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Successfully joined group with generation Generation{generationId=1, memberId='consumer-pong-service-3-55b45bdc-b3bf-4086-98ec-3a4dbb9445d0', protocol='range'}
2024-12-31 21:06:40.132 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Finished assignment for group at generation 1: {consumer-pong-service-3-55b45bdc-b3bf-4086-98ec-3a4dbb9445d0=Assignment(partitions=[pong-message-topic-0, pong-message-topic-1])}
2024-12-31 21:06:40.133 [GroupCoordinator 0]: Assignment received from leader consumer-pong-service-3-55b45bdc-b3bf-4086-98ec-3a4dbb9445d0 for group pong-service for generation 1. The group has 1 members, 0 of which are static.
2024-12-31 21:06:40.136 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Successfully synced group in generation Generation{generationId=1, memberId='consumer-pong-service-3-55b45bdc-b3bf-4086-98ec-3a4dbb9445d0', protocol='range'}
2024-12-31 21:06:40.136 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Notifying assignor about the new Assignment(partitions=[pong-message-topic-0, pong-message-topic-1])
2024-12-31 21:06:40.138 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Adding newly assigned partitions: pong-message-topic-0, pong-message-topic-1
2024-12-31 21:06:40.139 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Found no committed offset for partition pong-message-topic-0
2024-12-31 21:06:40.140 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Found no committed offset for partition pong-message-topic-1
2024-12-31 21:06:40.141 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Found no committed offset for partition pong-message-topic-0
2024-12-31 21:06:40.141 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Found no committed offset for partition pong-message-topic-1
2024-12-31 21:06:40.143 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting offset for partition pong-message-topic-0 to position FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:59444 (id: 0 rack: null)], epoch=0}}.
2024-12-31 21:06:40.144 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting offset for partition pong-message-topic-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:59444 (id: 0 rack: null)], epoch=0}}.
2024-12-31 21:06:40.152 pong-service: partitions assigned: [pong-message-topic-0, pong-message-topic-1]
2024-12-31 21:06:40.250 [KafkaServer id=0] shutting down
2024-12-31 21:06:40.250 [KafkaServer id=0] Starting controlled shutdown
2024-12-31 21:06:40.255 [Controller id=0] Shutting down broker 0
2024-12-31 21:06:40.256 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:06:40.257 [KafkaServer id=0] Controlled shutdown request returned successfully after 2ms
2024-12-31 21:06:40.258 [/config/changes-event-process-thread]: Shutting down
2024-12-31 21:06:40.258 [/config/changes-event-process-thread]: Stopped
2024-12-31 21:06:40.258 [/config/changes-event-process-thread]: Shutdown completed
2024-12-31 21:06:40.258 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
2024-12-31 21:06:40.259 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:06:40.259 [Producer clientId=producer-2] Node 0 disconnected.
2024-12-31 21:06:40.259 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:06:40.259 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:06:40.260 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Cancelled in-flight FETCH request with correlation id 16 due to node 0 being disconnected (elapsed time since creation: 107ms, elapsed time since send: 107ms, request timeout: 30000ms)
2024-12-31 21:06:40.260 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Cancelled in-flight METADATA request with correlation id 17 due to node 0 being disconnected (elapsed time since creation: 25ms, elapsed time since send: 25ms, request timeout: 30000ms)
2024-12-31 21:06:40.260 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node 2147483647 disconnected.
2024-12-31 21:06:40.260 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2024-12-31 21:06:40.260 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Group coordinator localhost:59444 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
2024-12-31 21:06:40.260 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors
2024-12-31 21:06:40.260 [data-plane Kafka Request Handler on Broker 0], shutting down
2024-12-31 21:06:40.262 [data-plane Kafka Request Handler on Broker 0], shut down completely
2024-12-31 21:06:40.262 [ExpirationReaper-0-AlterAcls]: Shutting down
2024-12-31 21:06:40.263 [ExpirationReaper-0-AlterAcls]: Shutdown completed
2024-12-31 21:06:40.263 [ExpirationReaper-0-AlterAcls]: Stopped
2024-12-31 21:06:40.263 [KafkaApi-0] Shutdown complete.
2024-12-31 21:06:40.263 [ExpirationReaper-0-topic]: Shutting down
2024-12-31 21:06:40.263 [ExpirationReaper-0-topic]: Stopped
2024-12-31 21:06:40.263 [ExpirationReaper-0-topic]: Shutdown completed
2024-12-31 21:06:40.263 [TransactionCoordinator id=0] Shutting down.
2024-12-31 21:06:40.263 [Transaction State Manager 0]: Shutdown complete
2024-12-31 21:06:40.263 [Transaction Marker Channel Manager 0]: Shutting down
2024-12-31 21:06:40.263 [Transaction Marker Channel Manager 0]: Stopped
2024-12-31 21:06:40.263 [Transaction Marker Channel Manager 0]: Shutdown completed
2024-12-31 21:06:40.263 [TransactionCoordinator id=0] Shutdown complete.
2024-12-31 21:06:40.264 [GroupCoordinator 0]: Shutting down.
2024-12-31 21:06:40.264 [ExpirationReaper-0-Heartbeat]: Shutting down
2024-12-31 21:06:40.264 [ExpirationReaper-0-Heartbeat]: Shutdown completed
2024-12-31 21:06:40.264 [ExpirationReaper-0-Heartbeat]: Stopped
2024-12-31 21:06:40.264 [ExpirationReaper-0-Rebalance]: Shutting down
2024-12-31 21:06:40.264 [ExpirationReaper-0-Rebalance]: Stopped
2024-12-31 21:06:40.264 [ExpirationReaper-0-Rebalance]: Shutdown completed
2024-12-31 21:06:40.264 [GroupCoordinator 0]: Shutdown complete.
2024-12-31 21:06:40.264 [ReplicaManager broker=0] Shutting down
2024-12-31 21:06:40.264 [LogDirFailureHandler]: Shutting down
2024-12-31 21:06:40.264 [LogDirFailureHandler]: Stopped
2024-12-31 21:06:40.264 [LogDirFailureHandler]: Shutdown completed
2024-12-31 21:06:40.264 [ReplicaFetcherManager on broker 0] shutting down
2024-12-31 21:06:40.266 [ReplicaFetcherManager on broker 0] shutdown completed
2024-12-31 21:06:40.266 [ReplicaAlterLogDirsManager on broker 0] shutting down
2024-12-31 21:06:40.266 [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2024-12-31 21:06:40.266 [ExpirationReaper-0-Fetch]: Shutting down
2024-12-31 21:06:40.266 [ExpirationReaper-0-Fetch]: Shutdown completed
2024-12-31 21:06:40.266 [ExpirationReaper-0-Fetch]: Stopped
2024-12-31 21:06:40.266 [ExpirationReaper-0-Produce]: Shutting down
2024-12-31 21:06:40.266 [ExpirationReaper-0-Produce]: Stopped
2024-12-31 21:06:40.266 [ExpirationReaper-0-Produce]: Shutdown completed
2024-12-31 21:06:40.266 [ExpirationReaper-0-DeleteRecords]: Shutting down
2024-12-31 21:06:40.267 [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2024-12-31 21:06:40.267 [ExpirationReaper-0-DeleteRecords]: Stopped
2024-12-31 21:06:40.267 [ExpirationReaper-0-ElectLeader]: Shutting down
2024-12-31 21:06:40.267 [ExpirationReaper-0-ElectLeader]: Shutdown completed
2024-12-31 21:06:40.267 [ExpirationReaper-0-ElectLeader]: Stopped
2024-12-31 21:06:40.275 [ReplicaManager broker=0] Shut down completely
2024-12-31 21:06:40.276 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutting down
2024-12-31 21:06:40.276 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Stopped
2024-12-31 21:06:40.276 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutdown completed
2024-12-31 21:06:40.277 Broker to controller channel manager for alterPartition shutdown
2024-12-31 21:06:40.277 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down
2024-12-31 21:06:40.277 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed
2024-12-31 21:06:40.277 [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped
2024-12-31 21:06:40.277 Broker to controller channel manager for forwarding shutdown
2024-12-31 21:06:40.277 Shutting down.
2024-12-31 21:06:40.277 Shutting down the log cleaner.
2024-12-31 21:06:40.277 [kafka-log-cleaner-thread-0]: Shutting down
2024-12-31 21:06:40.277 [kafka-log-cleaner-thread-0]: Shutdown completed
2024-12-31 21:06:40.277 [kafka-log-cleaner-thread-0]: Stopped
2024-12-31 21:06:40.293 [ProducerStateManager partition=pong-message-topic-0] Wrote producer snapshot at offset 1 with 0 producer ids in 3 ms.
2024-12-31 21:06:40.306 [ProducerStateManager partition=__consumer_offsets-2] Wrote producer snapshot at offset 3 with 0 producer ids in 2 ms.
2024-12-31 21:06:40.316 Shutdown complete.
2024-12-31 21:06:40.317 [ControllerEventThread controllerId=0] Shutting down
2024-12-31 21:06:40.317 [ControllerEventThread controllerId=0] Shutdown completed
2024-12-31 21:06:40.317 [ControllerEventThread controllerId=0] Stopped
2024-12-31 21:06:40.317 [PartitionStateMachine controllerId=0] Stopped partition state machine
2024-12-31 21:06:40.317 [ReplicaStateMachine controllerId=0] Stopped replica state machine
2024-12-31 21:06:40.317 [RequestSendThread controllerId=0] Shutting down
2024-12-31 21:06:40.317 [RequestSendThread controllerId=0] Shutdown completed
2024-12-31 21:06:40.317 [RequestSendThread controllerId=0] Stopped
2024-12-31 21:06:40.318 [Controller id=0] Resigned
2024-12-31 21:06:40.319 [feature-zk-node-event-process-thread]: Shutting down
2024-12-31 21:06:40.319 [feature-zk-node-event-process-thread]: Stopped
2024-12-31 21:06:40.319 [feature-zk-node-event-process-thread]: Shutdown completed
2024-12-31 21:06:40.319 [ZooKeeperClient Kafka server] Closing.
2024-12-31 21:06:40.360 [Producer clientId=producer-2] Node 0 disconnected.
2024-12-31 21:06:40.360 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:06:40.360 [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:59444) could not be established. Broker may not be available.
2024-12-31 21:06:40.360 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node 0 (localhost/127.0.0.1:59444) could not be established. Broker may not be available.
2024-12-31 21:06:40.423 Session: 0x100176e67980000 closed
2024-12-31 21:06:40.423 EventThread shut down for session: 0x100176e67980000
2024-12-31 21:06:40.423 [ZooKeeperClient Kafka server] Closed.
2024-12-31 21:06:40.423 [ThrottledChannelReaper-Fetch]: Shutting down
2024-12-31 21:06:40.423 [ThrottledChannelReaper-Fetch]: Stopped
2024-12-31 21:06:40.423 [ThrottledChannelReaper-Fetch]: Shutdown completed
2024-12-31 21:06:40.423 [ThrottledChannelReaper-Produce]: Shutting down
2024-12-31 21:06:40.424 [ThrottledChannelReaper-Produce]: Stopped
2024-12-31 21:06:40.424 [ThrottledChannelReaper-Produce]: Shutdown completed
2024-12-31 21:06:40.424 [ThrottledChannelReaper-Request]: Shutting down
2024-12-31 21:06:40.424 [ThrottledChannelReaper-Request]: Shutdown completed
2024-12-31 21:06:40.424 [ThrottledChannelReaper-ControllerMutation]: Shutting down
2024-12-31 21:06:40.424 [ThrottledChannelReaper-Request]: Stopped
2024-12-31 21:06:40.424 [ThrottledChannelReaper-ControllerMutation]: Stopped
2024-12-31 21:06:40.424 [ThrottledChannelReaper-ControllerMutation]: Shutdown completed
2024-12-31 21:06:40.424 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server
2024-12-31 21:06:40.434 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed
2024-12-31 21:06:40.434 Metrics scheduler closed
2024-12-31 21:06:40.434 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:06:40.434 Metrics reporters closed
2024-12-31 21:06:40.434 Broker and topic stats closed
2024-12-31 21:06:40.434 App info kafka.server for 0 unregistered
2024-12-31 21:06:40.434 [KafkaServer id=0] shut down completed
2024-12-31 21:06:40.446 ConnnectionExpirerThread interrupted
2024-12-31 21:06:40.446 accept thread exitted run method
2024-12-31 21:06:40.447 selector thread exitted run method
2024-12-31 21:06:40.447 selector thread exitted run method
2024-12-31 21:06:40.447 shutting down
2024-12-31 21:06:40.447 Shutting down
2024-12-31 21:06:40.447 Draining request throttler queue
2024-12-31 21:06:40.447 RequestThrottler shutdown. Dropped 0 requests
2024-12-31 21:06:40.447 Shutting down
2024-12-31 21:06:40.447 Shutting down
2024-12-31 21:06:40.447 Shutting down
2024-12-31 21:06:40.447 PrepRequestProcessor exited loop!
2024-12-31 21:06:40.447 SyncRequestProcessor exited!
2024-12-31 21:06:40.448 shutdown of request processor complete
2024-12-31 21:06:40.464 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Revoke previously assigned partitions pong-message-topic-0, pong-message-topic-1
2024-12-31 21:06:40.464 pong-service: partitions revoked: [pong-message-topic-0, pong-message-topic-1]
2024-12-31 21:06:40.464 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:06:40.464 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:06:40.464 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Unsubscribed all topics or patterns and assigned partitions
2024-12-31 21:06:40.464 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:06:40.464 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:06:40.464 Metrics scheduler closed
2024-12-31 21:06:40.464 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:06:40.464 Metrics reporters closed
2024-12-31 21:06:40.464 App info kafka.consumer for consumer-pong-service-3 unregistered
2024-12-31 21:06:40.464 pong-service: Consumer stopped
2024-12-31 21:06:40.464 [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 30000 ms.
2024-12-31 21:06:40.464 Metrics scheduler closed
2024-12-31 21:06:40.464 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:06:40.464 Metrics reporters closed
2024-12-31 21:06:40.464 App info kafka.producer for producer-2 unregistered
2024-12-31 21:06:40.468 Closing JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:06:40.471 HikariPool-3 - Shutdown initiated...
2024-12-31 21:06:40.471 HikariPool-3 - Shutdown completed.
2024-12-31 21:06:58.054 Could not detect default configuration classes for test class [com.demo.controller.PongControllerSpec]: PongControllerSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:06:58.214 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.controller.PongControllerSpec
2024-12-31 21:06:58.411 Could not detect default configuration classes for test class [com.demo.dao.MessageRepositorySpec]: MessageRepositorySpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:06:58.420 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.dao.MessageRepositorySpec
2024-12-31 21:06:58.445 Could not detect default configuration classes for test class [com.demo.kafka.KafkaSpec]: KafkaSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:06:58.472 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.kafka.KafkaSpec
2024-12-31 21:06:58.512 Could not detect default configuration classes for test class [com.demo.controller.PongControllerSpec]: PongControllerSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:06:58.513 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.controller.PongControllerSpec
2024-12-31 21:06:58.520 Could not detect default configuration classes for test class [com.demo.dao.MessageRepositorySpec]: MessageRepositorySpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:06:58.520 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.dao.MessageRepositorySpec
2024-12-31 21:06:58.520 Could not detect default configuration classes for test class [com.demo.kafka.KafkaSpec]: KafkaSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:06:58.529 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.kafka.KafkaSpec
2024-12-31 21:06:58.904 Registered kafka:type=kafka.Log4jController MBean
2024-12-31 21:06:58.979 
2024-12-31 21:06:58.979   ______                  _                                          
2024-12-31 21:06:58.979  |___  /                 | |                                         
2024-12-31 21:06:58.979     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __   
2024-12-31 21:06:58.979    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__|
2024-12-31 21:06:58.979   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |    
2024-12-31 21:06:58.979  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_|
2024-12-31 21:06:58.979                                               | |                     
2024-12-31 21:06:58.979                                               |_|                     
2024-12-31 21:06:58.979 
2024-12-31 21:07:04.233 Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT
2024-12-31 21:07:04.233 Server environment:host.name=Joe
2024-12-31 21:07:04.233 Server environment:java.version=17.0.12
2024-12-31 21:07:04.233 Server environment:java.vendor=Oracle Corporation
2024-12-31 21:07:04.233 Server environment:java.home=C:\work\jdk-17
2024-12-31 21:07:04.233 Server environment:java.class.path=C:\code\hsbc\demo\pong\target\test-classes;C:\code\hsbc\demo\pong\target\classes;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-webflux\3.1.4\spring-boot-starter-webflux-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter\3.1.4\spring-boot-starter-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot\3.1.4\spring-boot-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-autoconfigure\3.1.4\spring-boot-autoconfigure-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-logging\3.1.4\spring-boot-starter-logging-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\ch\qos\logback\logback-classic\1.4.11\logback-classic-1.4.11.jar;C:\work\apache-maven-3.8.8\repo\ch\qos\logback\logback-core\1.4.11\logback-core-1.4.11.jar;C:\work\apache-maven-3.8.8\repo\org\apache\logging\log4j\log4j-to-slf4j\2.20.0\log4j-to-slf4j-2.20.0.jar;C:\work\apache-maven-3.8.8\repo\org\apache\logging\log4j\log4j-api\2.20.0\log4j-api-2.20.0.jar;C:\work\apache-maven-3.8.8\repo\org\slf4j\jul-to-slf4j\2.0.9\jul-to-slf4j-2.0.9.jar;C:\work\apache-maven-3.8.8\repo\jakarta\annotation\jakarta.annotation-api\2.1.1\jakarta.annotation-api-2.1.1.jar;C:\work\apache-maven-3.8.8\repo\org\yaml\snakeyaml\1.33\snakeyaml-1.33.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-json\3.1.4\spring-boot-starter-json-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-databind\2.15.2\jackson-databind-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-annotations\2.15.2\jackson-annotations-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-core\2.15.2\jackson-core-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.15.2\jackson-datatype-jdk8-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.15.2\jackson-datatype-jsr310-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\module\jackson-module-parameter-names\2.15.2\jackson-module-parameter-names-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-reactor-netty\3.1.4\spring-boot-starter-reactor-netty-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\netty\reactor-netty-http\1.1.11\reactor-netty-http-1.1.11.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-http\4.1.97.Final\netty-codec-http-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-http2\4.1.97.Final\netty-codec-http2-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns\4.1.97.Final\netty-resolver-dns-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-dns\4.1.97.Final\netty-codec-dns-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns-native-macos\4.1.97.Final\netty-resolver-dns-native-macos-4.1.97.Final-osx-x86_64.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns-classes-macos\4.1.97.Final\netty-resolver-dns-classes-macos-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final-linux-x86_64.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\netty\reactor-netty-core\1.1.11\reactor-netty-core-1.1.11.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-handler-proxy\4.1.97.Final\netty-handler-proxy-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-socks\4.1.97.Final\netty-codec-socks-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-web\6.0.12\spring-web-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-beans\6.0.12\spring-beans-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-webflux\6.0.12\spring-webflux-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\reactor-core\3.5.10\reactor-core-3.5.10.jar;C:\work\apache-maven-3.8.8\repo\org\reactivestreams\reactive-streams\1.0.4\reactive-streams-1.0.4.jar;C:\work\apache-maven-3.8.8\repo\com\google\guava\guava\19.0\guava-19.0.jar;C:\work\apache-maven-3.8.8\repo\commons-io\commons-io\2.11.0\commons-io-2.11.0.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-data-redis\3.1.4\spring-boot-starter-data-redis-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-redis\3.1.4\spring-data-redis-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-keyvalue\3.1.4\spring-data-keyvalue-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-oxm\6.0.12\spring-oxm-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-aop\6.0.12\spring-aop-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-context-support\6.0.12\spring-context-support-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\io\lettuce\lettuce-core\6.2.6.RELEASE\lettuce-core-6.2.6.RELEASE.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-common\4.1.97.Final\netty-common-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-handler\4.1.97.Final\netty-handler-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver\4.1.97.Final\netty-resolver-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-buffer\4.1.97.Final\netty-buffer-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-unix-common\4.1.97.Final\netty-transport-native-unix-common-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec\4.1.97.Final\netty-codec-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport\4.1.97.Final\netty-transport-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-data-jpa\3.1.4\spring-boot-starter-data-jpa-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-aop\3.1.4\spring-boot-starter-aop-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\aspectj\aspectjweaver\1.9.20\aspectjweaver-1.9.20.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-jdbc\3.1.4\spring-boot-starter-jdbc-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\zaxxer\HikariCP\5.0.1\HikariCP-5.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-jdbc\6.0.12\spring-jdbc-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\hibernate\orm\hibernate-core\6.2.9.Final\hibernate-core-6.2.9.Final.jar;C:\work\apache-maven-3.8.8\repo\jakarta\persistence\jakarta.persistence-api\3.1.0\jakarta.persistence-api-3.1.0.jar;C:\work\apache-maven-3.8.8\repo\jakarta\transaction\jakarta.transaction-api\2.0.1\jakarta.transaction-api-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\jboss\logging\jboss-logging\3.5.3.Final\jboss-logging-3.5.3.Final.jar;C:\work\apache-maven-3.8.8\repo\org\hibernate\common\hibernate-commons-annotations\6.0.6.Final\hibernate-commons-annotations-6.0.6.Final.jar;C:\work\apache-maven-3.8.8\repo\io\smallrye\jandex\3.0.5\jandex-3.0.5.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\classmate\1.5.1\classmate-1.5.1.jar;C:\work\apache-maven-3.8.8\repo\net\bytebuddy\byte-buddy\1.14.8\byte-buddy-1.14.8.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\jaxb-runtime\4.0.3\jaxb-runtime-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\jaxb-core\4.0.3\jaxb-core-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\eclipse\angus\angus-activation\2.0.1\angus-activation-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\txw2\4.0.3\txw2-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\com\sun\istack\istack-commons-runtime\4.1.2\istack-commons-runtime-4.1.2.jar;C:\work\apache-maven-3.8.8\repo\jakarta\inject\jakarta.inject-api\2.0.1\jakarta.inject-api-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\antlr\antlr4-runtime\4.10.1\antlr4-runtime-4.10.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-jpa\3.1.4\spring-data-jpa-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-commons\3.1.4\spring-data-commons-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-orm\6.0.12\spring-orm-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-aspects\6.0.12\spring-aspects-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\postgresql\postgresql\42.6.0\postgresql-42.6.0.jar;C:\work\apache-maven-3.8.8\repo\org\checkerframework\checker-qual\3.31.0\checker-qual-3.31.0.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\kafka\spring-kafka\3.0.11\spring-kafka-3.0.11.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-context\6.0.12\spring-context-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-expression\6.0.12\spring-expression-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-messaging\6.0.12\spring-messaging-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-tx\6.0.12\spring-tx-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\retry\spring-retry\2.0.3\spring-retry-2.0.3.jar;C:\work\apache-maven-3.8.8\repo\io\micrometer\micrometer-observation\1.11.4\micrometer-observation-1.11.4.jar;C:\work\apache-maven-3.8.8\repo\io\micrometer\micrometer-commons\1.11.4\micrometer-commons-1.11.4.jar;C:\work\apache-maven-3.8.8\repo\com\google\code\findbugs\jsr305\3.0.2\jsr305-3.0.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\com\github\luben\zstd-jni\1.5.2-1\zstd-jni-1.5.2-1.jar;C:\work\apache-maven-3.8.8\repo\org\lz4\lz4-java\1.8.0\lz4-java-1.8.0.jar;C:\work\apache-maven-3.8.8\repo\org\xerial\snappy\snappy-java\1.1.8.4\snappy-java-1.1.8.4.jar;C:\work\apache-maven-3.8.8\repo\org\slf4j\slf4j-api\2.0.9\slf4j-api-2.0.9.jar;C:\work\apache-maven-3.8.8\repo\com\h2database\h2\1.4.200\h2-1.4.200.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-test\3.1.4\spring-boot-starter-test-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-test\3.1.4\spring-boot-test-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-test-autoconfigure\3.1.4\spring-boot-test-autoconfigure-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\jayway\jsonpath\json-path\2.8.0\json-path-2.8.0.jar;C:\work\apache-maven-3.8.8\repo\jakarta\xml\bind\jakarta.xml.bind-api\4.0.1\jakarta.xml.bind-api-4.0.1.jar;C:\work\apache-maven-3.8.8\repo\jakarta\activation\jakarta.activation-api\2.1.2\jakarta.activation-api-2.1.2.jar;C:\work\apache-maven-3.8.8\repo\net\minidev\json-smart\2.4.11\json-smart-2.4.11.jar;C:\work\apache-maven-3.8.8\repo\net\minidev\accessors-smart\2.4.11\accessors-smart-2.4.11.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm\9.3\asm-9.3.jar;C:\work\apache-maven-3.8.8\repo\org\assertj\assertj-core\3.24.2\assertj-core-3.24.2.jar;C:\work\apache-maven-3.8.8\repo\org\hamcrest\hamcrest\2.2\hamcrest-2.2.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter\5.9.3\junit-jupiter-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-params\5.9.3\junit-jupiter-params-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-engine\5.9.3\junit-jupiter-engine-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\mockito\mockito-core\5.3.1\mockito-core-5.3.1.jar;C:\work\apache-maven-3.8.8\repo\net\bytebuddy\byte-buddy-agent\1.14.8\byte-buddy-agent-1.14.8.jar;C:\work\apache-maven-3.8.8\repo\org\objenesis\objenesis\3.3\objenesis-3.3.jar;C:\work\apache-maven-3.8.8\repo\org\mockito\mockito-junit-jupiter\5.3.1\mockito-junit-jupiter-5.3.1.jar;C:\work\apache-maven-3.8.8\repo\org\skyscreamer\jsonassert\1.5.1\jsonassert-1.5.1.jar;C:\work\apache-maven-3.8.8\repo\com\vaadin\external\google\android-json\0.0.20131108.vaadin1\android-json-0.0.20131108.vaadin1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-core\6.0.12\spring-core-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-jcl\6.0.12\spring-jcl-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-test\6.0.12\spring-test-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\xmlunit\xmlunit-core\2.9.1\xmlunit-core-2.9.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy\4.0.15\groovy-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-ant\4.0.15\groovy-ant-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant\1.10.14\ant-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-junit\1.10.14\ant-junit-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-launcher\1.10.14\ant-launcher-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-antlr\1.10.14\ant-antlr-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-cli-picocli\4.0.15\groovy-cli-picocli-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\info\picocli\picocli\4.7.5\picocli-4.7.5.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-console\4.0.15\groovy-console-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\github\javaparser\javaparser-core\3.25.5\javaparser-core-3.25.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-util\9.5\asm-util-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-tree\9.5\asm-tree-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-analysis\9.5\asm-analysis-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\abego\treelayout\org.abego.treelayout.core\1.0.3\org.abego.treelayout.core-1.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ivy\ivy\2.5.2\ivy-2.5.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-datetime\4.0.15\groovy-datetime-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-docgenerator\4.0.15\groovy-docgenerator-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\thoughtworks\qdox\qdox\1.12.1\qdox-1.12.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-groovydoc\4.0.15\groovy-groovydoc-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-groovysh\4.0.15\groovy-groovysh-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\jline\jline\2.14.6\jline-2.14.6.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-jmx\4.0.15\groovy-jmx-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-json\4.0.15\groovy-json-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-jsr223\4.0.15\groovy-jsr223-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-macro\4.0.15\groovy-macro-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-nio\4.0.15\groovy-nio-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-servlet\4.0.15\groovy-servlet-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-sql\4.0.15\groovy-sql-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-swing\4.0.15\groovy-swing-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-templates\4.0.15\groovy-templates-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-test\4.0.15\groovy-test-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\junit\junit\4.13.2\junit-4.13.2.jar;C:\work\apache-maven-3.8.8\repo\org\hamcrest\hamcrest-core\2.2\hamcrest-core-2.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-test-junit5\4.0.15\groovy-test-junit5-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-xml\4.0.15\groovy-xml-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-yaml\4.0.15\groovy-yaml-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\dataformat\jackson-dataformat-yaml\2.15.2\jackson-dataformat-yaml-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\org\spockframework\spock-core\2.4-M1-groovy-4.0\spock-core-2.4-M1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-engine\1.9.3\junit-platform-engine-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\opentest4j\opentest4j\1.2.0\opentest4j-1.2.0.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-commons\1.9.3\junit-platform-commons-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\apiguardian\apiguardian-api\1.1.2\apiguardian-api-1.1.2.jar;C:\work\apache-maven-3.8.8\repo\org\spockframework\spock-spring\2.4-M1-groovy-4.0\spock-spring-2.4-M1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\com\athaydes\spock-reports\2.5.1-groovy-4.0\spock-reports-2.5.1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\com\github\codemonstur\embedded-redis\1.4.2\embedded-redis-1.4.2.jar;C:\work\apache-maven-3.8.8\repo\redis\clients\jedis\4.3.2\jedis-4.3.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\commons\commons-pool2\2.11.1\commons-pool2-2.11.1.jar;C:\work\apache-maven-3.8.8\repo\org\json\json\20220320\json-20220320.jar;C:\work\apache-maven-3.8.8\repo\com\google\code\gson\gson\2.10.1\gson-2.10.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\kafka\spring-kafka-test\3.0.11\spring-kafka-test-3.0.11.jar;C:\work\apache-maven-3.8.8\repo\org\apache\zookeeper\zookeeper\3.6.3\zookeeper-3.6.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\zookeeper\zookeeper-jute\3.6.3\zookeeper-jute-3.6.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-classes-epoll\4.1.97.Final\netty-transport-classes-epoll-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1-test.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-metadata\3.4.1\kafka-metadata-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-server-common\3.4.1\kafka-server-common-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-raft\3.4.1\kafka-raft-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-streams-test-utils\3.4.1\kafka-streams-test-utils-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-streams\3.4.1\kafka-streams-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\rocksdb\rocksdbjni\7.1.2\rocksdbjni-7.1.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\scala-library\2.13.10\scala-library-2.13.10.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-group-coordinator\3.4.1\kafka-group-coordinator-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-storage\3.4.1\kafka-storage-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-storage-api\3.4.1\kafka-storage-api-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\net\sourceforge\argparse4j\argparse4j\0.7.0\argparse4j-0.7.0.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\module\jackson-module-scala_2.13\2.15.2\jackson-module-scala_2.13-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\thoughtworks\paranamer\paranamer\2.8\paranamer-2.8.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\dataformat\jackson-dataformat-csv\2.15.2\jackson-dataformat-csv-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\net\sf\jopt-simple\jopt-simple\5.0.4\jopt-simple-5.0.4.jar;C:\work\apache-maven-3.8.8\repo\org\bitbucket\b_c\jose4j\0.9.3\jose4j-0.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\modules\scala-collection-compat_2.13\2.10.0\scala-collection-compat_2.13-2.10.0.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\modules\scala-java8-compat_2.13\1.0.2\scala-java8-compat_2.13-1.0.2.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\scala-reflect\2.13.10\scala-reflect-2.13.10.jar;C:\work\apache-maven-3.8.8\repo\com\typesafe\scala-logging\scala-logging_2.13\3.9.4\scala-logging_2.13-3.9.4.jar;C:\work\apache-maven-3.8.8\repo\io\dropwizard\metrics\metrics-core\4.2.19\metrics-core-4.2.19.jar;C:\work\apache-maven-3.8.8\repo\commons-cli\commons-cli\1.4\commons-cli-1.4.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1-test.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-api\5.9.3\junit-jupiter-api-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-launcher\1.9.3\junit-platform-launcher-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\awaitility\awaitility\4.2.0\awaitility-4.2.0.jar;
2024-12-31 21:07:04.233 Server environment:java.library.path=C:\work\jdk-17\bin;C:\windows\Sun\Java\bin;C:\windows\system32;C:\windows;C:\work\python312\Scripts\;C:\work\python312\;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program\Git\cmd;C:\Program\PowerShell\7\;C:\Program Files\dotnet\;C:\Users\joech\AppData\Local\Microsoft\WindowsApps;C:\Users\joech\AppData\Local\GitHubDesktop\bin;C:\Program\Microsoft VS Code\bin;C:\work\apache-maven-3.8.8\bin;C:\Program Files\Tesseract-OCR;C:\work\jdk-17\bin;;.
2024-12-31 21:07:04.233 Server environment:java.io.tmpdir=C:\Users\joech\AppData\Local\Temp\
2024-12-31 21:07:04.233 Server environment:java.compiler=<NA>
2024-12-31 21:07:04.233 Server environment:os.name=Windows 11
2024-12-31 21:07:04.233 Server environment:os.arch=amd64
2024-12-31 21:07:04.233 Server environment:os.version=10.0
2024-12-31 21:07:04.233 Server environment:user.name=joech
2024-12-31 21:07:04.233 Server environment:user.home=C:\Users\joech
2024-12-31 21:07:04.233 Server environment:user.dir=C:\code\hsbc\demo\pong
2024-12-31 21:07:04.233 Server environment:os.memory.free=87MB
2024-12-31 21:07:04.233 Server environment:os.memory.max=15816MB
2024-12-31 21:07:04.233 Server environment:os.memory.total=136MB
2024-12-31 21:07:04.233 zookeeper.enableEagerACLCheck = false
2024-12-31 21:07:04.241 zookeeper.digest.enabled = true
2024-12-31 21:07:04.241 zookeeper.closeSessionTxn.enabled = true
2024-12-31 21:07:04.241 zookeeper.flushDelay=0
2024-12-31 21:07:04.241 zookeeper.maxWriteQueuePollTime=0
2024-12-31 21:07:04.241 zookeeper.maxBatchSize=1000
2024-12-31 21:07:04.241 zookeeper.intBufferStartingSizeBytes = 1024
2024-12-31 21:07:04.243 zookeeper.snapshot.trust.empty : false
2024-12-31 21:07:04.266 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:07:04.266 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:07:04.281 zookeeper.snapshotSizeFactor = 0.33
2024-12-31 21:07:04.281 zookeeper.commitLogCount=500
2024-12-31 21:07:04.283 Weighed connection throttling is disabled
2024-12-31 21:07:04.283 minSessionTimeout set to 1600
2024-12-31 21:07:04.283 maxSessionTimeout set to 16000
2024-12-31 21:07:04.283 Response cache size is initialized with value 400.
2024-12-31 21:07:04.283 Response cache size is initialized with value 400.
2024-12-31 21:07:04.296 zookeeper.pathStats.slotCapacity = 60
2024-12-31 21:07:04.296 zookeeper.pathStats.slotDuration = 15
2024-12-31 21:07:04.296 zookeeper.pathStats.maxDepth = 6
2024-12-31 21:07:04.296 zookeeper.pathStats.initialDelay = 5
2024-12-31 21:07:04.296 zookeeper.pathStats.delay = 5
2024-12-31 21:07:04.296 zookeeper.pathStats.enabled = false
2024-12-31 21:07:04.296 The max bytes for all large requests are set to 104857600
2024-12-31 21:07:04.296 The large request threshold is set to -1
2024-12-31 21:07:04.296 Created server with tickTime 800 minSessionTimeout 1600 maxSessionTimeout 16000 clientPortListenBacklog -1 datadir C:\Users\joech\AppData\Local\Temp\kafka-4949642767587536701\version-2 snapdir C:\Users\joech\AppData\Local\Temp\kafka-12705443102775682803\version-2
2024-12-31 21:07:04.358 maxCnxns is not configured, using default value 0.
2024-12-31 21:07:04.358 Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers.
2024-12-31 21:07:04.374 binding to port /127.0.0.1:0
2024-12-31 21:07:04.407 zookeeper.snapshot.compression.method = CHECKED
2024-12-31 21:07:04.408 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-12705443102775682803\version-2\snapshot.0
2024-12-31 21:07:04.417 Snapshot loaded in 33 ms, highest zxid is 0x0, digest is 1371985504
2024-12-31 21:07:04.417 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-12705443102775682803\version-2\snapshot.0
2024-12-31 21:07:04.418 Snapshot taken in 1 ms
2024-12-31 21:07:04.439 PrepRequestProcessor (sid:0) started, reconfigEnabled=false
2024-12-31 21:07:04.439 zookeeper.request_throttler.shutdownTimeout = 10000
2024-12-31 21:07:04.896 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.23fe1155-4ed9-4f7a-a6c4-37bce40c42959321802500161184416
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59460
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:07:04.949 Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
2024-12-31 21:07:05.050 starting
2024-12-31 21:07:05.051 Connecting to zookeeper on 127.0.0.1:59460
2024-12-31 21:07:05.076 [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:59460.
2024-12-31 21:07:10.369 Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT
2024-12-31 21:07:10.370 Client environment:host.name=Joe
2024-12-31 21:07:10.370 Client environment:java.version=17.0.12
2024-12-31 21:07:10.370 Client environment:java.vendor=Oracle Corporation
2024-12-31 21:07:10.370 Client environment:java.home=C:\work\jdk-17
2024-12-31 21:07:10.370 Client environment:java.class.path=C:\code\hsbc\demo\pong\target\test-classes;C:\code\hsbc\demo\pong\target\classes;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-webflux\3.1.4\spring-boot-starter-webflux-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter\3.1.4\spring-boot-starter-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot\3.1.4\spring-boot-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-autoconfigure\3.1.4\spring-boot-autoconfigure-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-logging\3.1.4\spring-boot-starter-logging-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\ch\qos\logback\logback-classic\1.4.11\logback-classic-1.4.11.jar;C:\work\apache-maven-3.8.8\repo\ch\qos\logback\logback-core\1.4.11\logback-core-1.4.11.jar;C:\work\apache-maven-3.8.8\repo\org\apache\logging\log4j\log4j-to-slf4j\2.20.0\log4j-to-slf4j-2.20.0.jar;C:\work\apache-maven-3.8.8\repo\org\apache\logging\log4j\log4j-api\2.20.0\log4j-api-2.20.0.jar;C:\work\apache-maven-3.8.8\repo\org\slf4j\jul-to-slf4j\2.0.9\jul-to-slf4j-2.0.9.jar;C:\work\apache-maven-3.8.8\repo\jakarta\annotation\jakarta.annotation-api\2.1.1\jakarta.annotation-api-2.1.1.jar;C:\work\apache-maven-3.8.8\repo\org\yaml\snakeyaml\1.33\snakeyaml-1.33.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-json\3.1.4\spring-boot-starter-json-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-databind\2.15.2\jackson-databind-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-annotations\2.15.2\jackson-annotations-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-core\2.15.2\jackson-core-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.15.2\jackson-datatype-jdk8-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.15.2\jackson-datatype-jsr310-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\module\jackson-module-parameter-names\2.15.2\jackson-module-parameter-names-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-reactor-netty\3.1.4\spring-boot-starter-reactor-netty-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\netty\reactor-netty-http\1.1.11\reactor-netty-http-1.1.11.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-http\4.1.97.Final\netty-codec-http-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-http2\4.1.97.Final\netty-codec-http2-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns\4.1.97.Final\netty-resolver-dns-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-dns\4.1.97.Final\netty-codec-dns-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns-native-macos\4.1.97.Final\netty-resolver-dns-native-macos-4.1.97.Final-osx-x86_64.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns-classes-macos\4.1.97.Final\netty-resolver-dns-classes-macos-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final-linux-x86_64.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\netty\reactor-netty-core\1.1.11\reactor-netty-core-1.1.11.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-handler-proxy\4.1.97.Final\netty-handler-proxy-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-socks\4.1.97.Final\netty-codec-socks-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-web\6.0.12\spring-web-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-beans\6.0.12\spring-beans-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-webflux\6.0.12\spring-webflux-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\reactor-core\3.5.10\reactor-core-3.5.10.jar;C:\work\apache-maven-3.8.8\repo\org\reactivestreams\reactive-streams\1.0.4\reactive-streams-1.0.4.jar;C:\work\apache-maven-3.8.8\repo\com\google\guava\guava\19.0\guava-19.0.jar;C:\work\apache-maven-3.8.8\repo\commons-io\commons-io\2.11.0\commons-io-2.11.0.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-data-redis\3.1.4\spring-boot-starter-data-redis-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-redis\3.1.4\spring-data-redis-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-keyvalue\3.1.4\spring-data-keyvalue-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-oxm\6.0.12\spring-oxm-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-aop\6.0.12\spring-aop-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-context-support\6.0.12\spring-context-support-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\io\lettuce\lettuce-core\6.2.6.RELEASE\lettuce-core-6.2.6.RELEASE.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-common\4.1.97.Final\netty-common-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-handler\4.1.97.Final\netty-handler-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver\4.1.97.Final\netty-resolver-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-buffer\4.1.97.Final\netty-buffer-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-unix-common\4.1.97.Final\netty-transport-native-unix-common-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec\4.1.97.Final\netty-codec-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport\4.1.97.Final\netty-transport-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-data-jpa\3.1.4\spring-boot-starter-data-jpa-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-aop\3.1.4\spring-boot-starter-aop-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\aspectj\aspectjweaver\1.9.20\aspectjweaver-1.9.20.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-jdbc\3.1.4\spring-boot-starter-jdbc-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\zaxxer\HikariCP\5.0.1\HikariCP-5.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-jdbc\6.0.12\spring-jdbc-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\hibernate\orm\hibernate-core\6.2.9.Final\hibernate-core-6.2.9.Final.jar;C:\work\apache-maven-3.8.8\repo\jakarta\persistence\jakarta.persistence-api\3.1.0\jakarta.persistence-api-3.1.0.jar;C:\work\apache-maven-3.8.8\repo\jakarta\transaction\jakarta.transaction-api\2.0.1\jakarta.transaction-api-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\jboss\logging\jboss-logging\3.5.3.Final\jboss-logging-3.5.3.Final.jar;C:\work\apache-maven-3.8.8\repo\org\hibernate\common\hibernate-commons-annotations\6.0.6.Final\hibernate-commons-annotations-6.0.6.Final.jar;C:\work\apache-maven-3.8.8\repo\io\smallrye\jandex\3.0.5\jandex-3.0.5.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\classmate\1.5.1\classmate-1.5.1.jar;C:\work\apache-maven-3.8.8\repo\net\bytebuddy\byte-buddy\1.14.8\byte-buddy-1.14.8.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\jaxb-runtime\4.0.3\jaxb-runtime-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\jaxb-core\4.0.3\jaxb-core-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\eclipse\angus\angus-activation\2.0.1\angus-activation-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\txw2\4.0.3\txw2-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\com\sun\istack\istack-commons-runtime\4.1.2\istack-commons-runtime-4.1.2.jar;C:\work\apache-maven-3.8.8\repo\jakarta\inject\jakarta.inject-api\2.0.1\jakarta.inject-api-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\antlr\antlr4-runtime\4.10.1\antlr4-runtime-4.10.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-jpa\3.1.4\spring-data-jpa-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-commons\3.1.4\spring-data-commons-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-orm\6.0.12\spring-orm-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-aspects\6.0.12\spring-aspects-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\postgresql\postgresql\42.6.0\postgresql-42.6.0.jar;C:\work\apache-maven-3.8.8\repo\org\checkerframework\checker-qual\3.31.0\checker-qual-3.31.0.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\kafka\spring-kafka\3.0.11\spring-kafka-3.0.11.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-context\6.0.12\spring-context-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-expression\6.0.12\spring-expression-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-messaging\6.0.12\spring-messaging-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-tx\6.0.12\spring-tx-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\retry\spring-retry\2.0.3\spring-retry-2.0.3.jar;C:\work\apache-maven-3.8.8\repo\io\micrometer\micrometer-observation\1.11.4\micrometer-observation-1.11.4.jar;C:\work\apache-maven-3.8.8\repo\io\micrometer\micrometer-commons\1.11.4\micrometer-commons-1.11.4.jar;C:\work\apache-maven-3.8.8\repo\com\google\code\findbugs\jsr305\3.0.2\jsr305-3.0.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\com\github\luben\zstd-jni\1.5.2-1\zstd-jni-1.5.2-1.jar;C:\work\apache-maven-3.8.8\repo\org\lz4\lz4-java\1.8.0\lz4-java-1.8.0.jar;C:\work\apache-maven-3.8.8\repo\org\xerial\snappy\snappy-java\1.1.8.4\snappy-java-1.1.8.4.jar;C:\work\apache-maven-3.8.8\repo\org\slf4j\slf4j-api\2.0.9\slf4j-api-2.0.9.jar;C:\work\apache-maven-3.8.8\repo\com\h2database\h2\1.4.200\h2-1.4.200.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-test\3.1.4\spring-boot-starter-test-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-test\3.1.4\spring-boot-test-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-test-autoconfigure\3.1.4\spring-boot-test-autoconfigure-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\jayway\jsonpath\json-path\2.8.0\json-path-2.8.0.jar;C:\work\apache-maven-3.8.8\repo\jakarta\xml\bind\jakarta.xml.bind-api\4.0.1\jakarta.xml.bind-api-4.0.1.jar;C:\work\apache-maven-3.8.8\repo\jakarta\activation\jakarta.activation-api\2.1.2\jakarta.activation-api-2.1.2.jar;C:\work\apache-maven-3.8.8\repo\net\minidev\json-smart\2.4.11\json-smart-2.4.11.jar;C:\work\apache-maven-3.8.8\repo\net\minidev\accessors-smart\2.4.11\accessors-smart-2.4.11.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm\9.3\asm-9.3.jar;C:\work\apache-maven-3.8.8\repo\org\assertj\assertj-core\3.24.2\assertj-core-3.24.2.jar;C:\work\apache-maven-3.8.8\repo\org\hamcrest\hamcrest\2.2\hamcrest-2.2.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter\5.9.3\junit-jupiter-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-params\5.9.3\junit-jupiter-params-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-engine\5.9.3\junit-jupiter-engine-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\mockito\mockito-core\5.3.1\mockito-core-5.3.1.jar;C:\work\apache-maven-3.8.8\repo\net\bytebuddy\byte-buddy-agent\1.14.8\byte-buddy-agent-1.14.8.jar;C:\work\apache-maven-3.8.8\repo\org\objenesis\objenesis\3.3\objenesis-3.3.jar;C:\work\apache-maven-3.8.8\repo\org\mockito\mockito-junit-jupiter\5.3.1\mockito-junit-jupiter-5.3.1.jar;C:\work\apache-maven-3.8.8\repo\org\skyscreamer\jsonassert\1.5.1\jsonassert-1.5.1.jar;C:\work\apache-maven-3.8.8\repo\com\vaadin\external\google\android-json\0.0.20131108.vaadin1\android-json-0.0.20131108.vaadin1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-core\6.0.12\spring-core-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-jcl\6.0.12\spring-jcl-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-test\6.0.12\spring-test-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\xmlunit\xmlunit-core\2.9.1\xmlunit-core-2.9.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy\4.0.15\groovy-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-ant\4.0.15\groovy-ant-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant\1.10.14\ant-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-junit\1.10.14\ant-junit-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-launcher\1.10.14\ant-launcher-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-antlr\1.10.14\ant-antlr-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-cli-picocli\4.0.15\groovy-cli-picocli-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\info\picocli\picocli\4.7.5\picocli-4.7.5.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-console\4.0.15\groovy-console-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\github\javaparser\javaparser-core\3.25.5\javaparser-core-3.25.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-util\9.5\asm-util-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-tree\9.5\asm-tree-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-analysis\9.5\asm-analysis-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\abego\treelayout\org.abego.treelayout.core\1.0.3\org.abego.treelayout.core-1.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ivy\ivy\2.5.2\ivy-2.5.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-datetime\4.0.15\groovy-datetime-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-docgenerator\4.0.15\groovy-docgenerator-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\thoughtworks\qdox\qdox\1.12.1\qdox-1.12.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-groovydoc\4.0.15\groovy-groovydoc-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-groovysh\4.0.15\groovy-groovysh-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\jline\jline\2.14.6\jline-2.14.6.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-jmx\4.0.15\groovy-jmx-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-json\4.0.15\groovy-json-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-jsr223\4.0.15\groovy-jsr223-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-macro\4.0.15\groovy-macro-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-nio\4.0.15\groovy-nio-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-servlet\4.0.15\groovy-servlet-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-sql\4.0.15\groovy-sql-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-swing\4.0.15\groovy-swing-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-templates\4.0.15\groovy-templates-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-test\4.0.15\groovy-test-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\junit\junit\4.13.2\junit-4.13.2.jar;C:\work\apache-maven-3.8.8\repo\org\hamcrest\hamcrest-core\2.2\hamcrest-core-2.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-test-junit5\4.0.15\groovy-test-junit5-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-xml\4.0.15\groovy-xml-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-yaml\4.0.15\groovy-yaml-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\dataformat\jackson-dataformat-yaml\2.15.2\jackson-dataformat-yaml-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\org\spockframework\spock-core\2.4-M1-groovy-4.0\spock-core-2.4-M1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-engine\1.9.3\junit-platform-engine-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\opentest4j\opentest4j\1.2.0\opentest4j-1.2.0.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-commons\1.9.3\junit-platform-commons-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\apiguardian\apiguardian-api\1.1.2\apiguardian-api-1.1.2.jar;C:\work\apache-maven-3.8.8\repo\org\spockframework\spock-spring\2.4-M1-groovy-4.0\spock-spring-2.4-M1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\com\athaydes\spock-reports\2.5.1-groovy-4.0\spock-reports-2.5.1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\com\github\codemonstur\embedded-redis\1.4.2\embedded-redis-1.4.2.jar;C:\work\apache-maven-3.8.8\repo\redis\clients\jedis\4.3.2\jedis-4.3.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\commons\commons-pool2\2.11.1\commons-pool2-2.11.1.jar;C:\work\apache-maven-3.8.8\repo\org\json\json\20220320\json-20220320.jar;C:\work\apache-maven-3.8.8\repo\com\google\code\gson\gson\2.10.1\gson-2.10.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\kafka\spring-kafka-test\3.0.11\spring-kafka-test-3.0.11.jar;C:\work\apache-maven-3.8.8\repo\org\apache\zookeeper\zookeeper\3.6.3\zookeeper-3.6.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\zookeeper\zookeeper-jute\3.6.3\zookeeper-jute-3.6.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-classes-epoll\4.1.97.Final\netty-transport-classes-epoll-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1-test.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-metadata\3.4.1\kafka-metadata-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-server-common\3.4.1\kafka-server-common-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-raft\3.4.1\kafka-raft-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-streams-test-utils\3.4.1\kafka-streams-test-utils-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-streams\3.4.1\kafka-streams-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\rocksdb\rocksdbjni\7.1.2\rocksdbjni-7.1.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\scala-library\2.13.10\scala-library-2.13.10.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-group-coordinator\3.4.1\kafka-group-coordinator-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-storage\3.4.1\kafka-storage-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-storage-api\3.4.1\kafka-storage-api-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\net\sourceforge\argparse4j\argparse4j\0.7.0\argparse4j-0.7.0.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\module\jackson-module-scala_2.13\2.15.2\jackson-module-scala_2.13-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\thoughtworks\paranamer\paranamer\2.8\paranamer-2.8.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\dataformat\jackson-dataformat-csv\2.15.2\jackson-dataformat-csv-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\net\sf\jopt-simple\jopt-simple\5.0.4\jopt-simple-5.0.4.jar;C:\work\apache-maven-3.8.8\repo\org\bitbucket\b_c\jose4j\0.9.3\jose4j-0.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\modules\scala-collection-compat_2.13\2.10.0\scala-collection-compat_2.13-2.10.0.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\modules\scala-java8-compat_2.13\1.0.2\scala-java8-compat_2.13-1.0.2.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\scala-reflect\2.13.10\scala-reflect-2.13.10.jar;C:\work\apache-maven-3.8.8\repo\com\typesafe\scala-logging\scala-logging_2.13\3.9.4\scala-logging_2.13-3.9.4.jar;C:\work\apache-maven-3.8.8\repo\io\dropwizard\metrics\metrics-core\4.2.19\metrics-core-4.2.19.jar;C:\work\apache-maven-3.8.8\repo\commons-cli\commons-cli\1.4\commons-cli-1.4.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1-test.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-api\5.9.3\junit-jupiter-api-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-launcher\1.9.3\junit-platform-launcher-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\awaitility\awaitility\4.2.0\awaitility-4.2.0.jar;
2024-12-31 21:07:10.374 Client environment:java.library.path=C:\work\jdk-17\bin;C:\windows\Sun\Java\bin;C:\windows\system32;C:\windows;C:\work\python312\Scripts\;C:\work\python312\;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program\Git\cmd;C:\Program\PowerShell\7\;C:\Program Files\dotnet\;C:\Users\joech\AppData\Local\Microsoft\WindowsApps;C:\Users\joech\AppData\Local\GitHubDesktop\bin;C:\Program\Microsoft VS Code\bin;C:\work\apache-maven-3.8.8\bin;C:\Program Files\Tesseract-OCR;C:\work\jdk-17\bin;;.
2024-12-31 21:07:10.375 Client environment:java.io.tmpdir=C:\Users\joech\AppData\Local\Temp\
2024-12-31 21:07:10.375 Client environment:java.compiler=<NA>
2024-12-31 21:07:10.375 Client environment:os.name=Windows 11
2024-12-31 21:07:10.375 Client environment:os.arch=amd64
2024-12-31 21:07:10.375 Client environment:os.version=10.0
2024-12-31 21:07:10.375 Client environment:user.name=joech
2024-12-31 21:07:10.375 Client environment:user.home=C:\Users\joech
2024-12-31 21:07:10.375 Client environment:user.dir=C:\code\hsbc\demo\pong
2024-12-31 21:07:10.375 Client environment:os.memory.free=85MB
2024-12-31 21:07:10.375 Client environment:os.memory.max=15816MB
2024-12-31 21:07:10.375 Client environment:os.memory.total=136MB
2024-12-31 21:07:10.381 Initiating client connection, connectString=127.0.0.1:59460 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@3bc2146c
2024-12-31 21:07:10.389 jute.maxbuffer value is 4194304 Bytes
2024-12-31 21:07:10.397 zookeeper.request.timeout value is 0. feature enabled=false
2024-12-31 21:07:10.399 Opening socket connection to server /127.0.0.1:59460.
2024-12-31 21:07:10.399 [ZooKeeperClient Kafka server] Waiting until connected.
2024-12-31 21:07:10.401 Socket connection established, initiating session, client: /127.0.0.1:59461, server: /127.0.0.1:59460
2024-12-31 21:07:10.411 Creating new log file: log.1
2024-12-31 21:07:10.425 ZooKeeper audit is disabled.
2024-12-31 21:07:10.430 Session establishment complete on server /127.0.0.1:59460, session id = 0x100176ecb260000, negotiated timeout = 16000
2024-12-31 21:07:10.435 [ZooKeeperClient Kafka server] Connected.
2024-12-31 21:07:10.909 Cluster ID = gfbNscIMSSOPylMaJwslLg
2024-12-31 21:07:10.916 No meta.properties file under dir C:\Users\joech\AppData\Local\Temp\spring.kafka.23fe1155-4ed9-4f7a-a6c4-37bce40c42959321802500161184416\meta.properties
2024-12-31 21:07:10.978 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.23fe1155-4ed9-4f7a-a6c4-37bce40c42959321802500161184416
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59460
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:07:11.021 [ThrottledChannelReaper-Fetch]: Starting
2024-12-31 21:07:11.021 [ThrottledChannelReaper-Produce]: Starting
2024-12-31 21:07:11.022 [ThrottledChannelReaper-Request]: Starting
2024-12-31 21:07:11.027 [ThrottledChannelReaper-ControllerMutation]: Starting
2024-12-31 21:07:11.074 Loading logs from log dirs ArraySeq(C:\Users\joech\AppData\Local\Temp\spring.kafka.23fe1155-4ed9-4f7a-a6c4-37bce40c42959321802500161184416)
2024-12-31 21:07:11.079 Attempting recovery for all logs in C:\Users\joech\AppData\Local\Temp\spring.kafka.23fe1155-4ed9-4f7a-a6c4-37bce40c42959321802500161184416 since no clean shutdown file was found
2024-12-31 21:07:11.091 Loaded 0 logs in 16ms.
2024-12-31 21:07:11.091 Starting log cleanup with a period of 300000 ms.
2024-12-31 21:07:11.095 Starting log flusher with a default period of 9223372036854775807 ms.
2024-12-31 21:07:11.112 Starting the log cleaner
2024-12-31 21:07:11.126 [kafka-log-cleaner-thread-0]: Starting
2024-12-31 21:07:11.146 [feature-zk-node-event-process-thread]: Starting
2024-12-31 21:07:11.163 Feature ZK node at path: /feature does not exist
2024-12-31 21:07:11.205 [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting
2024-12-31 21:07:11.726 Updated connection-accept-rate max connection creation rate to 2147483647
2024-12-31 21:07:11.738 Awaiting socket connections on localhost:59462.
2024-12-31 21:07:11.795 [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT)
2024-12-31 21:07:11.807 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Starting
2024-12-31 21:07:11.838 [ExpirationReaper-0-Produce]: Starting
2024-12-31 21:07:11.839 [ExpirationReaper-0-Fetch]: Starting
2024-12-31 21:07:11.840 [ExpirationReaper-0-DeleteRecords]: Starting
2024-12-31 21:07:11.842 [ExpirationReaper-0-ElectLeader]: Starting
2024-12-31 21:07:11.870 [LogDirFailureHandler]: Starting
2024-12-31 21:07:11.903 Creating /brokers/ids/0 (is it secure? false)
2024-12-31 21:07:11.934 Stat of the created znode at /brokers/ids/0 is: 25,25,1735650431921,1735650431921,1,0,0,72083358660034560,204,0,25

2024-12-31 21:07:11.935 Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:59462, czxid (broker epoch): 25
2024-12-31 21:07:12.032 [ControllerEventThread controllerId=0] Starting
2024-12-31 21:07:12.039 [ExpirationReaper-0-topic]: Starting
2024-12-31 21:07:12.049 [ExpirationReaper-0-Heartbeat]: Starting
2024-12-31 21:07:12.050 [ExpirationReaper-0-Rebalance]: Starting
2024-12-31 21:07:12.061 Successfully created /controller_epoch with initial epoch 0
2024-12-31 21:07:12.070 [Controller id=0] 0 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1
2024-12-31 21:07:12.075 [Controller id=0] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map())
2024-12-31 21:07:12.080 Feature ZK node created at path: /feature
2024-12-31 21:07:12.081 [GroupCoordinator 0]: Starting up.
2024-12-31 21:07:12.088 [GroupCoordinator 0]: Startup complete.
2024-12-31 21:07:12.120 [TransactionCoordinator id=0] Starting up.
2024-12-31 21:07:12.125 [Transaction Marker Channel Manager 0]: Starting
2024-12-31 21:07:12.125 [TransactionCoordinator id=0] Startup complete.
2024-12-31 21:07:12.132 [Controller id=0] Registering handlers
2024-12-31 21:07:12.132 [MetadataCache brokerId=0] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0).
2024-12-31 21:07:12.137 [Controller id=0] Deleting log dir event notifications
2024-12-31 21:07:12.139 [Controller id=0] Deleting isr change notifications
2024-12-31 21:07:12.141 [Controller id=0] Initializing controller context
2024-12-31 21:07:12.167 [Controller id=0] Initialized broker epochs cache: HashMap(0 -> 25)
2024-12-31 21:07:12.177 [ExpirationReaper-0-AlterAcls]: Starting
2024-12-31 21:07:12.192 [RequestSendThread controllerId=0] Starting
2024-12-31 21:07:12.195 [Controller id=0] Currently active brokers in the cluster: Set(0)
2024-12-31 21:07:12.196 [Controller id=0] Currently shutting brokers in the cluster: HashSet()
2024-12-31 21:07:12.196 [Controller id=0] Current list of topics in the cluster: HashSet()
2024-12-31 21:07:12.197 [Controller id=0] Fetching topic deletions in progress
2024-12-31 21:07:12.200 [Controller id=0] List of topics to be deleted: 
2024-12-31 21:07:12.201 [Controller id=0] List of topics ineligible for deletion: 
2024-12-31 21:07:12.201 [Controller id=0] Initializing topic deletion manager
2024-12-31 21:07:12.201 [Topic Deletion Manager 0] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet()
2024-12-31 21:07:12.205 [Controller id=0] Sending update metadata request
2024-12-31 21:07:12.209 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions
2024-12-31 21:07:12.227 [ReplicaStateMachine controllerId=0] Initializing replica state
2024-12-31 21:07:12.228 [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2024-12-31 21:07:12.230 [/config/changes-event-process-thread]: Starting
2024-12-31 21:07:12.237 [ReplicaStateMachine controllerId=0] Triggering offline replica state changes
2024-12-31 21:07:12.238 [PartitionStateMachine controllerId=0] Initializing partition state
2024-12-31 21:07:12.238 [PartitionStateMachine controllerId=0] Triggering online partition state changes
2024-12-31 21:07:12.240 [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing.
2024-12-31 21:07:12.241 [RequestSendThread controllerId=0] Controller 0 connected to localhost:59462 (id: 0 rack: null) for sending state change requests
2024-12-31 21:07:12.244 [Controller id=0] Ready to serve as the new controller with epoch 1
2024-12-31 21:07:12.252 Kafka version: 3.4.1
2024-12-31 21:07:12.252 Kafka commitId: 8a516edc2755df89
2024-12-31 21:07:12.252 Kafka startTimeMs: 1735650432248
2024-12-31 21:07:12.253 [Controller id=0] Partitions undergoing preferred replica election: 
2024-12-31 21:07:12.253 [KafkaServer id=0] started
2024-12-31 21:07:12.255 [Controller id=0] Partitions that completed preferred replica election: 
2024-12-31 21:07:12.255 [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2024-12-31 21:07:12.255 [Controller id=0] Resuming preferred replica election for partitions: 
2024-12-31 21:07:12.256 [Controller id=0] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered
2024-12-31 21:07:12.261 AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [127.0.0.1:59462]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-31 21:07:12.271 [Controller id=0] Starting the controller scheduler
2024-12-31 21:07:12.312 Kafka version: 3.4.1
2024-12-31 21:07:12.312 Kafka commitId: 8a516edc2755df89
2024-12-31 21:07:12.312 Kafka startTimeMs: 1735650432312
2024-12-31 21:07:12.326 [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use node localhost:59462 (id: 0 rack: null)
2024-12-31 21:07:12.411 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Recorded new controller, from now on will use node localhost:59462 (id: 0 rack: null)
2024-12-31 21:07:12.439 Creating topic pong-message-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0))
2024-12-31 21:07:12.464 [Controller id=0] New topics: [Set(pong-message-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(pong-message-topic,Some(ChsiiFwASJytTqkQxwy8jg),Map(pong-message-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), pong-message-topic-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:07:12.466 [Controller id=0] New partition creation callback for pong-message-topic-0,pong-message-topic-1
2024-12-31 21:07:12.469 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:07:12.470 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:07:12.470 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:07:12.475 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:07:12.503 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:07:12.503 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:07:12.505 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2024-12-31 21:07:12.507 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2024-12-31 21:07:12.509 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:07:12.515 [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 for 2 partitions
2024-12-31 21:07:12.557 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(pong-message-topic-0, pong-message-topic-1)
2024-12-31 21:07:12.558 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2024-12-31 21:07:12.646 [LogLoader partition=pong-message-topic-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.23fe1155-4ed9-4f7a-a6c4-37bce40c42959321802500161184416] Loading producer state till offset 0 with message format version 2
2024-12-31 21:07:12.664 Created log for partition pong-message-topic-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.23fe1155-4ed9-4f7a-a6c4-37bce40c42959321802500161184416\pong-message-topic-0 with properties {}
2024-12-31 21:07:12.665 [Partition pong-message-topic-0 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-0
2024-12-31 21:07:12.666 [Partition pong-message-topic-0 broker=0] Log loaded for partition pong-message-topic-0 with initial high watermark 0
2024-12-31 21:07:12.667 [Broker id=0] Leader pong-message-topic-0 with topic id Some(ChsiiFwASJytTqkQxwy8jg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:07:12.682 [LogLoader partition=pong-message-topic-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.23fe1155-4ed9-4f7a-a6c4-37bce40c42959321802500161184416] Loading producer state till offset 0 with message format version 2
2024-12-31 21:07:12.683 Created log for partition pong-message-topic-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.23fe1155-4ed9-4f7a-a6c4-37bce40c42959321802500161184416\pong-message-topic-1 with properties {}
2024-12-31 21:07:12.684 [Partition pong-message-topic-1 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-1
2024-12-31 21:07:12.684 [Partition pong-message-topic-1 broker=0] Log loaded for partition pong-message-topic-1 with initial high watermark 0
2024-12-31 21:07:12.684 [Broker id=0] Leader pong-message-topic-1 with topic id Some(ChsiiFwASJytTqkQxwy8jg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:07:12.692 [Broker id=0] Finished LeaderAndIsr request in 180ms correlationId 1 from controller 0 for 2 partitions
2024-12-31 21:07:12.700 [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2
2024-12-31 21:07:12.706 App info kafka.admin.client for adminclient-1 unregistered
2024-12-31 21:07:12.709 Metrics scheduler closed
2024-12-31 21:07:12.709 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:07:12.709 Metrics reporters closed
2024-12-31 21:07:13.082 

Found multiple occurrences of org.json.JSONObject on the class path:

	jar:file:/C:/work/apache-maven-3.8.8/repo/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar!/org/json/JSONObject.class
	jar:file:/C:/work/apache-maven-3.8.8/repo/org/json/json/20220320/json-20220320.jar!/org/json/JSONObject.class

You may wish to exclude one of them to ensure predictable runtime behavior

2024-12-31 21:07:13.105 zookeeper.snapshot.trust.empty : false
2024-12-31 21:07:13.107 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:07:13.107 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:07:13.107 zookeeper.snapshotSizeFactor = 0.33
2024-12-31 21:07:13.107 zookeeper.commitLogCount=500
2024-12-31 21:07:13.107 minSessionTimeout set to 1600
2024-12-31 21:07:13.107 maxSessionTimeout set to 16000
2024-12-31 21:07:13.107 Response cache size is initialized with value 400.
2024-12-31 21:07:13.107 Response cache size is initialized with value 400.
2024-12-31 21:07:13.107 zookeeper.pathStats.slotCapacity = 60
2024-12-31 21:07:13.107 zookeeper.pathStats.slotDuration = 15
2024-12-31 21:07:13.107 zookeeper.pathStats.maxDepth = 6
2024-12-31 21:07:13.107 zookeeper.pathStats.initialDelay = 5
2024-12-31 21:07:13.107 zookeeper.pathStats.delay = 5
2024-12-31 21:07:13.107 zookeeper.pathStats.enabled = false
2024-12-31 21:07:13.108 The max bytes for all large requests are set to 104857600
2024-12-31 21:07:13.108 The large request threshold is set to -1
2024-12-31 21:07:13.108 Created server with tickTime 800 minSessionTimeout 1600 maxSessionTimeout 16000 clientPortListenBacklog -1 datadir C:\Users\joech\AppData\Local\Temp\kafka-6165839194754601384\version-2 snapdir C:\Users\joech\AppData\Local\Temp\kafka-3013505205506138482\version-2
2024-12-31 21:07:13.108 maxCnxns is not configured, using default value 0.
2024-12-31 21:07:13.108 Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers.
2024-12-31 21:07:13.112 binding to port /127.0.0.1:0
2024-12-31 21:07:13.114 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-3013505205506138482\version-2\snapshot.0
2024-12-31 21:07:13.115 Snapshot loaded in 2 ms, highest zxid is 0x0, digest is 1371985504
2024-12-31 21:07:13.115 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-3013505205506138482\version-2\snapshot.0
2024-12-31 21:07:13.116 Snapshot taken in 1 ms
2024-12-31 21:07:13.117 PrepRequestProcessor (sid:0) started, reconfigEnabled=false
2024-12-31 21:07:13.120 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.c756c72b-5d82-4b74-8b6d-f801a5cb7cb39768400266859306237
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59466
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:07:13.124 starting
2024-12-31 21:07:13.124 Connecting to zookeeper on 127.0.0.1:59466
2024-12-31 21:07:13.125 [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:59466.
2024-12-31 21:07:13.125 Initiating client connection, connectString=127.0.0.1:59466 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2889a7ae
2024-12-31 21:07:13.127 jute.maxbuffer value is 4194304 Bytes
2024-12-31 21:07:13.128 zookeeper.request.timeout value is 0. feature enabled=false
2024-12-31 21:07:13.128 [ZooKeeperClient Kafka server] Waiting until connected.
2024-12-31 21:07:13.128 Opening socket connection to server /127.0.0.1:59466.
2024-12-31 21:07:13.129 Socket connection established, initiating session, client: /127.0.0.1:59467, server: /127.0.0.1:59466
2024-12-31 21:07:13.130 Creating new log file: log.1
2024-12-31 21:07:13.137 Session establishment complete on server /127.0.0.1:59466, session id = 0x100176eed1c0000, negotiated timeout = 16000
2024-12-31 21:07:13.138 [ZooKeeperClient Kafka server] Connected.
2024-12-31 21:07:13.171 Cluster ID = jr-5LRATTXKFxQ3XwVClgw
2024-12-31 21:07:13.171 No meta.properties file under dir C:\Users\joech\AppData\Local\Temp\spring.kafka.c756c72b-5d82-4b74-8b6d-f801a5cb7cb39768400266859306237\meta.properties
2024-12-31 21:07:13.183 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.c756c72b-5d82-4b74-8b6d-f801a5cb7cb39768400266859306237
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59466
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:07:13.195 [ThrottledChannelReaper-Fetch]: Starting
2024-12-31 21:07:13.195 [ThrottledChannelReaper-Produce]: Starting
2024-12-31 21:07:13.195 [ThrottledChannelReaper-Request]: Starting
2024-12-31 21:07:13.195 [ThrottledChannelReaper-ControllerMutation]: Starting
2024-12-31 21:07:13.205 Loading logs from log dirs ArraySeq(C:\Users\joech\AppData\Local\Temp\spring.kafka.c756c72b-5d82-4b74-8b6d-f801a5cb7cb39768400266859306237)
2024-12-31 21:07:13.207 Attempting recovery for all logs in C:\Users\joech\AppData\Local\Temp\spring.kafka.c756c72b-5d82-4b74-8b6d-f801a5cb7cb39768400266859306237 since no clean shutdown file was found
2024-12-31 21:07:13.208 Loaded 0 logs in 2ms.
2024-12-31 21:07:13.208 Starting log cleanup with a period of 300000 ms.
2024-12-31 21:07:13.208 Starting log flusher with a default period of 9223372036854775807 ms.
2024-12-31 21:07:13.210 Starting the log cleaner
2024-12-31 21:07:13.211 [kafka-log-cleaner-thread-0]: Starting
2024-12-31 21:07:13.213 [feature-zk-node-event-process-thread]: Starting
2024-12-31 21:07:13.214 Feature ZK node at path: /feature does not exist
2024-12-31 21:07:13.217 [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting
2024-12-31 21:07:13.236 Updated connection-accept-rate max connection creation rate to 2147483647
2024-12-31 21:07:13.239 Awaiting socket connections on localhost:59468.
2024-12-31 21:07:13.250 [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT)
2024-12-31 21:07:13.253 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Starting
2024-12-31 21:07:13.254 [ExpirationReaper-0-Produce]: Starting
2024-12-31 21:07:13.256 [ExpirationReaper-0-Fetch]: Starting
2024-12-31 21:07:13.256 [ExpirationReaper-0-DeleteRecords]: Starting
2024-12-31 21:07:13.257 [ExpirationReaper-0-ElectLeader]: Starting
2024-12-31 21:07:13.258 [LogDirFailureHandler]: Starting
2024-12-31 21:07:13.263 Creating /brokers/ids/0 (is it secure? false)
2024-12-31 21:07:13.265 Stat of the created znode at /brokers/ids/0 is: 25,25,1735650433264,1735650433264,1,0,0,72083359229804544,204,0,25

2024-12-31 21:07:13.265 Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:59468, czxid (broker epoch): 25
2024-12-31 21:07:13.274 [ControllerEventThread controllerId=0] Starting
2024-12-31 21:07:13.274 [ExpirationReaper-0-topic]: Starting
2024-12-31 21:07:13.275 [ExpirationReaper-0-Heartbeat]: Starting
2024-12-31 21:07:13.275 [ExpirationReaper-0-Rebalance]: Starting
2024-12-31 21:07:13.276 [GroupCoordinator 0]: Starting up.
2024-12-31 21:07:13.277 [GroupCoordinator 0]: Startup complete.
2024-12-31 21:07:13.277 Successfully created /controller_epoch with initial epoch 0
2024-12-31 21:07:13.280 [TransactionCoordinator id=0] Starting up.
2024-12-31 21:07:13.280 [Controller id=0] 0 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1
2024-12-31 21:07:13.280 [Controller id=0] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map())
2024-12-31 21:07:13.280 [TransactionCoordinator id=0] Startup complete.
2024-12-31 21:07:13.281 [Transaction Marker Channel Manager 0]: Starting
2024-12-31 21:07:13.282 Feature ZK node created at path: /feature
2024-12-31 21:07:13.283 [ExpirationReaper-0-AlterAcls]: Starting
2024-12-31 21:07:13.283 [MetadataCache brokerId=0] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0).
2024-12-31 21:07:13.283 [Controller id=0] Registering handlers
2024-12-31 21:07:13.285 [Controller id=0] Deleting log dir event notifications
2024-12-31 21:07:13.285 [/config/changes-event-process-thread]: Starting
2024-12-31 21:07:13.285 [Controller id=0] Deleting isr change notifications
2024-12-31 21:07:13.287 [Controller id=0] Initializing controller context
2024-12-31 21:07:13.288 [Controller id=0] Initialized broker epochs cache: HashMap(0 -> 25)
2024-12-31 21:07:13.290 [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing.
2024-12-31 21:07:13.290 Kafka version: 3.4.1
2024-12-31 21:07:13.290 Kafka commitId: 8a516edc2755df89
2024-12-31 21:07:13.291 Kafka startTimeMs: 1735650433290
2024-12-31 21:07:13.295 [Controller id=0] Currently active brokers in the cluster: Set(0)
2024-12-31 21:07:13.295 [RequestSendThread controllerId=0] Starting
2024-12-31 21:07:13.295 [Controller id=0] Currently shutting brokers in the cluster: HashSet()
2024-12-31 21:07:13.295 [Controller id=0] Current list of topics in the cluster: HashSet()
2024-12-31 21:07:13.295 [Controller id=0] Fetching topic deletions in progress
2024-12-31 21:07:13.291 Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.server:type=app-info,id=0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1865)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:960)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:895)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:523)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:563)
	at kafka.utils.TestUtils$.createServer(TestUtils.scala:188)
	at kafka.utils.TestUtils$.createServer(TestUtils.scala:182)
	at kafka.utils.TestUtils.createServer(TestUtils.scala)
	at org.springframework.kafka.test.EmbeddedKafkaBroker.afterPropertiesSet(EmbeddedKafkaBroker.java:369)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1817)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1766)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:410)
	at org.springframework.kafka.test.context.EmbeddedKafkaContextCustomizer.customizeContext(EmbeddedKafkaContextCustomizer.java:116)
	at org.springframework.boot.test.context.SpringBootContextLoader$ContextCustomizerAdapter.initialize(SpringBootContextLoader.java:435)
	at org.springframework.boot.SpringApplication.applyInitializers(SpringApplication.java:610)
	at org.springframework.boot.SpringApplication.prepareContext(SpringApplication.java:390)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:314)
	at org.springframework.boot.test.context.SpringBootContextLoader.lambda$loadContext$3(SpringBootContextLoader.java:137)
	at org.springframework.util.function.ThrowingSupplier.get(ThrowingSupplier.java:58)
	at org.springframework.util.function.ThrowingSupplier.get(ThrowingSupplier.java:46)
	at org.springframework.boot.SpringApplication.withHook(SpringApplication.java:1409)
	at org.springframework.boot.test.context.SpringBootContextLoader$ContextLoaderHook.run(SpringBootContextLoader.java:545)
	at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:137)
	at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:108)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:187)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:119)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:127)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:141)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:97)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:241)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:56)
	at org.spockframework.spring.SpringInterceptor.interceptInitializerMethod(SpringInterceptor.java:46)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:24)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:101)
	at org.spockframework.runtime.PlatformSpecRunner.invoke(PlatformSpecRunner.java:398)
	at org.spockframework.runtime.PlatformSpecRunner.runInitializer(PlatformSpecRunner.java:259)
	at org.spockframework.runtime.PlatformSpecRunner.runInitializer(PlatformSpecRunner.java:254)
	at org.spockframework.runtime.IterationNode.prepare(IterationNode.java:31)
	at org.spockframework.runtime.IterationNode.prepare(IterationNode.java:13)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$prepare$2(NodeTestTask.java:123)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.prepare(NodeTestTask.java:123)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:90)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:226)
	at org.spockframework.runtime.ParameterizedFeatureChildExecutor.execute(ParameterizedFeatureChildExecutor.java:104)
	at org.spockframework.runtime.PlatformParameterizedSpecRunner$1.runIteration(PlatformParameterizedSpecRunner.java:72)
	at org.spockframework.runtime.extension.IDataDriver.lambda$static$0(IDataDriver.java:37)
	at org.spockframework.runtime.PlatformParameterizedSpecRunner.runParameterizedFeature(PlatformParameterizedSpecRunner.java:47)
	at org.spockframework.runtime.ParameterizedFeatureNode.execute(ParameterizedFeatureNode.java:40)
	at org.spockframework.runtime.ParameterizedFeatureNode.execute(ParameterizedFeatureNode.java:16)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.spockframework.runtime.SpockNode.sneakyInvoke(SpockNode.java:40)
	at org.spockframework.runtime.FeatureNode.lambda$around$0(FeatureNode.java:41)
	at org.spockframework.runtime.PlatformSpecRunner.lambda$createMethodInfoForDoRunFeature$4(PlatformSpecRunner.java:199)
	at org.spockframework.runtime.model.MethodInfo.invoke(MethodInfo.java:156)
	at org.spockframework.runtime.PlatformSpecRunner.invokeRaw(PlatformSpecRunner.java:407)
	at org.spockframework.runtime.PlatformSpecRunner.invoke(PlatformSpecRunner.java:390)
	at org.spockframework.runtime.PlatformSpecRunner.runFeature(PlatformSpecRunner.java:192)
	at org.spockframework.runtime.FeatureNode.around(FeatureNode.java:41)
	at org.spockframework.runtime.FeatureNode.around(FeatureNode.java:12)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1511)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.spockframework.runtime.SpockNode.sneakyInvoke(SpockNode.java:40)
	at org.spockframework.runtime.SpecNode.lambda$around$0(SpecNode.java:63)
	at org.spockframework.runtime.PlatformSpecRunner.lambda$createMethodInfoForDoRunSpec$0(PlatformSpecRunner.java:61)
	at org.spockframework.runtime.model.MethodInfo.invoke(MethodInfo.java:156)
	at org.spockframework.runtime.PlatformSpecRunner.invokeRaw(PlatformSpecRunner.java:407)
	at org.spockframework.runtime.PlatformSpecRunner.invoke(PlatformSpecRunner.java:390)
	at org.spockframework.runtime.PlatformSpecRunner.runSpec(PlatformSpecRunner.java:55)
	at org.spockframework.runtime.SpecNode.around(SpecNode.java:63)
	at org.spockframework.runtime.SpecNode.around(SpecNode.java:11)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1511)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:147)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:127)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:90)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:55)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:102)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:150)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2024-12-31 21:07:13.296 [KafkaServer id=0] started
2024-12-31 21:07:13.296 [Controller id=0] List of topics to be deleted: 
2024-12-31 21:07:13.296 [Controller id=0] List of topics ineligible for deletion: 
2024-12-31 21:07:13.296 [Controller id=0] Initializing topic deletion manager
2024-12-31 21:07:13.296 [Topic Deletion Manager 0] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet()
2024-12-31 21:07:13.296 [Controller id=0] Sending update metadata request
2024-12-31 21:07:13.296 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions
2024-12-31 21:07:13.296 AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [127.0.0.1:59468]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-31 21:07:13.297 [ReplicaStateMachine controllerId=0] Initializing replica state
2024-12-31 21:07:13.297 [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2024-12-31 21:07:13.297 [ReplicaStateMachine controllerId=0] Triggering offline replica state changes
2024-12-31 21:07:13.297 [PartitionStateMachine controllerId=0] Initializing partition state
2024-12-31 21:07:13.297 [PartitionStateMachine controllerId=0] Triggering online partition state changes
2024-12-31 21:07:13.297 [Controller id=0] Ready to serve as the new controller with epoch 1
2024-12-31 21:07:13.297 [RequestSendThread controllerId=0] Controller 0 connected to localhost:59468 (id: 0 rack: null) for sending state change requests
2024-12-31 21:07:13.299 [Controller id=0] Partitions undergoing preferred replica election: 
2024-12-31 21:07:13.299 [Controller id=0] Partitions that completed preferred replica election: 
2024-12-31 21:07:13.299 [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2024-12-31 21:07:13.299 [Controller id=0] Resuming preferred replica election for partitions: 
2024-12-31 21:07:13.299 [Controller id=0] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered
2024-12-31 21:07:13.299 Kafka version: 3.4.1
2024-12-31 21:07:13.299 Kafka commitId: 8a516edc2755df89
2024-12-31 21:07:13.299 Kafka startTimeMs: 1735650433299
2024-12-31 21:07:13.301 [Controller id=0] Starting the controller scheduler
2024-12-31 21:07:13.313 Creating topic pong-message-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2024-12-31 21:07:13.318 [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use node localhost:59468 (id: 0 rack: null)
2024-12-31 21:07:13.320 [Controller id=0] New topics: [Set(pong-message-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(pong-message-topic,Some(lx9kWgf_R2CiJxOhxd1BVA),Map(pong-message-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:07:13.320 [Controller id=0] New partition creation callback for pong-message-topic-0
2024-12-31 21:07:13.321 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:07:13.321 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:07:13.321 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:07:13.324 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:07:13.324 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions
2024-12-31 21:07:13.326 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 1 partitions
2024-12-31 21:07:13.326 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:07:13.326 [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 for 1 partitions
2024-12-31 21:07:13.327 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(pong-message-topic-0)
2024-12-31 21:07:13.327 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions
2024-12-31 21:07:13.338 [LogLoader partition=pong-message-topic-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.c756c72b-5d82-4b74-8b6d-f801a5cb7cb39768400266859306237] Loading producer state till offset 0 with message format version 2
2024-12-31 21:07:13.338 Created log for partition pong-message-topic-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.c756c72b-5d82-4b74-8b6d-f801a5cb7cb39768400266859306237\pong-message-topic-0 with properties {}
2024-12-31 21:07:13.339 [Partition pong-message-topic-0 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-0
2024-12-31 21:07:13.339 [Partition pong-message-topic-0 broker=0] Log loaded for partition pong-message-topic-0 with initial high watermark 0
2024-12-31 21:07:13.339 [Broker id=0] Leader pong-message-topic-0 with topic id Some(lx9kWgf_R2CiJxOhxd1BVA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:07:13.341 [Broker id=0] Finished LeaderAndIsr request in 15ms correlationId 1 from controller 0 for 1 partitions
2024-12-31 21:07:13.344 [Broker id=0] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2
2024-12-31 21:07:13.346 App info kafka.admin.client for adminclient-2 unregistered
2024-12-31 21:07:13.347 Metrics scheduler closed
2024-12-31 21:07:13.347 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:07:13.347 Metrics reporters closed
2024-12-31 21:07:13.354 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Recorded new controller, from now on will use node localhost:59468 (id: 0 rack: null)
2024-12-31 21:07:13.359 Starting PongControllerSpec using Java 17.0.12 with PID 27352 (started by joech in C:\code\hsbc\demo\pong)
2024-12-31 21:07:13.359 No active profile set, falling back to 1 default profile: "default"
2024-12-31 21:07:13.986 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:07:13.990 Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2024-12-31 21:07:14.138 Finished Spring Data repository scanning in 138 ms. Found 1 JPA repository interfaces.
2024-12-31 21:07:14.162 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:07:14.164 Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2024-12-31 21:07:14.184 Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.demo.dao.MessageRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2024-12-31 21:07:14.184 Finished Spring Data repository scanning in 6 ms. Found 0 Redis repository interfaces.
2024-12-31 21:07:14.920 HHH000204: Processing PersistenceUnitInfo [name: default]
2024-12-31 21:07:15.001 HHH000412: Hibernate ORM core version 6.2.9.Final
2024-12-31 21:07:15.005 HHH000406: Using bytecode reflection optimizer
2024-12-31 21:07:15.193 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:07:15.386 No LoadTimeWeaver setup: ignoring JPA class transformer
2024-12-31 21:07:15.415 HikariPool-1 - Starting...
2024-12-31 21:07:15.731 HikariPool-1 - Added connection conn0: url=jdbc:h2:mem:testdb user=SA
2024-12-31 21:07:15.735 HikariPool-1 - Start completed.
2024-12-31 21:07:16.077 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:07:16.747 HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2024-12-31 21:07:16.860 Initialized JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:07:17.274 [Controller id=0] Processing automatic preferred replica leader election
2024-12-31 21:07:18.301 [Controller id=0] Processing automatic preferred replica leader election
2024-12-31 21:07:18.400 Netty started on port 59472
2024-12-31 21:07:18.429 ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:59462]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-pong-service-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = pong-service
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2024-12-31 21:07:18.471 These configurations '[spring.json.trusted.packages]' were supplied but are not used yet.
2024-12-31 21:07:18.471 Kafka version: 3.4.1
2024-12-31 21:07:18.471 Kafka commitId: 8a516edc2755df89
2024-12-31 21:07:18.471 Kafka startTimeMs: 1735650438471
2024-12-31 21:07:18.472 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Subscribed to topic(s): pong-message-topic
2024-12-31 21:07:18.490 Started PongControllerSpec in 5.705 seconds (process running for 22.571)
2024-12-31 21:07:18.498 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting the last seen epoch of partition pong-message-topic-0 to 0 since the associated topicId changed from null to ChsiiFwASJytTqkQxwy8jg
2024-12-31 21:07:18.499 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting the last seen epoch of partition pong-message-topic-1 to 0 since the associated topicId changed from null to ChsiiFwASJytTqkQxwy8jg
2024-12-31 21:07:18.501 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Cluster ID: gfbNscIMSSOPylMaJwslLg
2024-12-31 21:07:18.502 Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0))
2024-12-31 21:07:18.508 [Controller id=0] New topics: [Set(__consumer_offsets)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(__consumer_offsets,Some(J5VEeosLRbevbzMEmMLmZA),HashMap(__consumer_offsets-4 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-3 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-2 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:07:18.508 [Controller id=0] New partition creation callback for __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2024-12-31 21:07:18.508 [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:07:18.508 [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:07:18.508 [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:07:18.509 [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:07:18.509 [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:07:18.509 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:07:18.509 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:07:18.518 [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:07:18.518 [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:07:18.518 [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:07:18.518 [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:07:18.518 [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:07:18.518 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 5 become-leader and 0 become-follower partitions
2024-12-31 21:07:18.518 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 5 partitions
2024-12-31 21:07:18.519 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:07:18.519 [Broker id=0] Handling LeaderAndIsr request correlationId 3 from controller 0 for 5 partitions
2024-12-31 21:07:18.521 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-4, __consumer_offsets-3, __consumer_offsets-2, __consumer_offsets-0, __consumer_offsets-1)
2024-12-31 21:07:18.521 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 3 from controller 0 epoch 1 as part of the become-leader transition for 5 partitions
2024-12-31 21:07:18.533 [LogLoader partition=__consumer_offsets-3, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.23fe1155-4ed9-4f7a-a6c4-37bce40c42959321802500161184416] Loading producer state till offset 0 with message format version 2
2024-12-31 21:07:18.534 Created log for partition __consumer_offsets-3 in C:\Users\joech\AppData\Local\Temp\spring.kafka.23fe1155-4ed9-4f7a-a6c4-37bce40c42959321802500161184416\__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:07:18.543 [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
2024-12-31 21:07:18.543 [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0
2024-12-31 21:07:18.543 [Broker id=0] Leader __consumer_offsets-3 with topic id Some(J5VEeosLRbevbzMEmMLmZA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:07:18.552 [LogLoader partition=__consumer_offsets-2, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.23fe1155-4ed9-4f7a-a6c4-37bce40c42959321802500161184416] Loading producer state till offset 0 with message format version 2
2024-12-31 21:07:18.553 Created log for partition __consumer_offsets-2 in C:\Users\joech\AppData\Local\Temp\spring.kafka.23fe1155-4ed9-4f7a-a6c4-37bce40c42959321802500161184416\__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:07:18.553 [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
2024-12-31 21:07:18.553 [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0
2024-12-31 21:07:18.553 [Broker id=0] Leader __consumer_offsets-2 with topic id Some(J5VEeosLRbevbzMEmMLmZA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:07:18.561 [LogLoader partition=__consumer_offsets-4, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.23fe1155-4ed9-4f7a-a6c4-37bce40c42959321802500161184416] Loading producer state till offset 0 with message format version 2
2024-12-31 21:07:18.562 Created log for partition __consumer_offsets-4 in C:\Users\joech\AppData\Local\Temp\spring.kafka.23fe1155-4ed9-4f7a-a6c4-37bce40c42959321802500161184416\__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:07:18.562 [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
2024-12-31 21:07:18.562 [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0
2024-12-31 21:07:18.562 [Broker id=0] Leader __consumer_offsets-4 with topic id Some(J5VEeosLRbevbzMEmMLmZA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:07:18.571 [LogLoader partition=__consumer_offsets-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.23fe1155-4ed9-4f7a-a6c4-37bce40c42959321802500161184416] Loading producer state till offset 0 with message format version 2
2024-12-31 21:07:18.572 Created log for partition __consumer_offsets-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.23fe1155-4ed9-4f7a-a6c4-37bce40c42959321802500161184416\__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:07:18.572 [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
2024-12-31 21:07:18.572 [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0
2024-12-31 21:07:18.572 [Broker id=0] Leader __consumer_offsets-1 with topic id Some(J5VEeosLRbevbzMEmMLmZA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:07:18.581 [LogLoader partition=__consumer_offsets-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.23fe1155-4ed9-4f7a-a6c4-37bce40c42959321802500161184416] Loading producer state till offset 0 with message format version 2
2024-12-31 21:07:18.582 Created log for partition __consumer_offsets-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.23fe1155-4ed9-4f7a-a6c4-37bce40c42959321802500161184416\__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:07:18.582 [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
2024-12-31 21:07:18.582 [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0
2024-12-31 21:07:18.582 [Broker id=0] Leader __consumer_offsets-0 with topic id Some(J5VEeosLRbevbzMEmMLmZA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:07:18.585 [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 0
2024-12-31 21:07:18.586 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0
2024-12-31 21:07:18.586 [GroupCoordinator 0]: Elected as the group coordinator for partition 2 in epoch 0
2024-12-31 21:07:18.586 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0
2024-12-31 21:07:18.586 [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 0
2024-12-31 21:07:18.586 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0
2024-12-31 21:07:18.587 [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 0
2024-12-31 21:07:18.587 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0
2024-12-31 21:07:18.587 [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 0
2024-12-31 21:07:18.587 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0
2024-12-31 21:07:18.587 [Broker id=0] Finished LeaderAndIsr request in 68ms correlationId 3 from controller 0 for 5 partitions
2024-12-31 21:07:18.588 [Broker id=0] Add 5 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 4
2024-12-31 21:07:18.591 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 5 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler.
2024-12-31 21:07:18.591 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler.
2024-12-31 21:07:18.591 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler.
2024-12-31 21:07:18.592 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler.
2024-12-31 21:07:18.592 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler.
2024-12-31 21:07:18.602 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Discovered group coordinator localhost:59462 (id: 2147483647 rack: null)
2024-12-31 21:07:18.604 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] (Re-)joining group
2024-12-31 21:07:18.621 [GroupCoordinator 0]: Dynamic member with unknown member id joins group pong-service in Empty state. Created a new member id consumer-pong-service-1-47139c6e-abc0-4ed7-ba82-b892d098f70f and request the member to rejoin with this id.
2024-12-31 21:07:18.625 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: need to re-join with the given member-id: consumer-pong-service-1-47139c6e-abc0-4ed7-ba82-b892d098f70f
2024-12-31 21:07:18.626 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2024-12-31 21:07:18.626 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] (Re-)joining group
2024-12-31 21:07:18.630 [GroupCoordinator 0]: Preparing to rebalance group pong-service in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-pong-service-1-47139c6e-abc0-4ed7-ba82-b892d098f70f with group instance id None; client reason: rebalance failed due to MemberIdRequiredException)
2024-12-31 21:07:18.634 [GroupCoordinator 0]: Stabilized group pong-service generation 1 (__consumer_offsets-2) with 1 members
2024-12-31 21:07:18.635 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Successfully joined group with generation Generation{generationId=1, memberId='consumer-pong-service-1-47139c6e-abc0-4ed7-ba82-b892d098f70f', protocol='range'}
2024-12-31 21:07:18.638 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Finished assignment for group at generation 1: {consumer-pong-service-1-47139c6e-abc0-4ed7-ba82-b892d098f70f=Assignment(partitions=[pong-message-topic-0, pong-message-topic-1])}
2024-12-31 21:07:18.644 [GroupCoordinator 0]: Assignment received from leader consumer-pong-service-1-47139c6e-abc0-4ed7-ba82-b892d098f70f for group pong-service for generation 1. The group has 1 members, 0 of which are static.
2024-12-31 21:07:18.690 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Successfully synced group in generation Generation{generationId=1, memberId='consumer-pong-service-1-47139c6e-abc0-4ed7-ba82-b892d098f70f', protocol='range'}
2024-12-31 21:07:18.690 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Notifying assignor about the new Assignment(partitions=[pong-message-topic-0, pong-message-topic-1])
2024-12-31 21:07:18.693 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Adding newly assigned partitions: pong-message-topic-0, pong-message-topic-1
2024-12-31 21:07:18.700 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-0
2024-12-31 21:07:18.700 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-1
2024-12-31 21:07:18.703 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-0
2024-12-31 21:07:18.703 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-1
2024-12-31 21:07:18.713 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting offset for partition pong-message-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:59462 (id: 0 rack: null)], epoch=0}}.
2024-12-31 21:07:18.713 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting offset for partition pong-message-topic-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:59462 (id: 0 rack: null)], epoch=0}}.
2024-12-31 21:07:18.734 pong-service: partitions assigned: [pong-message-topic-0, pong-message-topic-1]
2024-12-31 21:07:19.313 Received ping message: Hello
2024-12-31 21:07:19.323 Idempotence will be disabled because acks is set to 0, not set to 'all'.
2024-12-31 21:07:19.323 ProducerConfig values: 
	acks = 0
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:59462]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2024-12-31 21:07:19.342 Kafka version: 3.4.1
2024-12-31 21:07:19.342 Kafka commitId: 8a516edc2755df89
2024-12-31 21:07:19.342 Kafka startTimeMs: 1735650439342
2024-12-31 21:07:19.347 [Producer clientId=producer-1] Cluster ID: gfbNscIMSSOPylMaJwslLg
2024-12-31 21:07:19.351 [Producer clientId=producer-1] Resetting the last seen epoch of partition pong-message-topic-0 to 0 since the associated topicId changed from null to ChsiiFwASJytTqkQxwy8jg
2024-12-31 21:07:19.351 [Producer clientId=producer-1] Resetting the last seen epoch of partition pong-message-topic-1 to 0 since the associated topicId changed from null to ChsiiFwASJytTqkQxwy8jg
2024-12-31 21:07:20.761 Received ping message: Hello
2024-12-31 21:07:20.771 Received ping message: Hello
2024-12-31 21:07:20.771 Throttling request as too many requests in the same second
2024-12-31 21:07:21.227 [KafkaServer id=0] shutting down
2024-12-31 21:07:21.228 [KafkaServer id=0] Starting controlled shutdown
2024-12-31 21:07:21.239 [Controller id=0] Shutting down broker 0
2024-12-31 21:07:21.245 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:07:21.250 [KafkaServer id=0] Controlled shutdown request returned successfully after 16ms
2024-12-31 21:07:21.252 [/config/changes-event-process-thread]: Shutting down
2024-12-31 21:07:21.254 [/config/changes-event-process-thread]: Shutdown completed
2024-12-31 21:07:21.254 [/config/changes-event-process-thread]: Stopped
2024-12-31 21:07:21.254 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
2024-12-31 21:07:21.258 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:07:21.258 [Producer clientId=producer-1] Node 0 disconnected.
2024-12-31 21:07:21.261 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Cancelled in-flight FETCH request with correlation id 22 due to node 0 being disconnected (elapsed time since creation: 475ms, elapsed time since send: 474ms, request timeout: 30000ms)
2024-12-31 21:07:21.261 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 2147483647 disconnected.
2024-12-31 21:07:21.262 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:07:21.262 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:07:21.262 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Group coordinator localhost:59462 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
2024-12-31 21:07:21.262 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Error sending fetch request (sessionId=2094528248, epoch=6) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2024-12-31 21:07:21.263 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors
2024-12-31 21:07:21.263 [data-plane Kafka Request Handler on Broker 0], shutting down
2024-12-31 21:07:21.265 [data-plane Kafka Request Handler on Broker 0], shut down completely
2024-12-31 21:07:21.268 [ExpirationReaper-0-AlterAcls]: Shutting down
2024-12-31 21:07:21.273 [ExpirationReaper-0-AlterAcls]: Shutdown completed
2024-12-31 21:07:21.273 [ExpirationReaper-0-AlterAcls]: Stopped
2024-12-31 21:07:21.274 [KafkaApi-0] Shutdown complete.
2024-12-31 21:07:21.275 [ExpirationReaper-0-topic]: Shutting down
2024-12-31 21:07:21.276 [ExpirationReaper-0-topic]: Stopped
2024-12-31 21:07:21.276 [ExpirationReaper-0-topic]: Shutdown completed
2024-12-31 21:07:21.278 [TransactionCoordinator id=0] Shutting down.
2024-12-31 21:07:21.279 [Transaction State Manager 0]: Shutdown complete
2024-12-31 21:07:21.279 [Transaction Marker Channel Manager 0]: Shutting down
2024-12-31 21:07:21.279 [Transaction Marker Channel Manager 0]: Stopped
2024-12-31 21:07:21.279 [Transaction Marker Channel Manager 0]: Shutdown completed
2024-12-31 21:07:21.280 [TransactionCoordinator id=0] Shutdown complete.
2024-12-31 21:07:21.280 [GroupCoordinator 0]: Shutting down.
2024-12-31 21:07:21.282 [ExpirationReaper-0-Heartbeat]: Shutting down
2024-12-31 21:07:21.282 [ExpirationReaper-0-Heartbeat]: Shutdown completed
2024-12-31 21:07:21.282 [ExpirationReaper-0-Heartbeat]: Stopped
2024-12-31 21:07:21.282 [ExpirationReaper-0-Rebalance]: Shutting down
2024-12-31 21:07:21.282 [ExpirationReaper-0-Rebalance]: Stopped
2024-12-31 21:07:21.282 [ExpirationReaper-0-Rebalance]: Shutdown completed
2024-12-31 21:07:21.283 [GroupCoordinator 0]: Shutdown complete.
2024-12-31 21:07:21.284 [ReplicaManager broker=0] Shutting down
2024-12-31 21:07:21.284 [LogDirFailureHandler]: Shutting down
2024-12-31 21:07:21.284 [LogDirFailureHandler]: Shutdown completed
2024-12-31 21:07:21.284 [LogDirFailureHandler]: Stopped
2024-12-31 21:07:21.285 [ReplicaFetcherManager on broker 0] shutting down
2024-12-31 21:07:21.286 [ReplicaFetcherManager on broker 0] shutdown completed
2024-12-31 21:07:21.286 [ReplicaAlterLogDirsManager on broker 0] shutting down
2024-12-31 21:07:21.286 [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2024-12-31 21:07:21.286 [ExpirationReaper-0-Fetch]: Shutting down
2024-12-31 21:07:21.288 [ExpirationReaper-0-Fetch]: Stopped
2024-12-31 21:07:21.288 [ExpirationReaper-0-Fetch]: Shutdown completed
2024-12-31 21:07:21.288 [ExpirationReaper-0-Produce]: Shutting down
2024-12-31 21:07:21.288 [ExpirationReaper-0-Produce]: Shutdown completed
2024-12-31 21:07:21.288 [ExpirationReaper-0-Produce]: Stopped
2024-12-31 21:07:21.289 [ExpirationReaper-0-DeleteRecords]: Shutting down
2024-12-31 21:07:21.289 [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2024-12-31 21:07:21.289 [ExpirationReaper-0-DeleteRecords]: Stopped
2024-12-31 21:07:21.289 [ExpirationReaper-0-ElectLeader]: Shutting down
2024-12-31 21:07:21.290 [ExpirationReaper-0-ElectLeader]: Stopped
2024-12-31 21:07:21.290 [ExpirationReaper-0-ElectLeader]: Shutdown completed
2024-12-31 21:07:21.300 [ReplicaManager broker=0] Shut down completely
2024-12-31 21:07:21.301 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutting down
2024-12-31 21:07:21.301 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Stopped
2024-12-31 21:07:21.301 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutdown completed
2024-12-31 21:07:21.304 Broker to controller channel manager for alterPartition shutdown
2024-12-31 21:07:21.304 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down
2024-12-31 21:07:21.304 [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped
2024-12-31 21:07:21.304 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed
2024-12-31 21:07:21.305 Broker to controller channel manager for forwarding shutdown
2024-12-31 21:07:21.305 Shutting down.
2024-12-31 21:07:21.307 Shutting down the log cleaner.
2024-12-31 21:07:21.307 [kafka-log-cleaner-thread-0]: Shutting down
2024-12-31 21:07:21.308 [kafka-log-cleaner-thread-0]: Shutdown completed
2024-12-31 21:07:21.308 [kafka-log-cleaner-thread-0]: Stopped
2024-12-31 21:07:21.349 [ProducerStateManager partition=pong-message-topic-1] Wrote producer snapshot at offset 3 with 0 producer ids in 4 ms.
2024-12-31 21:07:21.361 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:07:21.361 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node 0 (localhost/127.0.0.1:59462) could not be established. Broker may not be available.
2024-12-31 21:07:21.361 [ProducerStateManager partition=__consumer_offsets-2] Wrote producer snapshot at offset 6 with 0 producer ids in 2 ms.
2024-12-31 21:07:21.363 [Producer clientId=producer-1] Node 0 disconnected.
2024-12-31 21:07:21.363 [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:59462) could not be established. Broker may not be available.
2024-12-31 21:07:21.378 Shutdown complete.
2024-12-31 21:07:21.379 [ControllerEventThread controllerId=0] Shutting down
2024-12-31 21:07:21.379 [ControllerEventThread controllerId=0] Stopped
2024-12-31 21:07:21.379 [ControllerEventThread controllerId=0] Shutdown completed
2024-12-31 21:07:21.381 [PartitionStateMachine controllerId=0] Stopped partition state machine
2024-12-31 21:07:21.382 [ReplicaStateMachine controllerId=0] Stopped replica state machine
2024-12-31 21:07:21.383 [RequestSendThread controllerId=0] Shutting down
2024-12-31 21:07:21.383 [RequestSendThread controllerId=0] Shutdown completed
2024-12-31 21:07:21.383 [RequestSendThread controllerId=0] Stopped
2024-12-31 21:07:21.384 [Controller id=0] Resigned
2024-12-31 21:07:21.385 [feature-zk-node-event-process-thread]: Shutting down
2024-12-31 21:07:21.385 [feature-zk-node-event-process-thread]: Stopped
2024-12-31 21:07:21.385 [feature-zk-node-event-process-thread]: Shutdown completed
2024-12-31 21:07:21.385 [ZooKeeperClient Kafka server] Closing.
2024-12-31 21:07:21.500 EventThread shut down for session: 0x100176ecb260000
2024-12-31 21:07:21.500 Session: 0x100176ecb260000 closed
2024-12-31 21:07:21.501 [ZooKeeperClient Kafka server] Closed.
2024-12-31 21:07:21.501 [ThrottledChannelReaper-Fetch]: Shutting down
2024-12-31 21:07:21.505 [ThrottledChannelReaper-Fetch]: Shutdown completed
2024-12-31 21:07:21.505 [ThrottledChannelReaper-Fetch]: Stopped
2024-12-31 21:07:21.505 [ThrottledChannelReaper-Produce]: Shutting down
2024-12-31 21:07:21.505 [ThrottledChannelReaper-Produce]: Stopped
2024-12-31 21:07:21.505 [ThrottledChannelReaper-Produce]: Shutdown completed
2024-12-31 21:07:21.505 [ThrottledChannelReaper-Request]: Shutting down
2024-12-31 21:07:21.505 [ThrottledChannelReaper-Request]: Shutdown completed
2024-12-31 21:07:21.505 [ThrottledChannelReaper-ControllerMutation]: Shutting down
2024-12-31 21:07:21.505 [ThrottledChannelReaper-Request]: Stopped
2024-12-31 21:07:21.505 [ThrottledChannelReaper-ControllerMutation]: Shutdown completed
2024-12-31 21:07:21.505 [ThrottledChannelReaper-ControllerMutation]: Stopped
2024-12-31 21:07:21.506 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server
2024-12-31 21:07:21.513 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:07:21.513 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node 0 (localhost/127.0.0.1:59462) could not be established. Broker may not be available.
2024-12-31 21:07:21.514 [Producer clientId=producer-1] Node 0 disconnected.
2024-12-31 21:07:21.514 [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:59462) could not be established. Broker may not be available.
2024-12-31 21:07:21.526 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed
2024-12-31 21:07:21.527 Metrics scheduler closed
2024-12-31 21:07:21.527 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:07:21.527 Metrics reporters closed
2024-12-31 21:07:21.529 Broker and topic stats closed
2024-12-31 21:07:21.529 App info kafka.server for 0 unregistered
2024-12-31 21:07:21.530 [KafkaServer id=0] shut down completed
2024-12-31 21:07:21.547 ConnnectionExpirerThread interrupted
2024-12-31 21:07:21.547 accept thread exitted run method
2024-12-31 21:07:21.549 selector thread exitted run method
2024-12-31 21:07:21.549 selector thread exitted run method
2024-12-31 21:07:21.550 shutting down
2024-12-31 21:07:21.550 Shutting down
2024-12-31 21:07:21.550 Draining request throttler queue
2024-12-31 21:07:21.550 RequestThrottler shutdown. Dropped 0 requests
2024-12-31 21:07:21.550 Shutting down
2024-12-31 21:07:21.550 Shutting down
2024-12-31 21:07:21.550 Shutting down
2024-12-31 21:07:21.550 PrepRequestProcessor exited loop!
2024-12-31 21:07:21.550 SyncRequestProcessor exited!
2024-12-31 21:07:21.550 shutdown of request processor complete
2024-12-31 21:07:21.580 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Revoke previously assigned partitions pong-message-topic-0, pong-message-topic-1
2024-12-31 21:07:21.580 pong-service: partitions revoked: [pong-message-topic-0, pong-message-topic-1]
2024-12-31 21:07:21.581 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:07:21.581 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:07:21.581 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Unsubscribed all topics or patterns and assigned partitions
2024-12-31 21:07:21.581 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:07:21.581 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:07:21.582 Metrics scheduler closed
2024-12-31 21:07:21.582 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:07:21.582 Metrics reporters closed
2024-12-31 21:07:21.583 App info kafka.consumer for consumer-pong-service-1 unregistered
2024-12-31 21:07:21.583 pong-service: Consumer stopped
2024-12-31 21:07:21.590 [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2024-12-31 21:07:21.592 Metrics scheduler closed
2024-12-31 21:07:21.592 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:07:21.592 Metrics reporters closed
2024-12-31 21:07:21.592 App info kafka.producer for producer-1 unregistered
2024-12-31 21:07:21.612 Closing JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:07:21.615 HikariPool-1 - Shutdown initiated...
2024-12-31 21:07:21.618 HikariPool-1 - Shutdown completed.
2024-12-31 21:07:21.889 SessionTrackerImpl exited loop!
2024-12-31 21:07:23.642 [KafkaServer id=0] shutting down
2024-12-31 21:07:23.643 [/config/changes-event-process-thread]: Shutting down
2024-12-31 21:07:23.643 [/config/changes-event-process-thread]: Shutdown completed
2024-12-31 21:07:23.643 [/config/changes-event-process-thread]: Stopped
2024-12-31 21:07:23.643 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
2024-12-31 21:07:23.648 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors
2024-12-31 21:07:23.648 [data-plane Kafka Request Handler on Broker 0], shutting down
2024-12-31 21:07:23.649 [data-plane Kafka Request Handler on Broker 0], shut down completely
2024-12-31 21:07:23.650 [ExpirationReaper-0-AlterAcls]: Shutting down
2024-12-31 21:07:23.651 [ExpirationReaper-0-AlterAcls]: Stopped
2024-12-31 21:07:23.651 [ExpirationReaper-0-AlterAcls]: Shutdown completed
2024-12-31 21:07:23.651 [KafkaApi-0] Shutdown complete.
2024-12-31 21:07:23.651 [ExpirationReaper-0-topic]: Shutting down
2024-12-31 21:07:23.651 [ExpirationReaper-0-topic]: Stopped
2024-12-31 21:07:23.651 [ExpirationReaper-0-topic]: Shutdown completed
2024-12-31 21:07:23.651 [TransactionCoordinator id=0] Shutting down.
2024-12-31 21:07:23.651 [Transaction State Manager 0]: Shutdown complete
2024-12-31 21:07:23.651 [Transaction Marker Channel Manager 0]: Shutting down
2024-12-31 21:07:23.651 [Transaction Marker Channel Manager 0]: Stopped
2024-12-31 21:07:23.651 [Transaction Marker Channel Manager 0]: Shutdown completed
2024-12-31 21:07:23.653 [TransactionCoordinator id=0] Shutdown complete.
2024-12-31 21:07:23.653 [GroupCoordinator 0]: Shutting down.
2024-12-31 21:07:23.653 [ExpirationReaper-0-Heartbeat]: Shutting down
2024-12-31 21:07:23.654 [ExpirationReaper-0-Heartbeat]: Stopped
2024-12-31 21:07:23.654 [ExpirationReaper-0-Heartbeat]: Shutdown completed
2024-12-31 21:07:23.654 [ExpirationReaper-0-Rebalance]: Shutting down
2024-12-31 21:07:23.654 [ExpirationReaper-0-Rebalance]: Stopped
2024-12-31 21:07:23.654 [ExpirationReaper-0-Rebalance]: Shutdown completed
2024-12-31 21:07:23.654 [GroupCoordinator 0]: Shutdown complete.
2024-12-31 21:07:23.654 [ReplicaManager broker=0] Shutting down
2024-12-31 21:07:23.655 [LogDirFailureHandler]: Shutting down
2024-12-31 21:07:23.655 [LogDirFailureHandler]: Stopped
2024-12-31 21:07:23.655 [LogDirFailureHandler]: Shutdown completed
2024-12-31 21:07:23.655 [ReplicaFetcherManager on broker 0] shutting down
2024-12-31 21:07:23.655 [ReplicaFetcherManager on broker 0] shutdown completed
2024-12-31 21:07:23.655 [ReplicaAlterLogDirsManager on broker 0] shutting down
2024-12-31 21:07:23.655 [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2024-12-31 21:07:23.655 [ExpirationReaper-0-Fetch]: Shutting down
2024-12-31 21:07:23.655 [ExpirationReaper-0-Fetch]: Stopped
2024-12-31 21:07:23.655 [ExpirationReaper-0-Fetch]: Shutdown completed
2024-12-31 21:07:23.655 [ExpirationReaper-0-Produce]: Shutting down
2024-12-31 21:07:23.656 [ExpirationReaper-0-Produce]: Stopped
2024-12-31 21:07:23.656 [ExpirationReaper-0-Produce]: Shutdown completed
2024-12-31 21:07:23.656 [ExpirationReaper-0-DeleteRecords]: Shutting down
2024-12-31 21:07:23.656 [ExpirationReaper-0-DeleteRecords]: Stopped
2024-12-31 21:07:23.656 [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2024-12-31 21:07:23.656 [ExpirationReaper-0-ElectLeader]: Shutting down
2024-12-31 21:07:23.657 [ExpirationReaper-0-ElectLeader]: Stopped
2024-12-31 21:07:23.657 [ExpirationReaper-0-ElectLeader]: Shutdown completed
2024-12-31 21:07:23.665 [ReplicaManager broker=0] Shut down completely
2024-12-31 21:07:23.665 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutting down
2024-12-31 21:07:23.665 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Stopped
2024-12-31 21:07:23.665 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutdown completed
2024-12-31 21:07:23.666 Broker to controller channel manager for alterPartition shutdown
2024-12-31 21:07:23.666 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down
2024-12-31 21:07:23.667 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed
2024-12-31 21:07:23.667 [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped
2024-12-31 21:07:23.667 Broker to controller channel manager for forwarding shutdown
2024-12-31 21:07:23.667 Shutting down.
2024-12-31 21:07:23.667 Shutting down the log cleaner.
2024-12-31 21:07:23.667 [kafka-log-cleaner-thread-0]: Shutting down
2024-12-31 21:07:23.668 [kafka-log-cleaner-thread-0]: Shutdown completed
2024-12-31 21:07:23.668 [kafka-log-cleaner-thread-0]: Stopped
2024-12-31 21:07:23.679 Shutdown complete.
2024-12-31 21:07:23.679 [ControllerEventThread controllerId=0] Shutting down
2024-12-31 21:07:23.679 [ControllerEventThread controllerId=0] Shutdown completed
2024-12-31 21:07:23.679 [ControllerEventThread controllerId=0] Stopped
2024-12-31 21:07:23.680 [PartitionStateMachine controllerId=0] Stopped partition state machine
2024-12-31 21:07:23.680 [ReplicaStateMachine controllerId=0] Stopped replica state machine
2024-12-31 21:07:23.680 [RequestSendThread controllerId=0] Shutting down
2024-12-31 21:07:23.680 [RequestSendThread controllerId=0] Stopped
2024-12-31 21:07:23.680 [RequestSendThread controllerId=0] Shutdown completed
2024-12-31 21:07:23.681 [Controller id=0] Resigned
2024-12-31 21:07:23.681 [feature-zk-node-event-process-thread]: Shutting down
2024-12-31 21:07:23.681 [feature-zk-node-event-process-thread]: Stopped
2024-12-31 21:07:23.681 [feature-zk-node-event-process-thread]: Shutdown completed
2024-12-31 21:07:23.681 [ZooKeeperClient Kafka server] Closing.
2024-12-31 21:07:23.784 Session: 0x100176eed1c0000 closed
2024-12-31 21:07:23.784 EventThread shut down for session: 0x100176eed1c0000
2024-12-31 21:07:23.784 [ZooKeeperClient Kafka server] Closed.
2024-12-31 21:07:23.784 [ThrottledChannelReaper-Fetch]: Shutting down
2024-12-31 21:07:23.784 [ThrottledChannelReaper-Fetch]: Stopped
2024-12-31 21:07:23.784 [ThrottledChannelReaper-Fetch]: Shutdown completed
2024-12-31 21:07:23.786 [ThrottledChannelReaper-Produce]: Shutting down
2024-12-31 21:07:23.786 [ThrottledChannelReaper-Produce]: Stopped
2024-12-31 21:07:23.786 [ThrottledChannelReaper-Produce]: Shutdown completed
2024-12-31 21:07:23.786 [ThrottledChannelReaper-Request]: Shutting down
2024-12-31 21:07:23.786 [ThrottledChannelReaper-Request]: Stopped
2024-12-31 21:07:23.786 [ThrottledChannelReaper-Request]: Shutdown completed
2024-12-31 21:07:23.786 [ThrottledChannelReaper-ControllerMutation]: Shutting down
2024-12-31 21:07:23.786 [ThrottledChannelReaper-ControllerMutation]: Shutdown completed
2024-12-31 21:07:23.786 [ThrottledChannelReaper-ControllerMutation]: Stopped
2024-12-31 21:07:23.786 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server
2024-12-31 21:07:23.796 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed
2024-12-31 21:07:23.797 Metrics scheduler closed
2024-12-31 21:07:23.797 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:07:23.797 Metrics reporters closed
2024-12-31 21:07:23.797 Broker and topic stats closed
2024-12-31 21:07:23.797 App info kafka.server for 0 unregistered
2024-12-31 21:07:23.797 [KafkaServer id=0] shut down completed
2024-12-31 21:07:23.802 ConnnectionExpirerThread interrupted
2024-12-31 21:07:23.803 selector thread exitted run method
2024-12-31 21:07:23.803 accept thread exitted run method
2024-12-31 21:07:23.803 selector thread exitted run method
2024-12-31 21:07:23.806 shutting down
2024-12-31 21:07:23.806 Shutting down
2024-12-31 21:07:23.806 Draining request throttler queue
2024-12-31 21:07:23.806 RequestThrottler shutdown. Dropped 0 requests
2024-12-31 21:07:23.806 Shutting down
2024-12-31 21:07:23.806 Shutting down
2024-12-31 21:07:23.806 Shutting down
2024-12-31 21:07:23.806 PrepRequestProcessor exited loop!
2024-12-31 21:07:23.806 SyncRequestProcessor exited!
2024-12-31 21:07:23.806 shutdown of request processor complete
2024-12-31 21:07:24.289 SessionTrackerImpl exited loop!
2024-12-31 21:07:24.356 

Found multiple occurrences of org.json.JSONObject on the class path:

	jar:file:/C:/work/apache-maven-3.8.8/repo/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar!/org/json/JSONObject.class
	jar:file:/C:/work/apache-maven-3.8.8/repo/org/json/json/20220320/json-20220320.jar!/org/json/JSONObject.class

You may wish to exclude one of them to ensure predictable runtime behavior

2024-12-31 21:07:24.356 Starting MessageRepositorySpec using Java 17.0.12 with PID 27352 (started by joech in C:\code\hsbc\demo\pong)
2024-12-31 21:07:24.356 No active profile set, falling back to 1 default profile: "default"
2024-12-31 21:07:24.511 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:07:24.511 Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2024-12-31 21:07:24.535 Finished Spring Data repository scanning in 18 ms. Found 1 JPA repository interfaces.
2024-12-31 21:07:24.542 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:07:24.542 Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2024-12-31 21:07:24.545 Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.demo.dao.MessageRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2024-12-31 21:07:24.545 Finished Spring Data repository scanning in 3 ms. Found 0 Redis repository interfaces.
2024-12-31 21:07:24.653 HHH000204: Processing PersistenceUnitInfo [name: default]
2024-12-31 21:07:24.653 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:07:24.653 No LoadTimeWeaver setup: ignoring JPA class transformer
2024-12-31 21:07:24.653 HikariPool-2 - Starting...
2024-12-31 21:07:24.669 HikariPool-2 - Added connection conn10: url=jdbc:h2:mem:testdb user=SA
2024-12-31 21:07:24.669 HikariPool-2 - Start completed.
2024-12-31 21:07:24.682 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:07:24.705 HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2024-12-31 21:07:24.740 Initialized JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:07:24.998 ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:59462]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-pong-service-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = pong-service
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2024-12-31 21:07:25.004 These configurations '[spring.json.trusted.packages]' were supplied but are not used yet.
2024-12-31 21:07:25.004 Kafka version: 3.4.1
2024-12-31 21:07:25.004 Kafka commitId: 8a516edc2755df89
2024-12-31 21:07:25.004 Kafka startTimeMs: 1735650445004
2024-12-31 21:07:25.004 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Subscribed to topic(s): pong-message-topic
2024-12-31 21:07:25.011 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:07:25.011 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Connection to node -1 (/127.0.0.1:59462) could not be established. Broker may not be available.
2024-12-31 21:07:25.011 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Bootstrap broker 127.0.0.1:59462 (id: -1 rack: null) disconnected
2024-12-31 21:07:25.012 Started MessageRepositorySpec in 0.695 seconds (process running for 29.093)
2024-12-31 21:07:25.077 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:07:25.077 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:07:25.077 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Unsubscribed all topics or patterns and assigned partitions
2024-12-31 21:07:25.077 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:07:25.077 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:07:25.077 Metrics scheduler closed
2024-12-31 21:07:25.077 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:07:25.077 Metrics reporters closed
2024-12-31 21:07:25.077 App info kafka.consumer for consumer-pong-service-2 unregistered
2024-12-31 21:07:25.077 pong-service: Consumer stopped
2024-12-31 21:07:25.085 Closing JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:07:25.087 HikariPool-2 - Shutdown initiated...
2024-12-31 21:07:25.088 HikariPool-2 - Shutdown completed.
2024-12-31 21:07:25.114 zookeeper.snapshot.trust.empty : false
2024-12-31 21:07:25.114 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:07:25.114 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:07:25.114 zookeeper.snapshotSizeFactor = 0.33
2024-12-31 21:07:25.114 zookeeper.commitLogCount=500
2024-12-31 21:07:25.114 minSessionTimeout set to 1600
2024-12-31 21:07:25.114 maxSessionTimeout set to 16000
2024-12-31 21:07:25.114 Response cache size is initialized with value 400.
2024-12-31 21:07:25.114 Response cache size is initialized with value 400.
2024-12-31 21:07:25.114 zookeeper.pathStats.slotCapacity = 60
2024-12-31 21:07:25.114 zookeeper.pathStats.slotDuration = 15
2024-12-31 21:07:25.114 zookeeper.pathStats.maxDepth = 6
2024-12-31 21:07:25.114 zookeeper.pathStats.initialDelay = 5
2024-12-31 21:07:25.114 zookeeper.pathStats.delay = 5
2024-12-31 21:07:25.114 zookeeper.pathStats.enabled = false
2024-12-31 21:07:25.114 The max bytes for all large requests are set to 104857600
2024-12-31 21:07:25.114 The large request threshold is set to -1
2024-12-31 21:07:25.114 Created server with tickTime 800 minSessionTimeout 1600 maxSessionTimeout 16000 clientPortListenBacklog -1 datadir C:\Users\joech\AppData\Local\Temp\kafka-11046196718676997990\version-2 snapdir C:\Users\joech\AppData\Local\Temp\kafka-4549331769786575822\version-2
2024-12-31 21:07:25.114 maxCnxns is not configured, using default value 0.
2024-12-31 21:07:25.114 Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers.
2024-12-31 21:07:25.121 binding to port /127.0.0.1:0
2024-12-31 21:07:25.126 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-4549331769786575822\version-2\snapshot.0
2024-12-31 21:07:25.127 Snapshot loaded in 2 ms, highest zxid is 0x0, digest is 1371985504
2024-12-31 21:07:25.127 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-4549331769786575822\version-2\snapshot.0
2024-12-31 21:07:25.128 Snapshot taken in 1 ms
2024-12-31 21:07:25.129 PrepRequestProcessor (sid:0) started, reconfigEnabled=false
2024-12-31 21:07:25.132 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.c4b24ad9-d706-4b83-ad62-66d35eefc5b66997338529775204203
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59489
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:07:25.136 starting
2024-12-31 21:07:25.136 Connecting to zookeeper on 127.0.0.1:59489
2024-12-31 21:07:25.136 [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:59489.
2024-12-31 21:07:25.136 Initiating client connection, connectString=127.0.0.1:59489 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1adc896a
2024-12-31 21:07:25.138 jute.maxbuffer value is 4194304 Bytes
2024-12-31 21:07:25.139 zookeeper.request.timeout value is 0. feature enabled=false
2024-12-31 21:07:25.139 [ZooKeeperClient Kafka server] Waiting until connected.
2024-12-31 21:07:25.139 Opening socket connection to server /127.0.0.1:59489.
2024-12-31 21:07:25.141 Socket connection established, initiating session, client: /127.0.0.1:59490, server: /127.0.0.1:59489
2024-12-31 21:07:25.142 Creating new log file: log.1
2024-12-31 21:07:25.145 Session establishment complete on server /127.0.0.1:59489, session id = 0x100176f1c080000, negotiated timeout = 16000
2024-12-31 21:07:25.145 [ZooKeeperClient Kafka server] Connected.
2024-12-31 21:07:25.180 Cluster ID = 1n6SA5atQnyikiK_dZdOhg
2024-12-31 21:07:25.181 No meta.properties file under dir C:\Users\joech\AppData\Local\Temp\spring.kafka.c4b24ad9-d706-4b83-ad62-66d35eefc5b66997338529775204203\meta.properties
2024-12-31 21:07:25.191 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.c4b24ad9-d706-4b83-ad62-66d35eefc5b66997338529775204203
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59489
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:07:25.201 [ThrottledChannelReaper-Produce]: Starting
2024-12-31 21:07:25.201 [ThrottledChannelReaper-Fetch]: Starting
2024-12-31 21:07:25.201 [ThrottledChannelReaper-Request]: Starting
2024-12-31 21:07:25.201 [ThrottledChannelReaper-ControllerMutation]: Starting
2024-12-31 21:07:25.207 Loading logs from log dirs ArraySeq(C:\Users\joech\AppData\Local\Temp\spring.kafka.c4b24ad9-d706-4b83-ad62-66d35eefc5b66997338529775204203)
2024-12-31 21:07:25.207 Attempting recovery for all logs in C:\Users\joech\AppData\Local\Temp\spring.kafka.c4b24ad9-d706-4b83-ad62-66d35eefc5b66997338529775204203 since no clean shutdown file was found
2024-12-31 21:07:25.209 Loaded 0 logs in 1ms.
2024-12-31 21:07:25.209 Starting log cleanup with a period of 300000 ms.
2024-12-31 21:07:25.210 Starting log flusher with a default period of 9223372036854775807 ms.
2024-12-31 21:07:25.212 Starting the log cleaner
2024-12-31 21:07:25.213 [kafka-log-cleaner-thread-0]: Starting
2024-12-31 21:07:25.213 [feature-zk-node-event-process-thread]: Starting
2024-12-31 21:07:25.215 Feature ZK node at path: /feature does not exist
2024-12-31 21:07:25.219 [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting
2024-12-31 21:07:25.240 Updated connection-accept-rate max connection creation rate to 2147483647
2024-12-31 21:07:25.244 Awaiting socket connections on localhost:59491.
2024-12-31 21:07:25.251 [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT)
2024-12-31 21:07:25.254 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Starting
2024-12-31 21:07:25.254 [ExpirationReaper-0-Produce]: Starting
2024-12-31 21:07:25.256 [ExpirationReaper-0-Fetch]: Starting
2024-12-31 21:07:25.256 [ExpirationReaper-0-DeleteRecords]: Starting
2024-12-31 21:07:25.257 [ExpirationReaper-0-ElectLeader]: Starting
2024-12-31 21:07:25.258 [LogDirFailureHandler]: Starting
2024-12-31 21:07:25.262 Creating /brokers/ids/0 (is it secure? false)
2024-12-31 21:07:25.264 Stat of the created znode at /brokers/ids/0 is: 25,25,1735650445263,1735650445263,1,0,0,72083360017022976,204,0,25

2024-12-31 21:07:25.265 Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:59491, czxid (broker epoch): 25
2024-12-31 21:07:25.275 [ControllerEventThread controllerId=0] Starting
2024-12-31 21:07:25.277 [ExpirationReaper-0-topic]: Starting
2024-12-31 21:07:25.277 [ExpirationReaper-0-Heartbeat]: Starting
2024-12-31 21:07:25.277 [ExpirationReaper-0-Rebalance]: Starting
2024-12-31 21:07:25.278 [GroupCoordinator 0]: Starting up.
2024-12-31 21:07:25.279 [GroupCoordinator 0]: Startup complete.
2024-12-31 21:07:25.281 Successfully created /controller_epoch with initial epoch 0
2024-12-31 21:07:25.282 [TransactionCoordinator id=0] Starting up.
2024-12-31 21:07:25.283 [Controller id=0] 0 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1
2024-12-31 21:07:25.283 [TransactionCoordinator id=0] Startup complete.
2024-12-31 21:07:25.284 [Transaction Marker Channel Manager 0]: Starting
2024-12-31 21:07:25.284 [Controller id=0] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map())
2024-12-31 21:07:25.286 [ExpirationReaper-0-AlterAcls]: Starting
2024-12-31 21:07:25.286 Feature ZK node created at path: /feature
2024-12-31 21:07:25.287 [Controller id=0] Registering handlers
2024-12-31 21:07:25.287 [MetadataCache brokerId=0] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0).
2024-12-31 21:07:25.288 [/config/changes-event-process-thread]: Starting
2024-12-31 21:07:25.290 [Controller id=0] Deleting log dir event notifications
2024-12-31 21:07:25.290 [Controller id=0] Deleting isr change notifications
2024-12-31 21:07:25.291 [Controller id=0] Initializing controller context
2024-12-31 21:07:25.294 [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing.
2024-12-31 21:07:25.295 [Controller id=0] Initialized broker epochs cache: HashMap(0 -> 25)
2024-12-31 21:07:25.295 Kafka version: 3.4.1
2024-12-31 21:07:25.295 Kafka commitId: 8a516edc2755df89
2024-12-31 21:07:25.295 Kafka startTimeMs: 1735650445295
2024-12-31 21:07:25.295 [KafkaServer id=0] started
2024-12-31 21:07:25.296 AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [127.0.0.1:59491]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-31 21:07:25.299 Kafka version: 3.4.1
2024-12-31 21:07:25.300 Kafka commitId: 8a516edc2755df89
2024-12-31 21:07:25.300 Kafka startTimeMs: 1735650445299
2024-12-31 21:07:25.300 [Controller id=0] Currently active brokers in the cluster: Set(0)
2024-12-31 21:07:25.300 [Controller id=0] Currently shutting brokers in the cluster: HashSet()
2024-12-31 21:07:25.300 [Controller id=0] Current list of topics in the cluster: HashSet()
2024-12-31 21:07:25.300 [RequestSendThread controllerId=0] Starting
2024-12-31 21:07:25.300 [Controller id=0] Fetching topic deletions in progress
2024-12-31 21:07:25.301 [Controller id=0] List of topics to be deleted: 
2024-12-31 21:07:25.301 [Controller id=0] List of topics ineligible for deletion: 
2024-12-31 21:07:25.301 [Controller id=0] Initializing topic deletion manager
2024-12-31 21:07:25.301 [Topic Deletion Manager 0] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet()
2024-12-31 21:07:25.301 [Controller id=0] Sending update metadata request
2024-12-31 21:07:25.302 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions
2024-12-31 21:07:25.302 [ReplicaStateMachine controllerId=0] Initializing replica state
2024-12-31 21:07:25.302 [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2024-12-31 21:07:25.302 [ReplicaStateMachine controllerId=0] Triggering offline replica state changes
2024-12-31 21:07:25.302 [PartitionStateMachine controllerId=0] Initializing partition state
2024-12-31 21:07:25.302 [PartitionStateMachine controllerId=0] Triggering online partition state changes
2024-12-31 21:07:25.302 [Controller id=0] Ready to serve as the new controller with epoch 1
2024-12-31 21:07:25.303 [RequestSendThread controllerId=0] Controller 0 connected to localhost:59491 (id: 0 rack: null) for sending state change requests
2024-12-31 21:07:25.304 [Controller id=0] Partitions undergoing preferred replica election: 
2024-12-31 21:07:25.304 [Controller id=0] Partitions that completed preferred replica election: 
2024-12-31 21:07:25.304 [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2024-12-31 21:07:25.304 [Controller id=0] Resuming preferred replica election for partitions: 
2024-12-31 21:07:25.304 [Controller id=0] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered
2024-12-31 21:07:25.307 [Controller id=0] Starting the controller scheduler
2024-12-31 21:07:25.314 Creating topic pong-message-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0))
2024-12-31 21:07:25.320 [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use node localhost:59491 (id: 0 rack: null)
2024-12-31 21:07:25.324 [Controller id=0] New topics: [Set(pong-message-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(pong-message-topic,Some(6uZ_9R5sQ9Ojqt65M4uWUg),Map(pong-message-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), pong-message-topic-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:07:25.324 [Controller id=0] New partition creation callback for pong-message-topic-0,pong-message-topic-1
2024-12-31 21:07:25.324 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:07:25.324 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:07:25.324 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:07:25.325 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:07:25.335 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:07:25.335 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:07:25.335 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2024-12-31 21:07:25.337 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2024-12-31 21:07:25.337 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:07:25.338 [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 for 2 partitions
2024-12-31 21:07:25.339 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(pong-message-topic-0, pong-message-topic-1)
2024-12-31 21:07:25.339 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2024-12-31 21:07:25.355 [LogLoader partition=pong-message-topic-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.c4b24ad9-d706-4b83-ad62-66d35eefc5b66997338529775204203] Loading producer state till offset 0 with message format version 2
2024-12-31 21:07:25.355 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Recorded new controller, from now on will use node localhost:59491 (id: 0 rack: null)
2024-12-31 21:07:25.356 Created log for partition pong-message-topic-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.c4b24ad9-d706-4b83-ad62-66d35eefc5b66997338529775204203\pong-message-topic-0 with properties {}
2024-12-31 21:07:25.356 [Partition pong-message-topic-0 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-0
2024-12-31 21:07:25.356 [Partition pong-message-topic-0 broker=0] Log loaded for partition pong-message-topic-0 with initial high watermark 0
2024-12-31 21:07:25.357 [Broker id=0] Leader pong-message-topic-0 with topic id Some(6uZ_9R5sQ9Ojqt65M4uWUg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:07:25.369 [LogLoader partition=pong-message-topic-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.c4b24ad9-d706-4b83-ad62-66d35eefc5b66997338529775204203] Loading producer state till offset 0 with message format version 2
2024-12-31 21:07:25.370 Created log for partition pong-message-topic-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.c4b24ad9-d706-4b83-ad62-66d35eefc5b66997338529775204203\pong-message-topic-1 with properties {}
2024-12-31 21:07:25.370 [Partition pong-message-topic-1 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-1
2024-12-31 21:07:25.370 [Partition pong-message-topic-1 broker=0] Log loaded for partition pong-message-topic-1 with initial high watermark 0
2024-12-31 21:07:25.371 [Broker id=0] Leader pong-message-topic-1 with topic id Some(6uZ_9R5sQ9Ojqt65M4uWUg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:07:25.374 [Broker id=0] Finished LeaderAndIsr request in 36ms correlationId 1 from controller 0 for 2 partitions
2024-12-31 21:07:25.379 [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2
2024-12-31 21:07:25.381 App info kafka.admin.client for adminclient-3 unregistered
2024-12-31 21:07:25.382 Metrics scheduler closed
2024-12-31 21:07:25.382 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:07:25.382 Metrics reporters closed
2024-12-31 21:07:25.425 

Found multiple occurrences of org.json.JSONObject on the class path:

	jar:file:/C:/work/apache-maven-3.8.8/repo/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar!/org/json/JSONObject.class
	jar:file:/C:/work/apache-maven-3.8.8/repo/org/json/json/20220320/json-20220320.jar!/org/json/JSONObject.class

You may wish to exclude one of them to ensure predictable runtime behavior

2024-12-31 21:07:25.429 Starting KafkaSpec using Java 17.0.12 with PID 27352 (started by joech in C:\code\hsbc\demo\pong)
2024-12-31 21:07:25.430 No active profile set, falling back to 1 default profile: "default"
2024-12-31 21:07:25.584 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:07:25.586 Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2024-12-31 21:07:25.602 Finished Spring Data repository scanning in 16 ms. Found 1 JPA repository interfaces.
2024-12-31 21:07:25.606 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:07:25.606 Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2024-12-31 21:07:25.612 Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.demo.dao.MessageRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2024-12-31 21:07:25.612 Finished Spring Data repository scanning in 6 ms. Found 0 Redis repository interfaces.
2024-12-31 21:07:25.703 HHH000204: Processing PersistenceUnitInfo [name: default]
2024-12-31 21:07:25.715 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:07:25.715 No LoadTimeWeaver setup: ignoring JPA class transformer
2024-12-31 21:07:25.716 HikariPool-3 - Starting...
2024-12-31 21:07:25.720 HikariPool-3 - Added connection conn20: url=jdbc:h2:mem:testdb user=SA
2024-12-31 21:07:25.720 HikariPool-3 - Start completed.
2024-12-31 21:07:25.731 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:07:25.763 HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2024-12-31 21:07:25.785 Initialized JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:07:25.981 ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:59491]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-pong-service-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = pong-service
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2024-12-31 21:07:25.987 These configurations '[spring.json.trusted.packages]' were supplied but are not used yet.
2024-12-31 21:07:25.987 Kafka version: 3.4.1
2024-12-31 21:07:25.987 Kafka commitId: 8a516edc2755df89
2024-12-31 21:07:25.987 Kafka startTimeMs: 1735650445987
2024-12-31 21:07:25.987 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Subscribed to topic(s): pong-message-topic
2024-12-31 21:07:25.992 Started KafkaSpec in 0.605 seconds (process running for 30.072)
2024-12-31 21:07:25.995 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting the last seen epoch of partition pong-message-topic-0 to 0 since the associated topicId changed from null to 6uZ_9R5sQ9Ojqt65M4uWUg
2024-12-31 21:07:25.996 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting the last seen epoch of partition pong-message-topic-1 to 0 since the associated topicId changed from null to 6uZ_9R5sQ9Ojqt65M4uWUg
2024-12-31 21:07:25.996 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Cluster ID: 1n6SA5atQnyikiK_dZdOhg
2024-12-31 21:07:26.000 Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0))
2024-12-31 21:07:26.006 Idempotence will be disabled because acks is set to 0, not set to 'all'.
2024-12-31 21:07:26.006 ProducerConfig values: 
	acks = 0
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:59491]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2024-12-31 21:07:26.010 [Controller id=0] New topics: [Set(__consumer_offsets)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(__consumer_offsets,Some(QCraNUoORA2jZq59UZuiRA),HashMap(__consumer_offsets-4 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-3 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-2 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:07:26.011 [Controller id=0] New partition creation callback for __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2024-12-31 21:07:26.011 [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:07:26.011 [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:07:26.011 [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:07:26.011 [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:07:26.011 [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:07:26.011 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:07:26.012 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:07:26.012 Kafka version: 3.4.1
2024-12-31 21:07:26.012 Kafka commitId: 8a516edc2755df89
2024-12-31 21:07:26.012 Kafka startTimeMs: 1735650446012
2024-12-31 21:07:26.018 [Producer clientId=producer-2] Resetting the last seen epoch of partition pong-message-topic-0 to 0 since the associated topicId changed from null to 6uZ_9R5sQ9Ojqt65M4uWUg
2024-12-31 21:07:26.018 [Producer clientId=producer-2] Resetting the last seen epoch of partition pong-message-topic-1 to 0 since the associated topicId changed from null to 6uZ_9R5sQ9Ojqt65M4uWUg
2024-12-31 21:07:26.018 [Producer clientId=producer-2] Cluster ID: 1n6SA5atQnyikiK_dZdOhg
2024-12-31 21:07:26.023 [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:07:26.023 [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:07:26.024 [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:07:26.024 [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:07:26.024 [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:07:26.024 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 5 become-leader and 0 become-follower partitions
2024-12-31 21:07:26.024 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 5 partitions
2024-12-31 21:07:26.025 [Broker id=0] Handling LeaderAndIsr request correlationId 3 from controller 0 for 5 partitions
2024-12-31 21:07:26.026 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:07:26.027 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-4, __consumer_offsets-3, __consumer_offsets-2, __consumer_offsets-0, __consumer_offsets-1)
2024-12-31 21:07:26.027 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 3 from controller 0 epoch 1 as part of the become-leader transition for 5 partitions
2024-12-31 21:07:26.043 [LogLoader partition=__consumer_offsets-3, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.c4b24ad9-d706-4b83-ad62-66d35eefc5b66997338529775204203] Loading producer state till offset 0 with message format version 2
2024-12-31 21:07:26.044 Created log for partition __consumer_offsets-3 in C:\Users\joech\AppData\Local\Temp\spring.kafka.c4b24ad9-d706-4b83-ad62-66d35eefc5b66997338529775204203\__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:07:26.046 [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
2024-12-31 21:07:26.046 [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0
2024-12-31 21:07:26.047 [Broker id=0] Leader __consumer_offsets-3 with topic id Some(QCraNUoORA2jZq59UZuiRA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:07:26.061 [LogLoader partition=__consumer_offsets-2, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.c4b24ad9-d706-4b83-ad62-66d35eefc5b66997338529775204203] Loading producer state till offset 0 with message format version 2
2024-12-31 21:07:26.062 Created log for partition __consumer_offsets-2 in C:\Users\joech\AppData\Local\Temp\spring.kafka.c4b24ad9-d706-4b83-ad62-66d35eefc5b66997338529775204203\__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:07:26.062 [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
2024-12-31 21:07:26.062 [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0
2024-12-31 21:07:26.062 [Broker id=0] Leader __consumer_offsets-2 with topic id Some(QCraNUoORA2jZq59UZuiRA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:07:26.076 [LogLoader partition=__consumer_offsets-4, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.c4b24ad9-d706-4b83-ad62-66d35eefc5b66997338529775204203] Loading producer state till offset 0 with message format version 2
2024-12-31 21:07:26.078 Created log for partition __consumer_offsets-4 in C:\Users\joech\AppData\Local\Temp\spring.kafka.c4b24ad9-d706-4b83-ad62-66d35eefc5b66997338529775204203\__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:07:26.078 [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
2024-12-31 21:07:26.078 [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0
2024-12-31 21:07:26.078 [Broker id=0] Leader __consumer_offsets-4 with topic id Some(QCraNUoORA2jZq59UZuiRA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:07:26.091 [LogLoader partition=__consumer_offsets-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.c4b24ad9-d706-4b83-ad62-66d35eefc5b66997338529775204203] Loading producer state till offset 0 with message format version 2
2024-12-31 21:07:26.092 Created log for partition __consumer_offsets-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.c4b24ad9-d706-4b83-ad62-66d35eefc5b66997338529775204203\__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:07:26.092 [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
2024-12-31 21:07:26.092 [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0
2024-12-31 21:07:26.092 [Broker id=0] Leader __consumer_offsets-1 with topic id Some(QCraNUoORA2jZq59UZuiRA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:07:26.107 [LogLoader partition=__consumer_offsets-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.c4b24ad9-d706-4b83-ad62-66d35eefc5b66997338529775204203] Loading producer state till offset 0 with message format version 2
2024-12-31 21:07:26.108 Created log for partition __consumer_offsets-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.c4b24ad9-d706-4b83-ad62-66d35eefc5b66997338529775204203\__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:07:26.108 [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
2024-12-31 21:07:26.108 [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0
2024-12-31 21:07:26.108 [Broker id=0] Leader __consumer_offsets-0 with topic id Some(QCraNUoORA2jZq59UZuiRA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:07:26.113 [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 0
2024-12-31 21:07:26.113 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0
2024-12-31 21:07:26.113 [GroupCoordinator 0]: Elected as the group coordinator for partition 2 in epoch 0
2024-12-31 21:07:26.113 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0
2024-12-31 21:07:26.113 [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 0
2024-12-31 21:07:26.113 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0
2024-12-31 21:07:26.113 [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 0
2024-12-31 21:07:26.113 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0
2024-12-31 21:07:26.113 [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 0
2024-12-31 21:07:26.113 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0
2024-12-31 21:07:26.113 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler.
2024-12-31 21:07:26.113 [Broker id=0] Finished LeaderAndIsr request in 88ms correlationId 3 from controller 0 for 5 partitions
2024-12-31 21:07:26.113 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler.
2024-12-31 21:07:26.113 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler.
2024-12-31 21:07:26.115 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 2 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler.
2024-12-31 21:07:26.115 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler.
2024-12-31 21:07:26.116 [Broker id=0] Add 5 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 4
2024-12-31 21:07:26.206 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Discovered group coordinator localhost:59491 (id: 2147483647 rack: null)
2024-12-31 21:07:26.207 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] (Re-)joining group
2024-12-31 21:07:26.213 [GroupCoordinator 0]: Dynamic member with unknown member id joins group pong-service in Empty state. Created a new member id consumer-pong-service-3-ff05f815-a041-429d-ac4d-7d6377412fc4 and request the member to rejoin with this id.
2024-12-31 21:07:26.215 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Request joining group due to: need to re-join with the given member-id: consumer-pong-service-3-ff05f815-a041-429d-ac4d-7d6377412fc4
2024-12-31 21:07:26.215 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2024-12-31 21:07:26.215 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] (Re-)joining group
2024-12-31 21:07:26.217 [GroupCoordinator 0]: Preparing to rebalance group pong-service in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-pong-service-3-ff05f815-a041-429d-ac4d-7d6377412fc4 with group instance id None; client reason: rebalance failed due to MemberIdRequiredException)
2024-12-31 21:07:26.219 [GroupCoordinator 0]: Stabilized group pong-service generation 1 (__consumer_offsets-2) with 1 members
2024-12-31 21:07:26.220 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Successfully joined group with generation Generation{generationId=1, memberId='consumer-pong-service-3-ff05f815-a041-429d-ac4d-7d6377412fc4', protocol='range'}
2024-12-31 21:07:26.220 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Finished assignment for group at generation 1: {consumer-pong-service-3-ff05f815-a041-429d-ac4d-7d6377412fc4=Assignment(partitions=[pong-message-topic-0, pong-message-topic-1])}
2024-12-31 21:07:26.222 [GroupCoordinator 0]: Assignment received from leader consumer-pong-service-3-ff05f815-a041-429d-ac4d-7d6377412fc4 for group pong-service for generation 1. The group has 1 members, 0 of which are static.
2024-12-31 21:07:26.226 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Successfully synced group in generation Generation{generationId=1, memberId='consumer-pong-service-3-ff05f815-a041-429d-ac4d-7d6377412fc4', protocol='range'}
2024-12-31 21:07:26.226 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Notifying assignor about the new Assignment(partitions=[pong-message-topic-0, pong-message-topic-1])
2024-12-31 21:07:26.227 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Adding newly assigned partitions: pong-message-topic-0, pong-message-topic-1
2024-12-31 21:07:26.229 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Found no committed offset for partition pong-message-topic-0
2024-12-31 21:07:26.229 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Found no committed offset for partition pong-message-topic-1
2024-12-31 21:07:26.232 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Found no committed offset for partition pong-message-topic-0
2024-12-31 21:07:26.232 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Found no committed offset for partition pong-message-topic-1
2024-12-31 21:07:26.234 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting offset for partition pong-message-topic-0 to position FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:59491 (id: 0 rack: null)], epoch=0}}.
2024-12-31 21:07:26.234 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting offset for partition pong-message-topic-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:59491 (id: 0 rack: null)], epoch=0}}.
2024-12-31 21:07:26.245 pong-service: partitions assigned: [pong-message-topic-0, pong-message-topic-1]
2024-12-31 21:07:26.417 [KafkaServer id=0] shutting down
2024-12-31 21:07:26.418 [KafkaServer id=0] Starting controlled shutdown
2024-12-31 21:07:26.423 [Controller id=0] Shutting down broker 0
2024-12-31 21:07:26.423 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:07:26.424 [KafkaServer id=0] Controlled shutdown request returned successfully after 2ms
2024-12-31 21:07:26.425 [/config/changes-event-process-thread]: Shutting down
2024-12-31 21:07:26.425 [/config/changes-event-process-thread]: Shutdown completed
2024-12-31 21:07:26.425 [/config/changes-event-process-thread]: Stopped
2024-12-31 21:07:26.425 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
2024-12-31 21:07:26.426 [Producer clientId=producer-2] Node 0 disconnected.
2024-12-31 21:07:26.426 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:07:26.426 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Cancelled in-flight FETCH request with correlation id 16 due to node 0 being disconnected (elapsed time since creation: 181ms, elapsed time since send: 181ms, request timeout: 30000ms)
2024-12-31 21:07:26.426 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2024-12-31 21:07:26.426 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:07:26.426 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node 2147483647 disconnected.
2024-12-31 21:07:26.427 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:07:26.427 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Group coordinator localhost:59491 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
2024-12-31 21:07:26.427 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors
2024-12-31 21:07:26.427 [data-plane Kafka Request Handler on Broker 0], shutting down
2024-12-31 21:07:26.427 [data-plane Kafka Request Handler on Broker 0], shut down completely
2024-12-31 21:07:26.429 [ExpirationReaper-0-AlterAcls]: Shutting down
2024-12-31 21:07:26.429 [ExpirationReaper-0-AlterAcls]: Stopped
2024-12-31 21:07:26.429 [ExpirationReaper-0-AlterAcls]: Shutdown completed
2024-12-31 21:07:26.429 [KafkaApi-0] Shutdown complete.
2024-12-31 21:07:26.429 [ExpirationReaper-0-topic]: Shutting down
2024-12-31 21:07:26.430 [ExpirationReaper-0-topic]: Shutdown completed
2024-12-31 21:07:26.430 [ExpirationReaper-0-topic]: Stopped
2024-12-31 21:07:26.430 [TransactionCoordinator id=0] Shutting down.
2024-12-31 21:07:26.430 [Transaction State Manager 0]: Shutdown complete
2024-12-31 21:07:26.430 [Transaction Marker Channel Manager 0]: Shutting down
2024-12-31 21:07:26.430 [Transaction Marker Channel Manager 0]: Shutdown completed
2024-12-31 21:07:26.430 [Transaction Marker Channel Manager 0]: Stopped
2024-12-31 21:07:26.430 [TransactionCoordinator id=0] Shutdown complete.
2024-12-31 21:07:26.430 [GroupCoordinator 0]: Shutting down.
2024-12-31 21:07:26.430 [ExpirationReaper-0-Heartbeat]: Shutting down
2024-12-31 21:07:26.431 [ExpirationReaper-0-Heartbeat]: Shutdown completed
2024-12-31 21:07:26.431 [ExpirationReaper-0-Heartbeat]: Stopped
2024-12-31 21:07:26.431 [ExpirationReaper-0-Rebalance]: Shutting down
2024-12-31 21:07:26.431 [ExpirationReaper-0-Rebalance]: Stopped
2024-12-31 21:07:26.431 [ExpirationReaper-0-Rebalance]: Shutdown completed
2024-12-31 21:07:26.431 [GroupCoordinator 0]: Shutdown complete.
2024-12-31 21:07:26.431 [ReplicaManager broker=0] Shutting down
2024-12-31 21:07:26.431 [LogDirFailureHandler]: Shutting down
2024-12-31 21:07:26.431 [LogDirFailureHandler]: Shutdown completed
2024-12-31 21:07:26.431 [LogDirFailureHandler]: Stopped
2024-12-31 21:07:26.431 [ReplicaFetcherManager on broker 0] shutting down
2024-12-31 21:07:26.431 [ReplicaFetcherManager on broker 0] shutdown completed
2024-12-31 21:07:26.431 [ReplicaAlterLogDirsManager on broker 0] shutting down
2024-12-31 21:07:26.431 [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2024-12-31 21:07:26.431 [ExpirationReaper-0-Fetch]: Shutting down
2024-12-31 21:07:26.431 [ExpirationReaper-0-Fetch]: Stopped
2024-12-31 21:07:26.431 [ExpirationReaper-0-Fetch]: Shutdown completed
2024-12-31 21:07:26.433 [ExpirationReaper-0-Produce]: Shutting down
2024-12-31 21:07:26.433 [ExpirationReaper-0-Produce]: Stopped
2024-12-31 21:07:26.433 [ExpirationReaper-0-Produce]: Shutdown completed
2024-12-31 21:07:26.433 [ExpirationReaper-0-DeleteRecords]: Shutting down
2024-12-31 21:07:26.433 [ExpirationReaper-0-DeleteRecords]: Stopped
2024-12-31 21:07:26.433 [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2024-12-31 21:07:26.433 [ExpirationReaper-0-ElectLeader]: Shutting down
2024-12-31 21:07:26.433 [ExpirationReaper-0-ElectLeader]: Shutdown completed
2024-12-31 21:07:26.433 [ExpirationReaper-0-ElectLeader]: Stopped
2024-12-31 21:07:26.442 [ReplicaManager broker=0] Shut down completely
2024-12-31 21:07:26.442 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutting down
2024-12-31 21:07:26.442 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Stopped
2024-12-31 21:07:26.442 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutdown completed
2024-12-31 21:07:26.443 Broker to controller channel manager for alterPartition shutdown
2024-12-31 21:07:26.443 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down
2024-12-31 21:07:26.443 [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped
2024-12-31 21:07:26.443 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed
2024-12-31 21:07:26.443 Broker to controller channel manager for forwarding shutdown
2024-12-31 21:07:26.443 Shutting down.
2024-12-31 21:07:26.443 Shutting down the log cleaner.
2024-12-31 21:07:26.443 [kafka-log-cleaner-thread-0]: Shutting down
2024-12-31 21:07:26.444 [kafka-log-cleaner-thread-0]: Stopped
2024-12-31 21:07:26.444 [kafka-log-cleaner-thread-0]: Shutdown completed
2024-12-31 21:07:26.459 [ProducerStateManager partition=pong-message-topic-0] Wrote producer snapshot at offset 1 with 0 producer ids in 2 ms.
2024-12-31 21:07:26.472 [ProducerStateManager partition=__consumer_offsets-2] Wrote producer snapshot at offset 3 with 0 producer ids in 2 ms.
2024-12-31 21:07:26.482 Shutdown complete.
2024-12-31 21:07:26.482 [ControllerEventThread controllerId=0] Shutting down
2024-12-31 21:07:26.482 [ControllerEventThread controllerId=0] Stopped
2024-12-31 21:07:26.482 [ControllerEventThread controllerId=0] Shutdown completed
2024-12-31 21:07:26.483 [PartitionStateMachine controllerId=0] Stopped partition state machine
2024-12-31 21:07:26.483 [ReplicaStateMachine controllerId=0] Stopped replica state machine
2024-12-31 21:07:26.483 [RequestSendThread controllerId=0] Shutting down
2024-12-31 21:07:26.483 [RequestSendThread controllerId=0] Shutdown completed
2024-12-31 21:07:26.483 [RequestSendThread controllerId=0] Stopped
2024-12-31 21:07:26.484 [Controller id=0] Resigned
2024-12-31 21:07:26.484 [feature-zk-node-event-process-thread]: Shutting down
2024-12-31 21:07:26.484 [feature-zk-node-event-process-thread]: Stopped
2024-12-31 21:07:26.484 [feature-zk-node-event-process-thread]: Shutdown completed
2024-12-31 21:07:26.484 [ZooKeeperClient Kafka server] Closing.
2024-12-31 21:07:26.527 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:07:26.527 [Producer clientId=producer-2] Node 0 disconnected.
2024-12-31 21:07:26.527 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node 0 (localhost/127.0.0.1:59491) could not be established. Broker may not be available.
2024-12-31 21:07:26.527 [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:59491) could not be established. Broker may not be available.
2024-12-31 21:07:26.589 EventThread shut down for session: 0x100176f1c080000
2024-12-31 21:07:26.589 Session: 0x100176f1c080000 closed
2024-12-31 21:07:26.589 [ZooKeeperClient Kafka server] Closed.
2024-12-31 21:07:26.589 [ThrottledChannelReaper-Fetch]: Shutting down
2024-12-31 21:07:26.590 [ThrottledChannelReaper-Fetch]: Stopped
2024-12-31 21:07:26.590 [ThrottledChannelReaper-Fetch]: Shutdown completed
2024-12-31 21:07:26.590 [ThrottledChannelReaper-Produce]: Shutting down
2024-12-31 21:07:26.590 [ThrottledChannelReaper-Produce]: Shutdown completed
2024-12-31 21:07:26.590 [ThrottledChannelReaper-Produce]: Stopped
2024-12-31 21:07:26.590 [ThrottledChannelReaper-Request]: Shutting down
2024-12-31 21:07:26.590 [ThrottledChannelReaper-Request]: Stopped
2024-12-31 21:07:26.590 [ThrottledChannelReaper-Request]: Shutdown completed
2024-12-31 21:07:26.590 [ThrottledChannelReaper-ControllerMutation]: Shutting down
2024-12-31 21:07:26.590 [ThrottledChannelReaper-ControllerMutation]: Shutdown completed
2024-12-31 21:07:26.590 [ThrottledChannelReaper-ControllerMutation]: Stopped
2024-12-31 21:07:26.590 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server
2024-12-31 21:07:26.599 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed
2024-12-31 21:07:26.600 Metrics scheduler closed
2024-12-31 21:07:26.600 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:07:26.600 Metrics reporters closed
2024-12-31 21:07:26.600 Broker and topic stats closed
2024-12-31 21:07:26.600 App info kafka.server for 0 unregistered
2024-12-31 21:07:26.600 [KafkaServer id=0] shut down completed
2024-12-31 21:07:26.614 selector thread exitted run method
2024-12-31 21:07:26.614 selector thread exitted run method
2024-12-31 21:07:26.613 ConnnectionExpirerThread interrupted
2024-12-31 21:07:26.614 accept thread exitted run method
2024-12-31 21:07:26.614 shutting down
2024-12-31 21:07:26.614 Shutting down
2024-12-31 21:07:26.614 Draining request throttler queue
2024-12-31 21:07:26.615 RequestThrottler shutdown. Dropped 0 requests
2024-12-31 21:07:26.615 Shutting down
2024-12-31 21:07:26.615 Shutting down
2024-12-31 21:07:26.615 Shutting down
2024-12-31 21:07:26.615 PrepRequestProcessor exited loop!
2024-12-31 21:07:26.615 SyncRequestProcessor exited!
2024-12-31 21:07:26.615 shutdown of request processor complete
2024-12-31 21:07:26.631 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:07:26.631 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node 0 (localhost/127.0.0.1:59491) could not be established. Broker may not be available.
2024-12-31 21:07:26.631 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Revoke previously assigned partitions pong-message-topic-0, pong-message-topic-1
2024-12-31 21:07:26.631 pong-service: partitions revoked: [pong-message-topic-0, pong-message-topic-1]
2024-12-31 21:07:26.632 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:07:26.632 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:07:26.632 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Unsubscribed all topics or patterns and assigned partitions
2024-12-31 21:07:26.632 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:07:26.632 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:07:26.632 Metrics scheduler closed
2024-12-31 21:07:26.632 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:07:26.632 Metrics reporters closed
2024-12-31 21:07:26.632 App info kafka.consumer for consumer-pong-service-3 unregistered
2024-12-31 21:07:26.632 pong-service: Consumer stopped
2024-12-31 21:07:26.634 [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 30000 ms.
2024-12-31 21:07:26.634 Metrics scheduler closed
2024-12-31 21:07:26.634 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:07:26.635 Metrics reporters closed
2024-12-31 21:07:26.635 App info kafka.producer for producer-2 unregistered
2024-12-31 21:07:26.639 Closing JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:07:26.640 HikariPool-3 - Shutdown initiated...
2024-12-31 21:07:26.640 HikariPool-3 - Shutdown completed.
2024-12-31 21:07:26.689 SessionTrackerImpl exited loop!
2024-12-31 21:10:47.333 Could not detect default configuration classes for test class [com.demo.controller.PongControllerSpec]: PongControllerSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:10:47.516 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.controller.PongControllerSpec
2024-12-31 21:10:47.690 Could not detect default configuration classes for test class [com.demo.dao.MessageRepositorySpec]: MessageRepositorySpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:10:47.702 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.dao.MessageRepositorySpec
2024-12-31 21:10:47.726 Could not detect default configuration classes for test class [com.demo.kafka.KafkaSpec]: KafkaSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:10:47.751 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.kafka.KafkaSpec
2024-12-31 21:10:47.787 Could not detect default configuration classes for test class [com.demo.controller.PongControllerSpec]: PongControllerSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:10:47.790 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.controller.PongControllerSpec
2024-12-31 21:10:47.793 Could not detect default configuration classes for test class [com.demo.dao.MessageRepositorySpec]: MessageRepositorySpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:10:47.796 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.dao.MessageRepositorySpec
2024-12-31 21:10:47.796 Could not detect default configuration classes for test class [com.demo.kafka.KafkaSpec]: KafkaSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:10:47.796 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.kafka.KafkaSpec
2024-12-31 21:10:48.119 Registered kafka:type=kafka.Log4jController MBean
2024-12-31 21:10:48.194 
2024-12-31 21:10:48.194   ______                  _                                          
2024-12-31 21:10:48.194  |___  /                 | |                                         
2024-12-31 21:10:48.194     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __   
2024-12-31 21:10:48.194    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__|
2024-12-31 21:10:48.194   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |    
2024-12-31 21:10:48.194  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_|
2024-12-31 21:10:48.194                                               | |                     
2024-12-31 21:10:48.194                                               |_|                     
2024-12-31 21:10:48.194 
2024-12-31 21:10:53.571 Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT
2024-12-31 21:10:53.571 Server environment:host.name=Joe
2024-12-31 21:10:53.571 Server environment:java.version=17.0.12
2024-12-31 21:10:53.571 Server environment:java.vendor=Oracle Corporation
2024-12-31 21:10:53.571 Server environment:java.home=C:\work\jdk-17
2024-12-31 21:10:53.571 Server environment:java.class.path=C:\code\hsbc\demo\pong\target\test-classes;C:\code\hsbc\demo\pong\target\classes;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-webflux\3.1.4\spring-boot-starter-webflux-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter\3.1.4\spring-boot-starter-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot\3.1.4\spring-boot-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-autoconfigure\3.1.4\spring-boot-autoconfigure-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-logging\3.1.4\spring-boot-starter-logging-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\ch\qos\logback\logback-classic\1.4.11\logback-classic-1.4.11.jar;C:\work\apache-maven-3.8.8\repo\ch\qos\logback\logback-core\1.4.11\logback-core-1.4.11.jar;C:\work\apache-maven-3.8.8\repo\org\apache\logging\log4j\log4j-to-slf4j\2.20.0\log4j-to-slf4j-2.20.0.jar;C:\work\apache-maven-3.8.8\repo\org\apache\logging\log4j\log4j-api\2.20.0\log4j-api-2.20.0.jar;C:\work\apache-maven-3.8.8\repo\org\slf4j\jul-to-slf4j\2.0.9\jul-to-slf4j-2.0.9.jar;C:\work\apache-maven-3.8.8\repo\jakarta\annotation\jakarta.annotation-api\2.1.1\jakarta.annotation-api-2.1.1.jar;C:\work\apache-maven-3.8.8\repo\org\yaml\snakeyaml\1.33\snakeyaml-1.33.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-json\3.1.4\spring-boot-starter-json-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-databind\2.15.2\jackson-databind-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-annotations\2.15.2\jackson-annotations-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-core\2.15.2\jackson-core-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.15.2\jackson-datatype-jdk8-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.15.2\jackson-datatype-jsr310-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\module\jackson-module-parameter-names\2.15.2\jackson-module-parameter-names-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-reactor-netty\3.1.4\spring-boot-starter-reactor-netty-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\netty\reactor-netty-http\1.1.11\reactor-netty-http-1.1.11.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-http\4.1.97.Final\netty-codec-http-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-http2\4.1.97.Final\netty-codec-http2-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns\4.1.97.Final\netty-resolver-dns-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-dns\4.1.97.Final\netty-codec-dns-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns-native-macos\4.1.97.Final\netty-resolver-dns-native-macos-4.1.97.Final-osx-x86_64.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns-classes-macos\4.1.97.Final\netty-resolver-dns-classes-macos-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final-linux-x86_64.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\netty\reactor-netty-core\1.1.11\reactor-netty-core-1.1.11.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-handler-proxy\4.1.97.Final\netty-handler-proxy-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-socks\4.1.97.Final\netty-codec-socks-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-web\6.0.12\spring-web-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-beans\6.0.12\spring-beans-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-webflux\6.0.12\spring-webflux-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\reactor-core\3.5.10\reactor-core-3.5.10.jar;C:\work\apache-maven-3.8.8\repo\org\reactivestreams\reactive-streams\1.0.4\reactive-streams-1.0.4.jar;C:\work\apache-maven-3.8.8\repo\com\google\guava\guava\19.0\guava-19.0.jar;C:\work\apache-maven-3.8.8\repo\commons-io\commons-io\2.11.0\commons-io-2.11.0.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-data-redis\3.1.4\spring-boot-starter-data-redis-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-redis\3.1.4\spring-data-redis-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-keyvalue\3.1.4\spring-data-keyvalue-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-oxm\6.0.12\spring-oxm-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-aop\6.0.12\spring-aop-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-context-support\6.0.12\spring-context-support-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\io\lettuce\lettuce-core\6.2.6.RELEASE\lettuce-core-6.2.6.RELEASE.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-common\4.1.97.Final\netty-common-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-handler\4.1.97.Final\netty-handler-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver\4.1.97.Final\netty-resolver-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-buffer\4.1.97.Final\netty-buffer-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-unix-common\4.1.97.Final\netty-transport-native-unix-common-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec\4.1.97.Final\netty-codec-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport\4.1.97.Final\netty-transport-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-data-jpa\3.1.4\spring-boot-starter-data-jpa-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-aop\3.1.4\spring-boot-starter-aop-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\aspectj\aspectjweaver\1.9.20\aspectjweaver-1.9.20.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-jdbc\3.1.4\spring-boot-starter-jdbc-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\zaxxer\HikariCP\5.0.1\HikariCP-5.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-jdbc\6.0.12\spring-jdbc-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\hibernate\orm\hibernate-core\6.2.9.Final\hibernate-core-6.2.9.Final.jar;C:\work\apache-maven-3.8.8\repo\jakarta\persistence\jakarta.persistence-api\3.1.0\jakarta.persistence-api-3.1.0.jar;C:\work\apache-maven-3.8.8\repo\jakarta\transaction\jakarta.transaction-api\2.0.1\jakarta.transaction-api-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\jboss\logging\jboss-logging\3.5.3.Final\jboss-logging-3.5.3.Final.jar;C:\work\apache-maven-3.8.8\repo\org\hibernate\common\hibernate-commons-annotations\6.0.6.Final\hibernate-commons-annotations-6.0.6.Final.jar;C:\work\apache-maven-3.8.8\repo\io\smallrye\jandex\3.0.5\jandex-3.0.5.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\classmate\1.5.1\classmate-1.5.1.jar;C:\work\apache-maven-3.8.8\repo\net\bytebuddy\byte-buddy\1.14.8\byte-buddy-1.14.8.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\jaxb-runtime\4.0.3\jaxb-runtime-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\jaxb-core\4.0.3\jaxb-core-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\eclipse\angus\angus-activation\2.0.1\angus-activation-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\txw2\4.0.3\txw2-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\com\sun\istack\istack-commons-runtime\4.1.2\istack-commons-runtime-4.1.2.jar;C:\work\apache-maven-3.8.8\repo\jakarta\inject\jakarta.inject-api\2.0.1\jakarta.inject-api-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\antlr\antlr4-runtime\4.10.1\antlr4-runtime-4.10.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-jpa\3.1.4\spring-data-jpa-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-commons\3.1.4\spring-data-commons-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-orm\6.0.12\spring-orm-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-aspects\6.0.12\spring-aspects-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\postgresql\postgresql\42.6.0\postgresql-42.6.0.jar;C:\work\apache-maven-3.8.8\repo\org\checkerframework\checker-qual\3.31.0\checker-qual-3.31.0.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\kafka\spring-kafka\3.0.11\spring-kafka-3.0.11.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-context\6.0.12\spring-context-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-expression\6.0.12\spring-expression-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-messaging\6.0.12\spring-messaging-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-tx\6.0.12\spring-tx-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\retry\spring-retry\2.0.3\spring-retry-2.0.3.jar;C:\work\apache-maven-3.8.8\repo\io\micrometer\micrometer-observation\1.11.4\micrometer-observation-1.11.4.jar;C:\work\apache-maven-3.8.8\repo\io\micrometer\micrometer-commons\1.11.4\micrometer-commons-1.11.4.jar;C:\work\apache-maven-3.8.8\repo\com\google\code\findbugs\jsr305\3.0.2\jsr305-3.0.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\com\github\luben\zstd-jni\1.5.2-1\zstd-jni-1.5.2-1.jar;C:\work\apache-maven-3.8.8\repo\org\lz4\lz4-java\1.8.0\lz4-java-1.8.0.jar;C:\work\apache-maven-3.8.8\repo\org\xerial\snappy\snappy-java\1.1.8.4\snappy-java-1.1.8.4.jar;C:\work\apache-maven-3.8.8\repo\org\slf4j\slf4j-api\2.0.9\slf4j-api-2.0.9.jar;C:\work\apache-maven-3.8.8\repo\com\h2database\h2\1.4.200\h2-1.4.200.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-test\3.1.4\spring-boot-starter-test-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-test\3.1.4\spring-boot-test-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-test-autoconfigure\3.1.4\spring-boot-test-autoconfigure-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\jayway\jsonpath\json-path\2.8.0\json-path-2.8.0.jar;C:\work\apache-maven-3.8.8\repo\jakarta\xml\bind\jakarta.xml.bind-api\4.0.1\jakarta.xml.bind-api-4.0.1.jar;C:\work\apache-maven-3.8.8\repo\jakarta\activation\jakarta.activation-api\2.1.2\jakarta.activation-api-2.1.2.jar;C:\work\apache-maven-3.8.8\repo\net\minidev\json-smart\2.4.11\json-smart-2.4.11.jar;C:\work\apache-maven-3.8.8\repo\net\minidev\accessors-smart\2.4.11\accessors-smart-2.4.11.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm\9.3\asm-9.3.jar;C:\work\apache-maven-3.8.8\repo\org\assertj\assertj-core\3.24.2\assertj-core-3.24.2.jar;C:\work\apache-maven-3.8.8\repo\org\hamcrest\hamcrest\2.2\hamcrest-2.2.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter\5.9.3\junit-jupiter-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-params\5.9.3\junit-jupiter-params-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-engine\5.9.3\junit-jupiter-engine-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\mockito\mockito-core\5.3.1\mockito-core-5.3.1.jar;C:\work\apache-maven-3.8.8\repo\net\bytebuddy\byte-buddy-agent\1.14.8\byte-buddy-agent-1.14.8.jar;C:\work\apache-maven-3.8.8\repo\org\objenesis\objenesis\3.3\objenesis-3.3.jar;C:\work\apache-maven-3.8.8\repo\org\mockito\mockito-junit-jupiter\5.3.1\mockito-junit-jupiter-5.3.1.jar;C:\work\apache-maven-3.8.8\repo\org\skyscreamer\jsonassert\1.5.1\jsonassert-1.5.1.jar;C:\work\apache-maven-3.8.8\repo\com\vaadin\external\google\android-json\0.0.20131108.vaadin1\android-json-0.0.20131108.vaadin1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-core\6.0.12\spring-core-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-jcl\6.0.12\spring-jcl-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-test\6.0.12\spring-test-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\xmlunit\xmlunit-core\2.9.1\xmlunit-core-2.9.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy\4.0.15\groovy-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-ant\4.0.15\groovy-ant-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant\1.10.14\ant-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-junit\1.10.14\ant-junit-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-launcher\1.10.14\ant-launcher-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-antlr\1.10.14\ant-antlr-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-cli-picocli\4.0.15\groovy-cli-picocli-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\info\picocli\picocli\4.7.5\picocli-4.7.5.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-console\4.0.15\groovy-console-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\github\javaparser\javaparser-core\3.25.5\javaparser-core-3.25.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-util\9.5\asm-util-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-tree\9.5\asm-tree-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-analysis\9.5\asm-analysis-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\abego\treelayout\org.abego.treelayout.core\1.0.3\org.abego.treelayout.core-1.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ivy\ivy\2.5.2\ivy-2.5.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-datetime\4.0.15\groovy-datetime-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-docgenerator\4.0.15\groovy-docgenerator-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\thoughtworks\qdox\qdox\1.12.1\qdox-1.12.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-groovydoc\4.0.15\groovy-groovydoc-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-groovysh\4.0.15\groovy-groovysh-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\jline\jline\2.14.6\jline-2.14.6.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-jmx\4.0.15\groovy-jmx-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-json\4.0.15\groovy-json-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-jsr223\4.0.15\groovy-jsr223-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-macro\4.0.15\groovy-macro-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-nio\4.0.15\groovy-nio-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-servlet\4.0.15\groovy-servlet-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-sql\4.0.15\groovy-sql-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-swing\4.0.15\groovy-swing-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-templates\4.0.15\groovy-templates-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-test\4.0.15\groovy-test-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\junit\junit\4.13.2\junit-4.13.2.jar;C:\work\apache-maven-3.8.8\repo\org\hamcrest\hamcrest-core\2.2\hamcrest-core-2.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-test-junit5\4.0.15\groovy-test-junit5-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-xml\4.0.15\groovy-xml-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-yaml\4.0.15\groovy-yaml-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\dataformat\jackson-dataformat-yaml\2.15.2\jackson-dataformat-yaml-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\org\spockframework\spock-core\2.4-M1-groovy-4.0\spock-core-2.4-M1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-engine\1.9.3\junit-platform-engine-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\opentest4j\opentest4j\1.2.0\opentest4j-1.2.0.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-commons\1.9.3\junit-platform-commons-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\apiguardian\apiguardian-api\1.1.2\apiguardian-api-1.1.2.jar;C:\work\apache-maven-3.8.8\repo\org\spockframework\spock-spring\2.4-M1-groovy-4.0\spock-spring-2.4-M1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\com\athaydes\spock-reports\2.5.1-groovy-4.0\spock-reports-2.5.1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\com\github\codemonstur\embedded-redis\1.4.2\embedded-redis-1.4.2.jar;C:\work\apache-maven-3.8.8\repo\redis\clients\jedis\4.3.2\jedis-4.3.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\commons\commons-pool2\2.11.1\commons-pool2-2.11.1.jar;C:\work\apache-maven-3.8.8\repo\org\json\json\20220320\json-20220320.jar;C:\work\apache-maven-3.8.8\repo\com\google\code\gson\gson\2.10.1\gson-2.10.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\kafka\spring-kafka-test\3.0.11\spring-kafka-test-3.0.11.jar;C:\work\apache-maven-3.8.8\repo\org\apache\zookeeper\zookeeper\3.6.3\zookeeper-3.6.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\zookeeper\zookeeper-jute\3.6.3\zookeeper-jute-3.6.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-classes-epoll\4.1.97.Final\netty-transport-classes-epoll-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1-test.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-metadata\3.4.1\kafka-metadata-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-server-common\3.4.1\kafka-server-common-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-raft\3.4.1\kafka-raft-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-streams-test-utils\3.4.1\kafka-streams-test-utils-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-streams\3.4.1\kafka-streams-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\rocksdb\rocksdbjni\7.1.2\rocksdbjni-7.1.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\scala-library\2.13.10\scala-library-2.13.10.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-group-coordinator\3.4.1\kafka-group-coordinator-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-storage\3.4.1\kafka-storage-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-storage-api\3.4.1\kafka-storage-api-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\net\sourceforge\argparse4j\argparse4j\0.7.0\argparse4j-0.7.0.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\module\jackson-module-scala_2.13\2.15.2\jackson-module-scala_2.13-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\thoughtworks\paranamer\paranamer\2.8\paranamer-2.8.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\dataformat\jackson-dataformat-csv\2.15.2\jackson-dataformat-csv-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\net\sf\jopt-simple\jopt-simple\5.0.4\jopt-simple-5.0.4.jar;C:\work\apache-maven-3.8.8\repo\org\bitbucket\b_c\jose4j\0.9.3\jose4j-0.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\modules\scala-collection-compat_2.13\2.10.0\scala-collection-compat_2.13-2.10.0.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\modules\scala-java8-compat_2.13\1.0.2\scala-java8-compat_2.13-1.0.2.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\scala-reflect\2.13.10\scala-reflect-2.13.10.jar;C:\work\apache-maven-3.8.8\repo\com\typesafe\scala-logging\scala-logging_2.13\3.9.4\scala-logging_2.13-3.9.4.jar;C:\work\apache-maven-3.8.8\repo\io\dropwizard\metrics\metrics-core\4.2.19\metrics-core-4.2.19.jar;C:\work\apache-maven-3.8.8\repo\commons-cli\commons-cli\1.4\commons-cli-1.4.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1-test.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-api\5.9.3\junit-jupiter-api-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-launcher\1.9.3\junit-platform-launcher-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\awaitility\awaitility\4.2.0\awaitility-4.2.0.jar;
2024-12-31 21:10:53.573 Server environment:java.library.path=C:\work\jdk-17\bin;C:\windows\Sun\Java\bin;C:\windows\system32;C:\windows;C:\work\python312\Scripts\;C:\work\python312\;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program\Git\cmd;C:\Program\PowerShell\7\;C:\Program Files\dotnet\;C:\Users\joech\AppData\Local\Microsoft\WindowsApps;C:\Users\joech\AppData\Local\GitHubDesktop\bin;C:\Program\Microsoft VS Code\bin;C:\work\apache-maven-3.8.8\bin;C:\Program Files\Tesseract-OCR;C:\work\jdk-17\bin;;.
2024-12-31 21:10:53.573 Server environment:java.io.tmpdir=C:\Users\joech\AppData\Local\Temp\
2024-12-31 21:10:53.573 Server environment:java.compiler=<NA>
2024-12-31 21:10:53.573 Server environment:os.name=Windows 11
2024-12-31 21:10:53.573 Server environment:os.arch=amd64
2024-12-31 21:10:53.573 Server environment:os.version=10.0
2024-12-31 21:10:53.573 Server environment:user.name=joech
2024-12-31 21:10:53.573 Server environment:user.home=C:\Users\joech
2024-12-31 21:10:53.576 Server environment:user.dir=C:\code\hsbc\demo\pong
2024-12-31 21:10:53.576 Server environment:os.memory.free=72MB
2024-12-31 21:10:53.576 Server environment:os.memory.max=15816MB
2024-12-31 21:10:53.576 Server environment:os.memory.total=136MB
2024-12-31 21:10:53.576 zookeeper.enableEagerACLCheck = false
2024-12-31 21:10:53.576 zookeeper.digest.enabled = true
2024-12-31 21:10:53.576 zookeeper.closeSessionTxn.enabled = true
2024-12-31 21:10:53.576 zookeeper.flushDelay=0
2024-12-31 21:10:53.576 zookeeper.maxWriteQueuePollTime=0
2024-12-31 21:10:53.576 zookeeper.maxBatchSize=1000
2024-12-31 21:10:53.576 zookeeper.intBufferStartingSizeBytes = 1024
2024-12-31 21:10:53.582 zookeeper.snapshot.trust.empty : false
2024-12-31 21:10:53.603 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:10:53.603 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:10:53.603 zookeeper.snapshotSizeFactor = 0.33
2024-12-31 21:10:53.603 zookeeper.commitLogCount=500
2024-12-31 21:10:53.610 Weighed connection throttling is disabled
2024-12-31 21:10:53.610 minSessionTimeout set to 1600
2024-12-31 21:10:53.610 maxSessionTimeout set to 16000
2024-12-31 21:10:53.610 Response cache size is initialized with value 400.
2024-12-31 21:10:53.610 Response cache size is initialized with value 400.
2024-12-31 21:10:53.619 zookeeper.pathStats.slotCapacity = 60
2024-12-31 21:10:53.619 zookeeper.pathStats.slotDuration = 15
2024-12-31 21:10:53.619 zookeeper.pathStats.maxDepth = 6
2024-12-31 21:10:53.619 zookeeper.pathStats.initialDelay = 5
2024-12-31 21:10:53.619 zookeeper.pathStats.delay = 5
2024-12-31 21:10:53.619 zookeeper.pathStats.enabled = false
2024-12-31 21:10:53.619 The max bytes for all large requests are set to 104857600
2024-12-31 21:10:53.619 The large request threshold is set to -1
2024-12-31 21:10:53.619 Created server with tickTime 800 minSessionTimeout 1600 maxSessionTimeout 16000 clientPortListenBacklog -1 datadir C:\Users\joech\AppData\Local\Temp\kafka-6445923068857443062\version-2 snapdir C:\Users\joech\AppData\Local\Temp\kafka-215405280700017222\version-2
2024-12-31 21:10:53.670 maxCnxns is not configured, using default value 0.
2024-12-31 21:10:53.670 Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers.
2024-12-31 21:10:53.682 binding to port /127.0.0.1:0
2024-12-31 21:10:53.702 zookeeper.snapshot.compression.method = CHECKED
2024-12-31 21:10:53.703 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-215405280700017222\version-2\snapshot.0
2024-12-31 21:10:53.709 Snapshot loaded in 23 ms, highest zxid is 0x0, digest is 1371985504
2024-12-31 21:10:53.709 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-215405280700017222\version-2\snapshot.0
2024-12-31 21:10:53.710 Snapshot taken in 1 ms
2024-12-31 21:10:53.723 zookeeper.request_throttler.shutdownTimeout = 10000
2024-12-31 21:10:53.723 PrepRequestProcessor (sid:0) started, reconfigEnabled=false
2024-12-31 21:10:54.050 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.f6e1f35e-e0df-4070-8dd3-92a87bf0d9c711951431596782478271
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59521
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:10:54.089 Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
2024-12-31 21:10:54.176 starting
2024-12-31 21:10:54.176 Connecting to zookeeper on 127.0.0.1:59521
2024-12-31 21:10:54.195 [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:59521.
2024-12-31 21:10:59.433 Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT
2024-12-31 21:10:59.434 Client environment:host.name=Joe
2024-12-31 21:10:59.435 Client environment:java.version=17.0.12
2024-12-31 21:10:59.435 Client environment:java.vendor=Oracle Corporation
2024-12-31 21:10:59.435 Client environment:java.home=C:\work\jdk-17
2024-12-31 21:10:59.435 Client environment:java.class.path=C:\code\hsbc\demo\pong\target\test-classes;C:\code\hsbc\demo\pong\target\classes;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-webflux\3.1.4\spring-boot-starter-webflux-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter\3.1.4\spring-boot-starter-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot\3.1.4\spring-boot-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-autoconfigure\3.1.4\spring-boot-autoconfigure-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-logging\3.1.4\spring-boot-starter-logging-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\ch\qos\logback\logback-classic\1.4.11\logback-classic-1.4.11.jar;C:\work\apache-maven-3.8.8\repo\ch\qos\logback\logback-core\1.4.11\logback-core-1.4.11.jar;C:\work\apache-maven-3.8.8\repo\org\apache\logging\log4j\log4j-to-slf4j\2.20.0\log4j-to-slf4j-2.20.0.jar;C:\work\apache-maven-3.8.8\repo\org\apache\logging\log4j\log4j-api\2.20.0\log4j-api-2.20.0.jar;C:\work\apache-maven-3.8.8\repo\org\slf4j\jul-to-slf4j\2.0.9\jul-to-slf4j-2.0.9.jar;C:\work\apache-maven-3.8.8\repo\jakarta\annotation\jakarta.annotation-api\2.1.1\jakarta.annotation-api-2.1.1.jar;C:\work\apache-maven-3.8.8\repo\org\yaml\snakeyaml\1.33\snakeyaml-1.33.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-json\3.1.4\spring-boot-starter-json-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-databind\2.15.2\jackson-databind-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-annotations\2.15.2\jackson-annotations-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-core\2.15.2\jackson-core-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.15.2\jackson-datatype-jdk8-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.15.2\jackson-datatype-jsr310-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\module\jackson-module-parameter-names\2.15.2\jackson-module-parameter-names-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-reactor-netty\3.1.4\spring-boot-starter-reactor-netty-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\netty\reactor-netty-http\1.1.11\reactor-netty-http-1.1.11.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-http\4.1.97.Final\netty-codec-http-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-http2\4.1.97.Final\netty-codec-http2-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns\4.1.97.Final\netty-resolver-dns-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-dns\4.1.97.Final\netty-codec-dns-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns-native-macos\4.1.97.Final\netty-resolver-dns-native-macos-4.1.97.Final-osx-x86_64.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns-classes-macos\4.1.97.Final\netty-resolver-dns-classes-macos-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final-linux-x86_64.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\netty\reactor-netty-core\1.1.11\reactor-netty-core-1.1.11.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-handler-proxy\4.1.97.Final\netty-handler-proxy-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-socks\4.1.97.Final\netty-codec-socks-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-web\6.0.12\spring-web-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-beans\6.0.12\spring-beans-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-webflux\6.0.12\spring-webflux-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\reactor-core\3.5.10\reactor-core-3.5.10.jar;C:\work\apache-maven-3.8.8\repo\org\reactivestreams\reactive-streams\1.0.4\reactive-streams-1.0.4.jar;C:\work\apache-maven-3.8.8\repo\com\google\guava\guava\19.0\guava-19.0.jar;C:\work\apache-maven-3.8.8\repo\commons-io\commons-io\2.11.0\commons-io-2.11.0.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-data-redis\3.1.4\spring-boot-starter-data-redis-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-redis\3.1.4\spring-data-redis-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-keyvalue\3.1.4\spring-data-keyvalue-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-oxm\6.0.12\spring-oxm-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-aop\6.0.12\spring-aop-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-context-support\6.0.12\spring-context-support-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\io\lettuce\lettuce-core\6.2.6.RELEASE\lettuce-core-6.2.6.RELEASE.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-common\4.1.97.Final\netty-common-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-handler\4.1.97.Final\netty-handler-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver\4.1.97.Final\netty-resolver-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-buffer\4.1.97.Final\netty-buffer-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-unix-common\4.1.97.Final\netty-transport-native-unix-common-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec\4.1.97.Final\netty-codec-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport\4.1.97.Final\netty-transport-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-data-jpa\3.1.4\spring-boot-starter-data-jpa-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-aop\3.1.4\spring-boot-starter-aop-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\aspectj\aspectjweaver\1.9.20\aspectjweaver-1.9.20.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-jdbc\3.1.4\spring-boot-starter-jdbc-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\zaxxer\HikariCP\5.0.1\HikariCP-5.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-jdbc\6.0.12\spring-jdbc-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\hibernate\orm\hibernate-core\6.2.9.Final\hibernate-core-6.2.9.Final.jar;C:\work\apache-maven-3.8.8\repo\jakarta\persistence\jakarta.persistence-api\3.1.0\jakarta.persistence-api-3.1.0.jar;C:\work\apache-maven-3.8.8\repo\jakarta\transaction\jakarta.transaction-api\2.0.1\jakarta.transaction-api-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\jboss\logging\jboss-logging\3.5.3.Final\jboss-logging-3.5.3.Final.jar;C:\work\apache-maven-3.8.8\repo\org\hibernate\common\hibernate-commons-annotations\6.0.6.Final\hibernate-commons-annotations-6.0.6.Final.jar;C:\work\apache-maven-3.8.8\repo\io\smallrye\jandex\3.0.5\jandex-3.0.5.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\classmate\1.5.1\classmate-1.5.1.jar;C:\work\apache-maven-3.8.8\repo\net\bytebuddy\byte-buddy\1.14.8\byte-buddy-1.14.8.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\jaxb-runtime\4.0.3\jaxb-runtime-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\jaxb-core\4.0.3\jaxb-core-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\eclipse\angus\angus-activation\2.0.1\angus-activation-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\txw2\4.0.3\txw2-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\com\sun\istack\istack-commons-runtime\4.1.2\istack-commons-runtime-4.1.2.jar;C:\work\apache-maven-3.8.8\repo\jakarta\inject\jakarta.inject-api\2.0.1\jakarta.inject-api-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\antlr\antlr4-runtime\4.10.1\antlr4-runtime-4.10.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-jpa\3.1.4\spring-data-jpa-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-commons\3.1.4\spring-data-commons-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-orm\6.0.12\spring-orm-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-aspects\6.0.12\spring-aspects-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\postgresql\postgresql\42.6.0\postgresql-42.6.0.jar;C:\work\apache-maven-3.8.8\repo\org\checkerframework\checker-qual\3.31.0\checker-qual-3.31.0.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\kafka\spring-kafka\3.0.11\spring-kafka-3.0.11.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-context\6.0.12\spring-context-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-expression\6.0.12\spring-expression-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-messaging\6.0.12\spring-messaging-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-tx\6.0.12\spring-tx-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\retry\spring-retry\2.0.3\spring-retry-2.0.3.jar;C:\work\apache-maven-3.8.8\repo\io\micrometer\micrometer-observation\1.11.4\micrometer-observation-1.11.4.jar;C:\work\apache-maven-3.8.8\repo\io\micrometer\micrometer-commons\1.11.4\micrometer-commons-1.11.4.jar;C:\work\apache-maven-3.8.8\repo\com\google\code\findbugs\jsr305\3.0.2\jsr305-3.0.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\com\github\luben\zstd-jni\1.5.2-1\zstd-jni-1.5.2-1.jar;C:\work\apache-maven-3.8.8\repo\org\lz4\lz4-java\1.8.0\lz4-java-1.8.0.jar;C:\work\apache-maven-3.8.8\repo\org\xerial\snappy\snappy-java\1.1.8.4\snappy-java-1.1.8.4.jar;C:\work\apache-maven-3.8.8\repo\org\slf4j\slf4j-api\2.0.9\slf4j-api-2.0.9.jar;C:\work\apache-maven-3.8.8\repo\com\h2database\h2\1.4.200\h2-1.4.200.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-test\3.1.4\spring-boot-starter-test-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-test\3.1.4\spring-boot-test-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-test-autoconfigure\3.1.4\spring-boot-test-autoconfigure-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\jayway\jsonpath\json-path\2.8.0\json-path-2.8.0.jar;C:\work\apache-maven-3.8.8\repo\jakarta\xml\bind\jakarta.xml.bind-api\4.0.1\jakarta.xml.bind-api-4.0.1.jar;C:\work\apache-maven-3.8.8\repo\jakarta\activation\jakarta.activation-api\2.1.2\jakarta.activation-api-2.1.2.jar;C:\work\apache-maven-3.8.8\repo\net\minidev\json-smart\2.4.11\json-smart-2.4.11.jar;C:\work\apache-maven-3.8.8\repo\net\minidev\accessors-smart\2.4.11\accessors-smart-2.4.11.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm\9.3\asm-9.3.jar;C:\work\apache-maven-3.8.8\repo\org\assertj\assertj-core\3.24.2\assertj-core-3.24.2.jar;C:\work\apache-maven-3.8.8\repo\org\hamcrest\hamcrest\2.2\hamcrest-2.2.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter\5.9.3\junit-jupiter-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-params\5.9.3\junit-jupiter-params-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-engine\5.9.3\junit-jupiter-engine-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\mockito\mockito-core\5.3.1\mockito-core-5.3.1.jar;C:\work\apache-maven-3.8.8\repo\net\bytebuddy\byte-buddy-agent\1.14.8\byte-buddy-agent-1.14.8.jar;C:\work\apache-maven-3.8.8\repo\org\objenesis\objenesis\3.3\objenesis-3.3.jar;C:\work\apache-maven-3.8.8\repo\org\mockito\mockito-junit-jupiter\5.3.1\mockito-junit-jupiter-5.3.1.jar;C:\work\apache-maven-3.8.8\repo\org\skyscreamer\jsonassert\1.5.1\jsonassert-1.5.1.jar;C:\work\apache-maven-3.8.8\repo\com\vaadin\external\google\android-json\0.0.20131108.vaadin1\android-json-0.0.20131108.vaadin1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-core\6.0.12\spring-core-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-jcl\6.0.12\spring-jcl-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-test\6.0.12\spring-test-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\xmlunit\xmlunit-core\2.9.1\xmlunit-core-2.9.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy\4.0.15\groovy-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-ant\4.0.15\groovy-ant-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant\1.10.14\ant-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-junit\1.10.14\ant-junit-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-launcher\1.10.14\ant-launcher-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-antlr\1.10.14\ant-antlr-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-cli-picocli\4.0.15\groovy-cli-picocli-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\info\picocli\picocli\4.7.5\picocli-4.7.5.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-console\4.0.15\groovy-console-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\github\javaparser\javaparser-core\3.25.5\javaparser-core-3.25.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-util\9.5\asm-util-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-tree\9.5\asm-tree-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-analysis\9.5\asm-analysis-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\abego\treelayout\org.abego.treelayout.core\1.0.3\org.abego.treelayout.core-1.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ivy\ivy\2.5.2\ivy-2.5.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-datetime\4.0.15\groovy-datetime-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-docgenerator\4.0.15\groovy-docgenerator-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\thoughtworks\qdox\qdox\1.12.1\qdox-1.12.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-groovydoc\4.0.15\groovy-groovydoc-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-groovysh\4.0.15\groovy-groovysh-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\jline\jline\2.14.6\jline-2.14.6.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-jmx\4.0.15\groovy-jmx-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-json\4.0.15\groovy-json-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-jsr223\4.0.15\groovy-jsr223-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-macro\4.0.15\groovy-macro-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-nio\4.0.15\groovy-nio-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-servlet\4.0.15\groovy-servlet-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-sql\4.0.15\groovy-sql-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-swing\4.0.15\groovy-swing-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-templates\4.0.15\groovy-templates-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-test\4.0.15\groovy-test-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\junit\junit\4.13.2\junit-4.13.2.jar;C:\work\apache-maven-3.8.8\repo\org\hamcrest\hamcrest-core\2.2\hamcrest-core-2.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-test-junit5\4.0.15\groovy-test-junit5-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-xml\4.0.15\groovy-xml-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-yaml\4.0.15\groovy-yaml-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\dataformat\jackson-dataformat-yaml\2.15.2\jackson-dataformat-yaml-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\org\spockframework\spock-core\2.4-M1-groovy-4.0\spock-core-2.4-M1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-engine\1.9.3\junit-platform-engine-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\opentest4j\opentest4j\1.2.0\opentest4j-1.2.0.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-commons\1.9.3\junit-platform-commons-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\apiguardian\apiguardian-api\1.1.2\apiguardian-api-1.1.2.jar;C:\work\apache-maven-3.8.8\repo\org\spockframework\spock-spring\2.4-M1-groovy-4.0\spock-spring-2.4-M1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\com\athaydes\spock-reports\2.5.1-groovy-4.0\spock-reports-2.5.1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\com\github\codemonstur\embedded-redis\1.4.2\embedded-redis-1.4.2.jar;C:\work\apache-maven-3.8.8\repo\redis\clients\jedis\4.3.2\jedis-4.3.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\commons\commons-pool2\2.11.1\commons-pool2-2.11.1.jar;C:\work\apache-maven-3.8.8\repo\org\json\json\20220320\json-20220320.jar;C:\work\apache-maven-3.8.8\repo\com\google\code\gson\gson\2.10.1\gson-2.10.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\kafka\spring-kafka-test\3.0.11\spring-kafka-test-3.0.11.jar;C:\work\apache-maven-3.8.8\repo\org\apache\zookeeper\zookeeper\3.6.3\zookeeper-3.6.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\zookeeper\zookeeper-jute\3.6.3\zookeeper-jute-3.6.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-classes-epoll\4.1.97.Final\netty-transport-classes-epoll-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1-test.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-metadata\3.4.1\kafka-metadata-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-server-common\3.4.1\kafka-server-common-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-raft\3.4.1\kafka-raft-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-streams-test-utils\3.4.1\kafka-streams-test-utils-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-streams\3.4.1\kafka-streams-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\rocksdb\rocksdbjni\7.1.2\rocksdbjni-7.1.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\scala-library\2.13.10\scala-library-2.13.10.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-group-coordinator\3.4.1\kafka-group-coordinator-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-storage\3.4.1\kafka-storage-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-storage-api\3.4.1\kafka-storage-api-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\net\sourceforge\argparse4j\argparse4j\0.7.0\argparse4j-0.7.0.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\module\jackson-module-scala_2.13\2.15.2\jackson-module-scala_2.13-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\thoughtworks\paranamer\paranamer\2.8\paranamer-2.8.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\dataformat\jackson-dataformat-csv\2.15.2\jackson-dataformat-csv-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\net\sf\jopt-simple\jopt-simple\5.0.4\jopt-simple-5.0.4.jar;C:\work\apache-maven-3.8.8\repo\org\bitbucket\b_c\jose4j\0.9.3\jose4j-0.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\modules\scala-collection-compat_2.13\2.10.0\scala-collection-compat_2.13-2.10.0.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\modules\scala-java8-compat_2.13\1.0.2\scala-java8-compat_2.13-1.0.2.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\scala-reflect\2.13.10\scala-reflect-2.13.10.jar;C:\work\apache-maven-3.8.8\repo\com\typesafe\scala-logging\scala-logging_2.13\3.9.4\scala-logging_2.13-3.9.4.jar;C:\work\apache-maven-3.8.8\repo\io\dropwizard\metrics\metrics-core\4.2.19\metrics-core-4.2.19.jar;C:\work\apache-maven-3.8.8\repo\commons-cli\commons-cli\1.4\commons-cli-1.4.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1-test.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-api\5.9.3\junit-jupiter-api-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-launcher\1.9.3\junit-platform-launcher-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\awaitility\awaitility\4.2.0\awaitility-4.2.0.jar;
2024-12-31 21:10:59.439 Client environment:java.library.path=C:\work\jdk-17\bin;C:\windows\Sun\Java\bin;C:\windows\system32;C:\windows;C:\work\python312\Scripts\;C:\work\python312\;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program\Git\cmd;C:\Program\PowerShell\7\;C:\Program Files\dotnet\;C:\Users\joech\AppData\Local\Microsoft\WindowsApps;C:\Users\joech\AppData\Local\GitHubDesktop\bin;C:\Program\Microsoft VS Code\bin;C:\work\apache-maven-3.8.8\bin;C:\Program Files\Tesseract-OCR;C:\work\jdk-17\bin;;.
2024-12-31 21:10:59.439 Client environment:java.io.tmpdir=C:\Users\joech\AppData\Local\Temp\
2024-12-31 21:10:59.439 Client environment:java.compiler=<NA>
2024-12-31 21:10:59.439 Client environment:os.name=Windows 11
2024-12-31 21:10:59.439 Client environment:os.arch=amd64
2024-12-31 21:10:59.439 Client environment:os.version=10.0
2024-12-31 21:10:59.439 Client environment:user.name=joech
2024-12-31 21:10:59.439 Client environment:user.home=C:\Users\joech
2024-12-31 21:10:59.439 Client environment:user.dir=C:\code\hsbc\demo\pong
2024-12-31 21:10:59.439 Client environment:os.memory.free=519MB
2024-12-31 21:10:59.439 Client environment:os.memory.max=15816MB
2024-12-31 21:10:59.439 Client environment:os.memory.total=568MB
2024-12-31 21:10:59.446 Initiating client connection, connectString=127.0.0.1:59521 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@3bc2146c
2024-12-31 21:10:59.452 jute.maxbuffer value is 4194304 Bytes
2024-12-31 21:10:59.461 zookeeper.request.timeout value is 0. feature enabled=false
2024-12-31 21:10:59.463 [ZooKeeperClient Kafka server] Waiting until connected.
2024-12-31 21:10:59.464 Opening socket connection to server /127.0.0.1:59521.
2024-12-31 21:10:59.466 Socket connection established, initiating session, client: /127.0.0.1:59522, server: /127.0.0.1:59521
2024-12-31 21:10:59.476 Creating new log file: log.1
2024-12-31 21:10:59.492 ZooKeeper audit is disabled.
2024-12-31 21:10:59.497 Session establishment complete on server /127.0.0.1:59521, session id = 0x10017724ad00000, negotiated timeout = 16000
2024-12-31 21:10:59.502 [ZooKeeperClient Kafka server] Connected.
2024-12-31 21:10:59.997 Cluster ID = j_BKNdxkQx-naWEwRZNqVw
2024-12-31 21:11:00.003 No meta.properties file under dir C:\Users\joech\AppData\Local\Temp\spring.kafka.f6e1f35e-e0df-4070-8dd3-92a87bf0d9c711951431596782478271\meta.properties
2024-12-31 21:11:00.073 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.f6e1f35e-e0df-4070-8dd3-92a87bf0d9c711951431596782478271
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59521
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:11:00.120 [ThrottledChannelReaper-Fetch]: Starting
2024-12-31 21:11:00.120 [ThrottledChannelReaper-Produce]: Starting
2024-12-31 21:11:00.122 [ThrottledChannelReaper-Request]: Starting
2024-12-31 21:11:00.127 [ThrottledChannelReaper-ControllerMutation]: Starting
2024-12-31 21:11:00.173 Loading logs from log dirs ArraySeq(C:\Users\joech\AppData\Local\Temp\spring.kafka.f6e1f35e-e0df-4070-8dd3-92a87bf0d9c711951431596782478271)
2024-12-31 21:11:00.176 Attempting recovery for all logs in C:\Users\joech\AppData\Local\Temp\spring.kafka.f6e1f35e-e0df-4070-8dd3-92a87bf0d9c711951431596782478271 since no clean shutdown file was found
2024-12-31 21:11:00.190 Loaded 0 logs in 17ms.
2024-12-31 21:11:00.191 Starting log cleanup with a period of 300000 ms.
2024-12-31 21:11:00.194 Starting log flusher with a default period of 9223372036854775807 ms.
2024-12-31 21:11:00.214 Starting the log cleaner
2024-12-31 21:11:00.232 [kafka-log-cleaner-thread-0]: Starting
2024-12-31 21:11:00.258 [feature-zk-node-event-process-thread]: Starting
2024-12-31 21:11:00.275 Feature ZK node at path: /feature does not exist
2024-12-31 21:11:00.329 [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting
2024-12-31 21:11:00.865 Updated connection-accept-rate max connection creation rate to 2147483647
2024-12-31 21:11:00.875 Awaiting socket connections on localhost:59523.
2024-12-31 21:11:00.910 [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT)
2024-12-31 21:11:00.921 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Starting
2024-12-31 21:11:00.943 [ExpirationReaper-0-Produce]: Starting
2024-12-31 21:11:00.944 [ExpirationReaper-0-Fetch]: Starting
2024-12-31 21:11:00.945 [ExpirationReaper-0-DeleteRecords]: Starting
2024-12-31 21:11:00.946 [ExpirationReaper-0-ElectLeader]: Starting
2024-12-31 21:11:00.966 [LogDirFailureHandler]: Starting
2024-12-31 21:11:00.989 Creating /brokers/ids/0 (is it secure? false)
2024-12-31 21:11:01.011 Stat of the created znode at /brokers/ids/0 is: 25,25,1735650661002,1735650661002,1,0,0,72083373686784000,204,0,25

2024-12-31 21:11:01.013 Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:59523, czxid (broker epoch): 25
2024-12-31 21:11:01.090 [ControllerEventThread controllerId=0] Starting
2024-12-31 21:11:01.097 [ExpirationReaper-0-topic]: Starting
2024-12-31 21:11:01.109 [ExpirationReaper-0-Rebalance]: Starting
2024-12-31 21:11:01.108 [ExpirationReaper-0-Heartbeat]: Starting
2024-12-31 21:11:01.118 Successfully created /controller_epoch with initial epoch 0
2024-12-31 21:11:01.124 [Controller id=0] 0 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1
2024-12-31 21:11:01.130 [Controller id=0] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map())
2024-12-31 21:11:01.134 Feature ZK node created at path: /feature
2024-12-31 21:11:01.135 [GroupCoordinator 0]: Starting up.
2024-12-31 21:11:01.142 [GroupCoordinator 0]: Startup complete.
2024-12-31 21:11:01.167 [TransactionCoordinator id=0] Starting up.
2024-12-31 21:11:01.172 [Transaction Marker Channel Manager 0]: Starting
2024-12-31 21:11:01.172 [TransactionCoordinator id=0] Startup complete.
2024-12-31 21:11:01.178 [Controller id=0] Registering handlers
2024-12-31 21:11:01.178 [MetadataCache brokerId=0] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0).
2024-12-31 21:11:01.181 [Controller id=0] Deleting log dir event notifications
2024-12-31 21:11:01.184 [Controller id=0] Deleting isr change notifications
2024-12-31 21:11:01.187 [Controller id=0] Initializing controller context
2024-12-31 21:11:01.211 [Controller id=0] Initialized broker epochs cache: HashMap(0 -> 25)
2024-12-31 21:11:01.216 [ExpirationReaper-0-AlterAcls]: Starting
2024-12-31 21:11:01.234 [RequestSendThread controllerId=0] Starting
2024-12-31 21:11:01.236 [Controller id=0] Currently active brokers in the cluster: Set(0)
2024-12-31 21:11:01.236 [Controller id=0] Currently shutting brokers in the cluster: HashSet()
2024-12-31 21:11:01.237 [Controller id=0] Current list of topics in the cluster: HashSet()
2024-12-31 21:11:01.237 [Controller id=0] Fetching topic deletions in progress
2024-12-31 21:11:01.241 [Controller id=0] List of topics to be deleted: 
2024-12-31 21:11:01.241 [Controller id=0] List of topics ineligible for deletion: 
2024-12-31 21:11:01.241 [Controller id=0] Initializing topic deletion manager
2024-12-31 21:11:01.243 [Topic Deletion Manager 0] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet()
2024-12-31 21:11:01.245 [Controller id=0] Sending update metadata request
2024-12-31 21:11:01.249 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions
2024-12-31 21:11:01.258 [ReplicaStateMachine controllerId=0] Initializing replica state
2024-12-31 21:11:01.258 [/config/changes-event-process-thread]: Starting
2024-12-31 21:11:01.259 [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2024-12-31 21:11:01.272 [ReplicaStateMachine controllerId=0] Triggering offline replica state changes
2024-12-31 21:11:01.273 [PartitionStateMachine controllerId=0] Initializing partition state
2024-12-31 21:11:01.273 [PartitionStateMachine controllerId=0] Triggering online partition state changes
2024-12-31 21:11:01.276 [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing.
2024-12-31 21:11:01.278 [RequestSendThread controllerId=0] Controller 0 connected to localhost:59523 (id: 0 rack: null) for sending state change requests
2024-12-31 21:11:01.279 [Controller id=0] Ready to serve as the new controller with epoch 1
2024-12-31 21:11:01.282 Kafka version: 3.4.1
2024-12-31 21:11:01.282 Kafka commitId: 8a516edc2755df89
2024-12-31 21:11:01.282 Kafka startTimeMs: 1735650661280
2024-12-31 21:11:01.284 [KafkaServer id=0] started
2024-12-31 21:11:01.286 [Controller id=0] Partitions undergoing preferred replica election: 
2024-12-31 21:11:01.287 [Controller id=0] Partitions that completed preferred replica election: 
2024-12-31 21:11:01.288 [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2024-12-31 21:11:01.288 [Controller id=0] Resuming preferred replica election for partitions: 
2024-12-31 21:11:01.291 [Controller id=0] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered
2024-12-31 21:11:01.298 AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [127.0.0.1:59523]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-31 21:11:01.308 [Controller id=0] Starting the controller scheduler
2024-12-31 21:11:01.348 Kafka version: 3.4.1
2024-12-31 21:11:01.348 Kafka commitId: 8a516edc2755df89
2024-12-31 21:11:01.348 Kafka startTimeMs: 1735650661348
2024-12-31 21:11:01.425 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Recorded new controller, from now on will use node localhost:59523 (id: 0 rack: null)
2024-12-31 21:11:01.443 [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use node localhost:59523 (id: 0 rack: null)
2024-12-31 21:11:01.475 Creating topic pong-message-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0))
2024-12-31 21:11:01.504 [Controller id=0] New topics: [Set(pong-message-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(pong-message-topic,Some(RaEWstfGSiiC7HGKGzUZxA),Map(pong-message-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), pong-message-topic-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:11:01.506 [Controller id=0] New partition creation callback for pong-message-topic-0,pong-message-topic-1
2024-12-31 21:11:01.510 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:11:01.510 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:11:01.510 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:11:01.515 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:11:01.546 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:11:01.546 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:11:01.549 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2024-12-31 21:11:01.552 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2024-12-31 21:11:01.553 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:11:01.558 [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 for 2 partitions
2024-12-31 21:11:01.602 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(pong-message-topic-0, pong-message-topic-1)
2024-12-31 21:11:01.603 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2024-12-31 21:11:01.710 [LogLoader partition=pong-message-topic-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.f6e1f35e-e0df-4070-8dd3-92a87bf0d9c711951431596782478271] Loading producer state till offset 0 with message format version 2
2024-12-31 21:11:01.733 Created log for partition pong-message-topic-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.f6e1f35e-e0df-4070-8dd3-92a87bf0d9c711951431596782478271\pong-message-topic-0 with properties {}
2024-12-31 21:11:01.734 [Partition pong-message-topic-0 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-0
2024-12-31 21:11:01.735 [Partition pong-message-topic-0 broker=0] Log loaded for partition pong-message-topic-0 with initial high watermark 0
2024-12-31 21:11:01.737 [Broker id=0] Leader pong-message-topic-0 with topic id Some(RaEWstfGSiiC7HGKGzUZxA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:11:01.757 [LogLoader partition=pong-message-topic-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.f6e1f35e-e0df-4070-8dd3-92a87bf0d9c711951431596782478271] Loading producer state till offset 0 with message format version 2
2024-12-31 21:11:01.758 Created log for partition pong-message-topic-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.f6e1f35e-e0df-4070-8dd3-92a87bf0d9c711951431596782478271\pong-message-topic-1 with properties {}
2024-12-31 21:11:01.758 [Partition pong-message-topic-1 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-1
2024-12-31 21:11:01.758 [Partition pong-message-topic-1 broker=0] Log loaded for partition pong-message-topic-1 with initial high watermark 0
2024-12-31 21:11:01.758 [Broker id=0] Leader pong-message-topic-1 with topic id Some(RaEWstfGSiiC7HGKGzUZxA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:11:01.769 [Broker id=0] Finished LeaderAndIsr request in 213ms correlationId 1 from controller 0 for 2 partitions
2024-12-31 21:11:01.778 [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2
2024-12-31 21:11:01.786 App info kafka.admin.client for adminclient-1 unregistered
2024-12-31 21:11:01.789 Metrics scheduler closed
2024-12-31 21:11:01.789 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:11:01.789 Metrics reporters closed
2024-12-31 21:11:02.144 

Found multiple occurrences of org.json.JSONObject on the class path:

	jar:file:/C:/work/apache-maven-3.8.8/repo/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar!/org/json/JSONObject.class
	jar:file:/C:/work/apache-maven-3.8.8/repo/org/json/json/20220320/json-20220320.jar!/org/json/JSONObject.class

You may wish to exclude one of them to ensure predictable runtime behavior

2024-12-31 21:11:02.165 zookeeper.snapshot.trust.empty : false
2024-12-31 21:11:02.166 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:11:02.166 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:11:02.166 zookeeper.snapshotSizeFactor = 0.33
2024-12-31 21:11:02.166 zookeeper.commitLogCount=500
2024-12-31 21:11:02.166 minSessionTimeout set to 1600
2024-12-31 21:11:02.166 maxSessionTimeout set to 16000
2024-12-31 21:11:02.167 Response cache size is initialized with value 400.
2024-12-31 21:11:02.167 Response cache size is initialized with value 400.
2024-12-31 21:11:02.167 zookeeper.pathStats.slotCapacity = 60
2024-12-31 21:11:02.167 zookeeper.pathStats.slotDuration = 15
2024-12-31 21:11:02.167 zookeeper.pathStats.maxDepth = 6
2024-12-31 21:11:02.167 zookeeper.pathStats.initialDelay = 5
2024-12-31 21:11:02.167 zookeeper.pathStats.delay = 5
2024-12-31 21:11:02.167 zookeeper.pathStats.enabled = false
2024-12-31 21:11:02.167 The max bytes for all large requests are set to 104857600
2024-12-31 21:11:02.167 The large request threshold is set to -1
2024-12-31 21:11:02.167 Created server with tickTime 800 minSessionTimeout 1600 maxSessionTimeout 16000 clientPortListenBacklog -1 datadir C:\Users\joech\AppData\Local\Temp\kafka-9575038183947519830\version-2 snapdir C:\Users\joech\AppData\Local\Temp\kafka-6340533463892820698\version-2
2024-12-31 21:11:02.167 maxCnxns is not configured, using default value 0.
2024-12-31 21:11:02.168 Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers.
2024-12-31 21:11:02.170 binding to port /127.0.0.1:0
2024-12-31 21:11:02.174 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-6340533463892820698\version-2\snapshot.0
2024-12-31 21:11:02.175 Snapshot loaded in 2 ms, highest zxid is 0x0, digest is 1371985504
2024-12-31 21:11:02.175 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-6340533463892820698\version-2\snapshot.0
2024-12-31 21:11:02.175 Snapshot taken in 0 ms
2024-12-31 21:11:02.176 PrepRequestProcessor (sid:0) started, reconfigEnabled=false
2024-12-31 21:11:02.178 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.19ff00e9-962d-4cf1-bb29-228ba60c7fd14268511744825732741
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59527
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:11:02.182 starting
2024-12-31 21:11:02.182 Connecting to zookeeper on 127.0.0.1:59527
2024-12-31 21:11:02.183 [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:59527.
2024-12-31 21:11:02.183 Initiating client connection, connectString=127.0.0.1:59527 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@637ae337
2024-12-31 21:11:02.185 jute.maxbuffer value is 4194304 Bytes
2024-12-31 21:11:02.185 zookeeper.request.timeout value is 0. feature enabled=false
2024-12-31 21:11:02.185 [ZooKeeperClient Kafka server] Waiting until connected.
2024-12-31 21:11:02.186 Opening socket connection to server /127.0.0.1:59527.
2024-12-31 21:11:02.186 Socket connection established, initiating session, client: /127.0.0.1:59528, server: /127.0.0.1:59527
2024-12-31 21:11:02.187 Creating new log file: log.1
2024-12-31 21:11:02.196 Session establishment complete on server /127.0.0.1:59527, session id = 0x10017726be00000, negotiated timeout = 16000
2024-12-31 21:11:02.196 [ZooKeeperClient Kafka server] Connected.
2024-12-31 21:11:02.231 Cluster ID = ii4RKy4iRWOYTsccqzlIUQ
2024-12-31 21:11:02.232 No meta.properties file under dir C:\Users\joech\AppData\Local\Temp\spring.kafka.19ff00e9-962d-4cf1-bb29-228ba60c7fd14268511744825732741\meta.properties
2024-12-31 21:11:02.242 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.19ff00e9-962d-4cf1-bb29-228ba60c7fd14268511744825732741
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59527
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:11:02.254 [ThrottledChannelReaper-Request]: Starting
2024-12-31 21:11:02.254 [ThrottledChannelReaper-Fetch]: Starting
2024-12-31 21:11:02.254 [ThrottledChannelReaper-Produce]: Starting
2024-12-31 21:11:02.255 [ThrottledChannelReaper-ControllerMutation]: Starting
2024-12-31 21:11:02.265 Loading logs from log dirs ArraySeq(C:\Users\joech\AppData\Local\Temp\spring.kafka.19ff00e9-962d-4cf1-bb29-228ba60c7fd14268511744825732741)
2024-12-31 21:11:02.265 Attempting recovery for all logs in C:\Users\joech\AppData\Local\Temp\spring.kafka.19ff00e9-962d-4cf1-bb29-228ba60c7fd14268511744825732741 since no clean shutdown file was found
2024-12-31 21:11:02.267 Loaded 0 logs in 2ms.
2024-12-31 21:11:02.267 Starting log cleanup with a period of 300000 ms.
2024-12-31 21:11:02.267 Starting log flusher with a default period of 9223372036854775807 ms.
2024-12-31 21:11:02.269 Starting the log cleaner
2024-12-31 21:11:02.270 [kafka-log-cleaner-thread-0]: Starting
2024-12-31 21:11:02.270 [feature-zk-node-event-process-thread]: Starting
2024-12-31 21:11:02.272 Feature ZK node at path: /feature does not exist
2024-12-31 21:11:02.275 [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting
2024-12-31 21:11:02.294 Updated connection-accept-rate max connection creation rate to 2147483647
2024-12-31 21:11:02.296 Awaiting socket connections on localhost:59529.
2024-12-31 21:11:02.306 [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT)
2024-12-31 21:11:02.309 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Starting
2024-12-31 21:11:02.310 [ExpirationReaper-0-Produce]: Starting
2024-12-31 21:11:02.310 [ExpirationReaper-0-Fetch]: Starting
2024-12-31 21:11:02.311 [ExpirationReaper-0-DeleteRecords]: Starting
2024-12-31 21:11:02.311 [ExpirationReaper-0-ElectLeader]: Starting
2024-12-31 21:11:02.313 [LogDirFailureHandler]: Starting
2024-12-31 21:11:02.315 Creating /brokers/ids/0 (is it secure? false)
2024-12-31 21:11:02.317 Stat of the created znode at /brokers/ids/0 is: 25,25,1735650662316,1735650662316,1,0,0,72083374241480704,204,0,25

2024-12-31 21:11:02.317 Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:59529, czxid (broker epoch): 25
2024-12-31 21:11:02.327 [ControllerEventThread controllerId=0] Starting
2024-12-31 21:11:02.328 [ExpirationReaper-0-topic]: Starting
2024-12-31 21:11:02.328 [ExpirationReaper-0-Heartbeat]: Starting
2024-12-31 21:11:02.328 [ExpirationReaper-0-Rebalance]: Starting
2024-12-31 21:11:02.330 [GroupCoordinator 0]: Starting up.
2024-12-31 21:11:02.331 [GroupCoordinator 0]: Startup complete.
2024-12-31 21:11:02.331 Successfully created /controller_epoch with initial epoch 0
2024-12-31 21:11:02.333 [TransactionCoordinator id=0] Starting up.
2024-12-31 21:11:02.333 [Controller id=0] 0 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1
2024-12-31 21:11:02.335 [Controller id=0] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map())
2024-12-31 21:11:02.335 [TransactionCoordinator id=0] Startup complete.
2024-12-31 21:11:02.335 [Transaction Marker Channel Manager 0]: Starting
2024-12-31 21:11:02.336 Feature ZK node created at path: /feature
2024-12-31 21:11:02.336 [ExpirationReaper-0-AlterAcls]: Starting
2024-12-31 21:11:02.337 [Controller id=0] Registering handlers
2024-12-31 21:11:02.337 [MetadataCache brokerId=0] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0).
2024-12-31 21:11:02.340 [/config/changes-event-process-thread]: Starting
2024-12-31 21:11:02.340 [Controller id=0] Deleting log dir event notifications
2024-12-31 21:11:02.341 [Controller id=0] Deleting isr change notifications
2024-12-31 21:11:02.342 [Controller id=0] Initializing controller context
2024-12-31 21:11:02.345 [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing.
2024-12-31 21:11:02.345 [Controller id=0] Initialized broker epochs cache: HashMap(0 -> 25)
2024-12-31 21:11:02.345 Kafka version: 3.4.1
2024-12-31 21:11:02.345 Kafka commitId: 8a516edc2755df89
2024-12-31 21:11:02.345 Kafka startTimeMs: 1735650662345
2024-12-31 21:11:02.350 [Controller id=0] Currently active brokers in the cluster: Set(0)
2024-12-31 21:11:02.350 [RequestSendThread controllerId=0] Starting
2024-12-31 21:11:02.350 [Controller id=0] Currently shutting brokers in the cluster: HashSet()
2024-12-31 21:11:02.350 [Controller id=0] Current list of topics in the cluster: HashSet()
2024-12-31 21:11:02.350 [Controller id=0] Fetching topic deletions in progress
2024-12-31 21:11:02.346 Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.server:type=app-info,id=0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1865)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:960)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:895)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:523)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:563)
	at kafka.utils.TestUtils$.createServer(TestUtils.scala:188)
	at kafka.utils.TestUtils$.createServer(TestUtils.scala:182)
	at kafka.utils.TestUtils.createServer(TestUtils.scala)
	at org.springframework.kafka.test.EmbeddedKafkaBroker.afterPropertiesSet(EmbeddedKafkaBroker.java:369)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1817)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1766)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:410)
	at org.springframework.kafka.test.context.EmbeddedKafkaContextCustomizer.customizeContext(EmbeddedKafkaContextCustomizer.java:116)
	at org.springframework.boot.test.context.SpringBootContextLoader$ContextCustomizerAdapter.initialize(SpringBootContextLoader.java:435)
	at org.springframework.boot.SpringApplication.applyInitializers(SpringApplication.java:610)
	at org.springframework.boot.SpringApplication.prepareContext(SpringApplication.java:390)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:314)
	at org.springframework.boot.test.context.SpringBootContextLoader.lambda$loadContext$3(SpringBootContextLoader.java:137)
	at org.springframework.util.function.ThrowingSupplier.get(ThrowingSupplier.java:58)
	at org.springframework.util.function.ThrowingSupplier.get(ThrowingSupplier.java:46)
	at org.springframework.boot.SpringApplication.withHook(SpringApplication.java:1409)
	at org.springframework.boot.test.context.SpringBootContextLoader$ContextLoaderHook.run(SpringBootContextLoader.java:545)
	at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:137)
	at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:108)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:187)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:119)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:127)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:141)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:97)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:241)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:56)
	at org.spockframework.spring.SpringInterceptor.interceptInitializerMethod(SpringInterceptor.java:46)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:24)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:101)
	at org.spockframework.runtime.PlatformSpecRunner.invoke(PlatformSpecRunner.java:398)
	at org.spockframework.runtime.PlatformSpecRunner.runInitializer(PlatformSpecRunner.java:259)
	at org.spockframework.runtime.PlatformSpecRunner.runInitializer(PlatformSpecRunner.java:254)
	at org.spockframework.runtime.IterationNode.prepare(IterationNode.java:31)
	at org.spockframework.runtime.IterationNode.prepare(IterationNode.java:13)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$prepare$2(NodeTestTask.java:123)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.prepare(NodeTestTask.java:123)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:90)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:226)
	at org.spockframework.runtime.ParameterizedFeatureChildExecutor.execute(ParameterizedFeatureChildExecutor.java:104)
	at org.spockframework.runtime.PlatformParameterizedSpecRunner$1.runIteration(PlatformParameterizedSpecRunner.java:72)
	at org.spockframework.runtime.extension.IDataDriver.lambda$static$0(IDataDriver.java:37)
	at org.spockframework.runtime.PlatformParameterizedSpecRunner.runParameterizedFeature(PlatformParameterizedSpecRunner.java:47)
	at org.spockframework.runtime.ParameterizedFeatureNode.execute(ParameterizedFeatureNode.java:40)
	at org.spockframework.runtime.ParameterizedFeatureNode.execute(ParameterizedFeatureNode.java:16)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.spockframework.runtime.SpockNode.sneakyInvoke(SpockNode.java:40)
	at org.spockframework.runtime.FeatureNode.lambda$around$0(FeatureNode.java:41)
	at org.spockframework.runtime.PlatformSpecRunner.lambda$createMethodInfoForDoRunFeature$4(PlatformSpecRunner.java:199)
	at org.spockframework.runtime.model.MethodInfo.invoke(MethodInfo.java:156)
	at org.spockframework.runtime.PlatformSpecRunner.invokeRaw(PlatformSpecRunner.java:407)
	at org.spockframework.runtime.PlatformSpecRunner.invoke(PlatformSpecRunner.java:390)
	at org.spockframework.runtime.PlatformSpecRunner.runFeature(PlatformSpecRunner.java:192)
	at org.spockframework.runtime.FeatureNode.around(FeatureNode.java:41)
	at org.spockframework.runtime.FeatureNode.around(FeatureNode.java:12)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1511)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.spockframework.runtime.SpockNode.sneakyInvoke(SpockNode.java:40)
	at org.spockframework.runtime.SpecNode.lambda$around$0(SpecNode.java:63)
	at org.spockframework.runtime.PlatformSpecRunner.lambda$createMethodInfoForDoRunSpec$0(PlatformSpecRunner.java:61)
	at org.spockframework.runtime.model.MethodInfo.invoke(MethodInfo.java:156)
	at org.spockframework.runtime.PlatformSpecRunner.invokeRaw(PlatformSpecRunner.java:407)
	at org.spockframework.runtime.PlatformSpecRunner.invoke(PlatformSpecRunner.java:390)
	at org.spockframework.runtime.PlatformSpecRunner.runSpec(PlatformSpecRunner.java:55)
	at org.spockframework.runtime.SpecNode.around(SpecNode.java:63)
	at org.spockframework.runtime.SpecNode.around(SpecNode.java:11)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1511)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:147)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:127)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:90)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:55)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:102)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:150)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2024-12-31 21:11:02.351 [KafkaServer id=0] started
2024-12-31 21:11:02.352 AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [127.0.0.1:59529]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-31 21:11:02.352 [Controller id=0] List of topics to be deleted: 
2024-12-31 21:11:02.352 [Controller id=0] List of topics ineligible for deletion: 
2024-12-31 21:11:02.352 [Controller id=0] Initializing topic deletion manager
2024-12-31 21:11:02.352 [Topic Deletion Manager 0] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet()
2024-12-31 21:11:02.352 [Controller id=0] Sending update metadata request
2024-12-31 21:11:02.352 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions
2024-12-31 21:11:02.352 [ReplicaStateMachine controllerId=0] Initializing replica state
2024-12-31 21:11:02.352 [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2024-12-31 21:11:02.352 [ReplicaStateMachine controllerId=0] Triggering offline replica state changes
2024-12-31 21:11:02.352 [PartitionStateMachine controllerId=0] Initializing partition state
2024-12-31 21:11:02.352 [PartitionStateMachine controllerId=0] Triggering online partition state changes
2024-12-31 21:11:02.353 [Controller id=0] Ready to serve as the new controller with epoch 1
2024-12-31 21:11:02.353 [RequestSendThread controllerId=0] Controller 0 connected to localhost:59529 (id: 0 rack: null) for sending state change requests
2024-12-31 21:11:02.354 [Controller id=0] Partitions undergoing preferred replica election: 
2024-12-31 21:11:02.354 [Controller id=0] Partitions that completed preferred replica election: 
2024-12-31 21:11:02.354 [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2024-12-31 21:11:02.354 Kafka version: 3.4.1
2024-12-31 21:11:02.354 [Controller id=0] Resuming preferred replica election for partitions: 
2024-12-31 21:11:02.354 Kafka commitId: 8a516edc2755df89
2024-12-31 21:11:02.354 [Controller id=0] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered
2024-12-31 21:11:02.354 Kafka startTimeMs: 1735650662354
2024-12-31 21:11:02.356 [Controller id=0] Starting the controller scheduler
2024-12-31 21:11:02.365 Creating topic pong-message-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2024-12-31 21:11:02.372 [Controller id=0] New topics: [Set(pong-message-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(pong-message-topic,Some(igh-TIm4TGmVu6CJNRFDFw),Map(pong-message-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:11:02.372 [Controller id=0] New partition creation callback for pong-message-topic-0
2024-12-31 21:11:02.372 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:11:02.372 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:11:02.372 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:11:02.376 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:11:02.376 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions
2024-12-31 21:11:02.377 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 1 partitions
2024-12-31 21:11:02.377 [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use node localhost:59529 (id: 0 rack: null)
2024-12-31 21:11:02.377 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:11:02.377 [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 for 1 partitions
2024-12-31 21:11:02.378 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(pong-message-topic-0)
2024-12-31 21:11:02.378 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions
2024-12-31 21:11:02.389 [LogLoader partition=pong-message-topic-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.19ff00e9-962d-4cf1-bb29-228ba60c7fd14268511744825732741] Loading producer state till offset 0 with message format version 2
2024-12-31 21:11:02.391 Created log for partition pong-message-topic-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.19ff00e9-962d-4cf1-bb29-228ba60c7fd14268511744825732741\pong-message-topic-0 with properties {}
2024-12-31 21:11:02.391 [Partition pong-message-topic-0 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-0
2024-12-31 21:11:02.391 [Partition pong-message-topic-0 broker=0] Log loaded for partition pong-message-topic-0 with initial high watermark 0
2024-12-31 21:11:02.391 [Broker id=0] Leader pong-message-topic-0 with topic id Some(igh-TIm4TGmVu6CJNRFDFw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:11:02.393 [Broker id=0] Finished LeaderAndIsr request in 16ms correlationId 1 from controller 0 for 1 partitions
2024-12-31 21:11:02.397 [Broker id=0] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2
2024-12-31 21:11:02.399 App info kafka.admin.client for adminclient-2 unregistered
2024-12-31 21:11:02.399 Metrics scheduler closed
2024-12-31 21:11:02.401 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:11:02.401 Metrics reporters closed
2024-12-31 21:11:02.410 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Recorded new controller, from now on will use node localhost:59529 (id: 0 rack: null)
2024-12-31 21:11:02.410 Starting PongControllerSpec using Java 17.0.12 with PID 14548 (started by joech in C:\code\hsbc\demo\pong)
2024-12-31 21:11:02.411 No active profile set, falling back to 1 default profile: "default"
2024-12-31 21:11:03.055 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:11:03.058 Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2024-12-31 21:11:03.200 Finished Spring Data repository scanning in 133 ms. Found 1 JPA repository interfaces.
2024-12-31 21:11:03.221 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:11:03.223 Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2024-12-31 21:11:03.243 Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.demo.dao.MessageRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2024-12-31 21:11:03.243 Finished Spring Data repository scanning in 6 ms. Found 0 Redis repository interfaces.
2024-12-31 21:11:04.021 HHH000204: Processing PersistenceUnitInfo [name: default]
2024-12-31 21:11:04.106 HHH000412: Hibernate ORM core version 6.2.9.Final
2024-12-31 21:11:04.112 HHH000406: Using bytecode reflection optimizer
2024-12-31 21:11:04.310 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:11:04.511 No LoadTimeWeaver setup: ignoring JPA class transformer
2024-12-31 21:11:04.540 HikariPool-1 - Starting...
2024-12-31 21:11:04.884 HikariPool-1 - Added connection conn0: url=jdbc:h2:mem:testdb user=SA
2024-12-31 21:11:04.887 HikariPool-1 - Start completed.
2024-12-31 21:11:05.228 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:11:05.963 HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2024-12-31 21:11:06.073 Initialized JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:11:06.316 [Controller id=0] Processing automatic preferred replica leader election
2024-12-31 21:11:07.358 [Controller id=0] Processing automatic preferred replica leader election
2024-12-31 21:11:07.514 Netty started on port 59533
2024-12-31 21:11:07.555 ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:59523]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-pong-service-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = pong-service
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2024-12-31 21:11:07.597 These configurations '[spring.json.trusted.packages]' were supplied but are not used yet.
2024-12-31 21:11:07.598 Kafka version: 3.4.1
2024-12-31 21:11:07.598 Kafka commitId: 8a516edc2755df89
2024-12-31 21:11:07.598 Kafka startTimeMs: 1735650667598
2024-12-31 21:11:07.600 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Subscribed to topic(s): pong-message-topic
2024-12-31 21:11:07.620 Started PongControllerSpec in 5.758 seconds (process running for 22.44)
2024-12-31 21:11:07.632 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting the last seen epoch of partition pong-message-topic-0 to 0 since the associated topicId changed from null to RaEWstfGSiiC7HGKGzUZxA
2024-12-31 21:11:07.632 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting the last seen epoch of partition pong-message-topic-1 to 0 since the associated topicId changed from null to RaEWstfGSiiC7HGKGzUZxA
2024-12-31 21:11:07.634 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Cluster ID: j_BKNdxkQx-naWEwRZNqVw
2024-12-31 21:11:07.634 Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0))
2024-12-31 21:11:07.643 [Controller id=0] New topics: [Set(__consumer_offsets)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(__consumer_offsets,Some(7Oh7axlbSMWmPThXbedWsw),HashMap(__consumer_offsets-4 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-3 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-2 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:11:07.643 [Controller id=0] New partition creation callback for __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2024-12-31 21:11:07.643 [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:11:07.643 [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:11:07.643 [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:11:07.643 [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:11:07.643 [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:11:07.643 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:11:07.644 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:11:07.653 [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:11:07.653 [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:11:07.653 [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:11:07.653 [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:11:07.653 [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:11:07.653 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 5 become-leader and 0 become-follower partitions
2024-12-31 21:11:07.653 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 5 partitions
2024-12-31 21:11:07.654 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:11:07.655 [Broker id=0] Handling LeaderAndIsr request correlationId 3 from controller 0 for 5 partitions
2024-12-31 21:11:07.658 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-4, __consumer_offsets-3, __consumer_offsets-2, __consumer_offsets-0, __consumer_offsets-1)
2024-12-31 21:11:07.659 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 3 from controller 0 epoch 1 as part of the become-leader transition for 5 partitions
2024-12-31 21:11:07.666 [LogLoader partition=__consumer_offsets-3, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.f6e1f35e-e0df-4070-8dd3-92a87bf0d9c711951431596782478271] Loading producer state till offset 0 with message format version 2
2024-12-31 21:11:07.667 Created log for partition __consumer_offsets-3 in C:\Users\joech\AppData\Local\Temp\spring.kafka.f6e1f35e-e0df-4070-8dd3-92a87bf0d9c711951431596782478271\__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:11:07.668 [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
2024-12-31 21:11:07.668 [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0
2024-12-31 21:11:07.669 [Broker id=0] Leader __consumer_offsets-3 with topic id Some(7Oh7axlbSMWmPThXbedWsw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:11:07.677 [LogLoader partition=__consumer_offsets-2, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.f6e1f35e-e0df-4070-8dd3-92a87bf0d9c711951431596782478271] Loading producer state till offset 0 with message format version 2
2024-12-31 21:11:07.679 Created log for partition __consumer_offsets-2 in C:\Users\joech\AppData\Local\Temp\spring.kafka.f6e1f35e-e0df-4070-8dd3-92a87bf0d9c711951431596782478271\__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:11:07.679 [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
2024-12-31 21:11:07.680 [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0
2024-12-31 21:11:07.680 [Broker id=0] Leader __consumer_offsets-2 with topic id Some(7Oh7axlbSMWmPThXbedWsw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:11:07.689 [LogLoader partition=__consumer_offsets-4, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.f6e1f35e-e0df-4070-8dd3-92a87bf0d9c711951431596782478271] Loading producer state till offset 0 with message format version 2
2024-12-31 21:11:07.690 Created log for partition __consumer_offsets-4 in C:\Users\joech\AppData\Local\Temp\spring.kafka.f6e1f35e-e0df-4070-8dd3-92a87bf0d9c711951431596782478271\__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:11:07.690 [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
2024-12-31 21:11:07.690 [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0
2024-12-31 21:11:07.690 [Broker id=0] Leader __consumer_offsets-4 with topic id Some(7Oh7axlbSMWmPThXbedWsw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:11:07.700 [LogLoader partition=__consumer_offsets-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.f6e1f35e-e0df-4070-8dd3-92a87bf0d9c711951431596782478271] Loading producer state till offset 0 with message format version 2
2024-12-31 21:11:07.700 Created log for partition __consumer_offsets-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.f6e1f35e-e0df-4070-8dd3-92a87bf0d9c711951431596782478271\__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:11:07.701 [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
2024-12-31 21:11:07.701 [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0
2024-12-31 21:11:07.701 [Broker id=0] Leader __consumer_offsets-1 with topic id Some(7Oh7axlbSMWmPThXbedWsw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:11:07.711 [LogLoader partition=__consumer_offsets-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.f6e1f35e-e0df-4070-8dd3-92a87bf0d9c711951431596782478271] Loading producer state till offset 0 with message format version 2
2024-12-31 21:11:07.712 Created log for partition __consumer_offsets-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.f6e1f35e-e0df-4070-8dd3-92a87bf0d9c711951431596782478271\__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:11:07.712 [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
2024-12-31 21:11:07.712 [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0
2024-12-31 21:11:07.712 [Broker id=0] Leader __consumer_offsets-0 with topic id Some(7Oh7axlbSMWmPThXbedWsw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:11:07.716 [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 0
2024-12-31 21:11:07.717 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0
2024-12-31 21:11:07.718 [GroupCoordinator 0]: Elected as the group coordinator for partition 2 in epoch 0
2024-12-31 21:11:07.718 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0
2024-12-31 21:11:07.718 [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 0
2024-12-31 21:11:07.718 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0
2024-12-31 21:11:07.718 [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 0
2024-12-31 21:11:07.718 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0
2024-12-31 21:11:07.718 [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 0
2024-12-31 21:11:07.718 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0
2024-12-31 21:11:07.718 [Broker id=0] Finished LeaderAndIsr request in 63ms correlationId 3 from controller 0 for 5 partitions
2024-12-31 21:11:07.721 [Broker id=0] Add 5 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 4
2024-12-31 21:11:07.724 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 6 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler.
2024-12-31 21:11:07.724 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler.
2024-12-31 21:11:07.724 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler.
2024-12-31 21:11:07.724 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler.
2024-12-31 21:11:07.724 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler.
2024-12-31 21:11:07.738 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Discovered group coordinator localhost:59523 (id: 2147483647 rack: null)
2024-12-31 21:11:07.739 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] (Re-)joining group
2024-12-31 21:11:07.763 [GroupCoordinator 0]: Dynamic member with unknown member id joins group pong-service in Empty state. Created a new member id consumer-pong-service-1-94a6be58-7ab7-41cf-b348-692f39d4ce35 and request the member to rejoin with this id.
2024-12-31 21:11:07.766 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: need to re-join with the given member-id: consumer-pong-service-1-94a6be58-7ab7-41cf-b348-692f39d4ce35
2024-12-31 21:11:07.766 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2024-12-31 21:11:07.767 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] (Re-)joining group
2024-12-31 21:11:07.772 [GroupCoordinator 0]: Preparing to rebalance group pong-service in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-pong-service-1-94a6be58-7ab7-41cf-b348-692f39d4ce35 with group instance id None; client reason: rebalance failed due to MemberIdRequiredException)
2024-12-31 21:11:07.778 [GroupCoordinator 0]: Stabilized group pong-service generation 1 (__consumer_offsets-2) with 1 members
2024-12-31 21:11:07.778 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Successfully joined group with generation Generation{generationId=1, memberId='consumer-pong-service-1-94a6be58-7ab7-41cf-b348-692f39d4ce35', protocol='range'}
2024-12-31 21:11:07.781 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Finished assignment for group at generation 1: {consumer-pong-service-1-94a6be58-7ab7-41cf-b348-692f39d4ce35=Assignment(partitions=[pong-message-topic-0, pong-message-topic-1])}
2024-12-31 21:11:07.787 [GroupCoordinator 0]: Assignment received from leader consumer-pong-service-1-94a6be58-7ab7-41cf-b348-692f39d4ce35 for group pong-service for generation 1. The group has 1 members, 0 of which are static.
2024-12-31 21:11:07.833 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Successfully synced group in generation Generation{generationId=1, memberId='consumer-pong-service-1-94a6be58-7ab7-41cf-b348-692f39d4ce35', protocol='range'}
2024-12-31 21:11:07.833 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Notifying assignor about the new Assignment(partitions=[pong-message-topic-0, pong-message-topic-1])
2024-12-31 21:11:07.836 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Adding newly assigned partitions: pong-message-topic-0, pong-message-topic-1
2024-12-31 21:11:07.842 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-0
2024-12-31 21:11:07.844 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-1
2024-12-31 21:11:07.847 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-0
2024-12-31 21:11:07.847 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-1
2024-12-31 21:11:07.858 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting offset for partition pong-message-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:59523 (id: 0 rack: null)], epoch=0}}.
2024-12-31 21:11:07.859 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting offset for partition pong-message-topic-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:59523 (id: 0 rack: null)], epoch=0}}.
2024-12-31 21:11:07.875 pong-service: partitions assigned: [pong-message-topic-0, pong-message-topic-1]
2024-12-31 21:11:08.592 Received ping message: Hello
2024-12-31 21:11:08.603 Idempotence will be disabled because acks is set to 0, not set to 'all'.
2024-12-31 21:11:08.603 ProducerConfig values: 
	acks = 0
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:59523]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2024-12-31 21:11:08.623 Kafka version: 3.4.1
2024-12-31 21:11:08.623 Kafka commitId: 8a516edc2755df89
2024-12-31 21:11:08.623 Kafka startTimeMs: 1735650668623
2024-12-31 21:11:08.628 [Producer clientId=producer-1] Resetting the last seen epoch of partition pong-message-topic-0 to 0 since the associated topicId changed from null to RaEWstfGSiiC7HGKGzUZxA
2024-12-31 21:11:08.628 [Producer clientId=producer-1] Resetting the last seen epoch of partition pong-message-topic-1 to 0 since the associated topicId changed from null to RaEWstfGSiiC7HGKGzUZxA
2024-12-31 21:11:08.628 [Producer clientId=producer-1] Cluster ID: j_BKNdxkQx-naWEwRZNqVw
2024-12-31 21:11:09.907 Received ping message: Hello
2024-12-31 21:11:09.917 Throttling request as too many requests in the same second
2024-12-31 21:11:09.917 Received ping message: Hello
2024-12-31 21:11:10.390 [KafkaServer id=0] shutting down
2024-12-31 21:11:10.391 [KafkaServer id=0] Starting controlled shutdown
2024-12-31 21:11:10.403 [Controller id=0] Shutting down broker 0
2024-12-31 21:11:10.408 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:11:10.412 [KafkaServer id=0] Controlled shutdown request returned successfully after 13ms
2024-12-31 21:11:10.415 [/config/changes-event-process-thread]: Shutting down
2024-12-31 21:11:10.416 [/config/changes-event-process-thread]: Shutdown completed
2024-12-31 21:11:10.416 [/config/changes-event-process-thread]: Stopped
2024-12-31 21:11:10.416 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
2024-12-31 21:11:10.419 [Producer clientId=producer-1] Node 0 disconnected.
2024-12-31 21:11:10.419 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:11:10.424 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Cancelled in-flight FETCH request with correlation id 22 due to node 0 being disconnected (elapsed time since creation: 489ms, elapsed time since send: 489ms, request timeout: 30000ms)
2024-12-31 21:11:10.424 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 2147483647 disconnected.
2024-12-31 21:11:10.424 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:11:10.425 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Group coordinator localhost:59523 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
2024-12-31 21:11:10.425 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Error sending fetch request (sessionId=1855734705, epoch=6) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2024-12-31 21:11:10.425 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:11:10.425 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors
2024-12-31 21:11:10.426 [data-plane Kafka Request Handler on Broker 0], shutting down
2024-12-31 21:11:10.429 [data-plane Kafka Request Handler on Broker 0], shut down completely
2024-12-31 21:11:10.430 [ExpirationReaper-0-AlterAcls]: Shutting down
2024-12-31 21:11:10.435 [ExpirationReaper-0-AlterAcls]: Shutdown completed
2024-12-31 21:11:10.435 [ExpirationReaper-0-AlterAcls]: Stopped
2024-12-31 21:11:10.435 [KafkaApi-0] Shutdown complete.
2024-12-31 21:11:10.436 [ExpirationReaper-0-topic]: Shutting down
2024-12-31 21:11:10.436 [ExpirationReaper-0-topic]: Shutdown completed
2024-12-31 21:11:10.436 [ExpirationReaper-0-topic]: Stopped
2024-12-31 21:11:10.440 [TransactionCoordinator id=0] Shutting down.
2024-12-31 21:11:10.440 [Transaction State Manager 0]: Shutdown complete
2024-12-31 21:11:10.440 [Transaction Marker Channel Manager 0]: Shutting down
2024-12-31 21:11:10.441 [Transaction Marker Channel Manager 0]: Stopped
2024-12-31 21:11:10.441 [Transaction Marker Channel Manager 0]: Shutdown completed
2024-12-31 21:11:10.442 [TransactionCoordinator id=0] Shutdown complete.
2024-12-31 21:11:10.442 [GroupCoordinator 0]: Shutting down.
2024-12-31 21:11:10.442 [ExpirationReaper-0-Heartbeat]: Shutting down
2024-12-31 21:11:10.443 [ExpirationReaper-0-Heartbeat]: Shutdown completed
2024-12-31 21:11:10.443 [ExpirationReaper-0-Heartbeat]: Stopped
2024-12-31 21:11:10.443 [ExpirationReaper-0-Rebalance]: Shutting down
2024-12-31 21:11:10.443 [ExpirationReaper-0-Rebalance]: Stopped
2024-12-31 21:11:10.443 [ExpirationReaper-0-Rebalance]: Shutdown completed
2024-12-31 21:11:10.443 [GroupCoordinator 0]: Shutdown complete.
2024-12-31 21:11:10.444 [ReplicaManager broker=0] Shutting down
2024-12-31 21:11:10.444 [LogDirFailureHandler]: Shutting down
2024-12-31 21:11:10.444 [LogDirFailureHandler]: Stopped
2024-12-31 21:11:10.444 [LogDirFailureHandler]: Shutdown completed
2024-12-31 21:11:10.444 [ReplicaFetcherManager on broker 0] shutting down
2024-12-31 21:11:10.447 [ReplicaFetcherManager on broker 0] shutdown completed
2024-12-31 21:11:10.447 [ReplicaAlterLogDirsManager on broker 0] shutting down
2024-12-31 21:11:10.447 [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2024-12-31 21:11:10.447 [ExpirationReaper-0-Fetch]: Shutting down
2024-12-31 21:11:10.448 [ExpirationReaper-0-Fetch]: Shutdown completed
2024-12-31 21:11:10.448 [ExpirationReaper-0-Fetch]: Stopped
2024-12-31 21:11:10.448 [ExpirationReaper-0-Produce]: Shutting down
2024-12-31 21:11:10.448 [ExpirationReaper-0-Produce]: Shutdown completed
2024-12-31 21:11:10.448 [ExpirationReaper-0-Produce]: Stopped
2024-12-31 21:11:10.448 [ExpirationReaper-0-DeleteRecords]: Shutting down
2024-12-31 21:11:10.449 [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2024-12-31 21:11:10.449 [ExpirationReaper-0-DeleteRecords]: Stopped
2024-12-31 21:11:10.449 [ExpirationReaper-0-ElectLeader]: Shutting down
2024-12-31 21:11:10.449 [ExpirationReaper-0-ElectLeader]: Stopped
2024-12-31 21:11:10.449 [ExpirationReaper-0-ElectLeader]: Shutdown completed
2024-12-31 21:11:10.459 [ReplicaManager broker=0] Shut down completely
2024-12-31 21:11:10.461 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutting down
2024-12-31 21:11:10.462 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutdown completed
2024-12-31 21:11:10.462 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Stopped
2024-12-31 21:11:10.464 Broker to controller channel manager for alterPartition shutdown
2024-12-31 21:11:10.464 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down
2024-12-31 21:11:10.464 [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped
2024-12-31 21:11:10.464 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed
2024-12-31 21:11:10.465 Broker to controller channel manager for forwarding shutdown
2024-12-31 21:11:10.465 Shutting down.
2024-12-31 21:11:10.467 Shutting down the log cleaner.
2024-12-31 21:11:10.467 [kafka-log-cleaner-thread-0]: Shutting down
2024-12-31 21:11:10.469 [kafka-log-cleaner-thread-0]: Shutdown completed
2024-12-31 21:11:10.469 [kafka-log-cleaner-thread-0]: Stopped
2024-12-31 21:11:10.504 [ProducerStateManager partition=pong-message-topic-0] Wrote producer snapshot at offset 3 with 0 producer ids in 4 ms.
2024-12-31 21:11:10.518 [ProducerStateManager partition=__consumer_offsets-2] Wrote producer snapshot at offset 6 with 0 producer ids in 2 ms.
2024-12-31 21:11:10.522 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:11:10.522 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node 0 (localhost/127.0.0.1:59523) could not be established. Broker may not be available.
2024-12-31 21:11:10.526 [Producer clientId=producer-1] Node 0 disconnected.
2024-12-31 21:11:10.526 [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:59523) could not be established. Broker may not be available.
2024-12-31 21:11:10.535 Shutdown complete.
2024-12-31 21:11:10.536 [ControllerEventThread controllerId=0] Shutting down
2024-12-31 21:11:10.536 [ControllerEventThread controllerId=0] Stopped
2024-12-31 21:11:10.536 [ControllerEventThread controllerId=0] Shutdown completed
2024-12-31 21:11:10.538 [PartitionStateMachine controllerId=0] Stopped partition state machine
2024-12-31 21:11:10.539 [ReplicaStateMachine controllerId=0] Stopped replica state machine
2024-12-31 21:11:10.539 [RequestSendThread controllerId=0] Shutting down
2024-12-31 21:11:10.539 [RequestSendThread controllerId=0] Stopped
2024-12-31 21:11:10.539 [RequestSendThread controllerId=0] Shutdown completed
2024-12-31 21:11:10.541 [Controller id=0] Resigned
2024-12-31 21:11:10.541 [feature-zk-node-event-process-thread]: Shutting down
2024-12-31 21:11:10.541 [feature-zk-node-event-process-thread]: Shutdown completed
2024-12-31 21:11:10.541 [feature-zk-node-event-process-thread]: Stopped
2024-12-31 21:11:10.542 [ZooKeeperClient Kafka server] Closing.
2024-12-31 21:11:10.628 [Producer clientId=producer-1] Node 0 disconnected.
2024-12-31 21:11:10.628 [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:59523) could not be established. Broker may not be available.
2024-12-31 21:11:10.648 Session: 0x10017724ad00000 closed
2024-12-31 21:11:10.649 EventThread shut down for session: 0x10017724ad00000
2024-12-31 21:11:10.650 [ZooKeeperClient Kafka server] Closed.
2024-12-31 21:11:10.650 [ThrottledChannelReaper-Fetch]: Shutting down
2024-12-31 21:11:10.653 [ThrottledChannelReaper-Fetch]: Stopped
2024-12-31 21:11:10.653 [ThrottledChannelReaper-Fetch]: Shutdown completed
2024-12-31 21:11:10.653 [ThrottledChannelReaper-Produce]: Shutting down
2024-12-31 21:11:10.653 [ThrottledChannelReaper-Produce]: Stopped
2024-12-31 21:11:10.653 [ThrottledChannelReaper-Produce]: Shutdown completed
2024-12-31 21:11:10.653 [ThrottledChannelReaper-Request]: Shutting down
2024-12-31 21:11:10.653 [ThrottledChannelReaper-Request]: Stopped
2024-12-31 21:11:10.653 [ThrottledChannelReaper-Request]: Shutdown completed
2024-12-31 21:11:10.653 [ThrottledChannelReaper-ControllerMutation]: Shutting down
2024-12-31 21:11:10.653 [ThrottledChannelReaper-ControllerMutation]: Stopped
2024-12-31 21:11:10.653 [ThrottledChannelReaper-ControllerMutation]: Shutdown completed
2024-12-31 21:11:10.654 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server
2024-12-31 21:11:10.674 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:11:10.674 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node 0 (localhost/127.0.0.1:59523) could not be established. Broker may not be available.
2024-12-31 21:11:10.676 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed
2024-12-31 21:11:10.677 Metrics scheduler closed
2024-12-31 21:11:10.677 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:11:10.677 Metrics reporters closed
2024-12-31 21:11:10.678 Broker and topic stats closed
2024-12-31 21:11:10.678 App info kafka.server for 0 unregistered
2024-12-31 21:11:10.679 [KafkaServer id=0] shut down completed
2024-12-31 21:11:10.697 ConnnectionExpirerThread interrupted
2024-12-31 21:11:10.697 selector thread exitted run method
2024-12-31 21:11:10.697 accept thread exitted run method
2024-12-31 21:11:10.697 selector thread exitted run method
2024-12-31 21:11:10.698 shutting down
2024-12-31 21:11:10.698 Shutting down
2024-12-31 21:11:10.698 Draining request throttler queue
2024-12-31 21:11:10.698 RequestThrottler shutdown. Dropped 0 requests
2024-12-31 21:11:10.698 Shutting down
2024-12-31 21:11:10.698 Shutting down
2024-12-31 21:11:10.698 Shutting down
2024-12-31 21:11:10.698 PrepRequestProcessor exited loop!
2024-12-31 21:11:10.698 SyncRequestProcessor exited!
2024-12-31 21:11:10.699 shutdown of request processor complete
2024-12-31 21:11:10.729 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Revoke previously assigned partitions pong-message-topic-0, pong-message-topic-1
2024-12-31 21:11:10.729 pong-service: partitions revoked: [pong-message-topic-0, pong-message-topic-1]
2024-12-31 21:11:10.730 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:11:10.730 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:11:10.730 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Unsubscribed all topics or patterns and assigned partitions
2024-12-31 21:11:10.730 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:11:10.730 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:11:10.730 Metrics scheduler closed
2024-12-31 21:11:10.731 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:11:10.731 Metrics reporters closed
2024-12-31 21:11:10.732 App info kafka.consumer for consumer-pong-service-1 unregistered
2024-12-31 21:11:10.732 pong-service: Consumer stopped
2024-12-31 21:11:10.736 [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2024-12-31 21:11:10.740 Metrics scheduler closed
2024-12-31 21:11:10.740 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:11:10.740 Metrics reporters closed
2024-12-31 21:11:10.740 App info kafka.producer for producer-1 unregistered
2024-12-31 21:11:10.760 Closing JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:11:10.763 HikariPool-1 - Shutdown initiated...
2024-12-31 21:11:10.765 HikariPool-1 - Shutdown completed.
2024-12-31 21:11:11.490 SessionTrackerImpl exited loop!
2024-12-31 21:11:12.790 [KafkaServer id=0] shutting down
2024-12-31 21:11:12.791 [/config/changes-event-process-thread]: Shutting down
2024-12-31 21:11:12.791 [/config/changes-event-process-thread]: Stopped
2024-12-31 21:11:12.791 [/config/changes-event-process-thread]: Shutdown completed
2024-12-31 21:11:12.791 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
2024-12-31 21:11:12.798 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors
2024-12-31 21:11:12.798 [data-plane Kafka Request Handler on Broker 0], shutting down
2024-12-31 21:11:12.799 [data-plane Kafka Request Handler on Broker 0], shut down completely
2024-12-31 21:11:12.800 [ExpirationReaper-0-AlterAcls]: Shutting down
2024-12-31 21:11:12.801 [ExpirationReaper-0-AlterAcls]: Shutdown completed
2024-12-31 21:11:12.801 [ExpirationReaper-0-AlterAcls]: Stopped
2024-12-31 21:11:12.801 [KafkaApi-0] Shutdown complete.
2024-12-31 21:11:12.801 [ExpirationReaper-0-topic]: Shutting down
2024-12-31 21:11:12.801 [ExpirationReaper-0-topic]: Stopped
2024-12-31 21:11:12.801 [ExpirationReaper-0-topic]: Shutdown completed
2024-12-31 21:11:12.802 [TransactionCoordinator id=0] Shutting down.
2024-12-31 21:11:12.802 [Transaction State Manager 0]: Shutdown complete
2024-12-31 21:11:12.802 [Transaction Marker Channel Manager 0]: Shutting down
2024-12-31 21:11:12.802 [Transaction Marker Channel Manager 0]: Stopped
2024-12-31 21:11:12.802 [Transaction Marker Channel Manager 0]: Shutdown completed
2024-12-31 21:11:12.804 [TransactionCoordinator id=0] Shutdown complete.
2024-12-31 21:11:12.804 [GroupCoordinator 0]: Shutting down.
2024-12-31 21:11:12.805 [ExpirationReaper-0-Heartbeat]: Shutting down
2024-12-31 21:11:12.805 [ExpirationReaper-0-Heartbeat]: Stopped
2024-12-31 21:11:12.805 [ExpirationReaper-0-Heartbeat]: Shutdown completed
2024-12-31 21:11:12.806 [ExpirationReaper-0-Rebalance]: Shutting down
2024-12-31 21:11:12.807 [ExpirationReaper-0-Rebalance]: Shutdown completed
2024-12-31 21:11:12.807 [GroupCoordinator 0]: Shutdown complete.
2024-12-31 21:11:12.807 [ReplicaManager broker=0] Shutting down
2024-12-31 21:11:12.807 [LogDirFailureHandler]: Shutting down
2024-12-31 21:11:12.807 [ExpirationReaper-0-Rebalance]: Stopped
2024-12-31 21:11:12.807 [LogDirFailureHandler]: Shutdown completed
2024-12-31 21:11:12.807 [ReplicaFetcherManager on broker 0] shutting down
2024-12-31 21:11:12.807 [ReplicaFetcherManager on broker 0] shutdown completed
2024-12-31 21:11:12.807 [ReplicaAlterLogDirsManager on broker 0] shutting down
2024-12-31 21:11:12.807 [LogDirFailureHandler]: Stopped
2024-12-31 21:11:12.808 [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2024-12-31 21:11:12.808 [ExpirationReaper-0-Fetch]: Shutting down
2024-12-31 21:11:12.808 [ExpirationReaper-0-Fetch]: Stopped
2024-12-31 21:11:12.808 [ExpirationReaper-0-Fetch]: Shutdown completed
2024-12-31 21:11:12.809 [ExpirationReaper-0-Produce]: Shutting down
2024-12-31 21:11:12.809 [ExpirationReaper-0-Produce]: Stopped
2024-12-31 21:11:12.809 [ExpirationReaper-0-Produce]: Shutdown completed
2024-12-31 21:11:12.809 [ExpirationReaper-0-DeleteRecords]: Shutting down
2024-12-31 21:11:12.810 [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2024-12-31 21:11:12.810 [ExpirationReaper-0-DeleteRecords]: Stopped
2024-12-31 21:11:12.810 [ExpirationReaper-0-ElectLeader]: Shutting down
2024-12-31 21:11:12.810 [ExpirationReaper-0-ElectLeader]: Stopped
2024-12-31 21:11:12.810 [ExpirationReaper-0-ElectLeader]: Shutdown completed
2024-12-31 21:11:12.819 [ReplicaManager broker=0] Shut down completely
2024-12-31 21:11:12.820 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutting down
2024-12-31 21:11:12.820 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Stopped
2024-12-31 21:11:12.821 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutdown completed
2024-12-31 21:11:12.822 Broker to controller channel manager for alterPartition shutdown
2024-12-31 21:11:12.822 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down
2024-12-31 21:11:12.822 [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped
2024-12-31 21:11:12.822 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed
2024-12-31 21:11:12.824 Broker to controller channel manager for forwarding shutdown
2024-12-31 21:11:12.824 Shutting down.
2024-12-31 21:11:12.824 Shutting down the log cleaner.
2024-12-31 21:11:12.824 [kafka-log-cleaner-thread-0]: Shutting down
2024-12-31 21:11:12.824 [kafka-log-cleaner-thread-0]: Stopped
2024-12-31 21:11:12.824 [kafka-log-cleaner-thread-0]: Shutdown completed
2024-12-31 21:11:12.836 Shutdown complete.
2024-12-31 21:11:12.837 [ControllerEventThread controllerId=0] Shutting down
2024-12-31 21:11:12.837 [ControllerEventThread controllerId=0] Stopped
2024-12-31 21:11:12.837 [ControllerEventThread controllerId=0] Shutdown completed
2024-12-31 21:11:12.838 [PartitionStateMachine controllerId=0] Stopped partition state machine
2024-12-31 21:11:12.838 [ReplicaStateMachine controllerId=0] Stopped replica state machine
2024-12-31 21:11:12.838 [RequestSendThread controllerId=0] Shutting down
2024-12-31 21:11:12.838 [RequestSendThread controllerId=0] Stopped
2024-12-31 21:11:12.838 [RequestSendThread controllerId=0] Shutdown completed
2024-12-31 21:11:12.839 [Controller id=0] Resigned
2024-12-31 21:11:12.840 [feature-zk-node-event-process-thread]: Shutting down
2024-12-31 21:11:12.840 [feature-zk-node-event-process-thread]: Stopped
2024-12-31 21:11:12.840 [feature-zk-node-event-process-thread]: Shutdown completed
2024-12-31 21:11:12.840 [ZooKeeperClient Kafka server] Closing.
2024-12-31 21:11:12.943 EventThread shut down for session: 0x10017726be00000
2024-12-31 21:11:12.943 Session: 0x10017726be00000 closed
2024-12-31 21:11:12.943 [ZooKeeperClient Kafka server] Closed.
2024-12-31 21:11:12.943 [ThrottledChannelReaper-Fetch]: Shutting down
2024-12-31 21:11:12.943 [ThrottledChannelReaper-Fetch]: Shutdown completed
2024-12-31 21:11:12.943 [ThrottledChannelReaper-Fetch]: Stopped
2024-12-31 21:11:12.945 [ThrottledChannelReaper-Produce]: Shutting down
2024-12-31 21:11:12.945 [ThrottledChannelReaper-Produce]: Shutdown completed
2024-12-31 21:11:12.945 [ThrottledChannelReaper-Produce]: Stopped
2024-12-31 21:11:12.945 [ThrottledChannelReaper-Request]: Shutting down
2024-12-31 21:11:12.945 [ThrottledChannelReaper-Request]: Shutdown completed
2024-12-31 21:11:12.945 [ThrottledChannelReaper-ControllerMutation]: Shutting down
2024-12-31 21:11:12.945 [ThrottledChannelReaper-Request]: Stopped
2024-12-31 21:11:12.945 [ThrottledChannelReaper-ControllerMutation]: Stopped
2024-12-31 21:11:12.945 [ThrottledChannelReaper-ControllerMutation]: Shutdown completed
2024-12-31 21:11:12.945 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server
2024-12-31 21:11:12.956 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed
2024-12-31 21:11:12.957 Metrics scheduler closed
2024-12-31 21:11:12.957 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:11:12.957 Metrics reporters closed
2024-12-31 21:11:12.957 Broker and topic stats closed
2024-12-31 21:11:12.957 App info kafka.server for 0 unregistered
2024-12-31 21:11:12.957 [KafkaServer id=0] shut down completed
2024-12-31 21:11:12.962 ConnnectionExpirerThread interrupted
2024-12-31 21:11:12.962 accept thread exitted run method
2024-12-31 21:11:12.962 selector thread exitted run method
2024-12-31 21:11:12.962 selector thread exitted run method
2024-12-31 21:11:12.965 shutting down
2024-12-31 21:11:12.965 Shutting down
2024-12-31 21:11:12.965 Draining request throttler queue
2024-12-31 21:11:12.965 RequestThrottler shutdown. Dropped 0 requests
2024-12-31 21:11:12.965 Shutting down
2024-12-31 21:11:12.965 Shutting down
2024-12-31 21:11:12.965 Shutting down
2024-12-31 21:11:12.965 PrepRequestProcessor exited loop!
2024-12-31 21:11:12.965 SyncRequestProcessor exited!
2024-12-31 21:11:12.965 shutdown of request processor complete
2024-12-31 21:11:13.089 SessionTrackerImpl exited loop!
2024-12-31 21:11:13.463 

Found multiple occurrences of org.json.JSONObject on the class path:

	jar:file:/C:/work/apache-maven-3.8.8/repo/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar!/org/json/JSONObject.class
	jar:file:/C:/work/apache-maven-3.8.8/repo/org/json/json/20220320/json-20220320.jar!/org/json/JSONObject.class

You may wish to exclude one of them to ensure predictable runtime behavior

2024-12-31 21:11:13.464 Starting MessageRepositorySpec using Java 17.0.12 with PID 14548 (started by joech in C:\code\hsbc\demo\pong)
2024-12-31 21:11:13.464 No active profile set, falling back to 1 default profile: "default"
2024-12-31 21:11:13.629 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:11:13.629 Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2024-12-31 21:11:13.645 Finished Spring Data repository scanning in 17 ms. Found 1 JPA repository interfaces.
2024-12-31 21:11:13.645 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:11:13.645 Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2024-12-31 21:11:13.661 Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.demo.dao.MessageRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2024-12-31 21:11:13.661 Finished Spring Data repository scanning in 5 ms. Found 0 Redis repository interfaces.
2024-12-31 21:11:13.766 HHH000204: Processing PersistenceUnitInfo [name: default]
2024-12-31 21:11:13.777 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:11:13.777 No LoadTimeWeaver setup: ignoring JPA class transformer
2024-12-31 21:11:13.777 HikariPool-2 - Starting...
2024-12-31 21:11:13.782 HikariPool-2 - Added connection conn10: url=jdbc:h2:mem:testdb user=SA
2024-12-31 21:11:13.782 HikariPool-2 - Start completed.
2024-12-31 21:11:13.788 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:11:13.830 HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2024-12-31 21:11:13.864 Initialized JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:11:14.136 ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:59523]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-pong-service-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = pong-service
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2024-12-31 21:11:14.139 These configurations '[spring.json.trusted.packages]' were supplied but are not used yet.
2024-12-31 21:11:14.139 Kafka version: 3.4.1
2024-12-31 21:11:14.139 Kafka commitId: 8a516edc2755df89
2024-12-31 21:11:14.139 Kafka startTimeMs: 1735650674139
2024-12-31 21:11:14.139 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Subscribed to topic(s): pong-message-topic
2024-12-31 21:11:14.144 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:11:14.144 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Connection to node -1 (/127.0.0.1:59523) could not be established. Broker may not be available.
2024-12-31 21:11:14.144 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Bootstrap broker 127.0.0.1:59523 (id: -1 rack: null) disconnected
2024-12-31 21:11:14.144 Started MessageRepositorySpec in 0.728 seconds (process running for 28.968)
2024-12-31 21:11:14.194 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:11:14.194 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:11:14.194 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Unsubscribed all topics or patterns and assigned partitions
2024-12-31 21:11:14.194 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:11:14.194 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:11:14.194 Metrics scheduler closed
2024-12-31 21:11:14.194 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:11:14.194 Metrics reporters closed
2024-12-31 21:11:14.194 App info kafka.consumer for consumer-pong-service-2 unregistered
2024-12-31 21:11:14.194 pong-service: Consumer stopped
2024-12-31 21:11:14.203 Closing JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:11:14.205 HikariPool-2 - Shutdown initiated...
2024-12-31 21:11:14.207 HikariPool-2 - Shutdown completed.
2024-12-31 21:11:14.230 zookeeper.snapshot.trust.empty : false
2024-12-31 21:11:14.230 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:11:14.230 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:11:14.230 zookeeper.snapshotSizeFactor = 0.33
2024-12-31 21:11:14.230 zookeeper.commitLogCount=500
2024-12-31 21:11:14.230 minSessionTimeout set to 1600
2024-12-31 21:11:14.230 maxSessionTimeout set to 16000
2024-12-31 21:11:14.230 Response cache size is initialized with value 400.
2024-12-31 21:11:14.230 Response cache size is initialized with value 400.
2024-12-31 21:11:14.230 zookeeper.pathStats.slotCapacity = 60
2024-12-31 21:11:14.230 zookeeper.pathStats.slotDuration = 15
2024-12-31 21:11:14.230 zookeeper.pathStats.maxDepth = 6
2024-12-31 21:11:14.230 zookeeper.pathStats.initialDelay = 5
2024-12-31 21:11:14.230 zookeeper.pathStats.delay = 5
2024-12-31 21:11:14.230 zookeeper.pathStats.enabled = false
2024-12-31 21:11:14.230 The max bytes for all large requests are set to 104857600
2024-12-31 21:11:14.230 The large request threshold is set to -1
2024-12-31 21:11:14.230 Created server with tickTime 800 minSessionTimeout 1600 maxSessionTimeout 16000 clientPortListenBacklog -1 datadir C:\Users\joech\AppData\Local\Temp\kafka-8097592461102218463\version-2 snapdir C:\Users\joech\AppData\Local\Temp\kafka-2043520311693982996\version-2
2024-12-31 21:11:14.230 maxCnxns is not configured, using default value 0.
2024-12-31 21:11:14.230 Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers.
2024-12-31 21:11:14.239 binding to port /127.0.0.1:0
2024-12-31 21:11:14.243 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-2043520311693982996\version-2\snapshot.0
2024-12-31 21:11:14.244 Snapshot loaded in 2 ms, highest zxid is 0x0, digest is 1371985504
2024-12-31 21:11:14.244 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-2043520311693982996\version-2\snapshot.0
2024-12-31 21:11:14.245 Snapshot taken in 1 ms
2024-12-31 21:11:14.247 PrepRequestProcessor (sid:0) started, reconfigEnabled=false
2024-12-31 21:11:14.249 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.de253ca5-2546-4f2a-9a8b-58b52e8623352792338521625939979
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59551
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:11:14.254 starting
2024-12-31 21:11:14.255 Connecting to zookeeper on 127.0.0.1:59551
2024-12-31 21:11:14.256 [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:59551.
2024-12-31 21:11:14.256 Initiating client connection, connectString=127.0.0.1:59551 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@22e37920
2024-12-31 21:11:14.258 jute.maxbuffer value is 4194304 Bytes
2024-12-31 21:11:14.259 zookeeper.request.timeout value is 0. feature enabled=false
2024-12-31 21:11:14.259 [ZooKeeperClient Kafka server] Waiting until connected.
2024-12-31 21:11:14.259 Opening socket connection to server /127.0.0.1:59551.
2024-12-31 21:11:14.260 Socket connection established, initiating session, client: /127.0.0.1:59552, server: /127.0.0.1:59551
2024-12-31 21:11:14.261 Creating new log file: log.1
2024-12-31 21:11:14.270 Session establishment complete on server /127.0.0.1:59551, session id = 0x10017729b050000, negotiated timeout = 16000
2024-12-31 21:11:14.270 [ZooKeeperClient Kafka server] Connected.
2024-12-31 21:11:14.314 Cluster ID = 1LLA4K__RkyU_R8zSP7ubw
2024-12-31 21:11:14.314 No meta.properties file under dir C:\Users\joech\AppData\Local\Temp\spring.kafka.de253ca5-2546-4f2a-9a8b-58b52e8623352792338521625939979\meta.properties
2024-12-31 21:11:14.325 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.de253ca5-2546-4f2a-9a8b-58b52e8623352792338521625939979
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59551
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:11:14.333 [ThrottledChannelReaper-Fetch]: Starting
2024-12-31 21:11:14.333 [ThrottledChannelReaper-Produce]: Starting
2024-12-31 21:11:14.333 [ThrottledChannelReaper-Request]: Starting
2024-12-31 21:11:14.333 [ThrottledChannelReaper-ControllerMutation]: Starting
2024-12-31 21:11:14.344 Loading logs from log dirs ArraySeq(C:\Users\joech\AppData\Local\Temp\spring.kafka.de253ca5-2546-4f2a-9a8b-58b52e8623352792338521625939979)
2024-12-31 21:11:14.344 Attempting recovery for all logs in C:\Users\joech\AppData\Local\Temp\spring.kafka.de253ca5-2546-4f2a-9a8b-58b52e8623352792338521625939979 since no clean shutdown file was found
2024-12-31 21:11:14.346 Loaded 0 logs in 2ms.
2024-12-31 21:11:14.346 Starting log cleanup with a period of 300000 ms.
2024-12-31 21:11:14.347 Starting log flusher with a default period of 9223372036854775807 ms.
2024-12-31 21:11:14.348 Starting the log cleaner
2024-12-31 21:11:14.349 [kafka-log-cleaner-thread-0]: Starting
2024-12-31 21:11:14.349 [feature-zk-node-event-process-thread]: Starting
2024-12-31 21:11:14.351 Feature ZK node at path: /feature does not exist
2024-12-31 21:11:14.356 [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting
2024-12-31 21:11:14.377 Updated connection-accept-rate max connection creation rate to 2147483647
2024-12-31 21:11:14.380 Awaiting socket connections on localhost:59553.
2024-12-31 21:11:14.390 [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT)
2024-12-31 21:11:14.393 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Starting
2024-12-31 21:11:14.394 [ExpirationReaper-0-Produce]: Starting
2024-12-31 21:11:14.395 [ExpirationReaper-0-Fetch]: Starting
2024-12-31 21:11:14.395 [ExpirationReaper-0-DeleteRecords]: Starting
2024-12-31 21:11:14.395 [ExpirationReaper-0-ElectLeader]: Starting
2024-12-31 21:11:14.398 [LogDirFailureHandler]: Starting
2024-12-31 21:11:14.401 Creating /brokers/ids/0 (is it secure? false)
2024-12-31 21:11:14.404 Stat of the created znode at /brokers/ids/0 is: 25,25,1735650674402,1735650674402,1,0,0,72083375032434688,204,0,25

2024-12-31 21:11:14.404 Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:59553, czxid (broker epoch): 25
2024-12-31 21:11:14.415 [ControllerEventThread controllerId=0] Starting
2024-12-31 21:11:14.415 [ExpirationReaper-0-topic]: Starting
2024-12-31 21:11:14.416 [ExpirationReaper-0-Heartbeat]: Starting
2024-12-31 21:11:14.416 [ExpirationReaper-0-Rebalance]: Starting
2024-12-31 21:11:14.417 [GroupCoordinator 0]: Starting up.
2024-12-31 21:11:14.418 [GroupCoordinator 0]: Startup complete.
2024-12-31 21:11:14.420 Successfully created /controller_epoch with initial epoch 0
2024-12-31 21:11:14.422 [TransactionCoordinator id=0] Starting up.
2024-12-31 21:11:14.423 [Controller id=0] 0 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1
2024-12-31 21:11:14.424 [TransactionCoordinator id=0] Startup complete.
2024-12-31 21:11:14.424 [Transaction Marker Channel Manager 0]: Starting
2024-12-31 21:11:14.424 [Controller id=0] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map())
2024-12-31 21:11:14.425 [ExpirationReaper-0-AlterAcls]: Starting
2024-12-31 21:11:14.426 Feature ZK node created at path: /feature
2024-12-31 21:11:14.427 [Controller id=0] Registering handlers
2024-12-31 21:11:14.427 [MetadataCache brokerId=0] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0).
2024-12-31 21:11:14.429 [/config/changes-event-process-thread]: Starting
2024-12-31 21:11:14.429 [Controller id=0] Deleting log dir event notifications
2024-12-31 21:11:14.430 [Controller id=0] Deleting isr change notifications
2024-12-31 21:11:14.430 [Controller id=0] Initializing controller context
2024-12-31 21:11:14.434 [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing.
2024-12-31 21:11:14.434 [Controller id=0] Initialized broker epochs cache: HashMap(0 -> 25)
2024-12-31 21:11:14.434 Kafka version: 3.4.1
2024-12-31 21:11:14.434 Kafka commitId: 8a516edc2755df89
2024-12-31 21:11:14.434 Kafka startTimeMs: 1735650674434
2024-12-31 21:11:14.436 [KafkaServer id=0] started
2024-12-31 21:11:14.436 AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [127.0.0.1:59553]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-31 21:11:14.439 Kafka version: 3.4.1
2024-12-31 21:11:14.440 Kafka commitId: 8a516edc2755df89
2024-12-31 21:11:14.440 Kafka startTimeMs: 1735650674439
2024-12-31 21:11:14.440 [Controller id=0] Currently active brokers in the cluster: Set(0)
2024-12-31 21:11:14.440 [Controller id=0] Currently shutting brokers in the cluster: HashSet()
2024-12-31 21:11:14.440 [Controller id=0] Current list of topics in the cluster: HashSet()
2024-12-31 21:11:14.440 [RequestSendThread controllerId=0] Starting
2024-12-31 21:11:14.440 [Controller id=0] Fetching topic deletions in progress
2024-12-31 21:11:14.442 [Controller id=0] List of topics to be deleted: 
2024-12-31 21:11:14.442 [Controller id=0] List of topics ineligible for deletion: 
2024-12-31 21:11:14.442 [Controller id=0] Initializing topic deletion manager
2024-12-31 21:11:14.442 [Topic Deletion Manager 0] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet()
2024-12-31 21:11:14.442 [Controller id=0] Sending update metadata request
2024-12-31 21:11:14.442 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions
2024-12-31 21:11:14.443 [ReplicaStateMachine controllerId=0] Initializing replica state
2024-12-31 21:11:14.443 [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2024-12-31 21:11:14.443 [ReplicaStateMachine controllerId=0] Triggering offline replica state changes
2024-12-31 21:11:14.443 [PartitionStateMachine controllerId=0] Initializing partition state
2024-12-31 21:11:14.443 [PartitionStateMachine controllerId=0] Triggering online partition state changes
2024-12-31 21:11:14.443 [Controller id=0] Ready to serve as the new controller with epoch 1
2024-12-31 21:11:14.443 [RequestSendThread controllerId=0] Controller 0 connected to localhost:59553 (id: 0 rack: null) for sending state change requests
2024-12-31 21:11:14.446 [Controller id=0] Partitions undergoing preferred replica election: 
2024-12-31 21:11:14.446 [Controller id=0] Partitions that completed preferred replica election: 
2024-12-31 21:11:14.446 [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2024-12-31 21:11:14.446 [Controller id=0] Resuming preferred replica election for partitions: 
2024-12-31 21:11:14.446 [Controller id=0] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered
2024-12-31 21:11:14.448 [Controller id=0] Starting the controller scheduler
2024-12-31 21:11:14.455 Creating topic pong-message-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0))
2024-12-31 21:11:14.457 [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use node localhost:59553 (id: 0 rack: null)
2024-12-31 21:11:14.466 [Controller id=0] New topics: [Set(pong-message-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(pong-message-topic,Some(rGxx86FKSGifXNPylLy7GQ),Map(pong-message-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), pong-message-topic-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:11:14.466 [Controller id=0] New partition creation callback for pong-message-topic-0,pong-message-topic-1
2024-12-31 21:11:14.466 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:11:14.466 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:11:14.466 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:11:14.466 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:11:14.476 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:11:14.476 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:11:14.476 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2024-12-31 21:11:14.477 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2024-12-31 21:11:14.478 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:11:14.478 [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 for 2 partitions
2024-12-31 21:11:14.480 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(pong-message-topic-0, pong-message-topic-1)
2024-12-31 21:11:14.480 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2024-12-31 21:11:14.494 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Recorded new controller, from now on will use node localhost:59553 (id: 0 rack: null)
2024-12-31 21:11:14.495 [LogLoader partition=pong-message-topic-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.de253ca5-2546-4f2a-9a8b-58b52e8623352792338521625939979] Loading producer state till offset 0 with message format version 2
2024-12-31 21:11:14.496 Created log for partition pong-message-topic-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.de253ca5-2546-4f2a-9a8b-58b52e8623352792338521625939979\pong-message-topic-0 with properties {}
2024-12-31 21:11:14.497 [Partition pong-message-topic-0 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-0
2024-12-31 21:11:14.497 [Partition pong-message-topic-0 broker=0] Log loaded for partition pong-message-topic-0 with initial high watermark 0
2024-12-31 21:11:14.497 [Broker id=0] Leader pong-message-topic-0 with topic id Some(rGxx86FKSGifXNPylLy7GQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:11:14.509 [LogLoader partition=pong-message-topic-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.de253ca5-2546-4f2a-9a8b-58b52e8623352792338521625939979] Loading producer state till offset 0 with message format version 2
2024-12-31 21:11:14.510 Created log for partition pong-message-topic-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.de253ca5-2546-4f2a-9a8b-58b52e8623352792338521625939979\pong-message-topic-1 with properties {}
2024-12-31 21:11:14.510 [Partition pong-message-topic-1 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-1
2024-12-31 21:11:14.510 [Partition pong-message-topic-1 broker=0] Log loaded for partition pong-message-topic-1 with initial high watermark 0
2024-12-31 21:11:14.510 [Broker id=0] Leader pong-message-topic-1 with topic id Some(rGxx86FKSGifXNPylLy7GQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:11:14.515 [Broker id=0] Finished LeaderAndIsr request in 37ms correlationId 1 from controller 0 for 2 partitions
2024-12-31 21:11:14.518 [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2
2024-12-31 21:11:14.521 App info kafka.admin.client for adminclient-3 unregistered
2024-12-31 21:11:14.522 Metrics scheduler closed
2024-12-31 21:11:14.522 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:11:14.522 Metrics reporters closed
2024-12-31 21:11:14.569 

Found multiple occurrences of org.json.JSONObject on the class path:

	jar:file:/C:/work/apache-maven-3.8.8/repo/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar!/org/json/JSONObject.class
	jar:file:/C:/work/apache-maven-3.8.8/repo/org/json/json/20220320/json-20220320.jar!/org/json/JSONObject.class

You may wish to exclude one of them to ensure predictable runtime behavior

2024-12-31 21:11:14.573 Starting KafkaSpec using Java 17.0.12 with PID 14548 (started by joech in C:\code\hsbc\demo\pong)
2024-12-31 21:11:14.573 No active profile set, falling back to 1 default profile: "default"
2024-12-31 21:11:14.731 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:11:14.732 Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2024-12-31 21:11:14.751 Finished Spring Data repository scanning in 18 ms. Found 1 JPA repository interfaces.
2024-12-31 21:11:14.755 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:11:14.755 Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2024-12-31 21:11:14.759 Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.demo.dao.MessageRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2024-12-31 21:11:14.760 Finished Spring Data repository scanning in 4 ms. Found 0 Redis repository interfaces.
2024-12-31 21:11:14.845 HHH000204: Processing PersistenceUnitInfo [name: default]
2024-12-31 21:11:14.856 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:11:14.857 No LoadTimeWeaver setup: ignoring JPA class transformer
2024-12-31 21:11:14.858 HikariPool-3 - Starting...
2024-12-31 21:11:14.862 HikariPool-3 - Added connection conn20: url=jdbc:h2:mem:testdb user=SA
2024-12-31 21:11:14.862 HikariPool-3 - Start completed.
2024-12-31 21:11:14.875 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:11:14.902 HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2024-12-31 21:11:14.925 Initialized JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:11:15.126 ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:59553]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-pong-service-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = pong-service
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2024-12-31 21:11:15.132 These configurations '[spring.json.trusted.packages]' were supplied but are not used yet.
2024-12-31 21:11:15.132 Kafka version: 3.4.1
2024-12-31 21:11:15.132 Kafka commitId: 8a516edc2755df89
2024-12-31 21:11:15.132 Kafka startTimeMs: 1735650675132
2024-12-31 21:11:15.132 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Subscribed to topic(s): pong-message-topic
2024-12-31 21:11:15.137 Started KafkaSpec in 0.61 seconds (process running for 29.958)
2024-12-31 21:11:15.141 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting the last seen epoch of partition pong-message-topic-0 to 0 since the associated topicId changed from null to rGxx86FKSGifXNPylLy7GQ
2024-12-31 21:11:15.142 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting the last seen epoch of partition pong-message-topic-1 to 0 since the associated topicId changed from null to rGxx86FKSGifXNPylLy7GQ
2024-12-31 21:11:15.142 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Cluster ID: 1LLA4K__RkyU_R8zSP7ubw
2024-12-31 21:11:15.146 Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0))
2024-12-31 21:11:15.158 [Controller id=0] New topics: [Set(__consumer_offsets)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(__consumer_offsets,Some(MQFyEdtIRey-89umOrfHsw),HashMap(__consumer_offsets-4 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-3 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-2 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:11:15.158 [Controller id=0] New partition creation callback for __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2024-12-31 21:11:15.159 [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:11:15.159 [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:11:15.159 [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:11:15.159 [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:11:15.159 [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:11:15.159 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:11:15.159 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:11:15.161 Idempotence will be disabled because acks is set to 0, not set to 'all'.
2024-12-31 21:11:15.162 ProducerConfig values: 
	acks = 0
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:59553]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2024-12-31 21:11:15.166 Kafka version: 3.4.1
2024-12-31 21:11:15.167 Kafka commitId: 8a516edc2755df89
2024-12-31 21:11:15.167 Kafka startTimeMs: 1735650675166
2024-12-31 21:11:15.174 [Producer clientId=producer-2] Resetting the last seen epoch of partition pong-message-topic-0 to 0 since the associated topicId changed from null to rGxx86FKSGifXNPylLy7GQ
2024-12-31 21:11:15.174 [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:11:15.174 [Producer clientId=producer-2] Resetting the last seen epoch of partition pong-message-topic-1 to 0 since the associated topicId changed from null to rGxx86FKSGifXNPylLy7GQ
2024-12-31 21:11:15.174 [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:11:15.174 [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:11:15.174 [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:11:15.174 [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:11:15.175 [Producer clientId=producer-2] Cluster ID: 1LLA4K__RkyU_R8zSP7ubw
2024-12-31 21:11:15.175 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 5 become-leader and 0 become-follower partitions
2024-12-31 21:11:15.175 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 5 partitions
2024-12-31 21:11:15.176 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:11:15.177 [Broker id=0] Handling LeaderAndIsr request correlationId 3 from controller 0 for 5 partitions
2024-12-31 21:11:15.179 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-4, __consumer_offsets-3, __consumer_offsets-2, __consumer_offsets-0, __consumer_offsets-1)
2024-12-31 21:11:15.179 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 3 from controller 0 epoch 1 as part of the become-leader transition for 5 partitions
2024-12-31 21:11:15.194 [LogLoader partition=__consumer_offsets-3, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.de253ca5-2546-4f2a-9a8b-58b52e8623352792338521625939979] Loading producer state till offset 0 with message format version 2
2024-12-31 21:11:15.195 Created log for partition __consumer_offsets-3 in C:\Users\joech\AppData\Local\Temp\spring.kafka.de253ca5-2546-4f2a-9a8b-58b52e8623352792338521625939979\__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:11:15.197 [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
2024-12-31 21:11:15.197 [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0
2024-12-31 21:11:15.199 [Broker id=0] Leader __consumer_offsets-3 with topic id Some(MQFyEdtIRey-89umOrfHsw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:11:15.212 [LogLoader partition=__consumer_offsets-2, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.de253ca5-2546-4f2a-9a8b-58b52e8623352792338521625939979] Loading producer state till offset 0 with message format version 2
2024-12-31 21:11:15.213 Created log for partition __consumer_offsets-2 in C:\Users\joech\AppData\Local\Temp\spring.kafka.de253ca5-2546-4f2a-9a8b-58b52e8623352792338521625939979\__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:11:15.213 [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
2024-12-31 21:11:15.213 [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0
2024-12-31 21:11:15.213 [Broker id=0] Leader __consumer_offsets-2 with topic id Some(MQFyEdtIRey-89umOrfHsw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:11:15.228 [LogLoader partition=__consumer_offsets-4, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.de253ca5-2546-4f2a-9a8b-58b52e8623352792338521625939979] Loading producer state till offset 0 with message format version 2
2024-12-31 21:11:15.229 Created log for partition __consumer_offsets-4 in C:\Users\joech\AppData\Local\Temp\spring.kafka.de253ca5-2546-4f2a-9a8b-58b52e8623352792338521625939979\__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:11:15.229 [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
2024-12-31 21:11:15.229 [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0
2024-12-31 21:11:15.229 [Broker id=0] Leader __consumer_offsets-4 with topic id Some(MQFyEdtIRey-89umOrfHsw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:11:15.243 [LogLoader partition=__consumer_offsets-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.de253ca5-2546-4f2a-9a8b-58b52e8623352792338521625939979] Loading producer state till offset 0 with message format version 2
2024-12-31 21:11:15.244 Created log for partition __consumer_offsets-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.de253ca5-2546-4f2a-9a8b-58b52e8623352792338521625939979\__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:11:15.244 [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
2024-12-31 21:11:15.244 [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0
2024-12-31 21:11:15.245 [Broker id=0] Leader __consumer_offsets-1 with topic id Some(MQFyEdtIRey-89umOrfHsw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:11:15.258 [LogLoader partition=__consumer_offsets-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.de253ca5-2546-4f2a-9a8b-58b52e8623352792338521625939979] Loading producer state till offset 0 with message format version 2
2024-12-31 21:11:15.260 Created log for partition __consumer_offsets-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.de253ca5-2546-4f2a-9a8b-58b52e8623352792338521625939979\__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:11:15.260 [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
2024-12-31 21:11:15.260 [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0
2024-12-31 21:11:15.260 [Broker id=0] Leader __consumer_offsets-0 with topic id Some(MQFyEdtIRey-89umOrfHsw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:11:15.265 [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 0
2024-12-31 21:11:15.265 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0
2024-12-31 21:11:15.265 [GroupCoordinator 0]: Elected as the group coordinator for partition 2 in epoch 0
2024-12-31 21:11:15.265 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0
2024-12-31 21:11:15.265 [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 0
2024-12-31 21:11:15.265 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0
2024-12-31 21:11:15.265 [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 0
2024-12-31 21:11:15.265 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0
2024-12-31 21:11:15.265 [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 0
2024-12-31 21:11:15.265 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0
2024-12-31 21:11:15.265 [Broker id=0] Finished LeaderAndIsr request in 88ms correlationId 3 from controller 0 for 5 partitions
2024-12-31 21:11:15.265 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler.
2024-12-31 21:11:15.266 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler.
2024-12-31 21:11:15.266 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler.
2024-12-31 21:11:15.266 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler.
2024-12-31 21:11:15.266 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler.
2024-12-31 21:11:15.268 [Broker id=0] Add 5 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 4
2024-12-31 21:11:15.352 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Discovered group coordinator localhost:59553 (id: 2147483647 rack: null)
2024-12-31 21:11:15.354 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] (Re-)joining group
2024-12-31 21:11:15.360 [GroupCoordinator 0]: Dynamic member with unknown member id joins group pong-service in Empty state. Created a new member id consumer-pong-service-3-4d585c31-75a3-4e3e-81cc-814f905d68c8 and request the member to rejoin with this id.
2024-12-31 21:11:15.361 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Request joining group due to: need to re-join with the given member-id: consumer-pong-service-3-4d585c31-75a3-4e3e-81cc-814f905d68c8
2024-12-31 21:11:15.361 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2024-12-31 21:11:15.361 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] (Re-)joining group
2024-12-31 21:11:15.363 [GroupCoordinator 0]: Preparing to rebalance group pong-service in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-pong-service-3-4d585c31-75a3-4e3e-81cc-814f905d68c8 with group instance id None; client reason: rebalance failed due to MemberIdRequiredException)
2024-12-31 21:11:15.365 [GroupCoordinator 0]: Stabilized group pong-service generation 1 (__consumer_offsets-2) with 1 members
2024-12-31 21:11:15.366 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Successfully joined group with generation Generation{generationId=1, memberId='consumer-pong-service-3-4d585c31-75a3-4e3e-81cc-814f905d68c8', protocol='range'}
2024-12-31 21:11:15.367 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Finished assignment for group at generation 1: {consumer-pong-service-3-4d585c31-75a3-4e3e-81cc-814f905d68c8=Assignment(partitions=[pong-message-topic-0, pong-message-topic-1])}
2024-12-31 21:11:15.368 [GroupCoordinator 0]: Assignment received from leader consumer-pong-service-3-4d585c31-75a3-4e3e-81cc-814f905d68c8 for group pong-service for generation 1. The group has 1 members, 0 of which are static.
2024-12-31 21:11:15.372 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Successfully synced group in generation Generation{generationId=1, memberId='consumer-pong-service-3-4d585c31-75a3-4e3e-81cc-814f905d68c8', protocol='range'}
2024-12-31 21:11:15.372 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Notifying assignor about the new Assignment(partitions=[pong-message-topic-0, pong-message-topic-1])
2024-12-31 21:11:15.372 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Adding newly assigned partitions: pong-message-topic-0, pong-message-topic-1
2024-12-31 21:11:15.375 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Found no committed offset for partition pong-message-topic-0
2024-12-31 21:11:15.375 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Found no committed offset for partition pong-message-topic-1
2024-12-31 21:11:15.378 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Found no committed offset for partition pong-message-topic-0
2024-12-31 21:11:15.378 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Found no committed offset for partition pong-message-topic-1
2024-12-31 21:11:15.381 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting offset for partition pong-message-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:59553 (id: 0 rack: null)], epoch=0}}.
2024-12-31 21:11:15.381 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting offset for partition pong-message-topic-1 to position FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:59553 (id: 0 rack: null)], epoch=0}}.
2024-12-31 21:11:15.390 pong-service: partitions assigned: [pong-message-topic-0, pong-message-topic-1]
2024-12-31 21:11:15.599 [KafkaServer id=0] shutting down
2024-12-31 21:11:15.599 [KafkaServer id=0] Starting controlled shutdown
2024-12-31 21:11:15.603 [Controller id=0] Shutting down broker 0
2024-12-31 21:11:15.604 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:11:15.605 [KafkaServer id=0] Controlled shutdown request returned successfully after 2ms
2024-12-31 21:11:15.607 [/config/changes-event-process-thread]: Shutting down
2024-12-31 21:11:15.607 [/config/changes-event-process-thread]: Shutdown completed
2024-12-31 21:11:15.607 [/config/changes-event-process-thread]: Stopped
2024-12-31 21:11:15.607 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
2024-12-31 21:11:15.608 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:11:15.608 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:11:15.608 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Cancelled in-flight FETCH request with correlation id 16 due to node 0 being disconnected (elapsed time since creation: 218ms, elapsed time since send: 218ms, request timeout: 30000ms)
2024-12-31 21:11:15.608 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2024-12-31 21:11:15.608 [Producer clientId=producer-2] Node 0 disconnected.
2024-12-31 21:11:15.608 [Producer clientId=producer-2] Cancelled in-flight METADATA request with correlation id 4 due to node 0 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 30000ms)
2024-12-31 21:11:15.609 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node 2147483647 disconnected.
2024-12-31 21:11:15.609 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors
2024-12-31 21:11:15.609 [data-plane Kafka Request Handler on Broker 0], shutting down
2024-12-31 21:11:15.609 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:11:15.609 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Group coordinator localhost:59553 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
2024-12-31 21:11:15.609 [data-plane Kafka Request Handler on Broker 0], shut down completely
2024-12-31 21:11:15.610 [ExpirationReaper-0-AlterAcls]: Shutting down
2024-12-31 21:11:15.610 [ExpirationReaper-0-AlterAcls]: Shutdown completed
2024-12-31 21:11:15.610 [ExpirationReaper-0-AlterAcls]: Stopped
2024-12-31 21:11:15.612 [KafkaApi-0] Shutdown complete.
2024-12-31 21:11:15.612 [ExpirationReaper-0-topic]: Shutting down
2024-12-31 21:11:15.612 [ExpirationReaper-0-topic]: Stopped
2024-12-31 21:11:15.612 [ExpirationReaper-0-topic]: Shutdown completed
2024-12-31 21:11:15.612 [TransactionCoordinator id=0] Shutting down.
2024-12-31 21:11:15.612 [Transaction State Manager 0]: Shutdown complete
2024-12-31 21:11:15.612 [Transaction Marker Channel Manager 0]: Shutting down
2024-12-31 21:11:15.613 [Transaction Marker Channel Manager 0]: Stopped
2024-12-31 21:11:15.613 [Transaction Marker Channel Manager 0]: Shutdown completed
2024-12-31 21:11:15.613 [TransactionCoordinator id=0] Shutdown complete.
2024-12-31 21:11:15.613 [GroupCoordinator 0]: Shutting down.
2024-12-31 21:11:15.613 [ExpirationReaper-0-Heartbeat]: Shutting down
2024-12-31 21:11:15.613 [ExpirationReaper-0-Heartbeat]: Stopped
2024-12-31 21:11:15.613 [ExpirationReaper-0-Heartbeat]: Shutdown completed
2024-12-31 21:11:15.613 [ExpirationReaper-0-Rebalance]: Shutting down
2024-12-31 21:11:15.613 [ExpirationReaper-0-Rebalance]: Stopped
2024-12-31 21:11:15.613 [ExpirationReaper-0-Rebalance]: Shutdown completed
2024-12-31 21:11:15.614 [GroupCoordinator 0]: Shutdown complete.
2024-12-31 21:11:15.614 [ReplicaManager broker=0] Shutting down
2024-12-31 21:11:15.614 [LogDirFailureHandler]: Shutting down
2024-12-31 21:11:15.614 [LogDirFailureHandler]: Stopped
2024-12-31 21:11:15.614 [LogDirFailureHandler]: Shutdown completed
2024-12-31 21:11:15.614 [ReplicaFetcherManager on broker 0] shutting down
2024-12-31 21:11:15.615 [ReplicaFetcherManager on broker 0] shutdown completed
2024-12-31 21:11:15.615 [ReplicaAlterLogDirsManager on broker 0] shutting down
2024-12-31 21:11:15.615 [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2024-12-31 21:11:15.615 [ExpirationReaper-0-Fetch]: Shutting down
2024-12-31 21:11:15.615 [ExpirationReaper-0-Fetch]: Shutdown completed
2024-12-31 21:11:15.615 [ExpirationReaper-0-Fetch]: Stopped
2024-12-31 21:11:15.615 [ExpirationReaper-0-Produce]: Shutting down
2024-12-31 21:11:15.615 [ExpirationReaper-0-Produce]: Shutdown completed
2024-12-31 21:11:15.615 [ExpirationReaper-0-Produce]: Stopped
2024-12-31 21:11:15.615 [ExpirationReaper-0-DeleteRecords]: Shutting down
2024-12-31 21:11:15.615 [ExpirationReaper-0-DeleteRecords]: Stopped
2024-12-31 21:11:15.615 [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2024-12-31 21:11:15.616 [ExpirationReaper-0-ElectLeader]: Shutting down
2024-12-31 21:11:15.616 [ExpirationReaper-0-ElectLeader]: Stopped
2024-12-31 21:11:15.616 [ExpirationReaper-0-ElectLeader]: Shutdown completed
2024-12-31 21:11:15.624 [ReplicaManager broker=0] Shut down completely
2024-12-31 21:11:15.624 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutting down
2024-12-31 21:11:15.624 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Stopped
2024-12-31 21:11:15.624 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutdown completed
2024-12-31 21:11:15.625 Broker to controller channel manager for alterPartition shutdown
2024-12-31 21:11:15.625 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down
2024-12-31 21:11:15.625 [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped
2024-12-31 21:11:15.625 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed
2024-12-31 21:11:15.627 Broker to controller channel manager for forwarding shutdown
2024-12-31 21:11:15.627 Shutting down.
2024-12-31 21:11:15.627 Shutting down the log cleaner.
2024-12-31 21:11:15.627 [kafka-log-cleaner-thread-0]: Shutting down
2024-12-31 21:11:15.627 [kafka-log-cleaner-thread-0]: Shutdown completed
2024-12-31 21:11:15.627 [kafka-log-cleaner-thread-0]: Stopped
2024-12-31 21:11:15.645 [ProducerStateManager partition=pong-message-topic-1] Wrote producer snapshot at offset 1 with 0 producer ids in 2 ms.
2024-12-31 21:11:15.655 [ProducerStateManager partition=__consumer_offsets-2] Wrote producer snapshot at offset 3 with 0 producer ids in 2 ms.
2024-12-31 21:11:15.664 Shutdown complete.
2024-12-31 21:11:15.664 [ControllerEventThread controllerId=0] Shutting down
2024-12-31 21:11:15.664 [ControllerEventThread controllerId=0] Shutdown completed
2024-12-31 21:11:15.664 [ControllerEventThread controllerId=0] Stopped
2024-12-31 21:11:15.664 [PartitionStateMachine controllerId=0] Stopped partition state machine
2024-12-31 21:11:15.664 [ReplicaStateMachine controllerId=0] Stopped replica state machine
2024-12-31 21:11:15.664 [RequestSendThread controllerId=0] Shutting down
2024-12-31 21:11:15.664 [RequestSendThread controllerId=0] Shutdown completed
2024-12-31 21:11:15.664 [RequestSendThread controllerId=0] Stopped
2024-12-31 21:11:15.666 [Controller id=0] Resigned
2024-12-31 21:11:15.666 [feature-zk-node-event-process-thread]: Shutting down
2024-12-31 21:11:15.666 [feature-zk-node-event-process-thread]: Stopped
2024-12-31 21:11:15.666 [feature-zk-node-event-process-thread]: Shutdown completed
2024-12-31 21:11:15.666 [ZooKeeperClient Kafka server] Closing.
2024-12-31 21:11:15.710 [Producer clientId=producer-2] Node 0 disconnected.
2024-12-31 21:11:15.710 [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:59553) could not be established. Broker may not be available.
2024-12-31 21:11:15.711 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:11:15.711 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node 0 (localhost/127.0.0.1:59553) could not be established. Broker may not be available.
2024-12-31 21:11:15.770 Session: 0x10017729b050000 closed
2024-12-31 21:11:15.770 EventThread shut down for session: 0x10017729b050000
2024-12-31 21:11:15.770 [ZooKeeperClient Kafka server] Closed.
2024-12-31 21:11:15.770 [ThrottledChannelReaper-Fetch]: Shutting down
2024-12-31 21:11:15.771 [ThrottledChannelReaper-Fetch]: Stopped
2024-12-31 21:11:15.771 [ThrottledChannelReaper-Fetch]: Shutdown completed
2024-12-31 21:11:15.771 [ThrottledChannelReaper-Produce]: Shutting down
2024-12-31 21:11:15.771 [ThrottledChannelReaper-Produce]: Shutdown completed
2024-12-31 21:11:15.771 [ThrottledChannelReaper-Produce]: Stopped
2024-12-31 21:11:15.771 [ThrottledChannelReaper-Request]: Shutting down
2024-12-31 21:11:15.771 [ThrottledChannelReaper-Request]: Stopped
2024-12-31 21:11:15.771 [ThrottledChannelReaper-Request]: Shutdown completed
2024-12-31 21:11:15.771 [ThrottledChannelReaper-ControllerMutation]: Shutting down
2024-12-31 21:11:15.771 [ThrottledChannelReaper-ControllerMutation]: Stopped
2024-12-31 21:11:15.771 [ThrottledChannelReaper-ControllerMutation]: Shutdown completed
2024-12-31 21:11:15.771 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server
2024-12-31 21:11:15.781 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed
2024-12-31 21:11:15.781 Metrics scheduler closed
2024-12-31 21:11:15.781 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:11:15.781 Metrics reporters closed
2024-12-31 21:11:15.781 Broker and topic stats closed
2024-12-31 21:11:15.781 App info kafka.server for 0 unregistered
2024-12-31 21:11:15.781 [KafkaServer id=0] shut down completed
2024-12-31 21:11:15.793 ConnnectionExpirerThread interrupted
2024-12-31 21:11:15.793 selector thread exitted run method
2024-12-31 21:11:15.793 accept thread exitted run method
2024-12-31 21:11:15.793 selector thread exitted run method
2024-12-31 21:11:15.795 shutting down
2024-12-31 21:11:15.795 Shutting down
2024-12-31 21:11:15.795 Draining request throttler queue
2024-12-31 21:11:15.795 RequestThrottler shutdown. Dropped 0 requests
2024-12-31 21:11:15.795 Shutting down
2024-12-31 21:11:15.795 Shutting down
2024-12-31 21:11:15.795 Shutting down
2024-12-31 21:11:15.795 PrepRequestProcessor exited loop!
2024-12-31 21:11:15.795 SyncRequestProcessor exited!
2024-12-31 21:11:15.795 shutdown of request processor complete
2024-12-31 21:11:15.811 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:11:15.812 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node 0 (localhost/127.0.0.1:59553) could not be established. Broker may not be available.
2024-12-31 21:11:15.812 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Revoke previously assigned partitions pong-message-topic-0, pong-message-topic-1
2024-12-31 21:11:15.812 pong-service: partitions revoked: [pong-message-topic-0, pong-message-topic-1]
2024-12-31 21:11:15.812 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:11:15.812 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:11:15.812 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Unsubscribed all topics or patterns and assigned partitions
2024-12-31 21:11:15.812 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:11:15.812 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:11:15.812 Metrics scheduler closed
2024-12-31 21:11:15.812 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:11:15.812 Metrics reporters closed
2024-12-31 21:11:15.813 App info kafka.consumer for consumer-pong-service-3 unregistered
2024-12-31 21:11:15.813 pong-service: Consumer stopped
2024-12-31 21:11:15.814 [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 30000 ms.
2024-12-31 21:11:15.815 Metrics scheduler closed
2024-12-31 21:11:15.815 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:11:15.815 Metrics reporters closed
2024-12-31 21:11:15.815 App info kafka.producer for producer-2 unregistered
2024-12-31 21:11:15.818 Closing JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:11:15.819 HikariPool-3 - Shutdown initiated...
2024-12-31 21:11:15.820 HikariPool-3 - Shutdown completed.
2024-12-31 21:12:30.471 Could not detect default configuration classes for test class [com.demo.kafka.KafkaSpec]: KafkaSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:12:30.561 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.kafka.KafkaSpec
2024-12-31 21:12:30.895 Registered kafka:type=kafka.Log4jController MBean
2024-12-31 21:12:30.959 
2024-12-31 21:12:30.959   ______                  _                                          
2024-12-31 21:12:30.960  |___  /                 | |                                         
2024-12-31 21:12:30.960     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __   
2024-12-31 21:12:30.960    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__|
2024-12-31 21:12:30.960   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |    
2024-12-31 21:12:30.960  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_|
2024-12-31 21:12:30.960                                               | |                     
2024-12-31 21:12:30.960                                               |_|                     
2024-12-31 21:12:30.960 
2024-12-31 21:12:36.208 Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT
2024-12-31 21:12:36.209 Server environment:host.name=Joe
2024-12-31 21:12:36.209 Server environment:java.version=17.0.12
2024-12-31 21:12:36.209 Server environment:java.vendor=Oracle Corporation
2024-12-31 21:12:36.209 Server environment:java.home=C:\work\jdk-17
2024-12-31 21:12:36.209 Server environment:java.class.path=C:\work\ideaIC-2024.2.0.2.win\lib\idea_rt.jar;C:\work\ideaIC-2024.2.0.2.win\plugins\junit\lib\junit5-rt.jar;C:\work\ideaIC-2024.2.0.2.win\plugins\junit\lib\junit-rt.jar;C:\code\hsbc\demo\pong\target\test-classes;C:\code\hsbc\demo\pong\target\classes;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-webflux\3.1.4\spring-boot-starter-webflux-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter\3.1.4\spring-boot-starter-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot\3.1.4\spring-boot-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-autoconfigure\3.1.4\spring-boot-autoconfigure-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-logging\3.1.4\spring-boot-starter-logging-3.1.4.jar;C:\Users\joech\.m2\repository\ch\qos\logback\logback-classic\1.4.11\logback-classic-1.4.11.jar;C:\Users\joech\.m2\repository\ch\qos\logback\logback-core\1.4.11\logback-core-1.4.11.jar;C:\Users\joech\.m2\repository\org\apache\logging\log4j\log4j-to-slf4j\2.20.0\log4j-to-slf4j-2.20.0.jar;C:\Users\joech\.m2\repository\org\apache\logging\log4j\log4j-api\2.20.0\log4j-api-2.20.0.jar;C:\Users\joech\.m2\repository\org\slf4j\jul-to-slf4j\2.0.9\jul-to-slf4j-2.0.9.jar;C:\Users\joech\.m2\repository\jakarta\annotation\jakarta.annotation-api\2.1.1\jakarta.annotation-api-2.1.1.jar;C:\Users\joech\.m2\repository\org\yaml\snakeyaml\1.33\snakeyaml-1.33.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-json\3.1.4\spring-boot-starter-json-3.1.4.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\core\jackson-databind\2.15.2\jackson-databind-2.15.2.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\core\jackson-annotations\2.15.2\jackson-annotations-2.15.2.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\core\jackson-core\2.15.2\jackson-core-2.15.2.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.15.2\jackson-datatype-jdk8-2.15.2.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.15.2\jackson-datatype-jsr310-2.15.2.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\module\jackson-module-parameter-names\2.15.2\jackson-module-parameter-names-2.15.2.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-reactor-netty\3.1.4\spring-boot-starter-reactor-netty-3.1.4.jar;C:\Users\joech\.m2\repository\io\projectreactor\netty\reactor-netty-http\1.1.11\reactor-netty-http-1.1.11.jar;C:\Users\joech\.m2\repository\io\netty\netty-codec-http\4.1.97.Final\netty-codec-http-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-codec-http2\4.1.97.Final\netty-codec-http2-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-resolver-dns\4.1.97.Final\netty-resolver-dns-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-codec-dns\4.1.97.Final\netty-codec-dns-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-resolver-dns-native-macos\4.1.97.Final\netty-resolver-dns-native-macos-4.1.97.Final-osx-x86_64.jar;C:\Users\joech\.m2\repository\io\netty\netty-resolver-dns-classes-macos\4.1.97.Final\netty-resolver-dns-classes-macos-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final-linux-x86_64.jar;C:\Users\joech\.m2\repository\io\projectreactor\netty\reactor-netty-core\1.1.11\reactor-netty-core-1.1.11.jar;C:\Users\joech\.m2\repository\io\netty\netty-handler-proxy\4.1.97.Final\netty-handler-proxy-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-codec-socks\4.1.97.Final\netty-codec-socks-4.1.97.Final.jar;C:\Users\joech\.m2\repository\org\springframework\spring-web\6.0.12\spring-web-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-beans\6.0.12\spring-beans-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-webflux\6.0.12\spring-webflux-6.0.12.jar;C:\Users\joech\.m2\repository\io\projectreactor\reactor-core\3.5.10\reactor-core-3.5.10.jar;C:\Users\joech\.m2\repository\org\reactivestreams\reactive-streams\1.0.4\reactive-streams-1.0.4.jar;C:\Users\joech\.m2\repository\com\google\guava\guava\19.0\guava-19.0.jar;C:\Users\joech\.m2\repository\commons-io\commons-io\2.11.0\commons-io-2.11.0.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-data-redis\3.1.4\spring-boot-starter-data-redis-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\data\spring-data-redis\3.1.4\spring-data-redis-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\data\spring-data-keyvalue\3.1.4\spring-data-keyvalue-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\spring-oxm\6.0.12\spring-oxm-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-aop\6.0.12\spring-aop-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-context-support\6.0.12\spring-context-support-6.0.12.jar;C:\Users\joech\.m2\repository\io\lettuce\lettuce-core\6.2.6.RELEASE\lettuce-core-6.2.6.RELEASE.jar;C:\Users\joech\.m2\repository\io\netty\netty-common\4.1.97.Final\netty-common-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-handler\4.1.97.Final\netty-handler-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-resolver\4.1.97.Final\netty-resolver-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-buffer\4.1.97.Final\netty-buffer-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-transport-native-unix-common\4.1.97.Final\netty-transport-native-unix-common-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-codec\4.1.97.Final\netty-codec-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-transport\4.1.97.Final\netty-transport-4.1.97.Final.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-data-jpa\3.1.4\spring-boot-starter-data-jpa-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-aop\3.1.4\spring-boot-starter-aop-3.1.4.jar;C:\Users\joech\.m2\repository\org\aspectj\aspectjweaver\1.9.20\aspectjweaver-1.9.20.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-jdbc\3.1.4\spring-boot-starter-jdbc-3.1.4.jar;C:\Users\joech\.m2\repository\com\zaxxer\HikariCP\5.0.1\HikariCP-5.0.1.jar;C:\Users\joech\.m2\repository\org\springframework\spring-jdbc\6.0.12\spring-jdbc-6.0.12.jar;C:\Users\joech\.m2\repository\org\hibernate\orm\hibernate-core\6.2.9.Final\hibernate-core-6.2.9.Final.jar;C:\Users\joech\.m2\repository\jakarta\persistence\jakarta.persistence-api\3.1.0\jakarta.persistence-api-3.1.0.jar;C:\Users\joech\.m2\repository\jakarta\transaction\jakarta.transaction-api\2.0.1\jakarta.transaction-api-2.0.1.jar;C:\Users\joech\.m2\repository\org\jboss\logging\jboss-logging\3.5.3.Final\jboss-logging-3.5.3.Final.jar;C:\Users\joech\.m2\repository\org\hibernate\common\hibernate-commons-annotations\6.0.6.Final\hibernate-commons-annotations-6.0.6.Final.jar;C:\Users\joech\.m2\repository\io\smallrye\jandex\3.0.5\jandex-3.0.5.jar;C:\Users\joech\.m2\repository\com\fasterxml\classmate\1.5.1\classmate-1.5.1.jar;C:\Users\joech\.m2\repository\net\bytebuddy\byte-buddy\1.14.8\byte-buddy-1.14.8.jar;C:\Users\joech\.m2\repository\org\glassfish\jaxb\jaxb-runtime\4.0.3\jaxb-runtime-4.0.3.jar;C:\Users\joech\.m2\repository\org\glassfish\jaxb\jaxb-core\4.0.3\jaxb-core-4.0.3.jar;C:\Users\joech\.m2\repository\org\eclipse\angus\angus-activation\2.0.1\angus-activation-2.0.1.jar;C:\Users\joech\.m2\repository\org\glassfish\jaxb\txw2\4.0.3\txw2-4.0.3.jar;C:\Users\joech\.m2\repository\com\sun\istack\istack-commons-runtime\4.1.2\istack-commons-runtime-4.1.2.jar;C:\Users\joech\.m2\repository\jakarta\inject\jakarta.inject-api\2.0.1\jakarta.inject-api-2.0.1.jar;C:\Users\joech\.m2\repository\org\antlr\antlr4-runtime\4.10.1\antlr4-runtime-4.10.1.jar;C:\Users\joech\.m2\repository\org\springframework\data\spring-data-jpa\3.1.4\spring-data-jpa-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\data\spring-data-commons\3.1.4\spring-data-commons-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\spring-orm\6.0.12\spring-orm-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-aspects\6.0.12\spring-aspects-6.0.12.jar;C:\Users\joech\.m2\repository\org\postgresql\postgresql\42.6.0\postgresql-42.6.0.jar;C:\Users\joech\.m2\repository\org\checkerframework\checker-qual\3.31.0\checker-qual-3.31.0.jar;C:\Users\joech\.m2\repository\org\springframework\kafka\spring-kafka\3.0.11\spring-kafka-3.0.11.jar;C:\Users\joech\.m2\repository\org\springframework\spring-context\6.0.12\spring-context-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-expression\6.0.12\spring-expression-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-messaging\6.0.12\spring-messaging-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-tx\6.0.12\spring-tx-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\retry\spring-retry\2.0.3\spring-retry-2.0.3.jar;C:\Users\joech\.m2\repository\io\micrometer\micrometer-observation\1.11.4\micrometer-observation-1.11.4.jar;C:\Users\joech\.m2\repository\io\micrometer\micrometer-commons\1.11.4\micrometer-commons-1.11.4.jar;C:\Users\joech\.m2\repository\com\google\code\findbugs\jsr305\3.0.2\jsr305-3.0.2.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1.jar;C:\Users\joech\.m2\repository\com\github\luben\zstd-jni\1.5.2-1\zstd-jni-1.5.2-1.jar;C:\Users\joech\.m2\repository\org\lz4\lz4-java\1.8.0\lz4-java-1.8.0.jar;C:\Users\joech\.m2\repository\org\xerial\snappy\snappy-java\1.1.8.4\snappy-java-1.1.8.4.jar;C:\Users\joech\.m2\repository\org\slf4j\slf4j-api\2.0.9\slf4j-api-2.0.9.jar;C:\Users\joech\.m2\repository\com\h2database\h2\1.4.200\h2-1.4.200.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-test\3.1.4\spring-boot-starter-test-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-test\3.1.4\spring-boot-test-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-test-autoconfigure\3.1.4\spring-boot-test-autoconfigure-3.1.4.jar;C:\Users\joech\.m2\repository\com\jayway\jsonpath\json-path\2.8.0\json-path-2.8.0.jar;C:\Users\joech\.m2\repository\jakarta\xml\bind\jakarta.xml.bind-api\4.0.1\jakarta.xml.bind-api-4.0.1.jar;C:\Users\joech\.m2\repository\jakarta\activation\jakarta.activation-api\2.1.2\jakarta.activation-api-2.1.2.jar;C:\Users\joech\.m2\repository\net\minidev\json-smart\2.4.11\json-smart-2.4.11.jar;C:\Users\joech\.m2\repository\net\minidev\accessors-smart\2.4.11\accessors-smart-2.4.11.jar;C:\Users\joech\.m2\repository\org\ow2\asm\asm\9.3\asm-9.3.jar;C:\Users\joech\.m2\repository\org\assertj\assertj-core\3.24.2\assertj-core-3.24.2.jar;C:\Users\joech\.m2\repository\org\hamcrest\hamcrest\2.2\hamcrest-2.2.jar;C:\Users\joech\.m2\repository\org\junit\jupiter\junit-jupiter\5.9.3\junit-jupiter-5.9.3.jar;C:\Users\joech\.m2\repository\org\junit\jupiter\junit-jupiter-params\5.9.3\junit-jupiter-params-5.9.3.jar;C:\Users\joech\.m2\repository\org\junit\jupiter\junit-jupiter-engine\5.9.3\junit-jupiter-engine-5.9.3.jar;C:\Users\joech\.m2\repository\org\mockito\mockito-core\5.3.1\mockito-core-5.3.1.jar;C:\Users\joech\.m2\repository\net\bytebuddy\byte-buddy-agent\1.14.8\byte-buddy-agent-1.14.8.jar;C:\Users\joech\.m2\repository\org\objenesis\objenesis\3.3\objenesis-3.3.jar;C:\Users\joech\.m2\repository\org\mockito\mockito-junit-jupiter\5.3.1\mockito-junit-jupiter-5.3.1.jar;C:\Users\joech\.m2\repository\org\skyscreamer\jsonassert\1.5.1\jsonassert-1.5.1.jar;C:\Users\joech\.m2\repository\com\vaadin\external\google\android-json\0.0.20131108.vaadin1\android-json-0.0.20131108.vaadin1.jar;C:\Users\joech\.m2\repository\org\springframework\spring-core\6.0.12\spring-core-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-jcl\6.0.12\spring-jcl-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-test\6.0.12\spring-test-6.0.12.jar;C:\Users\joech\.m2\repository\org\xmlunit\xmlunit-core\2.9.1\xmlunit-core-2.9.1.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy\4.0.15\groovy-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-ant\4.0.15\groovy-ant-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\ant\ant\1.10.14\ant-1.10.14.jar;C:\Users\joech\.m2\repository\org\apache\ant\ant-junit\1.10.14\ant-junit-1.10.14.jar;C:\Users\joech\.m2\repository\org\apache\ant\ant-launcher\1.10.14\ant-launcher-1.10.14.jar;C:\Users\joech\.m2\repository\org\apache\ant\ant-antlr\1.10.14\ant-antlr-1.10.14.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-cli-picocli\4.0.15\groovy-cli-picocli-4.0.15.jar;C:\Users\joech\.m2\repository\info\picocli\picocli\4.7.5\picocli-4.7.5.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-console\4.0.15\groovy-console-4.0.15.jar;C:\Users\joech\.m2\repository\com\github\javaparser\javaparser-core\3.25.5\javaparser-core-3.25.5.jar;C:\Users\joech\.m2\repository\org\ow2\asm\asm-util\9.5\asm-util-9.5.jar;C:\Users\joech\.m2\repository\org\ow2\asm\asm-tree\9.5\asm-tree-9.5.jar;C:\Users\joech\.m2\repository\org\ow2\asm\asm-analysis\9.5\asm-analysis-9.5.jar;C:\Users\joech\.m2\repository\org\abego\treelayout\org.abego.treelayout.core\1.0.3\org.abego.treelayout.core-1.0.3.jar;C:\Users\joech\.m2\repository\org\apache\ivy\ivy\2.5.2\ivy-2.5.2.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-datetime\4.0.15\groovy-datetime-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-docgenerator\4.0.15\groovy-docgenerator-4.0.15.jar;C:\Users\joech\.m2\repository\com\thoughtworks\qdox\qdox\1.12.1\qdox-1.12.1.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-groovydoc\4.0.15\groovy-groovydoc-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-groovysh\4.0.15\groovy-groovysh-4.0.15.jar;C:\Users\joech\.m2\repository\jline\jline\2.14.6\jline-2.14.6.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-jmx\4.0.15\groovy-jmx-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-json\4.0.15\groovy-json-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-jsr223\4.0.15\groovy-jsr223-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-macro\4.0.15\groovy-macro-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-nio\4.0.15\groovy-nio-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-servlet\4.0.15\groovy-servlet-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-sql\4.0.15\groovy-sql-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-swing\4.0.15\groovy-swing-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-templates\4.0.15\groovy-templates-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-test\4.0.15\groovy-test-4.0.15.jar;C:\Users\joech\.m2\repository\junit\junit\4.13.2\junit-4.13.2.jar;C:\Users\joech\.m2\repository\org\hamcrest\hamcrest-core\2.2\hamcrest-core-2.2.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-test-junit5\4.0.15\groovy-test-junit5-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-xml\4.0.15\groovy-xml-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-yaml\4.0.15\groovy-yaml-4.0.15.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\dataformat\jackson-dataformat-yaml\2.15.2\jackson-dataformat-yaml-2.15.2.jar;C:\Users\joech\.m2\repository\org\spockframework\spock-core\2.4-M1-groovy-4.0\spock-core-2.4-M1-groovy-4.0.jar;C:\Users\joech\.m2\repository\org\junit\platform\junit-platform-engine\1.9.3\junit-platform-engine-1.9.3.jar;C:\Users\joech\.m2\repository\org\opentest4j\opentest4j\1.2.0\opentest4j-1.2.0.jar;C:\Users\joech\.m2\repository\org\junit\platform\junit-platform-commons\1.9.3\junit-platform-commons-1.9.3.jar;C:\Users\joech\.m2\repository\org\apiguardian\apiguardian-api\1.1.2\apiguardian-api-1.1.2.jar;C:\Users\joech\.m2\repository\org\spockframework\spock-spring\2.4-M1-groovy-4.0\spock-spring-2.4-M1-groovy-4.0.jar;C:\Users\joech\.m2\repository\com\athaydes\spock-reports\2.5.1-groovy-4.0\spock-reports-2.5.1-groovy-4.0.jar;C:\Users\joech\.m2\repository\com\github\codemonstur\embedded-redis\1.4.2\embedded-redis-1.4.2.jar;C:\Users\joech\.m2\repository\redis\clients\jedis\4.3.2\jedis-4.3.2.jar;C:\Users\joech\.m2\repository\org\apache\commons\commons-pool2\2.11.1\commons-pool2-2.11.1.jar;C:\Users\joech\.m2\repository\org\json\json\20220320\json-20220320.jar;C:\Users\joech\.m2\repository\com\google\code\gson\gson\2.10.1\gson-2.10.1.jar;C:\Users\joech\.m2\repository\org\springframework\kafka\spring-kafka-test\3.0.11\spring-kafka-test-3.0.11.jar;C:\Users\joech\.m2\repository\org\apache\zookeeper\zookeeper\3.6.3\zookeeper-3.6.3.jar;C:\Users\joech\.m2\repository\org\apache\zookeeper\zookeeper-jute\3.6.3\zookeeper-jute-3.6.3.jar;C:\Users\joech\.m2\repository\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;C:\Users\joech\.m2\repository\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-transport-classes-epoll\4.1.97.Final\netty-transport-classes-epoll-4.1.97.Final.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1-test.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-metadata\3.4.1\kafka-metadata-3.4.1.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-server-common\3.4.1\kafka-server-common-3.4.1.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-raft\3.4.1\kafka-raft-3.4.1.jar;C:\Users\joech\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-streams-test-utils\3.4.1\kafka-streams-test-utils-3.4.1.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-streams\3.4.1\kafka-streams-3.4.1.jar;C:\Users\joech\.m2\repository\org\rocksdb\rocksdbjni\7.1.2\rocksdbjni-7.1.2.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1.jar;C:\Users\joech\.m2\repository\org\scala-lang\scala-library\2.13.10\scala-library-2.13.10.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-group-coordinator\3.4.1\kafka-group-coordinator-3.4.1.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-storage\3.4.1\kafka-storage-3.4.1.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-storage-api\3.4.1\kafka-storage-api-3.4.1.jar;C:\Users\joech\.m2\repository\net\sourceforge\argparse4j\argparse4j\0.7.0\argparse4j-0.7.0.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\module\jackson-module-scala_2.13\2.15.2\jackson-module-scala_2.13-2.15.2.jar;C:\Users\joech\.m2\repository\com\thoughtworks\paranamer\paranamer\2.8\paranamer-2.8.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\dataformat\jackson-dataformat-csv\2.15.2\jackson-dataformat-csv-2.15.2.jar;C:\Users\joech\.m2\repository\net\sf\jopt-simple\jopt-simple\5.0.4\jopt-simple-5.0.4.jar;C:\Users\joech\.m2\repository\org\bitbucket\b_c\jose4j\0.9.3\jose4j-0.9.3.jar;C:\Users\joech\.m2\repository\org\scala-lang\modules\scala-collection-compat_2.13\2.10.0\scala-collection-compat_2.13-2.10.0.jar;C:\Users\joech\.m2\repository\org\scala-lang\modules\scala-java8-compat_2.13\1.0.2\scala-java8-compat_2.13-1.0.2.jar;C:\Users\joech\.m2\repository\org\scala-lang\scala-reflect\2.13.10\scala-reflect-2.13.10.jar;C:\Users\joech\.m2\repository\com\typesafe\scala-logging\scala-logging_2.13\3.9.4\scala-logging_2.13-3.9.4.jar;C:\Users\joech\.m2\repository\io\dropwizard\metrics\metrics-core\4.2.19\metrics-core-4.2.19.jar;C:\Users\joech\.m2\repository\commons-cli\commons-cli\1.4\commons-cli-1.4.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1-test.jar;C:\Users\joech\.m2\repository\org\junit\jupiter\junit-jupiter-api\5.9.3\junit-jupiter-api-5.9.3.jar;C:\Users\joech\.m2\repository\org\junit\platform\junit-platform-launcher\1.9.3\junit-platform-launcher-1.9.3.jar;C:\Users\joech\.m2\repository\org\awaitility\awaitility\4.2.0\awaitility-4.2.0.jar
2024-12-31 21:12:36.210 Server environment:java.library.path=C:\work\jdk-17\bin;C:\windows\Sun\Java\bin;C:\windows\system32;C:\windows;C:\work\python312\Scripts\;C:\work\python312\;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program\Git\cmd;C:\Program\PowerShell\7\;C:\Program Files\dotnet\;C:\Users\joech\AppData\Local\Microsoft\WindowsApps;C:\Users\joech\AppData\Local\GitHubDesktop\bin;C:\Program\Microsoft VS Code\bin;C:\work\apache-maven-3.8.8\bin;C:\Program Files\Tesseract-OCR;C:\work\jdk-17\bin;;.
2024-12-31 21:12:36.210 Server environment:java.io.tmpdir=C:\Users\joech\AppData\Local\Temp\
2024-12-31 21:12:36.210 Server environment:java.compiler=<NA>
2024-12-31 21:12:36.210 Server environment:os.name=Windows 11
2024-12-31 21:12:36.210 Server environment:os.arch=amd64
2024-12-31 21:12:36.210 Server environment:os.version=10.0
2024-12-31 21:12:36.210 Server environment:user.name=joech
2024-12-31 21:12:36.210 Server environment:user.home=C:\Users\joech
2024-12-31 21:12:36.210 Server environment:user.dir=C:\code\hsbc\demo\pong
2024-12-31 21:12:36.210 Server environment:os.memory.free=82MB
2024-12-31 21:12:36.210 Server environment:os.memory.max=15816MB
2024-12-31 21:12:36.210 Server environment:os.memory.total=136MB
2024-12-31 21:12:36.210 zookeeper.enableEagerACLCheck = false
2024-12-31 21:12:36.212 zookeeper.digest.enabled = true
2024-12-31 21:12:36.212 zookeeper.closeSessionTxn.enabled = true
2024-12-31 21:12:36.212 zookeeper.flushDelay=0
2024-12-31 21:12:36.212 zookeeper.maxWriteQueuePollTime=0
2024-12-31 21:12:36.212 zookeeper.maxBatchSize=1000
2024-12-31 21:12:36.212 zookeeper.intBufferStartingSizeBytes = 1024
2024-12-31 21:12:36.214 zookeeper.snapshot.trust.empty : false
2024-12-31 21:12:36.234 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:12:36.234 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:12:36.235 zookeeper.snapshotSizeFactor = 0.33
2024-12-31 21:12:36.236 zookeeper.commitLogCount=500
2024-12-31 21:12:36.239 Weighed connection throttling is disabled
2024-12-31 21:12:36.242 minSessionTimeout set to 1600
2024-12-31 21:12:36.242 maxSessionTimeout set to 16000
2024-12-31 21:12:36.243 Response cache size is initialized with value 400.
2024-12-31 21:12:36.243 Response cache size is initialized with value 400.
2024-12-31 21:12:36.244 zookeeper.pathStats.slotCapacity = 60
2024-12-31 21:12:36.244 zookeeper.pathStats.slotDuration = 15
2024-12-31 21:12:36.244 zookeeper.pathStats.maxDepth = 6
2024-12-31 21:12:36.244 zookeeper.pathStats.initialDelay = 5
2024-12-31 21:12:36.245 zookeeper.pathStats.delay = 5
2024-12-31 21:12:36.245 zookeeper.pathStats.enabled = false
2024-12-31 21:12:36.246 The max bytes for all large requests are set to 104857600
2024-12-31 21:12:36.246 The large request threshold is set to -1
2024-12-31 21:12:36.247 Created server with tickTime 800 minSessionTimeout 1600 maxSessionTimeout 16000 clientPortListenBacklog -1 datadir C:\Users\joech\AppData\Local\Temp\kafka-12307798914614530698\version-2 snapdir C:\Users\joech\AppData\Local\Temp\kafka-6195823003765779428\version-2
2024-12-31 21:12:36.290 maxCnxns is not configured, using default value 0.
2024-12-31 21:12:36.293 Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers.
2024-12-31 21:12:36.298 binding to port /127.0.0.1:0
2024-12-31 21:12:36.322 zookeeper.snapshot.compression.method = CHECKED
2024-12-31 21:12:36.322 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-6195823003765779428\version-2\snapshot.0
2024-12-31 21:12:36.327 Snapshot loaded in 22 ms, highest zxid is 0x0, digest is 1371985504
2024-12-31 21:12:36.327 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-6195823003765779428\version-2\snapshot.0
2024-12-31 21:12:36.329 Snapshot taken in 1 ms
2024-12-31 21:12:36.342 zookeeper.request_throttler.shutdownTimeout = 10000
2024-12-31 21:12:36.341 PrepRequestProcessor (sid:0) started, reconfigEnabled=false
2024-12-31 21:12:36.593 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.f04d93fc-cc12-4486-acc1-27f68bef1a688780609540308471751
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59573
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:12:36.617 Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
2024-12-31 21:12:36.681 starting
2024-12-31 21:12:36.681 Connecting to zookeeper on 127.0.0.1:59573
2024-12-31 21:12:36.704 [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:59573.
2024-12-31 21:12:41.946 Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT
2024-12-31 21:12:41.947 Client environment:host.name=Joe
2024-12-31 21:12:41.947 Client environment:java.version=17.0.12
2024-12-31 21:12:41.947 Client environment:java.vendor=Oracle Corporation
2024-12-31 21:12:41.947 Client environment:java.home=C:\work\jdk-17
2024-12-31 21:12:41.947 Client environment:java.class.path=C:\work\ideaIC-2024.2.0.2.win\lib\idea_rt.jar;C:\work\ideaIC-2024.2.0.2.win\plugins\junit\lib\junit5-rt.jar;C:\work\ideaIC-2024.2.0.2.win\plugins\junit\lib\junit-rt.jar;C:\code\hsbc\demo\pong\target\test-classes;C:\code\hsbc\demo\pong\target\classes;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-webflux\3.1.4\spring-boot-starter-webflux-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter\3.1.4\spring-boot-starter-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot\3.1.4\spring-boot-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-autoconfigure\3.1.4\spring-boot-autoconfigure-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-logging\3.1.4\spring-boot-starter-logging-3.1.4.jar;C:\Users\joech\.m2\repository\ch\qos\logback\logback-classic\1.4.11\logback-classic-1.4.11.jar;C:\Users\joech\.m2\repository\ch\qos\logback\logback-core\1.4.11\logback-core-1.4.11.jar;C:\Users\joech\.m2\repository\org\apache\logging\log4j\log4j-to-slf4j\2.20.0\log4j-to-slf4j-2.20.0.jar;C:\Users\joech\.m2\repository\org\apache\logging\log4j\log4j-api\2.20.0\log4j-api-2.20.0.jar;C:\Users\joech\.m2\repository\org\slf4j\jul-to-slf4j\2.0.9\jul-to-slf4j-2.0.9.jar;C:\Users\joech\.m2\repository\jakarta\annotation\jakarta.annotation-api\2.1.1\jakarta.annotation-api-2.1.1.jar;C:\Users\joech\.m2\repository\org\yaml\snakeyaml\1.33\snakeyaml-1.33.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-json\3.1.4\spring-boot-starter-json-3.1.4.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\core\jackson-databind\2.15.2\jackson-databind-2.15.2.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\core\jackson-annotations\2.15.2\jackson-annotations-2.15.2.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\core\jackson-core\2.15.2\jackson-core-2.15.2.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.15.2\jackson-datatype-jdk8-2.15.2.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.15.2\jackson-datatype-jsr310-2.15.2.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\module\jackson-module-parameter-names\2.15.2\jackson-module-parameter-names-2.15.2.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-reactor-netty\3.1.4\spring-boot-starter-reactor-netty-3.1.4.jar;C:\Users\joech\.m2\repository\io\projectreactor\netty\reactor-netty-http\1.1.11\reactor-netty-http-1.1.11.jar;C:\Users\joech\.m2\repository\io\netty\netty-codec-http\4.1.97.Final\netty-codec-http-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-codec-http2\4.1.97.Final\netty-codec-http2-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-resolver-dns\4.1.97.Final\netty-resolver-dns-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-codec-dns\4.1.97.Final\netty-codec-dns-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-resolver-dns-native-macos\4.1.97.Final\netty-resolver-dns-native-macos-4.1.97.Final-osx-x86_64.jar;C:\Users\joech\.m2\repository\io\netty\netty-resolver-dns-classes-macos\4.1.97.Final\netty-resolver-dns-classes-macos-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final-linux-x86_64.jar;C:\Users\joech\.m2\repository\io\projectreactor\netty\reactor-netty-core\1.1.11\reactor-netty-core-1.1.11.jar;C:\Users\joech\.m2\repository\io\netty\netty-handler-proxy\4.1.97.Final\netty-handler-proxy-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-codec-socks\4.1.97.Final\netty-codec-socks-4.1.97.Final.jar;C:\Users\joech\.m2\repository\org\springframework\spring-web\6.0.12\spring-web-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-beans\6.0.12\spring-beans-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-webflux\6.0.12\spring-webflux-6.0.12.jar;C:\Users\joech\.m2\repository\io\projectreactor\reactor-core\3.5.10\reactor-core-3.5.10.jar;C:\Users\joech\.m2\repository\org\reactivestreams\reactive-streams\1.0.4\reactive-streams-1.0.4.jar;C:\Users\joech\.m2\repository\com\google\guava\guava\19.0\guava-19.0.jar;C:\Users\joech\.m2\repository\commons-io\commons-io\2.11.0\commons-io-2.11.0.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-data-redis\3.1.4\spring-boot-starter-data-redis-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\data\spring-data-redis\3.1.4\spring-data-redis-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\data\spring-data-keyvalue\3.1.4\spring-data-keyvalue-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\spring-oxm\6.0.12\spring-oxm-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-aop\6.0.12\spring-aop-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-context-support\6.0.12\spring-context-support-6.0.12.jar;C:\Users\joech\.m2\repository\io\lettuce\lettuce-core\6.2.6.RELEASE\lettuce-core-6.2.6.RELEASE.jar;C:\Users\joech\.m2\repository\io\netty\netty-common\4.1.97.Final\netty-common-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-handler\4.1.97.Final\netty-handler-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-resolver\4.1.97.Final\netty-resolver-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-buffer\4.1.97.Final\netty-buffer-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-transport-native-unix-common\4.1.97.Final\netty-transport-native-unix-common-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-codec\4.1.97.Final\netty-codec-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-transport\4.1.97.Final\netty-transport-4.1.97.Final.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-data-jpa\3.1.4\spring-boot-starter-data-jpa-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-aop\3.1.4\spring-boot-starter-aop-3.1.4.jar;C:\Users\joech\.m2\repository\org\aspectj\aspectjweaver\1.9.20\aspectjweaver-1.9.20.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-jdbc\3.1.4\spring-boot-starter-jdbc-3.1.4.jar;C:\Users\joech\.m2\repository\com\zaxxer\HikariCP\5.0.1\HikariCP-5.0.1.jar;C:\Users\joech\.m2\repository\org\springframework\spring-jdbc\6.0.12\spring-jdbc-6.0.12.jar;C:\Users\joech\.m2\repository\org\hibernate\orm\hibernate-core\6.2.9.Final\hibernate-core-6.2.9.Final.jar;C:\Users\joech\.m2\repository\jakarta\persistence\jakarta.persistence-api\3.1.0\jakarta.persistence-api-3.1.0.jar;C:\Users\joech\.m2\repository\jakarta\transaction\jakarta.transaction-api\2.0.1\jakarta.transaction-api-2.0.1.jar;C:\Users\joech\.m2\repository\org\jboss\logging\jboss-logging\3.5.3.Final\jboss-logging-3.5.3.Final.jar;C:\Users\joech\.m2\repository\org\hibernate\common\hibernate-commons-annotations\6.0.6.Final\hibernate-commons-annotations-6.0.6.Final.jar;C:\Users\joech\.m2\repository\io\smallrye\jandex\3.0.5\jandex-3.0.5.jar;C:\Users\joech\.m2\repository\com\fasterxml\classmate\1.5.1\classmate-1.5.1.jar;C:\Users\joech\.m2\repository\net\bytebuddy\byte-buddy\1.14.8\byte-buddy-1.14.8.jar;C:\Users\joech\.m2\repository\org\glassfish\jaxb\jaxb-runtime\4.0.3\jaxb-runtime-4.0.3.jar;C:\Users\joech\.m2\repository\org\glassfish\jaxb\jaxb-core\4.0.3\jaxb-core-4.0.3.jar;C:\Users\joech\.m2\repository\org\eclipse\angus\angus-activation\2.0.1\angus-activation-2.0.1.jar;C:\Users\joech\.m2\repository\org\glassfish\jaxb\txw2\4.0.3\txw2-4.0.3.jar;C:\Users\joech\.m2\repository\com\sun\istack\istack-commons-runtime\4.1.2\istack-commons-runtime-4.1.2.jar;C:\Users\joech\.m2\repository\jakarta\inject\jakarta.inject-api\2.0.1\jakarta.inject-api-2.0.1.jar;C:\Users\joech\.m2\repository\org\antlr\antlr4-runtime\4.10.1\antlr4-runtime-4.10.1.jar;C:\Users\joech\.m2\repository\org\springframework\data\spring-data-jpa\3.1.4\spring-data-jpa-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\data\spring-data-commons\3.1.4\spring-data-commons-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\spring-orm\6.0.12\spring-orm-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-aspects\6.0.12\spring-aspects-6.0.12.jar;C:\Users\joech\.m2\repository\org\postgresql\postgresql\42.6.0\postgresql-42.6.0.jar;C:\Users\joech\.m2\repository\org\checkerframework\checker-qual\3.31.0\checker-qual-3.31.0.jar;C:\Users\joech\.m2\repository\org\springframework\kafka\spring-kafka\3.0.11\spring-kafka-3.0.11.jar;C:\Users\joech\.m2\repository\org\springframework\spring-context\6.0.12\spring-context-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-expression\6.0.12\spring-expression-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-messaging\6.0.12\spring-messaging-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-tx\6.0.12\spring-tx-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\retry\spring-retry\2.0.3\spring-retry-2.0.3.jar;C:\Users\joech\.m2\repository\io\micrometer\micrometer-observation\1.11.4\micrometer-observation-1.11.4.jar;C:\Users\joech\.m2\repository\io\micrometer\micrometer-commons\1.11.4\micrometer-commons-1.11.4.jar;C:\Users\joech\.m2\repository\com\google\code\findbugs\jsr305\3.0.2\jsr305-3.0.2.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1.jar;C:\Users\joech\.m2\repository\com\github\luben\zstd-jni\1.5.2-1\zstd-jni-1.5.2-1.jar;C:\Users\joech\.m2\repository\org\lz4\lz4-java\1.8.0\lz4-java-1.8.0.jar;C:\Users\joech\.m2\repository\org\xerial\snappy\snappy-java\1.1.8.4\snappy-java-1.1.8.4.jar;C:\Users\joech\.m2\repository\org\slf4j\slf4j-api\2.0.9\slf4j-api-2.0.9.jar;C:\Users\joech\.m2\repository\com\h2database\h2\1.4.200\h2-1.4.200.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-test\3.1.4\spring-boot-starter-test-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-test\3.1.4\spring-boot-test-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-test-autoconfigure\3.1.4\spring-boot-test-autoconfigure-3.1.4.jar;C:\Users\joech\.m2\repository\com\jayway\jsonpath\json-path\2.8.0\json-path-2.8.0.jar;C:\Users\joech\.m2\repository\jakarta\xml\bind\jakarta.xml.bind-api\4.0.1\jakarta.xml.bind-api-4.0.1.jar;C:\Users\joech\.m2\repository\jakarta\activation\jakarta.activation-api\2.1.2\jakarta.activation-api-2.1.2.jar;C:\Users\joech\.m2\repository\net\minidev\json-smart\2.4.11\json-smart-2.4.11.jar;C:\Users\joech\.m2\repository\net\minidev\accessors-smart\2.4.11\accessors-smart-2.4.11.jar;C:\Users\joech\.m2\repository\org\ow2\asm\asm\9.3\asm-9.3.jar;C:\Users\joech\.m2\repository\org\assertj\assertj-core\3.24.2\assertj-core-3.24.2.jar;C:\Users\joech\.m2\repository\org\hamcrest\hamcrest\2.2\hamcrest-2.2.jar;C:\Users\joech\.m2\repository\org\junit\jupiter\junit-jupiter\5.9.3\junit-jupiter-5.9.3.jar;C:\Users\joech\.m2\repository\org\junit\jupiter\junit-jupiter-params\5.9.3\junit-jupiter-params-5.9.3.jar;C:\Users\joech\.m2\repository\org\junit\jupiter\junit-jupiter-engine\5.9.3\junit-jupiter-engine-5.9.3.jar;C:\Users\joech\.m2\repository\org\mockito\mockito-core\5.3.1\mockito-core-5.3.1.jar;C:\Users\joech\.m2\repository\net\bytebuddy\byte-buddy-agent\1.14.8\byte-buddy-agent-1.14.8.jar;C:\Users\joech\.m2\repository\org\objenesis\objenesis\3.3\objenesis-3.3.jar;C:\Users\joech\.m2\repository\org\mockito\mockito-junit-jupiter\5.3.1\mockito-junit-jupiter-5.3.1.jar;C:\Users\joech\.m2\repository\org\skyscreamer\jsonassert\1.5.1\jsonassert-1.5.1.jar;C:\Users\joech\.m2\repository\com\vaadin\external\google\android-json\0.0.20131108.vaadin1\android-json-0.0.20131108.vaadin1.jar;C:\Users\joech\.m2\repository\org\springframework\spring-core\6.0.12\spring-core-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-jcl\6.0.12\spring-jcl-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-test\6.0.12\spring-test-6.0.12.jar;C:\Users\joech\.m2\repository\org\xmlunit\xmlunit-core\2.9.1\xmlunit-core-2.9.1.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy\4.0.15\groovy-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-ant\4.0.15\groovy-ant-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\ant\ant\1.10.14\ant-1.10.14.jar;C:\Users\joech\.m2\repository\org\apache\ant\ant-junit\1.10.14\ant-junit-1.10.14.jar;C:\Users\joech\.m2\repository\org\apache\ant\ant-launcher\1.10.14\ant-launcher-1.10.14.jar;C:\Users\joech\.m2\repository\org\apache\ant\ant-antlr\1.10.14\ant-antlr-1.10.14.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-cli-picocli\4.0.15\groovy-cli-picocli-4.0.15.jar;C:\Users\joech\.m2\repository\info\picocli\picocli\4.7.5\picocli-4.7.5.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-console\4.0.15\groovy-console-4.0.15.jar;C:\Users\joech\.m2\repository\com\github\javaparser\javaparser-core\3.25.5\javaparser-core-3.25.5.jar;C:\Users\joech\.m2\repository\org\ow2\asm\asm-util\9.5\asm-util-9.5.jar;C:\Users\joech\.m2\repository\org\ow2\asm\asm-tree\9.5\asm-tree-9.5.jar;C:\Users\joech\.m2\repository\org\ow2\asm\asm-analysis\9.5\asm-analysis-9.5.jar;C:\Users\joech\.m2\repository\org\abego\treelayout\org.abego.treelayout.core\1.0.3\org.abego.treelayout.core-1.0.3.jar;C:\Users\joech\.m2\repository\org\apache\ivy\ivy\2.5.2\ivy-2.5.2.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-datetime\4.0.15\groovy-datetime-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-docgenerator\4.0.15\groovy-docgenerator-4.0.15.jar;C:\Users\joech\.m2\repository\com\thoughtworks\qdox\qdox\1.12.1\qdox-1.12.1.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-groovydoc\4.0.15\groovy-groovydoc-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-groovysh\4.0.15\groovy-groovysh-4.0.15.jar;C:\Users\joech\.m2\repository\jline\jline\2.14.6\jline-2.14.6.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-jmx\4.0.15\groovy-jmx-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-json\4.0.15\groovy-json-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-jsr223\4.0.15\groovy-jsr223-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-macro\4.0.15\groovy-macro-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-nio\4.0.15\groovy-nio-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-servlet\4.0.15\groovy-servlet-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-sql\4.0.15\groovy-sql-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-swing\4.0.15\groovy-swing-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-templates\4.0.15\groovy-templates-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-test\4.0.15\groovy-test-4.0.15.jar;C:\Users\joech\.m2\repository\junit\junit\4.13.2\junit-4.13.2.jar;C:\Users\joech\.m2\repository\org\hamcrest\hamcrest-core\2.2\hamcrest-core-2.2.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-test-junit5\4.0.15\groovy-test-junit5-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-xml\4.0.15\groovy-xml-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-yaml\4.0.15\groovy-yaml-4.0.15.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\dataformat\jackson-dataformat-yaml\2.15.2\jackson-dataformat-yaml-2.15.2.jar;C:\Users\joech\.m2\repository\org\spockframework\spock-core\2.4-M1-groovy-4.0\spock-core-2.4-M1-groovy-4.0.jar;C:\Users\joech\.m2\repository\org\junit\platform\junit-platform-engine\1.9.3\junit-platform-engine-1.9.3.jar;C:\Users\joech\.m2\repository\org\opentest4j\opentest4j\1.2.0\opentest4j-1.2.0.jar;C:\Users\joech\.m2\repository\org\junit\platform\junit-platform-commons\1.9.3\junit-platform-commons-1.9.3.jar;C:\Users\joech\.m2\repository\org\apiguardian\apiguardian-api\1.1.2\apiguardian-api-1.1.2.jar;C:\Users\joech\.m2\repository\org\spockframework\spock-spring\2.4-M1-groovy-4.0\spock-spring-2.4-M1-groovy-4.0.jar;C:\Users\joech\.m2\repository\com\athaydes\spock-reports\2.5.1-groovy-4.0\spock-reports-2.5.1-groovy-4.0.jar;C:\Users\joech\.m2\repository\com\github\codemonstur\embedded-redis\1.4.2\embedded-redis-1.4.2.jar;C:\Users\joech\.m2\repository\redis\clients\jedis\4.3.2\jedis-4.3.2.jar;C:\Users\joech\.m2\repository\org\apache\commons\commons-pool2\2.11.1\commons-pool2-2.11.1.jar;C:\Users\joech\.m2\repository\org\json\json\20220320\json-20220320.jar;C:\Users\joech\.m2\repository\com\google\code\gson\gson\2.10.1\gson-2.10.1.jar;C:\Users\joech\.m2\repository\org\springframework\kafka\spring-kafka-test\3.0.11\spring-kafka-test-3.0.11.jar;C:\Users\joech\.m2\repository\org\apache\zookeeper\zookeeper\3.6.3\zookeeper-3.6.3.jar;C:\Users\joech\.m2\repository\org\apache\zookeeper\zookeeper-jute\3.6.3\zookeeper-jute-3.6.3.jar;C:\Users\joech\.m2\repository\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;C:\Users\joech\.m2\repository\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-transport-classes-epoll\4.1.97.Final\netty-transport-classes-epoll-4.1.97.Final.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1-test.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-metadata\3.4.1\kafka-metadata-3.4.1.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-server-common\3.4.1\kafka-server-common-3.4.1.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-raft\3.4.1\kafka-raft-3.4.1.jar;C:\Users\joech\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-streams-test-utils\3.4.1\kafka-streams-test-utils-3.4.1.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-streams\3.4.1\kafka-streams-3.4.1.jar;C:\Users\joech\.m2\repository\org\rocksdb\rocksdbjni\7.1.2\rocksdbjni-7.1.2.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1.jar;C:\Users\joech\.m2\repository\org\scala-lang\scala-library\2.13.10\scala-library-2.13.10.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-group-coordinator\3.4.1\kafka-group-coordinator-3.4.1.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-storage\3.4.1\kafka-storage-3.4.1.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-storage-api\3.4.1\kafka-storage-api-3.4.1.jar;C:\Users\joech\.m2\repository\net\sourceforge\argparse4j\argparse4j\0.7.0\argparse4j-0.7.0.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\module\jackson-module-scala_2.13\2.15.2\jackson-module-scala_2.13-2.15.2.jar;C:\Users\joech\.m2\repository\com\thoughtworks\paranamer\paranamer\2.8\paranamer-2.8.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\dataformat\jackson-dataformat-csv\2.15.2\jackson-dataformat-csv-2.15.2.jar;C:\Users\joech\.m2\repository\net\sf\jopt-simple\jopt-simple\5.0.4\jopt-simple-5.0.4.jar;C:\Users\joech\.m2\repository\org\bitbucket\b_c\jose4j\0.9.3\jose4j-0.9.3.jar;C:\Users\joech\.m2\repository\org\scala-lang\modules\scala-collection-compat_2.13\2.10.0\scala-collection-compat_2.13-2.10.0.jar;C:\Users\joech\.m2\repository\org\scala-lang\modules\scala-java8-compat_2.13\1.0.2\scala-java8-compat_2.13-1.0.2.jar;C:\Users\joech\.m2\repository\org\scala-lang\scala-reflect\2.13.10\scala-reflect-2.13.10.jar;C:\Users\joech\.m2\repository\com\typesafe\scala-logging\scala-logging_2.13\3.9.4\scala-logging_2.13-3.9.4.jar;C:\Users\joech\.m2\repository\io\dropwizard\metrics\metrics-core\4.2.19\metrics-core-4.2.19.jar;C:\Users\joech\.m2\repository\commons-cli\commons-cli\1.4\commons-cli-1.4.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1-test.jar;C:\Users\joech\.m2\repository\org\junit\jupiter\junit-jupiter-api\5.9.3\junit-jupiter-api-5.9.3.jar;C:\Users\joech\.m2\repository\org\junit\platform\junit-platform-launcher\1.9.3\junit-platform-launcher-1.9.3.jar;C:\Users\joech\.m2\repository\org\awaitility\awaitility\4.2.0\awaitility-4.2.0.jar
2024-12-31 21:12:41.948 Client environment:java.library.path=C:\work\jdk-17\bin;C:\windows\Sun\Java\bin;C:\windows\system32;C:\windows;C:\work\python312\Scripts\;C:\work\python312\;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program\Git\cmd;C:\Program\PowerShell\7\;C:\Program Files\dotnet\;C:\Users\joech\AppData\Local\Microsoft\WindowsApps;C:\Users\joech\AppData\Local\GitHubDesktop\bin;C:\Program\Microsoft VS Code\bin;C:\work\apache-maven-3.8.8\bin;C:\Program Files\Tesseract-OCR;C:\work\jdk-17\bin;;.
2024-12-31 21:12:41.948 Client environment:java.io.tmpdir=C:\Users\joech\AppData\Local\Temp\
2024-12-31 21:12:41.948 Client environment:java.compiler=<NA>
2024-12-31 21:12:41.948 Client environment:os.name=Windows 11
2024-12-31 21:12:41.948 Client environment:os.arch=amd64
2024-12-31 21:12:41.948 Client environment:os.version=10.0
2024-12-31 21:12:41.948 Client environment:user.name=joech
2024-12-31 21:12:41.948 Client environment:user.home=C:\Users\joech
2024-12-31 21:12:41.948 Client environment:user.dir=C:\code\hsbc\demo\pong
2024-12-31 21:12:41.948 Client environment:os.memory.free=108MB
2024-12-31 21:12:41.948 Client environment:os.memory.max=15816MB
2024-12-31 21:12:41.948 Client environment:os.memory.total=136MB
2024-12-31 21:12:41.952 Initiating client connection, connectString=127.0.0.1:59573 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@10a18e3e
2024-12-31 21:12:41.957 jute.maxbuffer value is 4194304 Bytes
2024-12-31 21:12:41.972 zookeeper.request.timeout value is 0. feature enabled=false
2024-12-31 21:12:41.973 [ZooKeeperClient Kafka server] Waiting until connected.
2024-12-31 21:12:41.973 Opening socket connection to server /127.0.0.1:59573.
2024-12-31 21:12:41.976 Socket connection established, initiating session, client: /127.0.0.1:59575, server: /127.0.0.1:59573
2024-12-31 21:12:41.984 Creating new log file: log.1
2024-12-31 21:12:41.994 ZooKeeper audit is disabled.
2024-12-31 21:12:41.999 Session establishment complete on server /127.0.0.1:59573, session id = 0x1001773dbaa0000, negotiated timeout = 16000
2024-12-31 21:12:42.004 [ZooKeeperClient Kafka server] Connected.
2024-12-31 21:12:42.300 Cluster ID = L24rYvyGSnq3jakR5pYFGg
2024-12-31 21:12:42.303 No meta.properties file under dir C:\Users\joech\AppData\Local\Temp\spring.kafka.f04d93fc-cc12-4486-acc1-27f68bef1a688780609540308471751\meta.properties
2024-12-31 21:12:42.348 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.f04d93fc-cc12-4486-acc1-27f68bef1a688780609540308471751
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59573
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:12:42.382 [ThrottledChannelReaper-Produce]: Starting
2024-12-31 21:12:42.381 [ThrottledChannelReaper-Fetch]: Starting
2024-12-31 21:12:42.383 [ThrottledChannelReaper-Request]: Starting
2024-12-31 21:12:42.386 [ThrottledChannelReaper-ControllerMutation]: Starting
2024-12-31 21:12:42.422 Loading logs from log dirs ArraySeq(C:\Users\joech\AppData\Local\Temp\spring.kafka.f04d93fc-cc12-4486-acc1-27f68bef1a688780609540308471751)
2024-12-31 21:12:42.425 Attempting recovery for all logs in C:\Users\joech\AppData\Local\Temp\spring.kafka.f04d93fc-cc12-4486-acc1-27f68bef1a688780609540308471751 since no clean shutdown file was found
2024-12-31 21:12:42.435 Loaded 0 logs in 12ms.
2024-12-31 21:12:42.436 Starting log cleanup with a period of 300000 ms.
2024-12-31 21:12:42.438 Starting log flusher with a default period of 9223372036854775807 ms.
2024-12-31 21:12:42.452 Starting the log cleaner
2024-12-31 21:12:42.463 [kafka-log-cleaner-thread-0]: Starting
2024-12-31 21:12:42.478 [feature-zk-node-event-process-thread]: Starting
2024-12-31 21:12:42.487 Feature ZK node at path: /feature does not exist
2024-12-31 21:12:42.515 [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting
2024-12-31 21:12:42.841 Updated connection-accept-rate max connection creation rate to 2147483647
2024-12-31 21:12:42.848 Awaiting socket connections on localhost:59578.
2024-12-31 21:12:42.877 [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT)
2024-12-31 21:12:42.884 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Starting
2024-12-31 21:12:42.898 [ExpirationReaper-0-Produce]: Starting
2024-12-31 21:12:42.898 [ExpirationReaper-0-Fetch]: Starting
2024-12-31 21:12:42.899 [ExpirationReaper-0-DeleteRecords]: Starting
2024-12-31 21:12:42.901 [ExpirationReaper-0-ElectLeader]: Starting
2024-12-31 21:12:42.915 [LogDirFailureHandler]: Starting
2024-12-31 21:12:42.935 Creating /brokers/ids/0 (is it secure? false)
2024-12-31 21:12:42.952 Stat of the created znode at /brokers/ids/0 is: 25,25,1735650762946,1735650762946,1,0,0,72083380411957248,204,0,25

2024-12-31 21:12:42.954 Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:59578, czxid (broker epoch): 25
2024-12-31 21:12:43.005 [ControllerEventThread controllerId=0] Starting
2024-12-31 21:12:43.008 [ExpirationReaper-0-topic]: Starting
2024-12-31 21:12:43.016 [ExpirationReaper-0-Heartbeat]: Starting
2024-12-31 21:12:43.016 [ExpirationReaper-0-Rebalance]: Starting
2024-12-31 21:12:43.026 Successfully created /controller_epoch with initial epoch 0
2024-12-31 21:12:43.030 [Controller id=0] 0 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1
2024-12-31 21:12:43.033 [GroupCoordinator 0]: Starting up.
2024-12-31 21:12:43.035 [Controller id=0] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map())
2024-12-31 21:12:43.039 Feature ZK node created at path: /feature
2024-12-31 21:12:43.042 [GroupCoordinator 0]: Startup complete.
2024-12-31 21:12:43.067 [TransactionCoordinator id=0] Starting up.
2024-12-31 21:12:43.073 [TransactionCoordinator id=0] Startup complete.
2024-12-31 21:12:43.073 [Transaction Marker Channel Manager 0]: Starting
2024-12-31 21:12:43.075 [Controller id=0] Registering handlers
2024-12-31 21:12:43.075 [MetadataCache brokerId=0] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0).
2024-12-31 21:12:43.080 [Controller id=0] Deleting log dir event notifications
2024-12-31 21:12:43.082 [Controller id=0] Deleting isr change notifications
2024-12-31 21:12:43.085 [Controller id=0] Initializing controller context
2024-12-31 21:12:43.102 [Controller id=0] Initialized broker epochs cache: HashMap(0 -> 25)
2024-12-31 21:12:43.106 [ExpirationReaper-0-AlterAcls]: Starting
2024-12-31 21:12:43.126 [RequestSendThread controllerId=0] Starting
2024-12-31 21:12:43.127 [Controller id=0] Currently active brokers in the cluster: Set(0)
2024-12-31 21:12:43.128 [Controller id=0] Currently shutting brokers in the cluster: HashSet()
2024-12-31 21:12:43.128 [Controller id=0] Current list of topics in the cluster: HashSet()
2024-12-31 21:12:43.128 [Controller id=0] Fetching topic deletions in progress
2024-12-31 21:12:43.132 [Controller id=0] List of topics to be deleted: 
2024-12-31 21:12:43.132 [Controller id=0] List of topics ineligible for deletion: 
2024-12-31 21:12:43.132 [Controller id=0] Initializing topic deletion manager
2024-12-31 21:12:43.133 [Topic Deletion Manager 0] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet()
2024-12-31 21:12:43.135 [Controller id=0] Sending update metadata request
2024-12-31 21:12:43.138 [/config/changes-event-process-thread]: Starting
2024-12-31 21:12:43.140 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions
2024-12-31 21:12:43.149 [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing.
2024-12-31 21:12:43.149 [ReplicaStateMachine controllerId=0] Initializing replica state
2024-12-31 21:12:43.150 [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2024-12-31 21:12:43.154 Kafka version: 3.4.1
2024-12-31 21:12:43.154 Kafka commitId: 8a516edc2755df89
2024-12-31 21:12:43.154 Kafka startTimeMs: 1735650763151
2024-12-31 21:12:43.155 [ReplicaStateMachine controllerId=0] Triggering offline replica state changes
2024-12-31 21:12:43.156 [KafkaServer id=0] started
2024-12-31 21:12:43.156 [PartitionStateMachine controllerId=0] Initializing partition state
2024-12-31 21:12:43.158 [PartitionStateMachine controllerId=0] Triggering online partition state changes
2024-12-31 21:12:43.160 [RequestSendThread controllerId=0] Controller 0 connected to localhost:59578 (id: 0 rack: null) for sending state change requests
2024-12-31 21:12:43.164 [Controller id=0] Ready to serve as the new controller with epoch 1
2024-12-31 21:12:43.167 AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [127.0.0.1:59578]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-31 21:12:43.175 [Controller id=0] Partitions undergoing preferred replica election: 
2024-12-31 21:12:43.176 [Controller id=0] Partitions that completed preferred replica election: 
2024-12-31 21:12:43.176 [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2024-12-31 21:12:43.176 [Controller id=0] Resuming preferred replica election for partitions: 
2024-12-31 21:12:43.177 [Controller id=0] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered
2024-12-31 21:12:43.187 [Controller id=0] Starting the controller scheduler
2024-12-31 21:12:43.204 Kafka version: 3.4.1
2024-12-31 21:12:43.204 Kafka commitId: 8a516edc2755df89
2024-12-31 21:12:43.204 Kafka startTimeMs: 1735650763204
2024-12-31 21:12:43.227 [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use node localhost:59578 (id: 0 rack: null)
2024-12-31 21:12:43.286 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Recorded new controller, from now on will use node localhost:59578 (id: 0 rack: null)
2024-12-31 21:12:43.298 Creating topic pong-message-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0))
2024-12-31 21:12:43.323 [Controller id=0] New topics: [Set(pong-message-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(pong-message-topic,Some(lHgSzKaOSByq2irXU8_3OA),Map(pong-message-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), pong-message-topic-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:12:43.325 [Controller id=0] New partition creation callback for pong-message-topic-0,pong-message-topic-1
2024-12-31 21:12:43.328 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:12:43.329 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:12:43.329 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:12:43.333 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:12:43.356 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:12:43.357 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:12:43.359 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2024-12-31 21:12:43.362 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2024-12-31 21:12:43.363 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:12:43.368 [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 for 2 partitions
2024-12-31 21:12:43.395 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(pong-message-topic-0, pong-message-topic-1)
2024-12-31 21:12:43.396 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2024-12-31 21:12:43.468 [LogLoader partition=pong-message-topic-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.f04d93fc-cc12-4486-acc1-27f68bef1a688780609540308471751] Loading producer state till offset 0 with message format version 2
2024-12-31 21:12:43.485 Created log for partition pong-message-topic-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.f04d93fc-cc12-4486-acc1-27f68bef1a688780609540308471751\pong-message-topic-0 with properties {}
2024-12-31 21:12:43.487 [Partition pong-message-topic-0 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-0
2024-12-31 21:12:43.488 [Partition pong-message-topic-0 broker=0] Log loaded for partition pong-message-topic-0 with initial high watermark 0
2024-12-31 21:12:43.489 [Broker id=0] Leader pong-message-topic-0 with topic id Some(lHgSzKaOSByq2irXU8_3OA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:12:43.503 [LogLoader partition=pong-message-topic-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.f04d93fc-cc12-4486-acc1-27f68bef1a688780609540308471751] Loading producer state till offset 0 with message format version 2
2024-12-31 21:12:43.504 Created log for partition pong-message-topic-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.f04d93fc-cc12-4486-acc1-27f68bef1a688780609540308471751\pong-message-topic-1 with properties {}
2024-12-31 21:12:43.504 [Partition pong-message-topic-1 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-1
2024-12-31 21:12:43.504 [Partition pong-message-topic-1 broker=0] Log loaded for partition pong-message-topic-1 with initial high watermark 0
2024-12-31 21:12:43.504 [Broker id=0] Leader pong-message-topic-1 with topic id Some(lHgSzKaOSByq2irXU8_3OA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:12:43.513 [Broker id=0] Finished LeaderAndIsr request in 147ms correlationId 1 from controller 0 for 2 partitions
2024-12-31 21:12:43.521 [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2
2024-12-31 21:12:43.527 App info kafka.admin.client for adminclient-1 unregistered
2024-12-31 21:12:43.530 Metrics scheduler closed
2024-12-31 21:12:43.530 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:12:43.530 Metrics reporters closed
2024-12-31 21:12:43.757 

Found multiple occurrences of org.json.JSONObject on the class path:

	jar:file:/C:/Users/joech/.m2/repository/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar!/org/json/JSONObject.class
	jar:file:/C:/Users/joech/.m2/repository/org/json/json/20220320/json-20220320.jar!/org/json/JSONObject.class

You may wish to exclude one of them to ensure predictable runtime behavior

2024-12-31 21:12:43.778 Starting KafkaSpec using Java 17.0.12 with PID 14952 (started by joech in C:\code\hsbc\demo\pong)
2024-12-31 21:12:43.779 No active profile set, falling back to 1 default profile: "default"
2024-12-31 21:12:44.342 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:12:44.344 Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2024-12-31 21:12:44.461 Finished Spring Data repository scanning in 109 ms. Found 1 JPA repository interfaces.
2024-12-31 21:12:44.482 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:12:44.483 Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2024-12-31 21:12:44.496 Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.demo.dao.MessageRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2024-12-31 21:12:44.496 Finished Spring Data repository scanning in 5 ms. Found 0 Redis repository interfaces.
2024-12-31 21:12:44.915 HHH000204: Processing PersistenceUnitInfo [name: default]
2024-12-31 21:12:44.971 HHH000412: Hibernate ORM core version 6.2.9.Final
2024-12-31 21:12:44.973 HHH000406: Using bytecode reflection optimizer
2024-12-31 21:12:45.111 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:12:45.220 No LoadTimeWeaver setup: ignoring JPA class transformer
2024-12-31 21:12:45.231 HikariPool-1 - Starting...
2024-12-31 21:12:45.360 HikariPool-1 - Added connection conn0: url=jdbc:h2:mem:testdb user=SA
2024-12-31 21:12:45.361 HikariPool-1 - Start completed.
2024-12-31 21:12:45.517 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:12:45.919 HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2024-12-31 21:12:45.983 Initialized JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:12:47.184 ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:59578]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-pong-service-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = pong-service
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2024-12-31 21:12:47.216 These configurations '[spring.json.trusted.packages]' were supplied but are not used yet.
2024-12-31 21:12:47.216 Kafka version: 3.4.1
2024-12-31 21:12:47.216 Kafka commitId: 8a516edc2755df89
2024-12-31 21:12:47.216 Kafka startTimeMs: 1735650767216
2024-12-31 21:12:47.218 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Subscribed to topic(s): pong-message-topic
2024-12-31 21:12:47.232 Started KafkaSpec in 3.659 seconds (process running for 18.149)
2024-12-31 21:12:47.247 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting the last seen epoch of partition pong-message-topic-0 to 0 since the associated topicId changed from null to lHgSzKaOSByq2irXU8_3OA
2024-12-31 21:12:47.247 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting the last seen epoch of partition pong-message-topic-1 to 0 since the associated topicId changed from null to lHgSzKaOSByq2irXU8_3OA
2024-12-31 21:12:47.248 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Cluster ID: L24rYvyGSnq3jakR5pYFGg
2024-12-31 21:12:47.250 Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0))
2024-12-31 21:12:47.258 [Controller id=0] New topics: [Set(__consumer_offsets)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(__consumer_offsets,Some(9Tv4hxOGT7ynvXTDHOa04g),HashMap(__consumer_offsets-4 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-3 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-2 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:12:47.258 [Controller id=0] New partition creation callback for __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2024-12-31 21:12:47.258 [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:12:47.258 [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:12:47.258 [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:12:47.260 [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:12:47.260 [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:12:47.260 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:12:47.260 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:12:47.268 [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:12:47.268 [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:12:47.268 [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:12:47.268 [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:12:47.268 [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:12:47.268 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 5 become-leader and 0 become-follower partitions
2024-12-31 21:12:47.269 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 5 partitions
2024-12-31 21:12:47.269 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:12:47.270 [Broker id=0] Handling LeaderAndIsr request correlationId 3 from controller 0 for 5 partitions
2024-12-31 21:12:47.273 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-4, __consumer_offsets-3, __consumer_offsets-2, __consumer_offsets-0, __consumer_offsets-1)
2024-12-31 21:12:47.273 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 3 from controller 0 epoch 1 as part of the become-leader transition for 5 partitions
2024-12-31 21:12:47.284 [LogLoader partition=__consumer_offsets-3, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.f04d93fc-cc12-4486-acc1-27f68bef1a688780609540308471751] Loading producer state till offset 0 with message format version 2
2024-12-31 21:12:47.285 Created log for partition __consumer_offsets-3 in C:\Users\joech\AppData\Local\Temp\spring.kafka.f04d93fc-cc12-4486-acc1-27f68bef1a688780609540308471751\__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:12:47.288 [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
2024-12-31 21:12:47.288 [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0
2024-12-31 21:12:47.288 [Broker id=0] Leader __consumer_offsets-3 with topic id Some(9Tv4hxOGT7ynvXTDHOa04g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:12:47.297 [LogLoader partition=__consumer_offsets-2, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.f04d93fc-cc12-4486-acc1-27f68bef1a688780609540308471751] Loading producer state till offset 0 with message format version 2
2024-12-31 21:12:47.297 Created log for partition __consumer_offsets-2 in C:\Users\joech\AppData\Local\Temp\spring.kafka.f04d93fc-cc12-4486-acc1-27f68bef1a688780609540308471751\__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:12:47.297 [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
2024-12-31 21:12:47.298 [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0
2024-12-31 21:12:47.298 [Broker id=0] Leader __consumer_offsets-2 with topic id Some(9Tv4hxOGT7ynvXTDHOa04g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:12:47.307 [LogLoader partition=__consumer_offsets-4, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.f04d93fc-cc12-4486-acc1-27f68bef1a688780609540308471751] Loading producer state till offset 0 with message format version 2
2024-12-31 21:12:47.308 Created log for partition __consumer_offsets-4 in C:\Users\joech\AppData\Local\Temp\spring.kafka.f04d93fc-cc12-4486-acc1-27f68bef1a688780609540308471751\__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:12:47.308 [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
2024-12-31 21:12:47.308 [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0
2024-12-31 21:12:47.308 [Broker id=0] Leader __consumer_offsets-4 with topic id Some(9Tv4hxOGT7ynvXTDHOa04g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:12:47.317 [LogLoader partition=__consumer_offsets-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.f04d93fc-cc12-4486-acc1-27f68bef1a688780609540308471751] Loading producer state till offset 0 with message format version 2
2024-12-31 21:12:47.318 Created log for partition __consumer_offsets-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.f04d93fc-cc12-4486-acc1-27f68bef1a688780609540308471751\__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:12:47.318 [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
2024-12-31 21:12:47.318 [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0
2024-12-31 21:12:47.318 [Broker id=0] Leader __consumer_offsets-1 with topic id Some(9Tv4hxOGT7ynvXTDHOa04g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:12:47.331 [LogLoader partition=__consumer_offsets-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.f04d93fc-cc12-4486-acc1-27f68bef1a688780609540308471751] Loading producer state till offset 0 with message format version 2
2024-12-31 21:12:47.332 Created log for partition __consumer_offsets-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.f04d93fc-cc12-4486-acc1-27f68bef1a688780609540308471751\__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:12:47.332 [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
2024-12-31 21:12:47.332 [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0
2024-12-31 21:12:47.332 [Broker id=0] Leader __consumer_offsets-0 with topic id Some(9Tv4hxOGT7ynvXTDHOa04g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:12:47.336 [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 0
2024-12-31 21:12:47.337 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0
2024-12-31 21:12:47.338 [GroupCoordinator 0]: Elected as the group coordinator for partition 2 in epoch 0
2024-12-31 21:12:47.338 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0
2024-12-31 21:12:47.338 [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 0
2024-12-31 21:12:47.338 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0
2024-12-31 21:12:47.338 [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 0
2024-12-31 21:12:47.338 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0
2024-12-31 21:12:47.338 [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 0
2024-12-31 21:12:47.338 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0
2024-12-31 21:12:47.338 [Broker id=0] Finished LeaderAndIsr request in 68ms correlationId 3 from controller 0 for 5 partitions
2024-12-31 21:12:47.340 [Broker id=0] Add 5 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 4
2024-12-31 21:12:47.343 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 6 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler.
2024-12-31 21:12:47.344 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler.
2024-12-31 21:12:47.344 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler.
2024-12-31 21:12:47.344 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler.
2024-12-31 21:12:47.344 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler.
2024-12-31 21:12:47.351 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Discovered group coordinator localhost:59578 (id: 2147483647 rack: null)
2024-12-31 21:12:47.353 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] (Re-)joining group
2024-12-31 21:12:47.372 [GroupCoordinator 0]: Dynamic member with unknown member id joins group pong-service in Empty state. Created a new member id consumer-pong-service-1-0b096c91-b4b8-4df2-9b28-216a81d1bc22 and request the member to rejoin with this id.
2024-12-31 21:12:47.376 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: need to re-join with the given member-id: consumer-pong-service-1-0b096c91-b4b8-4df2-9b28-216a81d1bc22
2024-12-31 21:12:47.376 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2024-12-31 21:12:47.376 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] (Re-)joining group
2024-12-31 21:12:47.383 [GroupCoordinator 0]: Preparing to rebalance group pong-service in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-pong-service-1-0b096c91-b4b8-4df2-9b28-216a81d1bc22 with group instance id None; client reason: rebalance failed due to MemberIdRequiredException)
2024-12-31 21:12:47.389 [GroupCoordinator 0]: Stabilized group pong-service generation 1 (__consumer_offsets-2) with 1 members
2024-12-31 21:12:47.390 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Successfully joined group with generation Generation{generationId=1, memberId='consumer-pong-service-1-0b096c91-b4b8-4df2-9b28-216a81d1bc22', protocol='range'}
2024-12-31 21:12:47.392 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Finished assignment for group at generation 1: {consumer-pong-service-1-0b096c91-b4b8-4df2-9b28-216a81d1bc22=Assignment(partitions=[pong-message-topic-0, pong-message-topic-1])}
2024-12-31 21:12:47.399 [GroupCoordinator 0]: Assignment received from leader consumer-pong-service-1-0b096c91-b4b8-4df2-9b28-216a81d1bc22 for group pong-service for generation 1. The group has 1 members, 0 of which are static.
2024-12-31 21:12:47.447 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Successfully synced group in generation Generation{generationId=1, memberId='consumer-pong-service-1-0b096c91-b4b8-4df2-9b28-216a81d1bc22', protocol='range'}
2024-12-31 21:12:47.447 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Notifying assignor about the new Assignment(partitions=[pong-message-topic-0, pong-message-topic-1])
2024-12-31 21:12:47.449 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Adding newly assigned partitions: pong-message-topic-0, pong-message-topic-1
2024-12-31 21:12:47.459 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-0
2024-12-31 21:12:47.460 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-1
2024-12-31 21:12:47.463 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-0
2024-12-31 21:12:47.464 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-1
2024-12-31 21:12:47.475 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting offset for partition pong-message-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:59578 (id: 0 rack: null)], epoch=0}}.
2024-12-31 21:12:47.475 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting offset for partition pong-message-topic-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:59578 (id: 0 rack: null)], epoch=0}}.
2024-12-31 21:12:47.496 pong-service: partitions assigned: [pong-message-topic-0, pong-message-topic-1]
2024-12-31 21:12:47.787 Idempotence will be disabled because acks is set to 0, not set to 'all'.
2024-12-31 21:12:47.787 ProducerConfig values: 
	acks = 0
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:59578]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2024-12-31 21:12:47.799 Kafka version: 3.4.1
2024-12-31 21:12:47.799 Kafka commitId: 8a516edc2755df89
2024-12-31 21:12:47.799 Kafka startTimeMs: 1735650767799
2024-12-31 21:12:47.802 [Producer clientId=producer-1] Resetting the last seen epoch of partition pong-message-topic-0 to 0 since the associated topicId changed from null to lHgSzKaOSByq2irXU8_3OA
2024-12-31 21:12:47.802 [Producer clientId=producer-1] Resetting the last seen epoch of partition pong-message-topic-1 to 0 since the associated topicId changed from null to lHgSzKaOSByq2irXU8_3OA
2024-12-31 21:12:47.802 [Producer clientId=producer-1] Cluster ID: L24rYvyGSnq3jakR5pYFGg
2024-12-31 21:12:47.956 [KafkaServer id=0] shutting down
2024-12-31 21:12:47.957 [KafkaServer id=0] Starting controlled shutdown
2024-12-31 21:12:47.962 [Controller id=0] Shutting down broker 0
2024-12-31 21:12:47.963 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:12:47.964 [KafkaServer id=0] Controlled shutdown request returned successfully after 5ms
2024-12-31 21:12:47.965 [/config/changes-event-process-thread]: Shutting down
2024-12-31 21:12:47.966 [/config/changes-event-process-thread]: Shutdown completed
2024-12-31 21:12:47.966 [/config/changes-event-process-thread]: Stopped
2024-12-31 21:12:47.966 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
2024-12-31 21:12:47.977 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:12:47.978 [Producer clientId=producer-1] Node 0 disconnected.
2024-12-31 21:12:47.980 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Cancelled in-flight FETCH request with correlation id 15 due to node 0 being disconnected (elapsed time since creation: 137ms, elapsed time since send: 137ms, request timeout: 30000ms)
2024-12-31 21:12:47.980 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:12:47.981 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 2147483647 disconnected.
2024-12-31 21:12:47.982 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:12:47.982 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors
2024-12-31 21:12:47.982 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Group coordinator localhost:59578 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
2024-12-31 21:12:47.982 [data-plane Kafka Request Handler on Broker 0], shutting down
2024-12-31 21:12:47.984 [data-plane Kafka Request Handler on Broker 0], shut down completely
2024-12-31 21:12:47.981 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Error sending fetch request (sessionId=1912206489, epoch=1) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2024-12-31 21:12:47.985 [ExpirationReaper-0-AlterAcls]: Shutting down
2024-12-31 21:12:47.987 [ExpirationReaper-0-AlterAcls]: Shutdown completed
2024-12-31 21:12:47.987 [ExpirationReaper-0-AlterAcls]: Stopped
2024-12-31 21:12:47.987 [KafkaApi-0] Shutdown complete.
2024-12-31 21:12:47.989 [ExpirationReaper-0-topic]: Shutting down
2024-12-31 21:12:47.989 [ExpirationReaper-0-topic]: Shutdown completed
2024-12-31 21:12:47.989 [ExpirationReaper-0-topic]: Stopped
2024-12-31 21:12:47.990 [TransactionCoordinator id=0] Shutting down.
2024-12-31 21:12:47.990 [Transaction State Manager 0]: Shutdown complete
2024-12-31 21:12:47.990 [Transaction Marker Channel Manager 0]: Shutting down
2024-12-31 21:12:47.990 [Transaction Marker Channel Manager 0]: Shutdown completed
2024-12-31 21:12:47.990 [Transaction Marker Channel Manager 0]: Stopped
2024-12-31 21:12:47.990 [TransactionCoordinator id=0] Shutdown complete.
2024-12-31 21:12:47.991 [GroupCoordinator 0]: Shutting down.
2024-12-31 21:12:47.991 [ExpirationReaper-0-Heartbeat]: Shutting down
2024-12-31 21:12:47.991 [ExpirationReaper-0-Heartbeat]: Shutdown completed
2024-12-31 21:12:47.991 [ExpirationReaper-0-Heartbeat]: Stopped
2024-12-31 21:12:47.991 [ExpirationReaper-0-Rebalance]: Shutting down
2024-12-31 21:12:47.991 [ExpirationReaper-0-Rebalance]: Shutdown completed
2024-12-31 21:12:47.991 [ExpirationReaper-0-Rebalance]: Stopped
2024-12-31 21:12:47.991 [GroupCoordinator 0]: Shutdown complete.
2024-12-31 21:12:47.992 [ReplicaManager broker=0] Shutting down
2024-12-31 21:12:47.992 [LogDirFailureHandler]: Shutting down
2024-12-31 21:12:47.992 [LogDirFailureHandler]: Stopped
2024-12-31 21:12:47.992 [LogDirFailureHandler]: Shutdown completed
2024-12-31 21:12:47.992 [ReplicaFetcherManager on broker 0] shutting down
2024-12-31 21:12:47.993 [ReplicaFetcherManager on broker 0] shutdown completed
2024-12-31 21:12:47.993 [ReplicaAlterLogDirsManager on broker 0] shutting down
2024-12-31 21:12:47.993 [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2024-12-31 21:12:47.993 [ExpirationReaper-0-Fetch]: Shutting down
2024-12-31 21:12:47.995 [ExpirationReaper-0-Fetch]: Shutdown completed
2024-12-31 21:12:47.995 [ExpirationReaper-0-Fetch]: Stopped
2024-12-31 21:12:47.995 [ExpirationReaper-0-Produce]: Shutting down
2024-12-31 21:12:47.995 [ExpirationReaper-0-Produce]: Stopped
2024-12-31 21:12:47.995 [ExpirationReaper-0-Produce]: Shutdown completed
2024-12-31 21:12:47.995 [ExpirationReaper-0-DeleteRecords]: Shutting down
2024-12-31 21:12:47.995 [ExpirationReaper-0-DeleteRecords]: Stopped
2024-12-31 21:12:47.995 [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2024-12-31 21:12:47.995 [ExpirationReaper-0-ElectLeader]: Shutting down
2024-12-31 21:12:47.995 [ExpirationReaper-0-ElectLeader]: Shutdown completed
2024-12-31 21:12:47.995 [ExpirationReaper-0-ElectLeader]: Stopped
2024-12-31 21:12:48.005 [ReplicaManager broker=0] Shut down completely
2024-12-31 21:12:48.005 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutting down
2024-12-31 21:12:48.005 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Stopped
2024-12-31 21:12:48.005 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutdown completed
2024-12-31 21:12:48.006 Broker to controller channel manager for alterPartition shutdown
2024-12-31 21:12:48.006 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down
2024-12-31 21:12:48.006 [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped
2024-12-31 21:12:48.006 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed
2024-12-31 21:12:48.006 Broker to controller channel manager for forwarding shutdown
2024-12-31 21:12:48.006 Shutting down.
2024-12-31 21:12:48.007 Shutting down the log cleaner.
2024-12-31 21:12:48.007 [kafka-log-cleaner-thread-0]: Shutting down
2024-12-31 21:12:48.008 [kafka-log-cleaner-thread-0]: Stopped
2024-12-31 21:12:48.008 [kafka-log-cleaner-thread-0]: Shutdown completed
2024-12-31 21:12:48.031 [ProducerStateManager partition=pong-message-topic-0] Wrote producer snapshot at offset 1 with 0 producer ids in 3 ms.
2024-12-31 21:12:48.042 [ProducerStateManager partition=__consumer_offsets-2] Wrote producer snapshot at offset 4 with 0 producer ids in 2 ms.
2024-12-31 21:12:48.053 Shutdown complete.
2024-12-31 21:12:48.053 [ControllerEventThread controllerId=0] Shutting down
2024-12-31 21:12:48.053 [ControllerEventThread controllerId=0] Shutdown completed
2024-12-31 21:12:48.053 [ControllerEventThread controllerId=0] Stopped
2024-12-31 21:12:48.054 [PartitionStateMachine controllerId=0] Stopped partition state machine
2024-12-31 21:12:48.054 [ReplicaStateMachine controllerId=0] Stopped replica state machine
2024-12-31 21:12:48.055 [RequestSendThread controllerId=0] Shutting down
2024-12-31 21:12:48.055 [RequestSendThread controllerId=0] Shutdown completed
2024-12-31 21:12:48.055 [RequestSendThread controllerId=0] Stopped
2024-12-31 21:12:48.056 [Controller id=0] Resigned
2024-12-31 21:12:48.056 [feature-zk-node-event-process-thread]: Shutting down
2024-12-31 21:12:48.056 [feature-zk-node-event-process-thread]: Shutdown completed
2024-12-31 21:12:48.056 [feature-zk-node-event-process-thread]: Stopped
2024-12-31 21:12:48.057 [ZooKeeperClient Kafka server] Closing.
2024-12-31 21:12:48.078 [Producer clientId=producer-1] Node 0 disconnected.
2024-12-31 21:12:48.078 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:12:48.079 [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:59578) could not be established. Broker may not be available.
2024-12-31 21:12:48.079 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node 0 (localhost/127.0.0.1:59578) could not be established. Broker may not be available.
2024-12-31 21:12:48.162 Session: 0x1001773dbaa0000 closed
2024-12-31 21:12:48.162 EventThread shut down for session: 0x1001773dbaa0000
2024-12-31 21:12:48.162 [ZooKeeperClient Kafka server] Closed.
2024-12-31 21:12:48.162 [ThrottledChannelReaper-Fetch]: Shutting down
2024-12-31 21:12:48.164 [ThrottledChannelReaper-Fetch]: Stopped
2024-12-31 21:12:48.164 [ThrottledChannelReaper-Fetch]: Shutdown completed
2024-12-31 21:12:48.164 [ThrottledChannelReaper-Produce]: Shutting down
2024-12-31 21:12:48.164 [ThrottledChannelReaper-Produce]: Stopped
2024-12-31 21:12:48.164 [ThrottledChannelReaper-Produce]: Shutdown completed
2024-12-31 21:12:48.164 [ThrottledChannelReaper-Request]: Shutting down
2024-12-31 21:12:48.164 [ThrottledChannelReaper-Request]: Stopped
2024-12-31 21:12:48.164 [ThrottledChannelReaper-Request]: Shutdown completed
2024-12-31 21:12:48.164 [ThrottledChannelReaper-ControllerMutation]: Shutting down
2024-12-31 21:12:48.164 [ThrottledChannelReaper-ControllerMutation]: Stopped
2024-12-31 21:12:48.164 [ThrottledChannelReaper-ControllerMutation]: Shutdown completed
2024-12-31 21:12:48.165 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server
2024-12-31 21:12:48.172 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed
2024-12-31 21:12:48.174 Metrics scheduler closed
2024-12-31 21:12:48.174 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:12:48.174 Metrics reporters closed
2024-12-31 21:12:48.175 Broker and topic stats closed
2024-12-31 21:12:48.175 App info kafka.server for 0 unregistered
2024-12-31 21:12:48.175 [KafkaServer id=0] shut down completed
2024-12-31 21:12:48.179 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:12:48.179 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node 0 (localhost/127.0.0.1:59578) could not be established. Broker may not be available.
2024-12-31 21:12:48.179 [Producer clientId=producer-1] Node 0 disconnected.
2024-12-31 21:12:48.180 [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:59578) could not be established. Broker may not be available.
2024-12-31 21:12:48.185 ConnnectionExpirerThread interrupted
2024-12-31 21:12:48.186 accept thread exitted run method
2024-12-31 21:12:48.186 selector thread exitted run method
2024-12-31 21:12:48.186 selector thread exitted run method
2024-12-31 21:12:48.186 shutting down
2024-12-31 21:12:48.186 Shutting down
2024-12-31 21:12:48.186 Draining request throttler queue
2024-12-31 21:12:48.186 RequestThrottler shutdown. Dropped 0 requests
2024-12-31 21:12:48.186 Shutting down
2024-12-31 21:12:48.186 Shutting down
2024-12-31 21:12:48.186 Shutting down
2024-12-31 21:12:48.186 PrepRequestProcessor exited loop!
2024-12-31 21:12:48.186 SyncRequestProcessor exited!
2024-12-31 21:12:48.186 shutdown of request processor complete
2024-12-31 21:12:48.213 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Revoke previously assigned partitions pong-message-topic-0, pong-message-topic-1
2024-12-31 21:12:48.214 pong-service: partitions revoked: [pong-message-topic-0, pong-message-topic-1]
2024-12-31 21:12:48.214 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:12:48.214 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:12:48.214 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Unsubscribed all topics or patterns and assigned partitions
2024-12-31 21:12:48.214 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:12:48.214 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:12:48.214 Metrics scheduler closed
2024-12-31 21:12:48.214 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:12:48.214 Metrics reporters closed
2024-12-31 21:12:48.215 App info kafka.consumer for consumer-pong-service-1 unregistered
2024-12-31 21:12:48.216 pong-service: Consumer stopped
2024-12-31 21:12:48.216 [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2024-12-31 21:12:48.217 Metrics scheduler closed
2024-12-31 21:12:48.217 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:12:48.217 Metrics reporters closed
2024-12-31 21:12:48.217 App info kafka.producer for producer-1 unregistered
2024-12-31 21:12:48.233 Closing JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:12:48.234 HikariPool-1 - Shutdown initiated...
2024-12-31 21:12:48.235 HikariPool-1 - Shutdown completed.
2024-12-31 21:12:48.289 SessionTrackerImpl exited loop!
2024-12-31 21:14:00.459 Could not detect default configuration classes for test class [com.demo.kafka.KafkaSpec]: KafkaSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:14:00.563 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.kafka.KafkaSpec
2024-12-31 21:14:01.027 

Found multiple occurrences of org.json.JSONObject on the class path:

	jar:file:/C:/Users/joech/.m2/repository/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar!/org/json/JSONObject.class
	jar:file:/C:/Users/joech/.m2/repository/org/json/json/20220320/json-20220320.jar!/org/json/JSONObject.class

You may wish to exclude one of them to ensure predictable runtime behavior

2024-12-31 21:14:01.041 Starting KafkaSpec using Java 17.0.12 with PID 24700 (started by joech in C:\code\hsbc\demo\pong)
2024-12-31 21:14:01.042 No active profile set, falling back to 1 default profile: "default"
2024-12-31 21:14:01.510 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:14:01.512 Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2024-12-31 21:14:01.628 Finished Spring Data repository scanning in 108 ms. Found 1 JPA repository interfaces.
2024-12-31 21:14:01.643 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:14:01.644 Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2024-12-31 21:14:01.657 Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.demo.dao.MessageRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2024-12-31 21:14:01.658 Finished Spring Data repository scanning in 5 ms. Found 0 Redis repository interfaces.
2024-12-31 21:14:02.062 HHH000204: Processing PersistenceUnitInfo [name: default]
2024-12-31 21:14:02.128 HHH000412: Hibernate ORM core version 6.2.9.Final
2024-12-31 21:14:02.130 HHH000406: Using bytecode reflection optimizer
2024-12-31 21:14:02.318 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:14:02.424 No LoadTimeWeaver setup: ignoring JPA class transformer
2024-12-31 21:14:02.438 HikariPool-1 - Starting...
2024-12-31 21:14:02.558 HikariPool-1 - Added connection conn0: url=jdbc:h2:mem:testdb user=SA
2024-12-31 21:14:02.560 HikariPool-1 - Start completed.
2024-12-31 21:14:02.729 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:14:03.209 HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2024-12-31 21:14:03.273 Initialized JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:14:05.105 ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-pong-service-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = pong-service
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2024-12-31 21:14:05.250 These configurations '[spring.json.trusted.packages]' were supplied but are not used yet.
2024-12-31 21:14:05.250 Kafka version: 3.4.1
2024-12-31 21:14:05.250 Kafka commitId: 8a516edc2755df89
2024-12-31 21:14:05.250 Kafka startTimeMs: 1735650845250
2024-12-31 21:14:05.257 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Subscribed to topic(s): pong-message-topic
2024-12-31 21:14:05.283 Started KafkaSpec in 4.425 seconds (process running for 6.21)
2024-12-31 21:14:05.717 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:05.722 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:05.722 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:05.829 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:05.830 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:05.830 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:05.942 Registered kafka:type=kafka.Log4jController MBean
2024-12-31 21:14:05.957 
2024-12-31 21:14:05.958   ______                  _                                          
2024-12-31 21:14:05.958  |___  /                 | |                                         
2024-12-31 21:14:05.958     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __   
2024-12-31 21:14:05.958    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__|
2024-12-31 21:14:05.958   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |    
2024-12-31 21:14:05.958  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_|
2024-12-31 21:14:05.958                                               | |                     
2024-12-31 21:14:05.958                                               |_|                     
2024-12-31 21:14:05.958 
2024-12-31 21:14:05.987 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:05.988 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:05.988 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:06.195 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:06.195 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:06.195 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:06.562 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:06.562 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:06.562 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:07.481 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:07.481 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:07.481 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:08.534 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:08.534 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:08.534 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:09.468 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:09.468 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:09.468 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:09.581 Could not detect default configuration classes for test class [com.demo.controller.PongControllerSpec]: PongControllerSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:14:09.758 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.controller.PongControllerSpec
2024-12-31 21:14:09.934 Could not detect default configuration classes for test class [com.demo.dao.MessageRepositorySpec]: MessageRepositorySpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:14:09.946 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.dao.MessageRepositorySpec
2024-12-31 21:14:09.957 Could not detect default configuration classes for test class [com.demo.kafka.KafkaSpec]: KafkaSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:14:09.973 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.kafka.KafkaSpec
2024-12-31 21:14:10.012 Could not detect default configuration classes for test class [com.demo.controller.PongControllerSpec]: PongControllerSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:14:10.016 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.controller.PongControllerSpec
2024-12-31 21:14:10.021 Could not detect default configuration classes for test class [com.demo.dao.MessageRepositorySpec]: MessageRepositorySpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:14:10.024 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.dao.MessageRepositorySpec
2024-12-31 21:14:10.028 Could not detect default configuration classes for test class [com.demo.kafka.KafkaSpec]: KafkaSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:14:10.029 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.kafka.KafkaSpec
2024-12-31 21:14:10.459 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:10.460 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:10.460 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:10.615 

Found multiple occurrences of org.json.JSONObject on the class path:

	jar:file:/C:/work/apache-maven-3.8.8/repo/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar!/org/json/JSONObject.class
	jar:file:/C:/work/apache-maven-3.8.8/repo/org/json/json/20220320/json-20220320.jar!/org/json/JSONObject.class

You may wish to exclude one of them to ensure predictable runtime behavior

2024-12-31 21:14:10.716 Registered kafka:type=kafka.Log4jController MBean
2024-12-31 21:14:10.797 
2024-12-31 21:14:10.798   ______                  _                                          
2024-12-31 21:14:10.798  |___  /                 | |                                         
2024-12-31 21:14:10.798     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __   
2024-12-31 21:14:10.798    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__|
2024-12-31 21:14:10.798   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |    
2024-12-31 21:14:10.798  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_|
2024-12-31 21:14:10.798                                               | |                     
2024-12-31 21:14:10.798                                               |_|                     
2024-12-31 21:14:10.798 
2024-12-31 21:14:11.244 Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT
2024-12-31 21:14:11.245 Server environment:host.name=Joe
2024-12-31 21:14:11.245 Server environment:java.version=17.0.12
2024-12-31 21:14:11.245 Server environment:java.vendor=Oracle Corporation
2024-12-31 21:14:11.245 Server environment:java.home=C:\work\jdk-17
2024-12-31 21:14:11.245 Server environment:java.class.path=C:\work\ideaIC-2024.2.0.2.win\lib\idea_rt.jar;C:\work\ideaIC-2024.2.0.2.win\plugins\junit\lib\junit5-rt.jar;C:\work\ideaIC-2024.2.0.2.win\plugins\junit\lib\junit-rt.jar;C:\code\hsbc\demo\pong\target\test-classes;C:\code\hsbc\demo\pong\target\classes;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-webflux\3.1.4\spring-boot-starter-webflux-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter\3.1.4\spring-boot-starter-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot\3.1.4\spring-boot-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-autoconfigure\3.1.4\spring-boot-autoconfigure-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-logging\3.1.4\spring-boot-starter-logging-3.1.4.jar;C:\Users\joech\.m2\repository\ch\qos\logback\logback-classic\1.4.11\logback-classic-1.4.11.jar;C:\Users\joech\.m2\repository\ch\qos\logback\logback-core\1.4.11\logback-core-1.4.11.jar;C:\Users\joech\.m2\repository\org\apache\logging\log4j\log4j-to-slf4j\2.20.0\log4j-to-slf4j-2.20.0.jar;C:\Users\joech\.m2\repository\org\apache\logging\log4j\log4j-api\2.20.0\log4j-api-2.20.0.jar;C:\Users\joech\.m2\repository\org\slf4j\jul-to-slf4j\2.0.9\jul-to-slf4j-2.0.9.jar;C:\Users\joech\.m2\repository\jakarta\annotation\jakarta.annotation-api\2.1.1\jakarta.annotation-api-2.1.1.jar;C:\Users\joech\.m2\repository\org\yaml\snakeyaml\1.33\snakeyaml-1.33.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-json\3.1.4\spring-boot-starter-json-3.1.4.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\core\jackson-databind\2.15.2\jackson-databind-2.15.2.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\core\jackson-annotations\2.15.2\jackson-annotations-2.15.2.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\core\jackson-core\2.15.2\jackson-core-2.15.2.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.15.2\jackson-datatype-jdk8-2.15.2.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.15.2\jackson-datatype-jsr310-2.15.2.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\module\jackson-module-parameter-names\2.15.2\jackson-module-parameter-names-2.15.2.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-reactor-netty\3.1.4\spring-boot-starter-reactor-netty-3.1.4.jar;C:\Users\joech\.m2\repository\io\projectreactor\netty\reactor-netty-http\1.1.11\reactor-netty-http-1.1.11.jar;C:\Users\joech\.m2\repository\io\netty\netty-codec-http\4.1.97.Final\netty-codec-http-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-codec-http2\4.1.97.Final\netty-codec-http2-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-resolver-dns\4.1.97.Final\netty-resolver-dns-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-codec-dns\4.1.97.Final\netty-codec-dns-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-resolver-dns-native-macos\4.1.97.Final\netty-resolver-dns-native-macos-4.1.97.Final-osx-x86_64.jar;C:\Users\joech\.m2\repository\io\netty\netty-resolver-dns-classes-macos\4.1.97.Final\netty-resolver-dns-classes-macos-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final-linux-x86_64.jar;C:\Users\joech\.m2\repository\io\projectreactor\netty\reactor-netty-core\1.1.11\reactor-netty-core-1.1.11.jar;C:\Users\joech\.m2\repository\io\netty\netty-handler-proxy\4.1.97.Final\netty-handler-proxy-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-codec-socks\4.1.97.Final\netty-codec-socks-4.1.97.Final.jar;C:\Users\joech\.m2\repository\org\springframework\spring-web\6.0.12\spring-web-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-beans\6.0.12\spring-beans-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-webflux\6.0.12\spring-webflux-6.0.12.jar;C:\Users\joech\.m2\repository\io\projectreactor\reactor-core\3.5.10\reactor-core-3.5.10.jar;C:\Users\joech\.m2\repository\org\reactivestreams\reactive-streams\1.0.4\reactive-streams-1.0.4.jar;C:\Users\joech\.m2\repository\com\google\guava\guava\19.0\guava-19.0.jar;C:\Users\joech\.m2\repository\commons-io\commons-io\2.11.0\commons-io-2.11.0.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-data-redis\3.1.4\spring-boot-starter-data-redis-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\data\spring-data-redis\3.1.4\spring-data-redis-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\data\spring-data-keyvalue\3.1.4\spring-data-keyvalue-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\spring-oxm\6.0.12\spring-oxm-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-aop\6.0.12\spring-aop-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-context-support\6.0.12\spring-context-support-6.0.12.jar;C:\Users\joech\.m2\repository\io\lettuce\lettuce-core\6.2.6.RELEASE\lettuce-core-6.2.6.RELEASE.jar;C:\Users\joech\.m2\repository\io\netty\netty-common\4.1.97.Final\netty-common-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-handler\4.1.97.Final\netty-handler-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-resolver\4.1.97.Final\netty-resolver-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-buffer\4.1.97.Final\netty-buffer-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-transport-native-unix-common\4.1.97.Final\netty-transport-native-unix-common-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-codec\4.1.97.Final\netty-codec-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-transport\4.1.97.Final\netty-transport-4.1.97.Final.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-data-jpa\3.1.4\spring-boot-starter-data-jpa-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-aop\3.1.4\spring-boot-starter-aop-3.1.4.jar;C:\Users\joech\.m2\repository\org\aspectj\aspectjweaver\1.9.20\aspectjweaver-1.9.20.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-jdbc\3.1.4\spring-boot-starter-jdbc-3.1.4.jar;C:\Users\joech\.m2\repository\com\zaxxer\HikariCP\5.0.1\HikariCP-5.0.1.jar;C:\Users\joech\.m2\repository\org\springframework\spring-jdbc\6.0.12\spring-jdbc-6.0.12.jar;C:\Users\joech\.m2\repository\org\hibernate\orm\hibernate-core\6.2.9.Final\hibernate-core-6.2.9.Final.jar;C:\Users\joech\.m2\repository\jakarta\persistence\jakarta.persistence-api\3.1.0\jakarta.persistence-api-3.1.0.jar;C:\Users\joech\.m2\repository\jakarta\transaction\jakarta.transaction-api\2.0.1\jakarta.transaction-api-2.0.1.jar;C:\Users\joech\.m2\repository\org\jboss\logging\jboss-logging\3.5.3.Final\jboss-logging-3.5.3.Final.jar;C:\Users\joech\.m2\repository\org\hibernate\common\hibernate-commons-annotations\6.0.6.Final\hibernate-commons-annotations-6.0.6.Final.jar;C:\Users\joech\.m2\repository\io\smallrye\jandex\3.0.5\jandex-3.0.5.jar;C:\Users\joech\.m2\repository\com\fasterxml\classmate\1.5.1\classmate-1.5.1.jar;C:\Users\joech\.m2\repository\net\bytebuddy\byte-buddy\1.14.8\byte-buddy-1.14.8.jar;C:\Users\joech\.m2\repository\org\glassfish\jaxb\jaxb-runtime\4.0.3\jaxb-runtime-4.0.3.jar;C:\Users\joech\.m2\repository\org\glassfish\jaxb\jaxb-core\4.0.3\jaxb-core-4.0.3.jar;C:\Users\joech\.m2\repository\org\eclipse\angus\angus-activation\2.0.1\angus-activation-2.0.1.jar;C:\Users\joech\.m2\repository\org\glassfish\jaxb\txw2\4.0.3\txw2-4.0.3.jar;C:\Users\joech\.m2\repository\com\sun\istack\istack-commons-runtime\4.1.2\istack-commons-runtime-4.1.2.jar;C:\Users\joech\.m2\repository\jakarta\inject\jakarta.inject-api\2.0.1\jakarta.inject-api-2.0.1.jar;C:\Users\joech\.m2\repository\org\antlr\antlr4-runtime\4.10.1\antlr4-runtime-4.10.1.jar;C:\Users\joech\.m2\repository\org\springframework\data\spring-data-jpa\3.1.4\spring-data-jpa-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\data\spring-data-commons\3.1.4\spring-data-commons-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\spring-orm\6.0.12\spring-orm-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-aspects\6.0.12\spring-aspects-6.0.12.jar;C:\Users\joech\.m2\repository\org\postgresql\postgresql\42.6.0\postgresql-42.6.0.jar;C:\Users\joech\.m2\repository\org\checkerframework\checker-qual\3.31.0\checker-qual-3.31.0.jar;C:\Users\joech\.m2\repository\org\springframework\kafka\spring-kafka\3.0.11\spring-kafka-3.0.11.jar;C:\Users\joech\.m2\repository\org\springframework\spring-context\6.0.12\spring-context-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-expression\6.0.12\spring-expression-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-messaging\6.0.12\spring-messaging-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-tx\6.0.12\spring-tx-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\retry\spring-retry\2.0.3\spring-retry-2.0.3.jar;C:\Users\joech\.m2\repository\io\micrometer\micrometer-observation\1.11.4\micrometer-observation-1.11.4.jar;C:\Users\joech\.m2\repository\io\micrometer\micrometer-commons\1.11.4\micrometer-commons-1.11.4.jar;C:\Users\joech\.m2\repository\com\google\code\findbugs\jsr305\3.0.2\jsr305-3.0.2.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1.jar;C:\Users\joech\.m2\repository\com\github\luben\zstd-jni\1.5.2-1\zstd-jni-1.5.2-1.jar;C:\Users\joech\.m2\repository\org\lz4\lz4-java\1.8.0\lz4-java-1.8.0.jar;C:\Users\joech\.m2\repository\org\xerial\snappy\snappy-java\1.1.8.4\snappy-java-1.1.8.4.jar;C:\Users\joech\.m2\repository\org\slf4j\slf4j-api\2.0.9\slf4j-api-2.0.9.jar;C:\Users\joech\.m2\repository\com\h2database\h2\1.4.200\h2-1.4.200.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-test\3.1.4\spring-boot-starter-test-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-test\3.1.4\spring-boot-test-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-test-autoconfigure\3.1.4\spring-boot-test-autoconfigure-3.1.4.jar;C:\Users\joech\.m2\repository\com\jayway\jsonpath\json-path\2.8.0\json-path-2.8.0.jar;C:\Users\joech\.m2\repository\jakarta\xml\bind\jakarta.xml.bind-api\4.0.1\jakarta.xml.bind-api-4.0.1.jar;C:\Users\joech\.m2\repository\jakarta\activation\jakarta.activation-api\2.1.2\jakarta.activation-api-2.1.2.jar;C:\Users\joech\.m2\repository\net\minidev\json-smart\2.4.11\json-smart-2.4.11.jar;C:\Users\joech\.m2\repository\net\minidev\accessors-smart\2.4.11\accessors-smart-2.4.11.jar;C:\Users\joech\.m2\repository\org\ow2\asm\asm\9.3\asm-9.3.jar;C:\Users\joech\.m2\repository\org\assertj\assertj-core\3.24.2\assertj-core-3.24.2.jar;C:\Users\joech\.m2\repository\org\hamcrest\hamcrest\2.2\hamcrest-2.2.jar;C:\Users\joech\.m2\repository\org\junit\jupiter\junit-jupiter\5.9.3\junit-jupiter-5.9.3.jar;C:\Users\joech\.m2\repository\org\junit\jupiter\junit-jupiter-params\5.9.3\junit-jupiter-params-5.9.3.jar;C:\Users\joech\.m2\repository\org\junit\jupiter\junit-jupiter-engine\5.9.3\junit-jupiter-engine-5.9.3.jar;C:\Users\joech\.m2\repository\org\mockito\mockito-core\5.3.1\mockito-core-5.3.1.jar;C:\Users\joech\.m2\repository\net\bytebuddy\byte-buddy-agent\1.14.8\byte-buddy-agent-1.14.8.jar;C:\Users\joech\.m2\repository\org\objenesis\objenesis\3.3\objenesis-3.3.jar;C:\Users\joech\.m2\repository\org\mockito\mockito-junit-jupiter\5.3.1\mockito-junit-jupiter-5.3.1.jar;C:\Users\joech\.m2\repository\org\skyscreamer\jsonassert\1.5.1\jsonassert-1.5.1.jar;C:\Users\joech\.m2\repository\com\vaadin\external\google\android-json\0.0.20131108.vaadin1\android-json-0.0.20131108.vaadin1.jar;C:\Users\joech\.m2\repository\org\springframework\spring-core\6.0.12\spring-core-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-jcl\6.0.12\spring-jcl-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-test\6.0.12\spring-test-6.0.12.jar;C:\Users\joech\.m2\repository\org\xmlunit\xmlunit-core\2.9.1\xmlunit-core-2.9.1.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy\4.0.15\groovy-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-ant\4.0.15\groovy-ant-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\ant\ant\1.10.14\ant-1.10.14.jar;C:\Users\joech\.m2\repository\org\apache\ant\ant-junit\1.10.14\ant-junit-1.10.14.jar;C:\Users\joech\.m2\repository\org\apache\ant\ant-launcher\1.10.14\ant-launcher-1.10.14.jar;C:\Users\joech\.m2\repository\org\apache\ant\ant-antlr\1.10.14\ant-antlr-1.10.14.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-cli-picocli\4.0.15\groovy-cli-picocli-4.0.15.jar;C:\Users\joech\.m2\repository\info\picocli\picocli\4.7.5\picocli-4.7.5.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-console\4.0.15\groovy-console-4.0.15.jar;C:\Users\joech\.m2\repository\com\github\javaparser\javaparser-core\3.25.5\javaparser-core-3.25.5.jar;C:\Users\joech\.m2\repository\org\ow2\asm\asm-util\9.5\asm-util-9.5.jar;C:\Users\joech\.m2\repository\org\ow2\asm\asm-tree\9.5\asm-tree-9.5.jar;C:\Users\joech\.m2\repository\org\ow2\asm\asm-analysis\9.5\asm-analysis-9.5.jar;C:\Users\joech\.m2\repository\org\abego\treelayout\org.abego.treelayout.core\1.0.3\org.abego.treelayout.core-1.0.3.jar;C:\Users\joech\.m2\repository\org\apache\ivy\ivy\2.5.2\ivy-2.5.2.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-datetime\4.0.15\groovy-datetime-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-docgenerator\4.0.15\groovy-docgenerator-4.0.15.jar;C:\Users\joech\.m2\repository\com\thoughtworks\qdox\qdox\1.12.1\qdox-1.12.1.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-groovydoc\4.0.15\groovy-groovydoc-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-groovysh\4.0.15\groovy-groovysh-4.0.15.jar;C:\Users\joech\.m2\repository\jline\jline\2.14.6\jline-2.14.6.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-jmx\4.0.15\groovy-jmx-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-json\4.0.15\groovy-json-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-jsr223\4.0.15\groovy-jsr223-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-macro\4.0.15\groovy-macro-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-nio\4.0.15\groovy-nio-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-servlet\4.0.15\groovy-servlet-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-sql\4.0.15\groovy-sql-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-swing\4.0.15\groovy-swing-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-templates\4.0.15\groovy-templates-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-test\4.0.15\groovy-test-4.0.15.jar;C:\Users\joech\.m2\repository\junit\junit\4.13.2\junit-4.13.2.jar;C:\Users\joech\.m2\repository\org\hamcrest\hamcrest-core\2.2\hamcrest-core-2.2.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-test-junit5\4.0.15\groovy-test-junit5-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-xml\4.0.15\groovy-xml-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-yaml\4.0.15\groovy-yaml-4.0.15.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\dataformat\jackson-dataformat-yaml\2.15.2\jackson-dataformat-yaml-2.15.2.jar;C:\Users\joech\.m2\repository\org\spockframework\spock-core\2.4-M1-groovy-4.0\spock-core-2.4-M1-groovy-4.0.jar;C:\Users\joech\.m2\repository\org\junit\platform\junit-platform-engine\1.9.3\junit-platform-engine-1.9.3.jar;C:\Users\joech\.m2\repository\org\opentest4j\opentest4j\1.2.0\opentest4j-1.2.0.jar;C:\Users\joech\.m2\repository\org\junit\platform\junit-platform-commons\1.9.3\junit-platform-commons-1.9.3.jar;C:\Users\joech\.m2\repository\org\apiguardian\apiguardian-api\1.1.2\apiguardian-api-1.1.2.jar;C:\Users\joech\.m2\repository\org\spockframework\spock-spring\2.4-M1-groovy-4.0\spock-spring-2.4-M1-groovy-4.0.jar;C:\Users\joech\.m2\repository\com\athaydes\spock-reports\2.5.1-groovy-4.0\spock-reports-2.5.1-groovy-4.0.jar;C:\Users\joech\.m2\repository\com\github\codemonstur\embedded-redis\1.4.2\embedded-redis-1.4.2.jar;C:\Users\joech\.m2\repository\redis\clients\jedis\4.3.2\jedis-4.3.2.jar;C:\Users\joech\.m2\repository\org\apache\commons\commons-pool2\2.11.1\commons-pool2-2.11.1.jar;C:\Users\joech\.m2\repository\org\json\json\20220320\json-20220320.jar;C:\Users\joech\.m2\repository\com\google\code\gson\gson\2.10.1\gson-2.10.1.jar;C:\Users\joech\.m2\repository\org\springframework\kafka\spring-kafka-test\3.0.11\spring-kafka-test-3.0.11.jar;C:\Users\joech\.m2\repository\org\apache\zookeeper\zookeeper\3.6.3\zookeeper-3.6.3.jar;C:\Users\joech\.m2\repository\org\apache\zookeeper\zookeeper-jute\3.6.3\zookeeper-jute-3.6.3.jar;C:\Users\joech\.m2\repository\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;C:\Users\joech\.m2\repository\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-transport-classes-epoll\4.1.97.Final\netty-transport-classes-epoll-4.1.97.Final.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1-test.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-metadata\3.4.1\kafka-metadata-3.4.1.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-server-common\3.4.1\kafka-server-common-3.4.1.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-raft\3.4.1\kafka-raft-3.4.1.jar;C:\Users\joech\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-streams-test-utils\3.4.1\kafka-streams-test-utils-3.4.1.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-streams\3.4.1\kafka-streams-3.4.1.jar;C:\Users\joech\.m2\repository\org\rocksdb\rocksdbjni\7.1.2\rocksdbjni-7.1.2.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1.jar;C:\Users\joech\.m2\repository\org\scala-lang\scala-library\2.13.10\scala-library-2.13.10.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-group-coordinator\3.4.1\kafka-group-coordinator-3.4.1.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-storage\3.4.1\kafka-storage-3.4.1.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-storage-api\3.4.1\kafka-storage-api-3.4.1.jar;C:\Users\joech\.m2\repository\net\sourceforge\argparse4j\argparse4j\0.7.0\argparse4j-0.7.0.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\module\jackson-module-scala_2.13\2.15.2\jackson-module-scala_2.13-2.15.2.jar;C:\Users\joech\.m2\repository\com\thoughtworks\paranamer\paranamer\2.8\paranamer-2.8.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\dataformat\jackson-dataformat-csv\2.15.2\jackson-dataformat-csv-2.15.2.jar;C:\Users\joech\.m2\repository\net\sf\jopt-simple\jopt-simple\5.0.4\jopt-simple-5.0.4.jar;C:\Users\joech\.m2\repository\org\bitbucket\b_c\jose4j\0.9.3\jose4j-0.9.3.jar;C:\Users\joech\.m2\repository\org\scala-lang\modules\scala-collection-compat_2.13\2.10.0\scala-collection-compat_2.13-2.10.0.jar;C:\Users\joech\.m2\repository\org\scala-lang\modules\scala-java8-compat_2.13\1.0.2\scala-java8-compat_2.13-1.0.2.jar;C:\Users\joech\.m2\repository\org\scala-lang\scala-reflect\2.13.10\scala-reflect-2.13.10.jar;C:\Users\joech\.m2\repository\com\typesafe\scala-logging\scala-logging_2.13\3.9.4\scala-logging_2.13-3.9.4.jar;C:\Users\joech\.m2\repository\io\dropwizard\metrics\metrics-core\4.2.19\metrics-core-4.2.19.jar;C:\Users\joech\.m2\repository\commons-cli\commons-cli\1.4\commons-cli-1.4.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1-test.jar;C:\Users\joech\.m2\repository\org\junit\jupiter\junit-jupiter-api\5.9.3\junit-jupiter-api-5.9.3.jar;C:\Users\joech\.m2\repository\org\junit\platform\junit-platform-launcher\1.9.3\junit-platform-launcher-1.9.3.jar;C:\Users\joech\.m2\repository\org\awaitility\awaitility\4.2.0\awaitility-4.2.0.jar
2024-12-31 21:14:11.245 Server environment:java.library.path=C:\work\jdk-17\bin;C:\windows\Sun\Java\bin;C:\windows\system32;C:\windows;C:\work\python312\Scripts\;C:\work\python312\;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program\Git\cmd;C:\Program\PowerShell\7\;C:\Program Files\dotnet\;C:\Users\joech\AppData\Local\Microsoft\WindowsApps;C:\Users\joech\AppData\Local\GitHubDesktop\bin;C:\Program\Microsoft VS Code\bin;C:\work\apache-maven-3.8.8\bin;C:\Program Files\Tesseract-OCR;C:\work\jdk-17\bin;;.
2024-12-31 21:14:11.245 Server environment:java.io.tmpdir=C:\Users\joech\AppData\Local\Temp\
2024-12-31 21:14:11.245 Server environment:java.compiler=<NA>
2024-12-31 21:14:11.245 Server environment:os.name=Windows 11
2024-12-31 21:14:11.245 Server environment:os.arch=amd64
2024-12-31 21:14:11.245 Server environment:os.version=10.0
2024-12-31 21:14:11.245 Server environment:user.name=joech
2024-12-31 21:14:11.245 Server environment:user.home=C:\Users\joech
2024-12-31 21:14:11.245 Server environment:user.dir=C:\code\hsbc\demo\pong
2024-12-31 21:14:11.245 Server environment:os.memory.free=55MB
2024-12-31 21:14:11.245 Server environment:os.memory.max=15816MB
2024-12-31 21:14:11.245 Server environment:os.memory.total=136MB
2024-12-31 21:14:11.246 zookeeper.enableEagerACLCheck = false
2024-12-31 21:14:11.246 zookeeper.digest.enabled = true
2024-12-31 21:14:11.246 zookeeper.closeSessionTxn.enabled = true
2024-12-31 21:14:11.246 zookeeper.flushDelay=0
2024-12-31 21:14:11.246 zookeeper.maxWriteQueuePollTime=0
2024-12-31 21:14:11.246 zookeeper.maxBatchSize=1000
2024-12-31 21:14:11.246 zookeeper.intBufferStartingSizeBytes = 1024
2024-12-31 21:14:11.249 zookeeper.snapshot.trust.empty : false
2024-12-31 21:14:11.265 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:14:11.265 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:14:11.265 zookeeper.snapshotSizeFactor = 0.33
2024-12-31 21:14:11.265 zookeeper.commitLogCount=500
2024-12-31 21:14:11.268 Weighed connection throttling is disabled
2024-12-31 21:14:11.270 minSessionTimeout set to 1600
2024-12-31 21:14:11.270 maxSessionTimeout set to 16000
2024-12-31 21:14:11.271 Response cache size is initialized with value 400.
2024-12-31 21:14:11.271 Response cache size is initialized with value 400.
2024-12-31 21:14:11.272 zookeeper.pathStats.slotCapacity = 60
2024-12-31 21:14:11.272 zookeeper.pathStats.slotDuration = 15
2024-12-31 21:14:11.272 zookeeper.pathStats.maxDepth = 6
2024-12-31 21:14:11.272 zookeeper.pathStats.initialDelay = 5
2024-12-31 21:14:11.272 zookeeper.pathStats.delay = 5
2024-12-31 21:14:11.273 zookeeper.pathStats.enabled = false
2024-12-31 21:14:11.274 The max bytes for all large requests are set to 104857600
2024-12-31 21:14:11.274 The large request threshold is set to -1
2024-12-31 21:14:11.274 Created server with tickTime 800 minSessionTimeout 1600 maxSessionTimeout 16000 clientPortListenBacklog -1 datadir C:\Users\joech\AppData\Local\Temp\kafka-12483109569141068924\version-2 snapdir C:\Users\joech\AppData\Local\Temp\kafka-9780811766426322511\version-2
2024-12-31 21:14:11.282 maxCnxns is not configured, using default value 0.
2024-12-31 21:14:11.284 Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers.
2024-12-31 21:14:11.288 binding to port /127.0.0.1:0
2024-12-31 21:14:11.307 zookeeper.snapshot.compression.method = CHECKED
2024-12-31 21:14:11.308 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-9780811766426322511\version-2\snapshot.0
2024-12-31 21:14:11.314 Snapshot loaded in 22 ms, highest zxid is 0x0, digest is 1371985504
2024-12-31 21:14:11.314 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-9780811766426322511\version-2\snapshot.0
2024-12-31 21:14:11.314 Snapshot taken in 1 ms
2024-12-31 21:14:11.326 PrepRequestProcessor (sid:0) started, reconfigEnabled=false
2024-12-31 21:14:11.326 zookeeper.request_throttler.shutdownTimeout = 10000
2024-12-31 21:14:11.339 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:11.339 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:11.339 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:11.611 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.9c13d1c7-bfc4-4fb1-92f3-195c59297f4318126558273090271927
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59608
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:14:11.640 Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
2024-12-31 21:14:11.720 starting
2024-12-31 21:14:11.720 Connecting to zookeeper on 127.0.0.1:59608
2024-12-31 21:14:11.737 [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:59608.
2024-12-31 21:14:12.350 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:12.350 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:12.350 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:13.411 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:13.411 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:13.411 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:14.573 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:14.573 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:14.573 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:15.577 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:15.577 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:15.577 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:16.053 Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT
2024-12-31 21:14:16.053 Server environment:host.name=Joe
2024-12-31 21:14:16.054 Server environment:java.version=17.0.12
2024-12-31 21:14:16.054 Server environment:java.vendor=Oracle Corporation
2024-12-31 21:14:16.054 Server environment:java.home=C:\work\jdk-17
2024-12-31 21:14:16.054 Server environment:java.class.path=C:\code\hsbc\demo\pong\target\test-classes;C:\code\hsbc\demo\pong\target\classes;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-webflux\3.1.4\spring-boot-starter-webflux-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter\3.1.4\spring-boot-starter-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot\3.1.4\spring-boot-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-autoconfigure\3.1.4\spring-boot-autoconfigure-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-logging\3.1.4\spring-boot-starter-logging-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\ch\qos\logback\logback-classic\1.4.11\logback-classic-1.4.11.jar;C:\work\apache-maven-3.8.8\repo\ch\qos\logback\logback-core\1.4.11\logback-core-1.4.11.jar;C:\work\apache-maven-3.8.8\repo\org\apache\logging\log4j\log4j-to-slf4j\2.20.0\log4j-to-slf4j-2.20.0.jar;C:\work\apache-maven-3.8.8\repo\org\apache\logging\log4j\log4j-api\2.20.0\log4j-api-2.20.0.jar;C:\work\apache-maven-3.8.8\repo\org\slf4j\jul-to-slf4j\2.0.9\jul-to-slf4j-2.0.9.jar;C:\work\apache-maven-3.8.8\repo\jakarta\annotation\jakarta.annotation-api\2.1.1\jakarta.annotation-api-2.1.1.jar;C:\work\apache-maven-3.8.8\repo\org\yaml\snakeyaml\1.33\snakeyaml-1.33.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-json\3.1.4\spring-boot-starter-json-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-databind\2.15.2\jackson-databind-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-annotations\2.15.2\jackson-annotations-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-core\2.15.2\jackson-core-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.15.2\jackson-datatype-jdk8-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.15.2\jackson-datatype-jsr310-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\module\jackson-module-parameter-names\2.15.2\jackson-module-parameter-names-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-reactor-netty\3.1.4\spring-boot-starter-reactor-netty-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\netty\reactor-netty-http\1.1.11\reactor-netty-http-1.1.11.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-http\4.1.97.Final\netty-codec-http-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-http2\4.1.97.Final\netty-codec-http2-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns\4.1.97.Final\netty-resolver-dns-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-dns\4.1.97.Final\netty-codec-dns-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns-native-macos\4.1.97.Final\netty-resolver-dns-native-macos-4.1.97.Final-osx-x86_64.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns-classes-macos\4.1.97.Final\netty-resolver-dns-classes-macos-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final-linux-x86_64.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\netty\reactor-netty-core\1.1.11\reactor-netty-core-1.1.11.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-handler-proxy\4.1.97.Final\netty-handler-proxy-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-socks\4.1.97.Final\netty-codec-socks-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-web\6.0.12\spring-web-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-beans\6.0.12\spring-beans-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-webflux\6.0.12\spring-webflux-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\reactor-core\3.5.10\reactor-core-3.5.10.jar;C:\work\apache-maven-3.8.8\repo\org\reactivestreams\reactive-streams\1.0.4\reactive-streams-1.0.4.jar;C:\work\apache-maven-3.8.8\repo\com\google\guava\guava\19.0\guava-19.0.jar;C:\work\apache-maven-3.8.8\repo\commons-io\commons-io\2.11.0\commons-io-2.11.0.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-data-redis\3.1.4\spring-boot-starter-data-redis-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-redis\3.1.4\spring-data-redis-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-keyvalue\3.1.4\spring-data-keyvalue-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-oxm\6.0.12\spring-oxm-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-aop\6.0.12\spring-aop-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-context-support\6.0.12\spring-context-support-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\io\lettuce\lettuce-core\6.2.6.RELEASE\lettuce-core-6.2.6.RELEASE.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-common\4.1.97.Final\netty-common-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-handler\4.1.97.Final\netty-handler-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver\4.1.97.Final\netty-resolver-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-buffer\4.1.97.Final\netty-buffer-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-unix-common\4.1.97.Final\netty-transport-native-unix-common-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec\4.1.97.Final\netty-codec-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport\4.1.97.Final\netty-transport-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-data-jpa\3.1.4\spring-boot-starter-data-jpa-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-aop\3.1.4\spring-boot-starter-aop-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\aspectj\aspectjweaver\1.9.20\aspectjweaver-1.9.20.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-jdbc\3.1.4\spring-boot-starter-jdbc-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\zaxxer\HikariCP\5.0.1\HikariCP-5.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-jdbc\6.0.12\spring-jdbc-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\hibernate\orm\hibernate-core\6.2.9.Final\hibernate-core-6.2.9.Final.jar;C:\work\apache-maven-3.8.8\repo\jakarta\persistence\jakarta.persistence-api\3.1.0\jakarta.persistence-api-3.1.0.jar;C:\work\apache-maven-3.8.8\repo\jakarta\transaction\jakarta.transaction-api\2.0.1\jakarta.transaction-api-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\jboss\logging\jboss-logging\3.5.3.Final\jboss-logging-3.5.3.Final.jar;C:\work\apache-maven-3.8.8\repo\org\hibernate\common\hibernate-commons-annotations\6.0.6.Final\hibernate-commons-annotations-6.0.6.Final.jar;C:\work\apache-maven-3.8.8\repo\io\smallrye\jandex\3.0.5\jandex-3.0.5.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\classmate\1.5.1\classmate-1.5.1.jar;C:\work\apache-maven-3.8.8\repo\net\bytebuddy\byte-buddy\1.14.8\byte-buddy-1.14.8.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\jaxb-runtime\4.0.3\jaxb-runtime-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\jaxb-core\4.0.3\jaxb-core-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\eclipse\angus\angus-activation\2.0.1\angus-activation-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\txw2\4.0.3\txw2-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\com\sun\istack\istack-commons-runtime\4.1.2\istack-commons-runtime-4.1.2.jar;C:\work\apache-maven-3.8.8\repo\jakarta\inject\jakarta.inject-api\2.0.1\jakarta.inject-api-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\antlr\antlr4-runtime\4.10.1\antlr4-runtime-4.10.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-jpa\3.1.4\spring-data-jpa-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-commons\3.1.4\spring-data-commons-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-orm\6.0.12\spring-orm-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-aspects\6.0.12\spring-aspects-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\postgresql\postgresql\42.6.0\postgresql-42.6.0.jar;C:\work\apache-maven-3.8.8\repo\org\checkerframework\checker-qual\3.31.0\checker-qual-3.31.0.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\kafka\spring-kafka\3.0.11\spring-kafka-3.0.11.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-context\6.0.12\spring-context-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-expression\6.0.12\spring-expression-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-messaging\6.0.12\spring-messaging-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-tx\6.0.12\spring-tx-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\retry\spring-retry\2.0.3\spring-retry-2.0.3.jar;C:\work\apache-maven-3.8.8\repo\io\micrometer\micrometer-observation\1.11.4\micrometer-observation-1.11.4.jar;C:\work\apache-maven-3.8.8\repo\io\micrometer\micrometer-commons\1.11.4\micrometer-commons-1.11.4.jar;C:\work\apache-maven-3.8.8\repo\com\google\code\findbugs\jsr305\3.0.2\jsr305-3.0.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\com\github\luben\zstd-jni\1.5.2-1\zstd-jni-1.5.2-1.jar;C:\work\apache-maven-3.8.8\repo\org\lz4\lz4-java\1.8.0\lz4-java-1.8.0.jar;C:\work\apache-maven-3.8.8\repo\org\xerial\snappy\snappy-java\1.1.8.4\snappy-java-1.1.8.4.jar;C:\work\apache-maven-3.8.8\repo\org\slf4j\slf4j-api\2.0.9\slf4j-api-2.0.9.jar;C:\work\apache-maven-3.8.8\repo\com\h2database\h2\1.4.200\h2-1.4.200.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-test\3.1.4\spring-boot-starter-test-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-test\3.1.4\spring-boot-test-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-test-autoconfigure\3.1.4\spring-boot-test-autoconfigure-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\jayway\jsonpath\json-path\2.8.0\json-path-2.8.0.jar;C:\work\apache-maven-3.8.8\repo\jakarta\xml\bind\jakarta.xml.bind-api\4.0.1\jakarta.xml.bind-api-4.0.1.jar;C:\work\apache-maven-3.8.8\repo\jakarta\activation\jakarta.activation-api\2.1.2\jakarta.activation-api-2.1.2.jar;C:\work\apache-maven-3.8.8\repo\net\minidev\json-smart\2.4.11\json-smart-2.4.11.jar;C:\work\apache-maven-3.8.8\repo\net\minidev\accessors-smart\2.4.11\accessors-smart-2.4.11.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm\9.3\asm-9.3.jar;C:\work\apache-maven-3.8.8\repo\org\assertj\assertj-core\3.24.2\assertj-core-3.24.2.jar;C:\work\apache-maven-3.8.8\repo\org\hamcrest\hamcrest\2.2\hamcrest-2.2.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter\5.9.3\junit-jupiter-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-params\5.9.3\junit-jupiter-params-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-engine\5.9.3\junit-jupiter-engine-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\mockito\mockito-core\5.3.1\mockito-core-5.3.1.jar;C:\work\apache-maven-3.8.8\repo\net\bytebuddy\byte-buddy-agent\1.14.8\byte-buddy-agent-1.14.8.jar;C:\work\apache-maven-3.8.8\repo\org\objenesis\objenesis\3.3\objenesis-3.3.jar;C:\work\apache-maven-3.8.8\repo\org\mockito\mockito-junit-jupiter\5.3.1\mockito-junit-jupiter-5.3.1.jar;C:\work\apache-maven-3.8.8\repo\org\skyscreamer\jsonassert\1.5.1\jsonassert-1.5.1.jar;C:\work\apache-maven-3.8.8\repo\com\vaadin\external\google\android-json\0.0.20131108.vaadin1\android-json-0.0.20131108.vaadin1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-core\6.0.12\spring-core-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-jcl\6.0.12\spring-jcl-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-test\6.0.12\spring-test-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\xmlunit\xmlunit-core\2.9.1\xmlunit-core-2.9.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy\4.0.15\groovy-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-ant\4.0.15\groovy-ant-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant\1.10.14\ant-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-junit\1.10.14\ant-junit-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-launcher\1.10.14\ant-launcher-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-antlr\1.10.14\ant-antlr-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-cli-picocli\4.0.15\groovy-cli-picocli-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\info\picocli\picocli\4.7.5\picocli-4.7.5.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-console\4.0.15\groovy-console-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\github\javaparser\javaparser-core\3.25.5\javaparser-core-3.25.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-util\9.5\asm-util-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-tree\9.5\asm-tree-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-analysis\9.5\asm-analysis-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\abego\treelayout\org.abego.treelayout.core\1.0.3\org.abego.treelayout.core-1.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ivy\ivy\2.5.2\ivy-2.5.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-datetime\4.0.15\groovy-datetime-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-docgenerator\4.0.15\groovy-docgenerator-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\thoughtworks\qdox\qdox\1.12.1\qdox-1.12.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-groovydoc\4.0.15\groovy-groovydoc-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-groovysh\4.0.15\groovy-groovysh-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\jline\jline\2.14.6\jline-2.14.6.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-jmx\4.0.15\groovy-jmx-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-json\4.0.15\groovy-json-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-jsr223\4.0.15\groovy-jsr223-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-macro\4.0.15\groovy-macro-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-nio\4.0.15\groovy-nio-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-servlet\4.0.15\groovy-servlet-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-sql\4.0.15\groovy-sql-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-swing\4.0.15\groovy-swing-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-templates\4.0.15\groovy-templates-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-test\4.0.15\groovy-test-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\junit\junit\4.13.2\junit-4.13.2.jar;C:\work\apache-maven-3.8.8\repo\org\hamcrest\hamcrest-core\2.2\hamcrest-core-2.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-test-junit5\4.0.15\groovy-test-junit5-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-xml\4.0.15\groovy-xml-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-yaml\4.0.15\groovy-yaml-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\dataformat\jackson-dataformat-yaml\2.15.2\jackson-dataformat-yaml-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\org\spockframework\spock-core\2.4-M1-groovy-4.0\spock-core-2.4-M1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-engine\1.9.3\junit-platform-engine-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\opentest4j\opentest4j\1.2.0\opentest4j-1.2.0.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-commons\1.9.3\junit-platform-commons-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\apiguardian\apiguardian-api\1.1.2\apiguardian-api-1.1.2.jar;C:\work\apache-maven-3.8.8\repo\org\spockframework\spock-spring\2.4-M1-groovy-4.0\spock-spring-2.4-M1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\com\athaydes\spock-reports\2.5.1-groovy-4.0\spock-reports-2.5.1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\com\github\codemonstur\embedded-redis\1.4.2\embedded-redis-1.4.2.jar;C:\work\apache-maven-3.8.8\repo\redis\clients\jedis\4.3.2\jedis-4.3.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\commons\commons-pool2\2.11.1\commons-pool2-2.11.1.jar;C:\work\apache-maven-3.8.8\repo\org\json\json\20220320\json-20220320.jar;C:\work\apache-maven-3.8.8\repo\com\google\code\gson\gson\2.10.1\gson-2.10.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\kafka\spring-kafka-test\3.0.11\spring-kafka-test-3.0.11.jar;C:\work\apache-maven-3.8.8\repo\org\apache\zookeeper\zookeeper\3.6.3\zookeeper-3.6.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\zookeeper\zookeeper-jute\3.6.3\zookeeper-jute-3.6.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-classes-epoll\4.1.97.Final\netty-transport-classes-epoll-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1-test.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-metadata\3.4.1\kafka-metadata-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-server-common\3.4.1\kafka-server-common-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-raft\3.4.1\kafka-raft-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-streams-test-utils\3.4.1\kafka-streams-test-utils-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-streams\3.4.1\kafka-streams-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\rocksdb\rocksdbjni\7.1.2\rocksdbjni-7.1.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\scala-library\2.13.10\scala-library-2.13.10.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-group-coordinator\3.4.1\kafka-group-coordinator-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-storage\3.4.1\kafka-storage-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-storage-api\3.4.1\kafka-storage-api-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\net\sourceforge\argparse4j\argparse4j\0.7.0\argparse4j-0.7.0.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\module\jackson-module-scala_2.13\2.15.2\jackson-module-scala_2.13-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\thoughtworks\paranamer\paranamer\2.8\paranamer-2.8.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\dataformat\jackson-dataformat-csv\2.15.2\jackson-dataformat-csv-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\net\sf\jopt-simple\jopt-simple\5.0.4\jopt-simple-5.0.4.jar;C:\work\apache-maven-3.8.8\repo\org\bitbucket\b_c\jose4j\0.9.3\jose4j-0.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\modules\scala-collection-compat_2.13\2.10.0\scala-collection-compat_2.13-2.10.0.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\modules\scala-java8-compat_2.13\1.0.2\scala-java8-compat_2.13-1.0.2.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\scala-reflect\2.13.10\scala-reflect-2.13.10.jar;C:\work\apache-maven-3.8.8\repo\com\typesafe\scala-logging\scala-logging_2.13\3.9.4\scala-logging_2.13-3.9.4.jar;C:\work\apache-maven-3.8.8\repo\io\dropwizard\metrics\metrics-core\4.2.19\metrics-core-4.2.19.jar;C:\work\apache-maven-3.8.8\repo\commons-cli\commons-cli\1.4\commons-cli-1.4.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1-test.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-api\5.9.3\junit-jupiter-api-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-launcher\1.9.3\junit-platform-launcher-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\awaitility\awaitility\4.2.0\awaitility-4.2.0.jar;
2024-12-31 21:14:16.057 Server environment:java.library.path=C:\work\jdk-17\bin;C:\windows\Sun\Java\bin;C:\windows\system32;C:\windows;C:\work\python312\Scripts\;C:\work\python312\;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program\Git\cmd;C:\Program\PowerShell\7\;C:\Program Files\dotnet\;C:\Users\joech\AppData\Local\Microsoft\WindowsApps;C:\Users\joech\AppData\Local\GitHubDesktop\bin;C:\Program\Microsoft VS Code\bin;C:\work\apache-maven-3.8.8\bin;C:\Program Files\Tesseract-OCR;C:\work\jdk-17\bin;;.
2024-12-31 21:14:16.057 Server environment:java.io.tmpdir=C:\Users\joech\AppData\Local\Temp\
2024-12-31 21:14:16.057 Server environment:java.compiler=<NA>
2024-12-31 21:14:16.057 Server environment:os.name=Windows 11
2024-12-31 21:14:16.057 Server environment:os.arch=amd64
2024-12-31 21:14:16.057 Server environment:os.version=10.0
2024-12-31 21:14:16.057 Server environment:user.name=joech
2024-12-31 21:14:16.057 Server environment:user.home=C:\Users\joech
2024-12-31 21:14:16.057 Server environment:user.dir=C:\code\hsbc\demo\pong
2024-12-31 21:14:16.057 Server environment:os.memory.free=39MB
2024-12-31 21:14:16.057 Server environment:os.memory.max=15816MB
2024-12-31 21:14:16.057 Server environment:os.memory.total=160MB
2024-12-31 21:14:16.057 zookeeper.enableEagerACLCheck = false
2024-12-31 21:14:16.060 zookeeper.digest.enabled = true
2024-12-31 21:14:16.060 zookeeper.closeSessionTxn.enabled = true
2024-12-31 21:14:16.060 zookeeper.flushDelay=0
2024-12-31 21:14:16.061 zookeeper.maxWriteQueuePollTime=0
2024-12-31 21:14:16.061 zookeeper.maxBatchSize=1000
2024-12-31 21:14:16.061 zookeeper.intBufferStartingSizeBytes = 1024
2024-12-31 21:14:16.065 zookeeper.snapshot.trust.empty : false
2024-12-31 21:14:16.107 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:14:16.108 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:14:16.108 zookeeper.snapshotSizeFactor = 0.33
2024-12-31 21:14:16.108 zookeeper.commitLogCount=500
2024-12-31 21:14:16.114 Weighed connection throttling is disabled
2024-12-31 21:14:16.128 minSessionTimeout set to 1600
2024-12-31 21:14:16.128 maxSessionTimeout set to 16000
2024-12-31 21:14:16.131 Response cache size is initialized with value 400.
2024-12-31 21:14:16.131 Response cache size is initialized with value 400.
2024-12-31 21:14:16.132 zookeeper.pathStats.slotCapacity = 60
2024-12-31 21:14:16.132 zookeeper.pathStats.slotDuration = 15
2024-12-31 21:14:16.132 zookeeper.pathStats.maxDepth = 6
2024-12-31 21:14:16.133 zookeeper.pathStats.initialDelay = 5
2024-12-31 21:14:16.133 zookeeper.pathStats.delay = 5
2024-12-31 21:14:16.133 zookeeper.pathStats.enabled = false
2024-12-31 21:14:16.136 The max bytes for all large requests are set to 104857600
2024-12-31 21:14:16.136 The large request threshold is set to -1
2024-12-31 21:14:16.136 Created server with tickTime 800 minSessionTimeout 1600 maxSessionTimeout 16000 clientPortListenBacklog -1 datadir C:\Users\joech\AppData\Local\Temp\kafka-9477801879606332462\version-2 snapdir C:\Users\joech\AppData\Local\Temp\kafka-15021356018300893888\version-2
2024-12-31 21:14:16.203 maxCnxns is not configured, using default value 0.
2024-12-31 21:14:16.208 Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers.
2024-12-31 21:14:16.216 binding to port /127.0.0.1:0
2024-12-31 21:14:16.247 zookeeper.snapshot.compression.method = CHECKED
2024-12-31 21:14:16.247 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-15021356018300893888\version-2\snapshot.0
2024-12-31 21:14:16.256 Snapshot loaded in 34 ms, highest zxid is 0x0, digest is 1371985504
2024-12-31 21:14:16.257 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-15021356018300893888\version-2\snapshot.0
2024-12-31 21:14:16.258 Snapshot taken in 1 ms
2024-12-31 21:14:16.276 PrepRequestProcessor (sid:0) started, reconfigEnabled=false
2024-12-31 21:14:16.276 zookeeper.request_throttler.shutdownTimeout = 10000
2024-12-31 21:14:16.683 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.13e9a513-d2a4-40a1-90b1-c5e8bcc6d28415572636074268719671
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59614
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:14:16.688 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:16.688 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:16.688 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:16.723 Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
2024-12-31 21:14:16.815 starting
2024-12-31 21:14:16.816 Connecting to zookeeper on 127.0.0.1:59614
2024-12-31 21:14:16.841 [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:59614.
2024-12-31 21:14:17.005 Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT
2024-12-31 21:14:17.006 Client environment:host.name=Joe
2024-12-31 21:14:17.006 Client environment:java.version=17.0.12
2024-12-31 21:14:17.006 Client environment:java.vendor=Oracle Corporation
2024-12-31 21:14:17.006 Client environment:java.home=C:\work\jdk-17
2024-12-31 21:14:17.006 Client environment:java.class.path=C:\work\ideaIC-2024.2.0.2.win\lib\idea_rt.jar;C:\work\ideaIC-2024.2.0.2.win\plugins\junit\lib\junit5-rt.jar;C:\work\ideaIC-2024.2.0.2.win\plugins\junit\lib\junit-rt.jar;C:\code\hsbc\demo\pong\target\test-classes;C:\code\hsbc\demo\pong\target\classes;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-webflux\3.1.4\spring-boot-starter-webflux-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter\3.1.4\spring-boot-starter-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot\3.1.4\spring-boot-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-autoconfigure\3.1.4\spring-boot-autoconfigure-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-logging\3.1.4\spring-boot-starter-logging-3.1.4.jar;C:\Users\joech\.m2\repository\ch\qos\logback\logback-classic\1.4.11\logback-classic-1.4.11.jar;C:\Users\joech\.m2\repository\ch\qos\logback\logback-core\1.4.11\logback-core-1.4.11.jar;C:\Users\joech\.m2\repository\org\apache\logging\log4j\log4j-to-slf4j\2.20.0\log4j-to-slf4j-2.20.0.jar;C:\Users\joech\.m2\repository\org\apache\logging\log4j\log4j-api\2.20.0\log4j-api-2.20.0.jar;C:\Users\joech\.m2\repository\org\slf4j\jul-to-slf4j\2.0.9\jul-to-slf4j-2.0.9.jar;C:\Users\joech\.m2\repository\jakarta\annotation\jakarta.annotation-api\2.1.1\jakarta.annotation-api-2.1.1.jar;C:\Users\joech\.m2\repository\org\yaml\snakeyaml\1.33\snakeyaml-1.33.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-json\3.1.4\spring-boot-starter-json-3.1.4.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\core\jackson-databind\2.15.2\jackson-databind-2.15.2.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\core\jackson-annotations\2.15.2\jackson-annotations-2.15.2.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\core\jackson-core\2.15.2\jackson-core-2.15.2.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.15.2\jackson-datatype-jdk8-2.15.2.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.15.2\jackson-datatype-jsr310-2.15.2.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\module\jackson-module-parameter-names\2.15.2\jackson-module-parameter-names-2.15.2.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-reactor-netty\3.1.4\spring-boot-starter-reactor-netty-3.1.4.jar;C:\Users\joech\.m2\repository\io\projectreactor\netty\reactor-netty-http\1.1.11\reactor-netty-http-1.1.11.jar;C:\Users\joech\.m2\repository\io\netty\netty-codec-http\4.1.97.Final\netty-codec-http-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-codec-http2\4.1.97.Final\netty-codec-http2-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-resolver-dns\4.1.97.Final\netty-resolver-dns-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-codec-dns\4.1.97.Final\netty-codec-dns-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-resolver-dns-native-macos\4.1.97.Final\netty-resolver-dns-native-macos-4.1.97.Final-osx-x86_64.jar;C:\Users\joech\.m2\repository\io\netty\netty-resolver-dns-classes-macos\4.1.97.Final\netty-resolver-dns-classes-macos-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final-linux-x86_64.jar;C:\Users\joech\.m2\repository\io\projectreactor\netty\reactor-netty-core\1.1.11\reactor-netty-core-1.1.11.jar;C:\Users\joech\.m2\repository\io\netty\netty-handler-proxy\4.1.97.Final\netty-handler-proxy-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-codec-socks\4.1.97.Final\netty-codec-socks-4.1.97.Final.jar;C:\Users\joech\.m2\repository\org\springframework\spring-web\6.0.12\spring-web-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-beans\6.0.12\spring-beans-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-webflux\6.0.12\spring-webflux-6.0.12.jar;C:\Users\joech\.m2\repository\io\projectreactor\reactor-core\3.5.10\reactor-core-3.5.10.jar;C:\Users\joech\.m2\repository\org\reactivestreams\reactive-streams\1.0.4\reactive-streams-1.0.4.jar;C:\Users\joech\.m2\repository\com\google\guava\guava\19.0\guava-19.0.jar;C:\Users\joech\.m2\repository\commons-io\commons-io\2.11.0\commons-io-2.11.0.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-data-redis\3.1.4\spring-boot-starter-data-redis-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\data\spring-data-redis\3.1.4\spring-data-redis-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\data\spring-data-keyvalue\3.1.4\spring-data-keyvalue-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\spring-oxm\6.0.12\spring-oxm-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-aop\6.0.12\spring-aop-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-context-support\6.0.12\spring-context-support-6.0.12.jar;C:\Users\joech\.m2\repository\io\lettuce\lettuce-core\6.2.6.RELEASE\lettuce-core-6.2.6.RELEASE.jar;C:\Users\joech\.m2\repository\io\netty\netty-common\4.1.97.Final\netty-common-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-handler\4.1.97.Final\netty-handler-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-resolver\4.1.97.Final\netty-resolver-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-buffer\4.1.97.Final\netty-buffer-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-transport-native-unix-common\4.1.97.Final\netty-transport-native-unix-common-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-codec\4.1.97.Final\netty-codec-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-transport\4.1.97.Final\netty-transport-4.1.97.Final.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-data-jpa\3.1.4\spring-boot-starter-data-jpa-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-aop\3.1.4\spring-boot-starter-aop-3.1.4.jar;C:\Users\joech\.m2\repository\org\aspectj\aspectjweaver\1.9.20\aspectjweaver-1.9.20.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-jdbc\3.1.4\spring-boot-starter-jdbc-3.1.4.jar;C:\Users\joech\.m2\repository\com\zaxxer\HikariCP\5.0.1\HikariCP-5.0.1.jar;C:\Users\joech\.m2\repository\org\springframework\spring-jdbc\6.0.12\spring-jdbc-6.0.12.jar;C:\Users\joech\.m2\repository\org\hibernate\orm\hibernate-core\6.2.9.Final\hibernate-core-6.2.9.Final.jar;C:\Users\joech\.m2\repository\jakarta\persistence\jakarta.persistence-api\3.1.0\jakarta.persistence-api-3.1.0.jar;C:\Users\joech\.m2\repository\jakarta\transaction\jakarta.transaction-api\2.0.1\jakarta.transaction-api-2.0.1.jar;C:\Users\joech\.m2\repository\org\jboss\logging\jboss-logging\3.5.3.Final\jboss-logging-3.5.3.Final.jar;C:\Users\joech\.m2\repository\org\hibernate\common\hibernate-commons-annotations\6.0.6.Final\hibernate-commons-annotations-6.0.6.Final.jar;C:\Users\joech\.m2\repository\io\smallrye\jandex\3.0.5\jandex-3.0.5.jar;C:\Users\joech\.m2\repository\com\fasterxml\classmate\1.5.1\classmate-1.5.1.jar;C:\Users\joech\.m2\repository\net\bytebuddy\byte-buddy\1.14.8\byte-buddy-1.14.8.jar;C:\Users\joech\.m2\repository\org\glassfish\jaxb\jaxb-runtime\4.0.3\jaxb-runtime-4.0.3.jar;C:\Users\joech\.m2\repository\org\glassfish\jaxb\jaxb-core\4.0.3\jaxb-core-4.0.3.jar;C:\Users\joech\.m2\repository\org\eclipse\angus\angus-activation\2.0.1\angus-activation-2.0.1.jar;C:\Users\joech\.m2\repository\org\glassfish\jaxb\txw2\4.0.3\txw2-4.0.3.jar;C:\Users\joech\.m2\repository\com\sun\istack\istack-commons-runtime\4.1.2\istack-commons-runtime-4.1.2.jar;C:\Users\joech\.m2\repository\jakarta\inject\jakarta.inject-api\2.0.1\jakarta.inject-api-2.0.1.jar;C:\Users\joech\.m2\repository\org\antlr\antlr4-runtime\4.10.1\antlr4-runtime-4.10.1.jar;C:\Users\joech\.m2\repository\org\springframework\data\spring-data-jpa\3.1.4\spring-data-jpa-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\data\spring-data-commons\3.1.4\spring-data-commons-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\spring-orm\6.0.12\spring-orm-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-aspects\6.0.12\spring-aspects-6.0.12.jar;C:\Users\joech\.m2\repository\org\postgresql\postgresql\42.6.0\postgresql-42.6.0.jar;C:\Users\joech\.m2\repository\org\checkerframework\checker-qual\3.31.0\checker-qual-3.31.0.jar;C:\Users\joech\.m2\repository\org\springframework\kafka\spring-kafka\3.0.11\spring-kafka-3.0.11.jar;C:\Users\joech\.m2\repository\org\springframework\spring-context\6.0.12\spring-context-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-expression\6.0.12\spring-expression-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-messaging\6.0.12\spring-messaging-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-tx\6.0.12\spring-tx-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\retry\spring-retry\2.0.3\spring-retry-2.0.3.jar;C:\Users\joech\.m2\repository\io\micrometer\micrometer-observation\1.11.4\micrometer-observation-1.11.4.jar;C:\Users\joech\.m2\repository\io\micrometer\micrometer-commons\1.11.4\micrometer-commons-1.11.4.jar;C:\Users\joech\.m2\repository\com\google\code\findbugs\jsr305\3.0.2\jsr305-3.0.2.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1.jar;C:\Users\joech\.m2\repository\com\github\luben\zstd-jni\1.5.2-1\zstd-jni-1.5.2-1.jar;C:\Users\joech\.m2\repository\org\lz4\lz4-java\1.8.0\lz4-java-1.8.0.jar;C:\Users\joech\.m2\repository\org\xerial\snappy\snappy-java\1.1.8.4\snappy-java-1.1.8.4.jar;C:\Users\joech\.m2\repository\org\slf4j\slf4j-api\2.0.9\slf4j-api-2.0.9.jar;C:\Users\joech\.m2\repository\com\h2database\h2\1.4.200\h2-1.4.200.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-starter-test\3.1.4\spring-boot-starter-test-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-test\3.1.4\spring-boot-test-3.1.4.jar;C:\Users\joech\.m2\repository\org\springframework\boot\spring-boot-test-autoconfigure\3.1.4\spring-boot-test-autoconfigure-3.1.4.jar;C:\Users\joech\.m2\repository\com\jayway\jsonpath\json-path\2.8.0\json-path-2.8.0.jar;C:\Users\joech\.m2\repository\jakarta\xml\bind\jakarta.xml.bind-api\4.0.1\jakarta.xml.bind-api-4.0.1.jar;C:\Users\joech\.m2\repository\jakarta\activation\jakarta.activation-api\2.1.2\jakarta.activation-api-2.1.2.jar;C:\Users\joech\.m2\repository\net\minidev\json-smart\2.4.11\json-smart-2.4.11.jar;C:\Users\joech\.m2\repository\net\minidev\accessors-smart\2.4.11\accessors-smart-2.4.11.jar;C:\Users\joech\.m2\repository\org\ow2\asm\asm\9.3\asm-9.3.jar;C:\Users\joech\.m2\repository\org\assertj\assertj-core\3.24.2\assertj-core-3.24.2.jar;C:\Users\joech\.m2\repository\org\hamcrest\hamcrest\2.2\hamcrest-2.2.jar;C:\Users\joech\.m2\repository\org\junit\jupiter\junit-jupiter\5.9.3\junit-jupiter-5.9.3.jar;C:\Users\joech\.m2\repository\org\junit\jupiter\junit-jupiter-params\5.9.3\junit-jupiter-params-5.9.3.jar;C:\Users\joech\.m2\repository\org\junit\jupiter\junit-jupiter-engine\5.9.3\junit-jupiter-engine-5.9.3.jar;C:\Users\joech\.m2\repository\org\mockito\mockito-core\5.3.1\mockito-core-5.3.1.jar;C:\Users\joech\.m2\repository\net\bytebuddy\byte-buddy-agent\1.14.8\byte-buddy-agent-1.14.8.jar;C:\Users\joech\.m2\repository\org\objenesis\objenesis\3.3\objenesis-3.3.jar;C:\Users\joech\.m2\repository\org\mockito\mockito-junit-jupiter\5.3.1\mockito-junit-jupiter-5.3.1.jar;C:\Users\joech\.m2\repository\org\skyscreamer\jsonassert\1.5.1\jsonassert-1.5.1.jar;C:\Users\joech\.m2\repository\com\vaadin\external\google\android-json\0.0.20131108.vaadin1\android-json-0.0.20131108.vaadin1.jar;C:\Users\joech\.m2\repository\org\springframework\spring-core\6.0.12\spring-core-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-jcl\6.0.12\spring-jcl-6.0.12.jar;C:\Users\joech\.m2\repository\org\springframework\spring-test\6.0.12\spring-test-6.0.12.jar;C:\Users\joech\.m2\repository\org\xmlunit\xmlunit-core\2.9.1\xmlunit-core-2.9.1.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy\4.0.15\groovy-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-ant\4.0.15\groovy-ant-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\ant\ant\1.10.14\ant-1.10.14.jar;C:\Users\joech\.m2\repository\org\apache\ant\ant-junit\1.10.14\ant-junit-1.10.14.jar;C:\Users\joech\.m2\repository\org\apache\ant\ant-launcher\1.10.14\ant-launcher-1.10.14.jar;C:\Users\joech\.m2\repository\org\apache\ant\ant-antlr\1.10.14\ant-antlr-1.10.14.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-cli-picocli\4.0.15\groovy-cli-picocli-4.0.15.jar;C:\Users\joech\.m2\repository\info\picocli\picocli\4.7.5\picocli-4.7.5.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-console\4.0.15\groovy-console-4.0.15.jar;C:\Users\joech\.m2\repository\com\github\javaparser\javaparser-core\3.25.5\javaparser-core-3.25.5.jar;C:\Users\joech\.m2\repository\org\ow2\asm\asm-util\9.5\asm-util-9.5.jar;C:\Users\joech\.m2\repository\org\ow2\asm\asm-tree\9.5\asm-tree-9.5.jar;C:\Users\joech\.m2\repository\org\ow2\asm\asm-analysis\9.5\asm-analysis-9.5.jar;C:\Users\joech\.m2\repository\org\abego\treelayout\org.abego.treelayout.core\1.0.3\org.abego.treelayout.core-1.0.3.jar;C:\Users\joech\.m2\repository\org\apache\ivy\ivy\2.5.2\ivy-2.5.2.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-datetime\4.0.15\groovy-datetime-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-docgenerator\4.0.15\groovy-docgenerator-4.0.15.jar;C:\Users\joech\.m2\repository\com\thoughtworks\qdox\qdox\1.12.1\qdox-1.12.1.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-groovydoc\4.0.15\groovy-groovydoc-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-groovysh\4.0.15\groovy-groovysh-4.0.15.jar;C:\Users\joech\.m2\repository\jline\jline\2.14.6\jline-2.14.6.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-jmx\4.0.15\groovy-jmx-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-json\4.0.15\groovy-json-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-jsr223\4.0.15\groovy-jsr223-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-macro\4.0.15\groovy-macro-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-nio\4.0.15\groovy-nio-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-servlet\4.0.15\groovy-servlet-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-sql\4.0.15\groovy-sql-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-swing\4.0.15\groovy-swing-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-templates\4.0.15\groovy-templates-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-test\4.0.15\groovy-test-4.0.15.jar;C:\Users\joech\.m2\repository\junit\junit\4.13.2\junit-4.13.2.jar;C:\Users\joech\.m2\repository\org\hamcrest\hamcrest-core\2.2\hamcrest-core-2.2.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-test-junit5\4.0.15\groovy-test-junit5-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-xml\4.0.15\groovy-xml-4.0.15.jar;C:\Users\joech\.m2\repository\org\apache\groovy\groovy-yaml\4.0.15\groovy-yaml-4.0.15.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\dataformat\jackson-dataformat-yaml\2.15.2\jackson-dataformat-yaml-2.15.2.jar;C:\Users\joech\.m2\repository\org\spockframework\spock-core\2.4-M1-groovy-4.0\spock-core-2.4-M1-groovy-4.0.jar;C:\Users\joech\.m2\repository\org\junit\platform\junit-platform-engine\1.9.3\junit-platform-engine-1.9.3.jar;C:\Users\joech\.m2\repository\org\opentest4j\opentest4j\1.2.0\opentest4j-1.2.0.jar;C:\Users\joech\.m2\repository\org\junit\platform\junit-platform-commons\1.9.3\junit-platform-commons-1.9.3.jar;C:\Users\joech\.m2\repository\org\apiguardian\apiguardian-api\1.1.2\apiguardian-api-1.1.2.jar;C:\Users\joech\.m2\repository\org\spockframework\spock-spring\2.4-M1-groovy-4.0\spock-spring-2.4-M1-groovy-4.0.jar;C:\Users\joech\.m2\repository\com\athaydes\spock-reports\2.5.1-groovy-4.0\spock-reports-2.5.1-groovy-4.0.jar;C:\Users\joech\.m2\repository\com\github\codemonstur\embedded-redis\1.4.2\embedded-redis-1.4.2.jar;C:\Users\joech\.m2\repository\redis\clients\jedis\4.3.2\jedis-4.3.2.jar;C:\Users\joech\.m2\repository\org\apache\commons\commons-pool2\2.11.1\commons-pool2-2.11.1.jar;C:\Users\joech\.m2\repository\org\json\json\20220320\json-20220320.jar;C:\Users\joech\.m2\repository\com\google\code\gson\gson\2.10.1\gson-2.10.1.jar;C:\Users\joech\.m2\repository\org\springframework\kafka\spring-kafka-test\3.0.11\spring-kafka-test-3.0.11.jar;C:\Users\joech\.m2\repository\org\apache\zookeeper\zookeeper\3.6.3\zookeeper-3.6.3.jar;C:\Users\joech\.m2\repository\org\apache\zookeeper\zookeeper-jute\3.6.3\zookeeper-jute-3.6.3.jar;C:\Users\joech\.m2\repository\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;C:\Users\joech\.m2\repository\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final.jar;C:\Users\joech\.m2\repository\io\netty\netty-transport-classes-epoll\4.1.97.Final\netty-transport-classes-epoll-4.1.97.Final.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1-test.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-metadata\3.4.1\kafka-metadata-3.4.1.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-server-common\3.4.1\kafka-server-common-3.4.1.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-raft\3.4.1\kafka-raft-3.4.1.jar;C:\Users\joech\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-streams-test-utils\3.4.1\kafka-streams-test-utils-3.4.1.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-streams\3.4.1\kafka-streams-3.4.1.jar;C:\Users\joech\.m2\repository\org\rocksdb\rocksdbjni\7.1.2\rocksdbjni-7.1.2.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1.jar;C:\Users\joech\.m2\repository\org\scala-lang\scala-library\2.13.10\scala-library-2.13.10.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-group-coordinator\3.4.1\kafka-group-coordinator-3.4.1.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-storage\3.4.1\kafka-storage-3.4.1.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka-storage-api\3.4.1\kafka-storage-api-3.4.1.jar;C:\Users\joech\.m2\repository\net\sourceforge\argparse4j\argparse4j\0.7.0\argparse4j-0.7.0.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\module\jackson-module-scala_2.13\2.15.2\jackson-module-scala_2.13-2.15.2.jar;C:\Users\joech\.m2\repository\com\thoughtworks\paranamer\paranamer\2.8\paranamer-2.8.jar;C:\Users\joech\.m2\repository\com\fasterxml\jackson\dataformat\jackson-dataformat-csv\2.15.2\jackson-dataformat-csv-2.15.2.jar;C:\Users\joech\.m2\repository\net\sf\jopt-simple\jopt-simple\5.0.4\jopt-simple-5.0.4.jar;C:\Users\joech\.m2\repository\org\bitbucket\b_c\jose4j\0.9.3\jose4j-0.9.3.jar;C:\Users\joech\.m2\repository\org\scala-lang\modules\scala-collection-compat_2.13\2.10.0\scala-collection-compat_2.13-2.10.0.jar;C:\Users\joech\.m2\repository\org\scala-lang\modules\scala-java8-compat_2.13\1.0.2\scala-java8-compat_2.13-1.0.2.jar;C:\Users\joech\.m2\repository\org\scala-lang\scala-reflect\2.13.10\scala-reflect-2.13.10.jar;C:\Users\joech\.m2\repository\com\typesafe\scala-logging\scala-logging_2.13\3.9.4\scala-logging_2.13-3.9.4.jar;C:\Users\joech\.m2\repository\io\dropwizard\metrics\metrics-core\4.2.19\metrics-core-4.2.19.jar;C:\Users\joech\.m2\repository\commons-cli\commons-cli\1.4\commons-cli-1.4.jar;C:\Users\joech\.m2\repository\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1-test.jar;C:\Users\joech\.m2\repository\org\junit\jupiter\junit-jupiter-api\5.9.3\junit-jupiter-api-5.9.3.jar;C:\Users\joech\.m2\repository\org\junit\platform\junit-platform-launcher\1.9.3\junit-platform-launcher-1.9.3.jar;C:\Users\joech\.m2\repository\org\awaitility\awaitility\4.2.0\awaitility-4.2.0.jar
2024-12-31 21:14:17.006 Client environment:java.library.path=C:\work\jdk-17\bin;C:\windows\Sun\Java\bin;C:\windows\system32;C:\windows;C:\work\python312\Scripts\;C:\work\python312\;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program\Git\cmd;C:\Program\PowerShell\7\;C:\Program Files\dotnet\;C:\Users\joech\AppData\Local\Microsoft\WindowsApps;C:\Users\joech\AppData\Local\GitHubDesktop\bin;C:\Program\Microsoft VS Code\bin;C:\work\apache-maven-3.8.8\bin;C:\Program Files\Tesseract-OCR;C:\work\jdk-17\bin;;.
2024-12-31 21:14:17.006 Client environment:java.io.tmpdir=C:\Users\joech\AppData\Local\Temp\
2024-12-31 21:14:17.006 Client environment:java.compiler=<NA>
2024-12-31 21:14:17.006 Client environment:os.name=Windows 11
2024-12-31 21:14:17.006 Client environment:os.arch=amd64
2024-12-31 21:14:17.006 Client environment:os.version=10.0
2024-12-31 21:14:17.006 Client environment:user.name=joech
2024-12-31 21:14:17.006 Client environment:user.home=C:\Users\joech
2024-12-31 21:14:17.006 Client environment:user.dir=C:\code\hsbc\demo\pong
2024-12-31 21:14:17.006 Client environment:os.memory.free=506MB
2024-12-31 21:14:17.006 Client environment:os.memory.max=15816MB
2024-12-31 21:14:17.006 Client environment:os.memory.total=568MB
2024-12-31 21:14:17.010 Initiating client connection, connectString=127.0.0.1:59608 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6465f4a
2024-12-31 21:14:17.015 jute.maxbuffer value is 4194304 Bytes
2024-12-31 21:14:17.021 zookeeper.request.timeout value is 0. feature enabled=false
2024-12-31 21:14:17.023 Opening socket connection to server /127.0.0.1:59608.
2024-12-31 21:14:17.023 [ZooKeeperClient Kafka server] Waiting until connected.
2024-12-31 21:14:17.024 Socket connection established, initiating session, client: /127.0.0.1:59616, server: /127.0.0.1:59608
2024-12-31 21:14:17.032 Creating new log file: log.1
2024-12-31 21:14:17.043 ZooKeeper audit is disabled.
2024-12-31 21:14:17.048 Session establishment complete on server /127.0.0.1:59608, session id = 0x10017754eb50000, negotiated timeout = 16000
2024-12-31 21:14:17.053 [ZooKeeperClient Kafka server] Connected.
2024-12-31 21:14:17.188 Cluster ID = SjzwkHoERxG9ErE3IU903w
2024-12-31 21:14:17.191 No meta.properties file under dir C:\Users\joech\AppData\Local\Temp\spring.kafka.9c13d1c7-bfc4-4fb1-92f3-195c59297f4318126558273090271927\meta.properties
2024-12-31 21:14:17.244 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.9c13d1c7-bfc4-4fb1-92f3-195c59297f4318126558273090271927
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59608
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:14:17.276 [ThrottledChannelReaper-Fetch]: Starting
2024-12-31 21:14:17.276 [ThrottledChannelReaper-Produce]: Starting
2024-12-31 21:14:17.277 [ThrottledChannelReaper-Request]: Starting
2024-12-31 21:14:17.279 [ThrottledChannelReaper-ControllerMutation]: Starting
2024-12-31 21:14:17.320 Loading logs from log dirs ArraySeq(C:\Users\joech\AppData\Local\Temp\spring.kafka.9c13d1c7-bfc4-4fb1-92f3-195c59297f4318126558273090271927)
2024-12-31 21:14:17.322 Attempting recovery for all logs in C:\Users\joech\AppData\Local\Temp\spring.kafka.9c13d1c7-bfc4-4fb1-92f3-195c59297f4318126558273090271927 since no clean shutdown file was found
2024-12-31 21:14:17.332 Loaded 0 logs in 12ms.
2024-12-31 21:14:17.332 Starting log cleanup with a period of 300000 ms.
2024-12-31 21:14:17.334 Starting log flusher with a default period of 9223372036854775807 ms.
2024-12-31 21:14:17.349 Starting the log cleaner
2024-12-31 21:14:17.359 [kafka-log-cleaner-thread-0]: Starting
2024-12-31 21:14:17.374 [feature-zk-node-event-process-thread]: Starting
2024-12-31 21:14:17.382 Feature ZK node at path: /feature does not exist
2024-12-31 21:14:17.392 [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting
2024-12-31 21:14:17.485 Updated connection-accept-rate max connection creation rate to 2147483647
2024-12-31 21:14:17.492 Awaiting socket connections on localhost:59617.
2024-12-31 21:14:17.514 [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT)
2024-12-31 21:14:17.521 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Starting
2024-12-31 21:14:17.536 [ExpirationReaper-0-Produce]: Starting
2024-12-31 21:14:17.537 [ExpirationReaper-0-Fetch]: Starting
2024-12-31 21:14:17.537 [ExpirationReaper-0-DeleteRecords]: Starting
2024-12-31 21:14:17.538 [ExpirationReaper-0-ElectLeader]: Starting
2024-12-31 21:14:17.550 [LogDirFailureHandler]: Starting
2024-12-31 21:14:17.567 Creating /brokers/ids/0 (is it secure? false)
2024-12-31 21:14:17.582 Stat of the created znode at /brokers/ids/0 is: 25,25,1735650857577,1735650857577,1,0,0,72083386637025280,204,0,25

2024-12-31 21:14:17.582 Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:59617, czxid (broker epoch): 25
2024-12-31 21:14:17.629 [ControllerEventThread controllerId=0] Starting
2024-12-31 21:14:17.632 [ExpirationReaper-0-topic]: Starting
2024-12-31 21:14:17.638 [ExpirationReaper-0-Heartbeat]: Starting
2024-12-31 21:14:17.639 [ExpirationReaper-0-Rebalance]: Starting
2024-12-31 21:14:17.646 Successfully created /controller_epoch with initial epoch 0
2024-12-31 21:14:17.651 [Controller id=0] 0 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1
2024-12-31 21:14:17.652 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:17.652 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:17.652 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:17.653 [GroupCoordinator 0]: Starting up.
2024-12-31 21:14:17.654 [Controller id=0] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map())
2024-12-31 21:14:17.657 Feature ZK node created at path: /feature
2024-12-31 21:14:17.658 [GroupCoordinator 0]: Startup complete.
2024-12-31 21:14:17.676 [TransactionCoordinator id=0] Starting up.
2024-12-31 21:14:17.679 [Transaction Marker Channel Manager 0]: Starting
2024-12-31 21:14:17.679 [TransactionCoordinator id=0] Startup complete.
2024-12-31 21:14:17.679 [Controller id=0] Registering handlers
2024-12-31 21:14:17.679 [MetadataCache brokerId=0] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0).
2024-12-31 21:14:17.682 [Controller id=0] Deleting log dir event notifications
2024-12-31 21:14:17.684 [Controller id=0] Deleting isr change notifications
2024-12-31 21:14:17.685 [Controller id=0] Initializing controller context
2024-12-31 21:14:17.698 [Controller id=0] Initialized broker epochs cache: HashMap(0 -> 25)
2024-12-31 21:14:17.707 [ExpirationReaper-0-AlterAcls]: Starting
2024-12-31 21:14:17.714 [RequestSendThread controllerId=0] Starting
2024-12-31 21:14:17.716 [Controller id=0] Currently active brokers in the cluster: Set(0)
2024-12-31 21:14:17.717 [Controller id=0] Currently shutting brokers in the cluster: HashSet()
2024-12-31 21:14:17.717 [Controller id=0] Current list of topics in the cluster: HashSet()
2024-12-31 21:14:17.717 [Controller id=0] Fetching topic deletions in progress
2024-12-31 21:14:17.719 [Controller id=0] List of topics to be deleted: 
2024-12-31 21:14:17.719 [Controller id=0] List of topics ineligible for deletion: 
2024-12-31 21:14:17.720 [Controller id=0] Initializing topic deletion manager
2024-12-31 21:14:17.720 [Topic Deletion Manager 0] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet()
2024-12-31 21:14:17.721 [Controller id=0] Sending update metadata request
2024-12-31 21:14:17.724 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions
2024-12-31 21:14:17.729 [/config/changes-event-process-thread]: Starting
2024-12-31 21:14:17.730 [ReplicaStateMachine controllerId=0] Initializing replica state
2024-12-31 21:14:17.730 [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2024-12-31 21:14:17.732 [RequestSendThread controllerId=0] Controller 0 connected to localhost:59617 (id: 0 rack: null) for sending state change requests
2024-12-31 21:14:17.737 [ReplicaStateMachine controllerId=0] Triggering offline replica state changes
2024-12-31 21:14:17.737 [PartitionStateMachine controllerId=0] Initializing partition state
2024-12-31 21:14:17.739 [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing.
2024-12-31 21:14:17.739 [PartitionStateMachine controllerId=0] Triggering online partition state changes
2024-12-31 21:14:17.741 Kafka version: 3.4.1
2024-12-31 21:14:17.741 Kafka commitId: 8a516edc2755df89
2024-12-31 21:14:17.741 Kafka startTimeMs: 1735650857741
2024-12-31 21:14:17.742 [KafkaServer id=0] started
2024-12-31 21:14:17.743 [Controller id=0] Ready to serve as the new controller with epoch 1
2024-12-31 21:14:17.745 AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [127.0.0.1:59617]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-31 21:14:17.747 [Controller id=0] Partitions undergoing preferred replica election: 
2024-12-31 21:14:17.748 [Controller id=0] Partitions that completed preferred replica election: 
2024-12-31 21:14:17.748 [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2024-12-31 21:14:17.748 [Controller id=0] Resuming preferred replica election for partitions: 
2024-12-31 21:14:17.749 [Controller id=0] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered
2024-12-31 21:14:17.759 [Controller id=0] Starting the controller scheduler
2024-12-31 21:14:17.772 Kafka version: 3.4.1
2024-12-31 21:14:17.772 Kafka commitId: 8a516edc2755df89
2024-12-31 21:14:17.772 Kafka startTimeMs: 1735650857772
2024-12-31 21:14:17.800 [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use node localhost:59617 (id: 0 rack: null)
2024-12-31 21:14:17.824 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Recorded new controller, from now on will use node localhost:59617 (id: 0 rack: null)
2024-12-31 21:14:17.838 Creating topic pong-message-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0))
2024-12-31 21:14:17.855 [Controller id=0] New topics: [Set(pong-message-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(pong-message-topic,Some(gNA-eHCrT9amU_tE9k1jJw),Map(pong-message-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), pong-message-topic-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:14:17.856 [Controller id=0] New partition creation callback for pong-message-topic-0,pong-message-topic-1
2024-12-31 21:14:17.858 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:14:17.858 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:14:17.858 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:14:17.863 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:14:17.881 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:14:17.882 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:14:17.883 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2024-12-31 21:14:17.885 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2024-12-31 21:14:17.886 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:14:17.890 [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 for 2 partitions
2024-12-31 21:14:17.918 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(pong-message-topic-0, pong-message-topic-1)
2024-12-31 21:14:17.919 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2024-12-31 21:14:17.978 [LogLoader partition=pong-message-topic-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.9c13d1c7-bfc4-4fb1-92f3-195c59297f4318126558273090271927] Loading producer state till offset 0 with message format version 2
2024-12-31 21:14:17.994 Created log for partition pong-message-topic-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.9c13d1c7-bfc4-4fb1-92f3-195c59297f4318126558273090271927\pong-message-topic-0 with properties {}
2024-12-31 21:14:17.995 [Partition pong-message-topic-0 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-0
2024-12-31 21:14:17.996 [Partition pong-message-topic-0 broker=0] Log loaded for partition pong-message-topic-0 with initial high watermark 0
2024-12-31 21:14:17.997 [Broker id=0] Leader pong-message-topic-0 with topic id Some(gNA-eHCrT9amU_tE9k1jJw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:14:18.010 [LogLoader partition=pong-message-topic-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.9c13d1c7-bfc4-4fb1-92f3-195c59297f4318126558273090271927] Loading producer state till offset 0 with message format version 2
2024-12-31 21:14:18.011 Created log for partition pong-message-topic-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.9c13d1c7-bfc4-4fb1-92f3-195c59297f4318126558273090271927\pong-message-topic-1 with properties {}
2024-12-31 21:14:18.011 [Partition pong-message-topic-1 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-1
2024-12-31 21:14:18.011 [Partition pong-message-topic-1 broker=0] Log loaded for partition pong-message-topic-1 with initial high watermark 0
2024-12-31 21:14:18.011 [Broker id=0] Leader pong-message-topic-1 with topic id Some(gNA-eHCrT9amU_tE9k1jJw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:14:18.020 [Broker id=0] Finished LeaderAndIsr request in 131ms correlationId 1 from controller 0 for 2 partitions
2024-12-31 21:14:18.026 [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2
2024-12-31 21:14:18.032 App info kafka.admin.client for adminclient-1 unregistered
2024-12-31 21:14:18.034 Metrics scheduler closed
2024-12-31 21:14:18.034 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:14:18.034 Metrics reporters closed
2024-12-31 21:14:18.186 Idempotence will be disabled because acks is set to 0, not set to 'all'.
2024-12-31 21:14:18.186 ProducerConfig values: 
	acks = 0
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2024-12-31 21:14:18.202 Kafka version: 3.4.1
2024-12-31 21:14:18.202 Kafka commitId: 8a516edc2755df89
2024-12-31 21:14:18.202 Kafka startTimeMs: 1735650858202
2024-12-31 21:14:18.204 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:14:18.204 [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:18.204 [Producer clientId=producer-1] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:18.258 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:14:18.258 [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:18.258 [Producer clientId=producer-1] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:18.409 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:14:18.409 [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:18.410 [Producer clientId=producer-1] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:18.563 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:18.565 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:18.565 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:18.661 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:14:18.662 [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:18.662 [Producer clientId=producer-1] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:19.119 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:14:19.120 [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:19.120 [Producer clientId=producer-1] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:19.523 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:19.524 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:19.524 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:19.827 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:14:19.828 [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:19.828 [Producer clientId=producer-1] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:20.677 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:20.679 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:20.679 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:21.040 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:14:21.040 [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:21.040 [Producer clientId=producer-1] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:21.486 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:21.486 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:21.487 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:21.848 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:14:21.848 [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:21.848 [Producer clientId=producer-1] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:22.096 Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT
2024-12-31 21:14:22.096 Client environment:host.name=Joe
2024-12-31 21:14:22.096 Client environment:java.version=17.0.12
2024-12-31 21:14:22.096 Client environment:java.vendor=Oracle Corporation
2024-12-31 21:14:22.097 Client environment:java.home=C:\work\jdk-17
2024-12-31 21:14:22.097 Client environment:java.class.path=C:\code\hsbc\demo\pong\target\test-classes;C:\code\hsbc\demo\pong\target\classes;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-webflux\3.1.4\spring-boot-starter-webflux-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter\3.1.4\spring-boot-starter-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot\3.1.4\spring-boot-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-autoconfigure\3.1.4\spring-boot-autoconfigure-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-logging\3.1.4\spring-boot-starter-logging-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\ch\qos\logback\logback-classic\1.4.11\logback-classic-1.4.11.jar;C:\work\apache-maven-3.8.8\repo\ch\qos\logback\logback-core\1.4.11\logback-core-1.4.11.jar;C:\work\apache-maven-3.8.8\repo\org\apache\logging\log4j\log4j-to-slf4j\2.20.0\log4j-to-slf4j-2.20.0.jar;C:\work\apache-maven-3.8.8\repo\org\apache\logging\log4j\log4j-api\2.20.0\log4j-api-2.20.0.jar;C:\work\apache-maven-3.8.8\repo\org\slf4j\jul-to-slf4j\2.0.9\jul-to-slf4j-2.0.9.jar;C:\work\apache-maven-3.8.8\repo\jakarta\annotation\jakarta.annotation-api\2.1.1\jakarta.annotation-api-2.1.1.jar;C:\work\apache-maven-3.8.8\repo\org\yaml\snakeyaml\1.33\snakeyaml-1.33.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-json\3.1.4\spring-boot-starter-json-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-databind\2.15.2\jackson-databind-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-annotations\2.15.2\jackson-annotations-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-core\2.15.2\jackson-core-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.15.2\jackson-datatype-jdk8-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.15.2\jackson-datatype-jsr310-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\module\jackson-module-parameter-names\2.15.2\jackson-module-parameter-names-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-reactor-netty\3.1.4\spring-boot-starter-reactor-netty-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\netty\reactor-netty-http\1.1.11\reactor-netty-http-1.1.11.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-http\4.1.97.Final\netty-codec-http-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-http2\4.1.97.Final\netty-codec-http2-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns\4.1.97.Final\netty-resolver-dns-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-dns\4.1.97.Final\netty-codec-dns-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns-native-macos\4.1.97.Final\netty-resolver-dns-native-macos-4.1.97.Final-osx-x86_64.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns-classes-macos\4.1.97.Final\netty-resolver-dns-classes-macos-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final-linux-x86_64.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\netty\reactor-netty-core\1.1.11\reactor-netty-core-1.1.11.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-handler-proxy\4.1.97.Final\netty-handler-proxy-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-socks\4.1.97.Final\netty-codec-socks-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-web\6.0.12\spring-web-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-beans\6.0.12\spring-beans-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-webflux\6.0.12\spring-webflux-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\reactor-core\3.5.10\reactor-core-3.5.10.jar;C:\work\apache-maven-3.8.8\repo\org\reactivestreams\reactive-streams\1.0.4\reactive-streams-1.0.4.jar;C:\work\apache-maven-3.8.8\repo\com\google\guava\guava\19.0\guava-19.0.jar;C:\work\apache-maven-3.8.8\repo\commons-io\commons-io\2.11.0\commons-io-2.11.0.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-data-redis\3.1.4\spring-boot-starter-data-redis-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-redis\3.1.4\spring-data-redis-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-keyvalue\3.1.4\spring-data-keyvalue-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-oxm\6.0.12\spring-oxm-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-aop\6.0.12\spring-aop-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-context-support\6.0.12\spring-context-support-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\io\lettuce\lettuce-core\6.2.6.RELEASE\lettuce-core-6.2.6.RELEASE.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-common\4.1.97.Final\netty-common-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-handler\4.1.97.Final\netty-handler-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver\4.1.97.Final\netty-resolver-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-buffer\4.1.97.Final\netty-buffer-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-unix-common\4.1.97.Final\netty-transport-native-unix-common-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec\4.1.97.Final\netty-codec-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport\4.1.97.Final\netty-transport-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-data-jpa\3.1.4\spring-boot-starter-data-jpa-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-aop\3.1.4\spring-boot-starter-aop-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\aspectj\aspectjweaver\1.9.20\aspectjweaver-1.9.20.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-jdbc\3.1.4\spring-boot-starter-jdbc-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\zaxxer\HikariCP\5.0.1\HikariCP-5.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-jdbc\6.0.12\spring-jdbc-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\hibernate\orm\hibernate-core\6.2.9.Final\hibernate-core-6.2.9.Final.jar;C:\work\apache-maven-3.8.8\repo\jakarta\persistence\jakarta.persistence-api\3.1.0\jakarta.persistence-api-3.1.0.jar;C:\work\apache-maven-3.8.8\repo\jakarta\transaction\jakarta.transaction-api\2.0.1\jakarta.transaction-api-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\jboss\logging\jboss-logging\3.5.3.Final\jboss-logging-3.5.3.Final.jar;C:\work\apache-maven-3.8.8\repo\org\hibernate\common\hibernate-commons-annotations\6.0.6.Final\hibernate-commons-annotations-6.0.6.Final.jar;C:\work\apache-maven-3.8.8\repo\io\smallrye\jandex\3.0.5\jandex-3.0.5.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\classmate\1.5.1\classmate-1.5.1.jar;C:\work\apache-maven-3.8.8\repo\net\bytebuddy\byte-buddy\1.14.8\byte-buddy-1.14.8.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\jaxb-runtime\4.0.3\jaxb-runtime-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\jaxb-core\4.0.3\jaxb-core-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\eclipse\angus\angus-activation\2.0.1\angus-activation-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\txw2\4.0.3\txw2-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\com\sun\istack\istack-commons-runtime\4.1.2\istack-commons-runtime-4.1.2.jar;C:\work\apache-maven-3.8.8\repo\jakarta\inject\jakarta.inject-api\2.0.1\jakarta.inject-api-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\antlr\antlr4-runtime\4.10.1\antlr4-runtime-4.10.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-jpa\3.1.4\spring-data-jpa-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-commons\3.1.4\spring-data-commons-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-orm\6.0.12\spring-orm-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-aspects\6.0.12\spring-aspects-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\postgresql\postgresql\42.6.0\postgresql-42.6.0.jar;C:\work\apache-maven-3.8.8\repo\org\checkerframework\checker-qual\3.31.0\checker-qual-3.31.0.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\kafka\spring-kafka\3.0.11\spring-kafka-3.0.11.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-context\6.0.12\spring-context-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-expression\6.0.12\spring-expression-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-messaging\6.0.12\spring-messaging-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-tx\6.0.12\spring-tx-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\retry\spring-retry\2.0.3\spring-retry-2.0.3.jar;C:\work\apache-maven-3.8.8\repo\io\micrometer\micrometer-observation\1.11.4\micrometer-observation-1.11.4.jar;C:\work\apache-maven-3.8.8\repo\io\micrometer\micrometer-commons\1.11.4\micrometer-commons-1.11.4.jar;C:\work\apache-maven-3.8.8\repo\com\google\code\findbugs\jsr305\3.0.2\jsr305-3.0.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\com\github\luben\zstd-jni\1.5.2-1\zstd-jni-1.5.2-1.jar;C:\work\apache-maven-3.8.8\repo\org\lz4\lz4-java\1.8.0\lz4-java-1.8.0.jar;C:\work\apache-maven-3.8.8\repo\org\xerial\snappy\snappy-java\1.1.8.4\snappy-java-1.1.8.4.jar;C:\work\apache-maven-3.8.8\repo\org\slf4j\slf4j-api\2.0.9\slf4j-api-2.0.9.jar;C:\work\apache-maven-3.8.8\repo\com\h2database\h2\1.4.200\h2-1.4.200.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-test\3.1.4\spring-boot-starter-test-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-test\3.1.4\spring-boot-test-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-test-autoconfigure\3.1.4\spring-boot-test-autoconfigure-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\jayway\jsonpath\json-path\2.8.0\json-path-2.8.0.jar;C:\work\apache-maven-3.8.8\repo\jakarta\xml\bind\jakarta.xml.bind-api\4.0.1\jakarta.xml.bind-api-4.0.1.jar;C:\work\apache-maven-3.8.8\repo\jakarta\activation\jakarta.activation-api\2.1.2\jakarta.activation-api-2.1.2.jar;C:\work\apache-maven-3.8.8\repo\net\minidev\json-smart\2.4.11\json-smart-2.4.11.jar;C:\work\apache-maven-3.8.8\repo\net\minidev\accessors-smart\2.4.11\accessors-smart-2.4.11.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm\9.3\asm-9.3.jar;C:\work\apache-maven-3.8.8\repo\org\assertj\assertj-core\3.24.2\assertj-core-3.24.2.jar;C:\work\apache-maven-3.8.8\repo\org\hamcrest\hamcrest\2.2\hamcrest-2.2.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter\5.9.3\junit-jupiter-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-params\5.9.3\junit-jupiter-params-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-engine\5.9.3\junit-jupiter-engine-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\mockito\mockito-core\5.3.1\mockito-core-5.3.1.jar;C:\work\apache-maven-3.8.8\repo\net\bytebuddy\byte-buddy-agent\1.14.8\byte-buddy-agent-1.14.8.jar;C:\work\apache-maven-3.8.8\repo\org\objenesis\objenesis\3.3\objenesis-3.3.jar;C:\work\apache-maven-3.8.8\repo\org\mockito\mockito-junit-jupiter\5.3.1\mockito-junit-jupiter-5.3.1.jar;C:\work\apache-maven-3.8.8\repo\org\skyscreamer\jsonassert\1.5.1\jsonassert-1.5.1.jar;C:\work\apache-maven-3.8.8\repo\com\vaadin\external\google\android-json\0.0.20131108.vaadin1\android-json-0.0.20131108.vaadin1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-core\6.0.12\spring-core-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-jcl\6.0.12\spring-jcl-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-test\6.0.12\spring-test-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\xmlunit\xmlunit-core\2.9.1\xmlunit-core-2.9.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy\4.0.15\groovy-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-ant\4.0.15\groovy-ant-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant\1.10.14\ant-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-junit\1.10.14\ant-junit-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-launcher\1.10.14\ant-launcher-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-antlr\1.10.14\ant-antlr-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-cli-picocli\4.0.15\groovy-cli-picocli-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\info\picocli\picocli\4.7.5\picocli-4.7.5.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-console\4.0.15\groovy-console-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\github\javaparser\javaparser-core\3.25.5\javaparser-core-3.25.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-util\9.5\asm-util-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-tree\9.5\asm-tree-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-analysis\9.5\asm-analysis-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\abego\treelayout\org.abego.treelayout.core\1.0.3\org.abego.treelayout.core-1.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ivy\ivy\2.5.2\ivy-2.5.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-datetime\4.0.15\groovy-datetime-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-docgenerator\4.0.15\groovy-docgenerator-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\thoughtworks\qdox\qdox\1.12.1\qdox-1.12.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-groovydoc\4.0.15\groovy-groovydoc-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-groovysh\4.0.15\groovy-groovysh-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\jline\jline\2.14.6\jline-2.14.6.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-jmx\4.0.15\groovy-jmx-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-json\4.0.15\groovy-json-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-jsr223\4.0.15\groovy-jsr223-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-macro\4.0.15\groovy-macro-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-nio\4.0.15\groovy-nio-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-servlet\4.0.15\groovy-servlet-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-sql\4.0.15\groovy-sql-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-swing\4.0.15\groovy-swing-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-templates\4.0.15\groovy-templates-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-test\4.0.15\groovy-test-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\junit\junit\4.13.2\junit-4.13.2.jar;C:\work\apache-maven-3.8.8\repo\org\hamcrest\hamcrest-core\2.2\hamcrest-core-2.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-test-junit5\4.0.15\groovy-test-junit5-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-xml\4.0.15\groovy-xml-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-yaml\4.0.15\groovy-yaml-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\dataformat\jackson-dataformat-yaml\2.15.2\jackson-dataformat-yaml-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\org\spockframework\spock-core\2.4-M1-groovy-4.0\spock-core-2.4-M1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-engine\1.9.3\junit-platform-engine-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\opentest4j\opentest4j\1.2.0\opentest4j-1.2.0.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-commons\1.9.3\junit-platform-commons-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\apiguardian\apiguardian-api\1.1.2\apiguardian-api-1.1.2.jar;C:\work\apache-maven-3.8.8\repo\org\spockframework\spock-spring\2.4-M1-groovy-4.0\spock-spring-2.4-M1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\com\athaydes\spock-reports\2.5.1-groovy-4.0\spock-reports-2.5.1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\com\github\codemonstur\embedded-redis\1.4.2\embedded-redis-1.4.2.jar;C:\work\apache-maven-3.8.8\repo\redis\clients\jedis\4.3.2\jedis-4.3.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\commons\commons-pool2\2.11.1\commons-pool2-2.11.1.jar;C:\work\apache-maven-3.8.8\repo\org\json\json\20220320\json-20220320.jar;C:\work\apache-maven-3.8.8\repo\com\google\code\gson\gson\2.10.1\gson-2.10.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\kafka\spring-kafka-test\3.0.11\spring-kafka-test-3.0.11.jar;C:\work\apache-maven-3.8.8\repo\org\apache\zookeeper\zookeeper\3.6.3\zookeeper-3.6.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\zookeeper\zookeeper-jute\3.6.3\zookeeper-jute-3.6.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-classes-epoll\4.1.97.Final\netty-transport-classes-epoll-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1-test.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-metadata\3.4.1\kafka-metadata-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-server-common\3.4.1\kafka-server-common-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-raft\3.4.1\kafka-raft-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-streams-test-utils\3.4.1\kafka-streams-test-utils-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-streams\3.4.1\kafka-streams-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\rocksdb\rocksdbjni\7.1.2\rocksdbjni-7.1.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\scala-library\2.13.10\scala-library-2.13.10.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-group-coordinator\3.4.1\kafka-group-coordinator-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-storage\3.4.1\kafka-storage-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-storage-api\3.4.1\kafka-storage-api-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\net\sourceforge\argparse4j\argparse4j\0.7.0\argparse4j-0.7.0.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\module\jackson-module-scala_2.13\2.15.2\jackson-module-scala_2.13-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\thoughtworks\paranamer\paranamer\2.8\paranamer-2.8.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\dataformat\jackson-dataformat-csv\2.15.2\jackson-dataformat-csv-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\net\sf\jopt-simple\jopt-simple\5.0.4\jopt-simple-5.0.4.jar;C:\work\apache-maven-3.8.8\repo\org\bitbucket\b_c\jose4j\0.9.3\jose4j-0.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\modules\scala-collection-compat_2.13\2.10.0\scala-collection-compat_2.13-2.10.0.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\modules\scala-java8-compat_2.13\1.0.2\scala-java8-compat_2.13-1.0.2.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\scala-reflect\2.13.10\scala-reflect-2.13.10.jar;C:\work\apache-maven-3.8.8\repo\com\typesafe\scala-logging\scala-logging_2.13\3.9.4\scala-logging_2.13-3.9.4.jar;C:\work\apache-maven-3.8.8\repo\io\dropwizard\metrics\metrics-core\4.2.19\metrics-core-4.2.19.jar;C:\work\apache-maven-3.8.8\repo\commons-cli\commons-cli\1.4\commons-cli-1.4.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1-test.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-api\5.9.3\junit-jupiter-api-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-launcher\1.9.3\junit-platform-launcher-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\awaitility\awaitility\4.2.0\awaitility-4.2.0.jar;
2024-12-31 21:14:22.099 Client environment:java.library.path=C:\work\jdk-17\bin;C:\windows\Sun\Java\bin;C:\windows\system32;C:\windows;C:\work\python312\Scripts\;C:\work\python312\;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program\Git\cmd;C:\Program\PowerShell\7\;C:\Program Files\dotnet\;C:\Users\joech\AppData\Local\Microsoft\WindowsApps;C:\Users\joech\AppData\Local\GitHubDesktop\bin;C:\Program\Microsoft VS Code\bin;C:\work\apache-maven-3.8.8\bin;C:\Program Files\Tesseract-OCR;C:\work\jdk-17\bin;;.
2024-12-31 21:14:22.100 Client environment:java.io.tmpdir=C:\Users\joech\AppData\Local\Temp\
2024-12-31 21:14:22.100 Client environment:java.compiler=<NA>
2024-12-31 21:14:22.100 Client environment:os.name=Windows 11
2024-12-31 21:14:22.100 Client environment:os.arch=amd64
2024-12-31 21:14:22.100 Client environment:os.version=10.0
2024-12-31 21:14:22.100 Client environment:user.name=joech
2024-12-31 21:14:22.100 Client environment:user.home=C:\Users\joech
2024-12-31 21:14:22.100 Client environment:user.dir=C:\code\hsbc\demo\pong
2024-12-31 21:14:22.100 Client environment:os.memory.free=55MB
2024-12-31 21:14:22.100 Client environment:os.memory.max=15816MB
2024-12-31 21:14:22.100 Client environment:os.memory.total=136MB
2024-12-31 21:14:22.108 Initiating client connection, connectString=127.0.0.1:59614 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@79414283
2024-12-31 21:14:22.115 jute.maxbuffer value is 4194304 Bytes
2024-12-31 21:14:22.124 zookeeper.request.timeout value is 0. feature enabled=false
2024-12-31 21:14:22.127 [ZooKeeperClient Kafka server] Waiting until connected.
2024-12-31 21:14:22.127 Opening socket connection to server /127.0.0.1:59614.
2024-12-31 21:14:22.130 Socket connection established, initiating session, client: /127.0.0.1:59634, server: /127.0.0.1:59614
2024-12-31 21:14:22.141 Creating new log file: log.1
2024-12-31 21:14:22.155 ZooKeeper audit is disabled.
2024-12-31 21:14:22.161 Session establishment complete on server /127.0.0.1:59614, session id = 0x100177562050000, negotiated timeout = 16000
2024-12-31 21:14:22.166 [ZooKeeperClient Kafka server] Connected.
2024-12-31 21:14:22.364 Cluster ID = Cm650zWGRryhb5URlNEt2g
2024-12-31 21:14:22.370 No meta.properties file under dir C:\Users\joech\AppData\Local\Temp\spring.kafka.13e9a513-d2a4-40a1-90b1-c5e8bcc6d28415572636074268719671\meta.properties
2024-12-31 21:14:22.438 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.13e9a513-d2a4-40a1-90b1-c5e8bcc6d28415572636074268719671
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59614
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:14:22.446 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:22.446 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:22.446 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:22.497 [ThrottledChannelReaper-Fetch]: Starting
2024-12-31 21:14:22.498 [ThrottledChannelReaper-Produce]: Starting
2024-12-31 21:14:22.502 [ThrottledChannelReaper-Request]: Starting
2024-12-31 21:14:22.508 [ThrottledChannelReaper-ControllerMutation]: Starting
2024-12-31 21:14:22.566 Loading logs from log dirs ArraySeq(C:\Users\joech\AppData\Local\Temp\spring.kafka.13e9a513-d2a4-40a1-90b1-c5e8bcc6d28415572636074268719671)
2024-12-31 21:14:22.573 Attempting recovery for all logs in C:\Users\joech\AppData\Local\Temp\spring.kafka.13e9a513-d2a4-40a1-90b1-c5e8bcc6d28415572636074268719671 since no clean shutdown file was found
2024-12-31 21:14:22.590 Loaded 0 logs in 24ms.
2024-12-31 21:14:22.591 Starting log cleanup with a period of 300000 ms.
2024-12-31 21:14:22.594 Starting log flusher with a default period of 9223372036854775807 ms.
2024-12-31 21:14:22.622 Starting the log cleaner
2024-12-31 21:14:22.641 [kafka-log-cleaner-thread-0]: Starting
2024-12-31 21:14:22.672 [feature-zk-node-event-process-thread]: Starting
2024-12-31 21:14:22.692 Feature ZK node at path: /feature does not exist
2024-12-31 21:14:22.741 [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting
2024-12-31 21:14:22.757 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:14:22.757 [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:22.757 [Producer clientId=producer-1] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:22.760 [Controller id=0] Processing automatic preferred replica leader election
2024-12-31 21:14:23.339 Updated connection-accept-rate max connection creation rate to 2147483647
2024-12-31 21:14:23.348 Awaiting socket connections on localhost:59637.
2024-12-31 21:14:23.383 [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT)
2024-12-31 21:14:23.391 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Starting
2024-12-31 21:14:23.420 [ExpirationReaper-0-Produce]: Starting
2024-12-31 21:14:23.421 [ExpirationReaper-0-Fetch]: Starting
2024-12-31 21:14:23.423 [ExpirationReaper-0-DeleteRecords]: Starting
2024-12-31 21:14:23.428 [ExpirationReaper-0-ElectLeader]: Starting
2024-12-31 21:14:23.455 [LogDirFailureHandler]: Starting
2024-12-31 21:14:23.482 Creating /brokers/ids/0 (is it secure? false)
2024-12-31 21:14:23.512 Stat of the created znode at /brokers/ids/0 is: 25,25,1735650863499,1735650863499,1,0,0,72083386961035264,204,0,25

2024-12-31 21:14:23.513 Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:59637, czxid (broker epoch): 25
2024-12-31 21:14:23.608 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:23.608 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:23.608 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:23.614 [ControllerEventThread controllerId=0] Starting
2024-12-31 21:14:23.620 [ExpirationReaper-0-topic]: Starting
2024-12-31 21:14:23.631 [ExpirationReaper-0-Heartbeat]: Starting
2024-12-31 21:14:23.631 [ExpirationReaper-0-Rebalance]: Starting
2024-12-31 21:14:23.642 Successfully created /controller_epoch with initial epoch 0
2024-12-31 21:14:23.649 [Controller id=0] 0 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1
2024-12-31 21:14:23.654 [Controller id=0] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map())
2024-12-31 21:14:23.656 [GroupCoordinator 0]: Starting up.
2024-12-31 21:14:23.659 Feature ZK node created at path: /feature
2024-12-31 21:14:23.664 [GroupCoordinator 0]: Startup complete.
2024-12-31 21:14:23.700 [TransactionCoordinator id=0] Starting up.
2024-12-31 21:14:23.705 [Transaction Marker Channel Manager 0]: Starting
2024-12-31 21:14:23.705 [TransactionCoordinator id=0] Startup complete.
2024-12-31 21:14:23.717 [Controller id=0] Registering handlers
2024-12-31 21:14:23.717 [MetadataCache brokerId=0] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0).
2024-12-31 21:14:23.721 [Controller id=0] Deleting log dir event notifications
2024-12-31 21:14:23.724 [Controller id=0] Deleting isr change notifications
2024-12-31 21:14:23.727 [Controller id=0] Initializing controller context
2024-12-31 21:14:23.752 [Controller id=0] Initialized broker epochs cache: HashMap(0 -> 25)
2024-12-31 21:14:23.755 [ExpirationReaper-0-AlterAcls]: Starting
2024-12-31 21:14:23.776 [RequestSendThread controllerId=0] Starting
2024-12-31 21:14:23.779 [Controller id=0] Currently active brokers in the cluster: Set(0)
2024-12-31 21:14:23.779 [Controller id=0] Currently shutting brokers in the cluster: HashSet()
2024-12-31 21:14:23.779 [Controller id=0] Current list of topics in the cluster: HashSet()
2024-12-31 21:14:23.780 [Controller id=0] Fetching topic deletions in progress
2024-12-31 21:14:23.782 [Controller id=0] List of topics to be deleted: 
2024-12-31 21:14:23.782 [Controller id=0] List of topics ineligible for deletion: 
2024-12-31 21:14:23.784 [Controller id=0] Initializing topic deletion manager
2024-12-31 21:14:23.785 [Topic Deletion Manager 0] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet()
2024-12-31 21:14:23.788 [Controller id=0] Sending update metadata request
2024-12-31 21:14:23.794 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions
2024-12-31 21:14:23.800 [/config/changes-event-process-thread]: Starting
2024-12-31 21:14:23.801 [ReplicaStateMachine controllerId=0] Initializing replica state
2024-12-31 21:14:23.802 [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2024-12-31 21:14:23.809 [ReplicaStateMachine controllerId=0] Triggering offline replica state changes
2024-12-31 21:14:23.810 [PartitionStateMachine controllerId=0] Initializing partition state
2024-12-31 21:14:23.810 [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing.
2024-12-31 21:14:23.810 [PartitionStateMachine controllerId=0] Triggering online partition state changes
2024-12-31 21:14:23.815 [RequestSendThread controllerId=0] Controller 0 connected to localhost:59637 (id: 0 rack: null) for sending state change requests
2024-12-31 21:14:23.817 Kafka version: 3.4.1
2024-12-31 21:14:23.817 Kafka commitId: 8a516edc2755df89
2024-12-31 21:14:23.817 Kafka startTimeMs: 1735650863814
2024-12-31 21:14:23.819 [Controller id=0] Ready to serve as the new controller with epoch 1
2024-12-31 21:14:23.820 [KafkaServer id=0] started
2024-12-31 21:14:23.826 [Controller id=0] Partitions undergoing preferred replica election: 
2024-12-31 21:14:23.826 [Controller id=0] Partitions that completed preferred replica election: 
2024-12-31 21:14:23.827 [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2024-12-31 21:14:23.827 [Controller id=0] Resuming preferred replica election for partitions: 
2024-12-31 21:14:23.829 [Controller id=0] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered
2024-12-31 21:14:23.830 AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [127.0.0.1:59637]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-31 21:14:23.843 [Controller id=0] Starting the controller scheduler
2024-12-31 21:14:23.884 Kafka version: 3.4.1
2024-12-31 21:14:23.884 Kafka commitId: 8a516edc2755df89
2024-12-31 21:14:23.884 Kafka startTimeMs: 1735650863884
2024-12-31 21:14:23.920 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:14:23.921 [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:23.921 [Producer clientId=producer-1] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:23.940 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Recorded new controller, from now on will use node localhost:59637 (id: 0 rack: null)
2024-12-31 21:14:23.940 [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use node localhost:59637 (id: 0 rack: null)
2024-12-31 21:14:24.017 Creating topic pong-message-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2024-12-31 21:14:24.044 [Controller id=0] New topics: [Set(pong-message-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(pong-message-topic,Some(PRYySdNQSiSulf_rOMOvrg),Map(pong-message-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:14:24.046 [Controller id=0] New partition creation callback for pong-message-topic-0
2024-12-31 21:14:24.048 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:14:24.049 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:14:24.054 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:14:24.082 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:14:24.085 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions
2024-12-31 21:14:24.088 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 1 partitions
2024-12-31 21:14:24.089 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:14:24.095 [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 for 1 partitions
2024-12-31 21:14:24.131 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(pong-message-topic-0)
2024-12-31 21:14:24.132 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions
2024-12-31 21:14:24.219 [LogLoader partition=pong-message-topic-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.13e9a513-d2a4-40a1-90b1-c5e8bcc6d28415572636074268719671] Loading producer state till offset 0 with message format version 2
2024-12-31 21:14:24.238 Created log for partition pong-message-topic-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.13e9a513-d2a4-40a1-90b1-c5e8bcc6d28415572636074268719671\pong-message-topic-0 with properties {}
2024-12-31 21:14:24.240 [Partition pong-message-topic-0 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-0
2024-12-31 21:14:24.240 [Partition pong-message-topic-0 broker=0] Log loaded for partition pong-message-topic-0 with initial high watermark 0
2024-12-31 21:14:24.242 [Broker id=0] Leader pong-message-topic-0 with topic id Some(PRYySdNQSiSulf_rOMOvrg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:14:24.258 [Broker id=0] Finished LeaderAndIsr request in 167ms correlationId 1 from controller 0 for 1 partitions
2024-12-31 21:14:24.267 [Broker id=0] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2
2024-12-31 21:14:24.275 App info kafka.admin.client for adminclient-1 unregistered
2024-12-31 21:14:24.279 Metrics scheduler closed
2024-12-31 21:14:24.279 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:14:24.279 Metrics reporters closed
2024-12-31 21:14:24.290 Starting PongControllerSpec using Java 17.0.12 with PID 24224 (started by joech in C:\code\hsbc\demo\pong)
2024-12-31 21:14:24.291 No active profile set, falling back to 1 default profile: "default"
2024-12-31 21:14:24.771 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:24.772 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:24.772 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:24.981 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:14:24.981 [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:24.981 [Producer clientId=producer-1] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:25.177 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:14:25.181 Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2024-12-31 21:14:25.422 Finished Spring Data repository scanning in 225 ms. Found 1 JPA repository interfaces.
2024-12-31 21:14:25.453 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:14:25.455 Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2024-12-31 21:14:25.482 Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.demo.dao.MessageRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2024-12-31 21:14:25.482 Finished Spring Data repository scanning in 8 ms. Found 0 Redis repository interfaces.
2024-12-31 21:14:25.829 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:25.829 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:25.829 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:25.890 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:14:25.891 [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:25.891 [Producer clientId=producer-1] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:26.496 HHH000204: Processing PersistenceUnitInfo [name: default]
2024-12-31 21:14:26.621 HHH000412: Hibernate ORM core version 6.2.9.Final
2024-12-31 21:14:26.627 HHH000406: Using bytecode reflection optimizer
2024-12-31 21:14:26.923 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:14:27.041 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:27.041 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:27.041 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:27.102 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:14:27.102 [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:27.102 [Producer clientId=producer-1] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:27.193 No LoadTimeWeaver setup: ignoring JPA class transformer
2024-12-31 21:14:27.232 HikariPool-1 - Starting...
2024-12-31 21:14:27.682 HikariPool-1 - Added connection conn0: url=jdbc:h2:mem:testdb user=SA
2024-12-31 21:14:27.685 HikariPool-1 - Start completed.
2024-12-31 21:14:28.160 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:28.160 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:14:28.161 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:28.161 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:28.161 [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:28.161 [Producer clientId=producer-1] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:28.167 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:14:28.850 [Controller id=0] Processing automatic preferred replica leader election
2024-12-31 21:14:29.020 Error deleting C:\Users\joech\AppData\Local\Temp\kafka-12483109569141068924
java.nio.file.FileSystemException: C:\Users\joech\AppData\Local\Temp\kafka-12483109569141068924\version-2\log.1: 另一个程序正在使用此文件，进程无法访问。
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:275)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.delete(AbstractFileSystemProvider.java:105)
	at java.base/java.nio.file.Files.delete(Files.java:1152)
	at org.apache.kafka.common.utils.Utils$1.visitFile(Utils.java:878)
	at org.apache.kafka.common.utils.Utils$1.visitFile(Utils.java:867)
	at java.base/java.nio.file.Files.walkFileTree(Files.java:2811)
	at java.base/java.nio.file.Files.walkFileTree(Files.java:2882)
	at org.apache.kafka.common.utils.Utils.delete(Utils.java:867)
	at org.apache.kafka.test.TestUtils.lambda$tempDirectory$1(TestUtils.java:223)
	at java.base/java.lang.Thread.run(Thread.java:842)
2024-12-31 21:14:29.023 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:14:29.023 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:14:29.023 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Unsubscribed all topics or patterns and assigned partitions
2024-12-31 21:14:29.023 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:14:29.023 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:14:29.023 Metrics scheduler closed
2024-12-31 21:14:29.023 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:14:29.023 Metrics reporters closed
2024-12-31 21:14:29.024 App info kafka.consumer for consumer-pong-service-1 unregistered
2024-12-31 21:14:29.024 pong-service: Consumer stopped
2024-12-31 21:14:29.025 [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2024-12-31 21:14:29.026 Metrics scheduler closed
2024-12-31 21:14:29.026 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:14:29.027 Metrics reporters closed
2024-12-31 21:14:29.027 App info kafka.producer for producer-1 unregistered
2024-12-31 21:14:29.036 [KafkaServer id=0] shutting down
2024-12-31 21:14:29.036 [KafkaServer id=0] Starting controlled shutdown
2024-12-31 21:14:29.043 [Controller id=0] Shutting down broker 0
2024-12-31 21:14:29.048 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:14:29.051 [KafkaServer id=0] Controlled shutdown request returned successfully after 10ms
2024-12-31 21:14:29.051 Closing JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:14:29.052 [/config/changes-event-process-thread]: Shutting down
2024-12-31 21:14:29.052 [/config/changes-event-process-thread]: Shutdown completed
2024-12-31 21:14:29.052 [/config/changes-event-process-thread]: Stopped
2024-12-31 21:14:29.053 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
2024-12-31 21:14:29.053 HikariPool-1 - Shutdown initiated...
2024-12-31 21:14:29.055 HikariPool-1 - Shutdown completed.
2024-12-31 21:14:29.327 HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2024-12-31 21:14:29.472 Initialized JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:14:31.492 Netty started on port 59652
2024-12-31 21:14:31.544 ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-pong-service-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = pong-service
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2024-12-31 21:14:31.614 These configurations '[spring.json.trusted.packages]' were supplied but are not used yet.
2024-12-31 21:14:31.614 Kafka version: 3.4.1
2024-12-31 21:14:31.614 Kafka commitId: 8a516edc2755df89
2024-12-31 21:14:31.614 Kafka startTimeMs: 1735650871614
2024-12-31 21:14:31.616 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Subscribed to topic(s): pong-message-topic
2024-12-31 21:14:31.641 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:31.642 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:31.642 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:31.644 Started PongControllerSpec in 21.281 seconds (process running for 24.131)
2024-12-31 21:14:31.751 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:31.752 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:31.752 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:31.861 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:31.861 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:31.862 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:32.095 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:32.095 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:32.095 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:32.388 zookeeper.snapshot.trust.empty : false
2024-12-31 21:14:32.389 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:14:32.390 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:14:32.390 zookeeper.snapshotSizeFactor = 0.33
2024-12-31 21:14:32.390 zookeeper.commitLogCount=500
2024-12-31 21:14:32.390 minSessionTimeout set to 1600
2024-12-31 21:14:32.390 maxSessionTimeout set to 16000
2024-12-31 21:14:32.390 Response cache size is initialized with value 400.
2024-12-31 21:14:32.390 Response cache size is initialized with value 400.
2024-12-31 21:14:32.390 zookeeper.pathStats.slotCapacity = 60
2024-12-31 21:14:32.390 zookeeper.pathStats.slotDuration = 15
2024-12-31 21:14:32.391 zookeeper.pathStats.maxDepth = 6
2024-12-31 21:14:32.391 zookeeper.pathStats.initialDelay = 5
2024-12-31 21:14:32.391 zookeeper.pathStats.delay = 5
2024-12-31 21:14:32.391 zookeeper.pathStats.enabled = false
2024-12-31 21:14:32.391 The max bytes for all large requests are set to 104857600
2024-12-31 21:14:32.391 The large request threshold is set to -1
2024-12-31 21:14:32.391 Created server with tickTime 800 minSessionTimeout 1600 maxSessionTimeout 16000 clientPortListenBacklog -1 datadir C:\Users\joech\AppData\Local\Temp\kafka-9562173192549804652\version-2 snapdir C:\Users\joech\AppData\Local\Temp\kafka-13762957692933847616\version-2
2024-12-31 21:14:32.391 maxCnxns is not configured, using default value 0.
2024-12-31 21:14:32.391 Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers.
2024-12-31 21:14:32.394 binding to port /127.0.0.1:0
2024-12-31 21:14:32.396 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-13762957692933847616\version-2\snapshot.0
2024-12-31 21:14:32.397 Snapshot loaded in 1 ms, highest zxid is 0x0, digest is 1371985504
2024-12-31 21:14:32.397 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-13762957692933847616\version-2\snapshot.0
2024-12-31 21:14:32.398 Snapshot taken in 0 ms
2024-12-31 21:14:32.399 PrepRequestProcessor (sid:0) started, reconfigEnabled=false
2024-12-31 21:14:32.401 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.a2a099ad-817b-4660-8e0b-8040ea33453313960523455105741971
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59657
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:14:32.405 starting
2024-12-31 21:14:32.405 Connecting to zookeeper on 127.0.0.1:59657
2024-12-31 21:14:32.406 [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:59657.
2024-12-31 21:14:32.406 Initiating client connection, connectString=127.0.0.1:59657 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@120d7d66
2024-12-31 21:14:32.408 jute.maxbuffer value is 4194304 Bytes
2024-12-31 21:14:32.409 zookeeper.request.timeout value is 0. feature enabled=false
2024-12-31 21:14:32.409 [ZooKeeperClient Kafka server] Waiting until connected.
2024-12-31 21:14:32.409 Opening socket connection to server /127.0.0.1:59657.
2024-12-31 21:14:32.410 Socket connection established, initiating session, client: /127.0.0.1:59658, server: /127.0.0.1:59657
2024-12-31 21:14:32.411 Creating new log file: log.1
2024-12-31 21:14:32.419 Session establishment complete on server /127.0.0.1:59657, session id = 0x1001775a10e0000, negotiated timeout = 16000
2024-12-31 21:14:32.419 [ZooKeeperClient Kafka server] Connected.
2024-12-31 21:14:32.460 Cluster ID = qpzdRyi3QhKk9NsfZQ2Tiw
2024-12-31 21:14:32.460 No meta.properties file under dir C:\Users\joech\AppData\Local\Temp\spring.kafka.a2a099ad-817b-4660-8e0b-8040ea33453313960523455105741971\meta.properties
2024-12-31 21:14:32.471 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.a2a099ad-817b-4660-8e0b-8040ea33453313960523455105741971
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59657
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:14:32.486 [ThrottledChannelReaper-Fetch]: Starting
2024-12-31 21:14:32.486 [ThrottledChannelReaper-Produce]: Starting
2024-12-31 21:14:32.486 [ThrottledChannelReaper-Request]: Starting
2024-12-31 21:14:32.486 [ThrottledChannelReaper-ControllerMutation]: Starting
2024-12-31 21:14:32.495 Loading logs from log dirs ArraySeq(C:\Users\joech\AppData\Local\Temp\spring.kafka.a2a099ad-817b-4660-8e0b-8040ea33453313960523455105741971)
2024-12-31 21:14:32.496 Attempting recovery for all logs in C:\Users\joech\AppData\Local\Temp\spring.kafka.a2a099ad-817b-4660-8e0b-8040ea33453313960523455105741971 since no clean shutdown file was found
2024-12-31 21:14:32.497 Loaded 0 logs in 2ms.
2024-12-31 21:14:32.498 Starting log cleanup with a period of 300000 ms.
2024-12-31 21:14:32.498 Starting log flusher with a default period of 9223372036854775807 ms.
2024-12-31 21:14:32.501 Starting the log cleaner
2024-12-31 21:14:32.503 [kafka-log-cleaner-thread-0]: Starting
2024-12-31 21:14:32.503 [feature-zk-node-event-process-thread]: Starting
2024-12-31 21:14:32.505 Feature ZK node at path: /feature does not exist
2024-12-31 21:14:32.508 [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting
2024-12-31 21:14:32.533 Updated connection-accept-rate max connection creation rate to 2147483647
2024-12-31 21:14:32.535 Awaiting socket connections on localhost:59659.
2024-12-31 21:14:32.545 [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT)
2024-12-31 21:14:32.549 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Starting
2024-12-31 21:14:32.550 [ExpirationReaper-0-Produce]: Starting
2024-12-31 21:14:32.551 [ExpirationReaper-0-Fetch]: Starting
2024-12-31 21:14:32.552 [ExpirationReaper-0-DeleteRecords]: Starting
2024-12-31 21:14:32.553 [ExpirationReaper-0-ElectLeader]: Starting
2024-12-31 21:14:32.555 [LogDirFailureHandler]: Starting
2024-12-31 21:14:32.558 Creating /brokers/ids/0 (is it secure? false)
2024-12-31 21:14:32.561 Stat of the created znode at /brokers/ids/0 is: 25,25,1735650872559,1735650872559,1,0,0,72083388018589696,204,0,25

2024-12-31 21:14:32.561 Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:59659, czxid (broker epoch): 25
2024-12-31 21:14:32.570 [ControllerEventThread controllerId=0] Starting
2024-12-31 21:14:32.572 [ExpirationReaper-0-topic]: Starting
2024-12-31 21:14:32.572 [ExpirationReaper-0-Heartbeat]: Starting
2024-12-31 21:14:32.573 [ExpirationReaper-0-Rebalance]: Starting
2024-12-31 21:14:32.573 [GroupCoordinator 0]: Starting up.
2024-12-31 21:14:32.575 [GroupCoordinator 0]: Startup complete.
2024-12-31 21:14:32.576 Successfully created /controller_epoch with initial epoch 0
2024-12-31 21:14:32.578 [TransactionCoordinator id=0] Starting up.
2024-12-31 21:14:32.579 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:32.579 [Controller id=0] 0 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1
2024-12-31 21:14:32.579 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:32.580 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:32.580 [TransactionCoordinator id=0] Startup complete.
2024-12-31 21:14:32.580 [Transaction Marker Channel Manager 0]: Starting
2024-12-31 21:14:32.580 [Controller id=0] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map())
2024-12-31 21:14:32.581 [ExpirationReaper-0-AlterAcls]: Starting
2024-12-31 21:14:32.582 Feature ZK node created at path: /feature
2024-12-31 21:14:32.584 [Controller id=0] Registering handlers
2024-12-31 21:14:32.584 [MetadataCache brokerId=0] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0).
2024-12-31 21:14:32.587 [/config/changes-event-process-thread]: Starting
2024-12-31 21:14:32.587 [Controller id=0] Deleting log dir event notifications
2024-12-31 21:14:32.588 [Controller id=0] Deleting isr change notifications
2024-12-31 21:14:32.589 [Controller id=0] Initializing controller context
2024-12-31 21:14:32.592 [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing.
2024-12-31 21:14:32.592 [Controller id=0] Initialized broker epochs cache: HashMap(0 -> 25)
2024-12-31 21:14:32.593 Kafka version: 3.4.1
2024-12-31 21:14:32.593 Kafka commitId: 8a516edc2755df89
2024-12-31 21:14:32.593 Kafka startTimeMs: 1735650872593
2024-12-31 21:14:32.599 [Controller id=0] Currently active brokers in the cluster: Set(0)
2024-12-31 21:14:32.599 [RequestSendThread controllerId=0] Starting
2024-12-31 21:14:32.599 [Controller id=0] Currently shutting brokers in the cluster: HashSet()
2024-12-31 21:14:32.599 [Controller id=0] Current list of topics in the cluster: HashSet()
2024-12-31 21:14:32.599 [Controller id=0] Fetching topic deletions in progress
2024-12-31 21:14:32.593 Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.server:type=app-info,id=0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1865)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:960)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:895)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:523)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:563)
	at kafka.utils.TestUtils$.createServer(TestUtils.scala:188)
	at kafka.utils.TestUtils$.createServer(TestUtils.scala:182)
	at kafka.utils.TestUtils.createServer(TestUtils.scala)
	at org.springframework.kafka.test.EmbeddedKafkaBroker.afterPropertiesSet(EmbeddedKafkaBroker.java:369)
	at org.codehaus.groovy.vmplugin.v8.IndyInterface.fromCache(IndyInterface.java:321)
	at com.demo.KafkaTestSupportSpec.setup(KafkaTestSupportSpec.groovy:13)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.spockframework.util.ReflectionUtil.invokeMethod(ReflectionUtil.java:196)
	at org.spockframework.runtime.model.MethodInfo.lambda$new$0(MethodInfo.java:49)
	at org.spockframework.runtime.model.MethodInfo.invoke(MethodInfo.java:156)
	at org.spockframework.runtime.PlatformSpecRunner.invokeRaw(PlatformSpecRunner.java:407)
	at org.spockframework.runtime.PlatformSpecRunner.invoke(PlatformSpecRunner.java:390)
	at org.spockframework.runtime.PlatformSpecRunner.doRunSetup(PlatformSpecRunner.java:313)
	at org.spockframework.runtime.PlatformSpecRunner.lambda$createMethodInfoForDoRunSetup$7(PlatformSpecRunner.java:295)
	at org.spockframework.runtime.model.MethodInfo.invoke(MethodInfo.java:156)
	at org.spockframework.runtime.PlatformSpecRunner.invokeRaw(PlatformSpecRunner.java:407)
	at org.spockframework.runtime.PlatformSpecRunner.invoke(PlatformSpecRunner.java:390)
	at org.spockframework.runtime.PlatformSpecRunner.runSetup(PlatformSpecRunner.java:289)
	at org.spockframework.runtime.PlatformSpecRunner.doRunSetup(PlatformSpecRunner.java:309)
	at org.spockframework.runtime.PlatformSpecRunner.lambda$createMethodInfoForDoRunSetup$7(PlatformSpecRunner.java:295)
	at org.spockframework.runtime.model.MethodInfo.invoke(MethodInfo.java:156)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:102)
	at org.spockframework.spring.SpringInterceptor.interceptSetupMethod(SpringInterceptor.java:55)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:30)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:101)
	at org.spockframework.runtime.PlatformSpecRunner.invoke(PlatformSpecRunner.java:398)
	at org.spockframework.runtime.PlatformSpecRunner.runSetup(PlatformSpecRunner.java:289)
	at org.spockframework.runtime.PlatformSpecRunner.runSetup(PlatformSpecRunner.java:284)
	at org.spockframework.runtime.IterationNode.before(IterationNode.java:40)
	at org.spockframework.runtime.IterationNode.before(IterationNode.java:13)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:148)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.spockframework.runtime.SpockNode.sneakyInvoke(SpockNode.java:40)
	at org.spockframework.runtime.IterationNode.lambda$around$0(IterationNode.java:67)
	at org.spockframework.runtime.PlatformSpecRunner.lambda$createMethodInfoForDoRunIteration$5(PlatformSpecRunner.java:236)
	at org.spockframework.runtime.model.MethodInfo.invoke(MethodInfo.java:156)
	at org.spockframework.runtime.PlatformSpecRunner.invokeRaw(PlatformSpecRunner.java:407)
	at org.spockframework.runtime.PlatformSpecRunner.invoke(PlatformSpecRunner.java:390)
	at org.spockframework.runtime.PlatformSpecRunner.runIteration(PlatformSpecRunner.java:218)
	at org.spockframework.runtime.IterationNode.around(IterationNode.java:67)
	at org.spockframework.runtime.IterationNode.around(IterationNode.java:13)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:226)
	at org.spockframework.runtime.ParameterizedFeatureChildExecutor.execute(ParameterizedFeatureChildExecutor.java:104)
	at org.spockframework.runtime.PlatformParameterizedSpecRunner$1.runIteration(PlatformParameterizedSpecRunner.java:72)
	at org.spockframework.runtime.extension.IDataDriver.lambda$static$0(IDataDriver.java:37)
	at org.spockframework.runtime.PlatformParameterizedSpecRunner.runParameterizedFeature(PlatformParameterizedSpecRunner.java:47)
	at org.spockframework.runtime.ParameterizedFeatureNode.execute(ParameterizedFeatureNode.java:40)
	at org.spockframework.runtime.ParameterizedFeatureNode.execute(ParameterizedFeatureNode.java:16)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.spockframework.runtime.SpockNode.sneakyInvoke(SpockNode.java:40)
	at org.spockframework.runtime.FeatureNode.lambda$around$0(FeatureNode.java:41)
	at org.spockframework.runtime.PlatformSpecRunner.lambda$createMethodInfoForDoRunFeature$4(PlatformSpecRunner.java:199)
	at org.spockframework.runtime.model.MethodInfo.invoke(MethodInfo.java:156)
	at org.spockframework.runtime.PlatformSpecRunner.invokeRaw(PlatformSpecRunner.java:407)
	at org.spockframework.runtime.PlatformSpecRunner.invoke(PlatformSpecRunner.java:390)
	at org.spockframework.runtime.PlatformSpecRunner.runFeature(PlatformSpecRunner.java:192)
	at org.spockframework.runtime.FeatureNode.around(FeatureNode.java:41)
	at org.spockframework.runtime.FeatureNode.around(FeatureNode.java:12)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1511)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.spockframework.runtime.SpockNode.sneakyInvoke(SpockNode.java:40)
	at org.spockframework.runtime.SpecNode.lambda$around$0(SpecNode.java:63)
	at org.spockframework.runtime.PlatformSpecRunner.lambda$createMethodInfoForDoRunSpec$0(PlatformSpecRunner.java:61)
	at org.spockframework.runtime.model.MethodInfo.invoke(MethodInfo.java:156)
	at org.spockframework.runtime.PlatformSpecRunner.invokeRaw(PlatformSpecRunner.java:407)
	at org.spockframework.runtime.PlatformSpecRunner.invoke(PlatformSpecRunner.java:390)
	at org.spockframework.runtime.PlatformSpecRunner.runSpec(PlatformSpecRunner.java:55)
	at org.spockframework.runtime.SpecNode.around(SpecNode.java:63)
	at org.spockframework.runtime.SpecNode.around(SpecNode.java:11)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1511)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:147)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:127)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:90)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:55)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:102)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:150)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2024-12-31 21:14:32.600 [KafkaServer id=0] started
2024-12-31 21:14:32.601 AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [127.0.0.1:59659]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-31 21:14:32.601 [Controller id=0] List of topics to be deleted: 
2024-12-31 21:14:32.601 [Controller id=0] List of topics ineligible for deletion: 
2024-12-31 21:14:32.602 [Controller id=0] Initializing topic deletion manager
2024-12-31 21:14:32.602 [Topic Deletion Manager 0] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet()
2024-12-31 21:14:32.602 [Controller id=0] Sending update metadata request
2024-12-31 21:14:32.602 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions
2024-12-31 21:14:32.603 [ReplicaStateMachine controllerId=0] Initializing replica state
2024-12-31 21:14:32.603 [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2024-12-31 21:14:32.603 [ReplicaStateMachine controllerId=0] Triggering offline replica state changes
2024-12-31 21:14:32.603 [PartitionStateMachine controllerId=0] Initializing partition state
2024-12-31 21:14:32.603 [PartitionStateMachine controllerId=0] Triggering online partition state changes
2024-12-31 21:14:32.603 [Controller id=0] Ready to serve as the new controller with epoch 1
2024-12-31 21:14:32.604 [RequestSendThread controllerId=0] Controller 0 connected to localhost:59659 (id: 0 rack: null) for sending state change requests
2024-12-31 21:14:32.605 Kafka version: 3.4.1
2024-12-31 21:14:32.605 Kafka commitId: 8a516edc2755df89
2024-12-31 21:14:32.605 Kafka startTimeMs: 1735650872605
2024-12-31 21:14:32.606 [Controller id=0] Partitions undergoing preferred replica election: 
2024-12-31 21:14:32.606 [Controller id=0] Partitions that completed preferred replica election: 
2024-12-31 21:14:32.606 [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2024-12-31 21:14:32.607 [Controller id=0] Resuming preferred replica election for partitions: 
2024-12-31 21:14:32.607 [Controller id=0] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered
2024-12-31 21:14:32.609 [Controller id=0] Starting the controller scheduler
2024-12-31 21:14:32.610 [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use node localhost:59659 (id: 0 rack: null)
2024-12-31 21:14:32.621 Creating topic pong-message-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0))
2024-12-31 21:14:32.630 [Controller id=0] New topics: [Set(pong-message-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(pong-message-topic,Some(vKE8-J4xSwOppvaarvMdlg),Map(pong-message-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), pong-message-topic-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:14:32.631 [Controller id=0] New partition creation callback for pong-message-topic-0,pong-message-topic-1
2024-12-31 21:14:32.631 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:14:32.631 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:14:32.631 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:14:32.632 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:14:32.640 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:14:32.640 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:14:32.640 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2024-12-31 21:14:32.641 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2024-12-31 21:14:32.641 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:14:32.641 [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 for 2 partitions
2024-12-31 21:14:32.643 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(pong-message-topic-0, pong-message-topic-1)
2024-12-31 21:14:32.643 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2024-12-31 21:14:32.654 [LogLoader partition=pong-message-topic-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.a2a099ad-817b-4660-8e0b-8040ea33453313960523455105741971] Loading producer state till offset 0 with message format version 2
2024-12-31 21:14:32.654 Created log for partition pong-message-topic-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.a2a099ad-817b-4660-8e0b-8040ea33453313960523455105741971\pong-message-topic-0 with properties {}
2024-12-31 21:14:32.655 [Partition pong-message-topic-0 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-0
2024-12-31 21:14:32.655 [Partition pong-message-topic-0 broker=0] Log loaded for partition pong-message-topic-0 with initial high watermark 0
2024-12-31 21:14:32.655 [Broker id=0] Leader pong-message-topic-0 with topic id Some(vKE8-J4xSwOppvaarvMdlg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:14:32.657 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Recorded new controller, from now on will use node localhost:59659 (id: 0 rack: null)
2024-12-31 21:14:32.665 [LogLoader partition=pong-message-topic-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.a2a099ad-817b-4660-8e0b-8040ea33453313960523455105741971] Loading producer state till offset 0 with message format version 2
2024-12-31 21:14:32.665 Created log for partition pong-message-topic-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.a2a099ad-817b-4660-8e0b-8040ea33453313960523455105741971\pong-message-topic-1 with properties {}
2024-12-31 21:14:32.665 [Partition pong-message-topic-1 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-1
2024-12-31 21:14:32.666 [Partition pong-message-topic-1 broker=0] Log loaded for partition pong-message-topic-1 with initial high watermark 0
2024-12-31 21:14:32.666 [Broker id=0] Leader pong-message-topic-1 with topic id Some(vKE8-J4xSwOppvaarvMdlg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:14:32.669 [Broker id=0] Finished LeaderAndIsr request in 28ms correlationId 1 from controller 0 for 2 partitions
2024-12-31 21:14:32.672 [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2
2024-12-31 21:14:32.673 App info kafka.admin.client for adminclient-2 unregistered
2024-12-31 21:14:32.674 Metrics scheduler closed
2024-12-31 21:14:32.674 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:14:32.674 Metrics reporters closed
2024-12-31 21:14:33.342 Received ping message: Hello
2024-12-31 21:14:33.355 Idempotence will be disabled because acks is set to 0, not set to 'all'.
2024-12-31 21:14:33.356 ProducerConfig values: 
	acks = 0
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2024-12-31 21:14:33.388 Kafka version: 3.4.1
2024-12-31 21:14:33.388 Kafka commitId: 8a516edc2755df89
2024-12-31 21:14:33.388 Kafka startTimeMs: 1735650873388
2024-12-31 21:14:33.391 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:14:33.391 [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:33.391 [Producer clientId=producer-1] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:33.458 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:14:33.459 [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:33.459 [Producer clientId=producer-1] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:33.504 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:33.504 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:33.505 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:33.567 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:14:33.567 [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:33.568 [Producer clientId=producer-1] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:33.802 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:14:33.802 [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:33.802 [Producer clientId=producer-1] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:34.227 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:14:34.227 [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:34.227 [Producer clientId=producer-1] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:34.677 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:34.677 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:34.677 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:35.082 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:14:35.082 [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:35.082 [Producer clientId=producer-1] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:35.598 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:35.599 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:35.599 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:36.134 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:14:36.134 [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:36.134 [Producer clientId=producer-1] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:36.522 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:36.522 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:36.522 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:37.244 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:14:37.244 [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:37.244 [Producer clientId=producer-1] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:37.524 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:37.524 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:37.524 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:37.617 [Controller id=0] Processing automatic preferred replica leader election
2024-12-31 21:14:38.082 [KafkaServer id=0] shutting down
2024-12-31 21:14:38.082 [KafkaServer id=0] Starting controlled shutdown
2024-12-31 21:14:38.095 [Controller id=0] Shutting down broker 0
2024-12-31 21:14:38.098 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:14:38.105 [KafkaServer id=0] Controlled shutdown request returned successfully after 15ms
2024-12-31 21:14:38.107 [/config/changes-event-process-thread]: Shutting down
2024-12-31 21:14:38.108 [/config/changes-event-process-thread]: Shutdown completed
2024-12-31 21:14:38.108 [/config/changes-event-process-thread]: Stopped
2024-12-31 21:14:38.108 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
2024-12-31 21:14:38.114 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors
2024-12-31 21:14:38.115 [data-plane Kafka Request Handler on Broker 0], shutting down
2024-12-31 21:14:38.117 [data-plane Kafka Request Handler on Broker 0], shut down completely
2024-12-31 21:14:38.119 [ExpirationReaper-0-AlterAcls]: Shutting down
2024-12-31 21:14:38.125 [ExpirationReaper-0-AlterAcls]: Stopped
2024-12-31 21:14:38.125 [ExpirationReaper-0-AlterAcls]: Shutdown completed
2024-12-31 21:14:38.125 [KafkaApi-0] Shutdown complete.
2024-12-31 21:14:38.126 [ExpirationReaper-0-topic]: Shutting down
2024-12-31 21:14:38.127 [ExpirationReaper-0-topic]: Stopped
2024-12-31 21:14:38.127 [ExpirationReaper-0-topic]: Shutdown completed
2024-12-31 21:14:38.128 [TransactionCoordinator id=0] Shutting down.
2024-12-31 21:14:38.129 [Transaction State Manager 0]: Shutdown complete
2024-12-31 21:14:38.129 [Transaction Marker Channel Manager 0]: Shutting down
2024-12-31 21:14:38.129 [Transaction Marker Channel Manager 0]: Shutdown completed
2024-12-31 21:14:38.129 [Transaction Marker Channel Manager 0]: Stopped
2024-12-31 21:14:38.130 [TransactionCoordinator id=0] Shutdown complete.
2024-12-31 21:14:38.130 [GroupCoordinator 0]: Shutting down.
2024-12-31 21:14:38.130 [ExpirationReaper-0-Heartbeat]: Shutting down
2024-12-31 21:14:38.132 [ExpirationReaper-0-Heartbeat]: Shutdown completed
2024-12-31 21:14:38.132 [ExpirationReaper-0-Heartbeat]: Stopped
2024-12-31 21:14:38.132 [ExpirationReaper-0-Rebalance]: Shutting down
2024-12-31 21:14:38.132 [ExpirationReaper-0-Rebalance]: Stopped
2024-12-31 21:14:38.132 [ExpirationReaper-0-Rebalance]: Shutdown completed
2024-12-31 21:14:38.133 [GroupCoordinator 0]: Shutdown complete.
2024-12-31 21:14:38.134 [ReplicaManager broker=0] Shutting down
2024-12-31 21:14:38.134 [LogDirFailureHandler]: Shutting down
2024-12-31 21:14:38.134 [LogDirFailureHandler]: Shutdown completed
2024-12-31 21:14:38.134 [LogDirFailureHandler]: Stopped
2024-12-31 21:14:38.135 [ReplicaFetcherManager on broker 0] shutting down
2024-12-31 21:14:38.136 [ReplicaFetcherManager on broker 0] shutdown completed
2024-12-31 21:14:38.137 [ReplicaAlterLogDirsManager on broker 0] shutting down
2024-12-31 21:14:38.137 [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2024-12-31 21:14:38.137 [ExpirationReaper-0-Fetch]: Shutting down
2024-12-31 21:14:38.137 [ExpirationReaper-0-Fetch]: Stopped
2024-12-31 21:14:38.137 [ExpirationReaper-0-Fetch]: Shutdown completed
2024-12-31 21:14:38.138 [ExpirationReaper-0-Produce]: Shutting down
2024-12-31 21:14:38.138 [ExpirationReaper-0-Produce]: Stopped
2024-12-31 21:14:38.138 [ExpirationReaper-0-Produce]: Shutdown completed
2024-12-31 21:14:38.138 [ExpirationReaper-0-DeleteRecords]: Shutting down
2024-12-31 21:14:38.138 [ExpirationReaper-0-DeleteRecords]: Stopped
2024-12-31 21:14:38.138 [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2024-12-31 21:14:38.139 [ExpirationReaper-0-ElectLeader]: Shutting down
2024-12-31 21:14:38.139 [ExpirationReaper-0-ElectLeader]: Stopped
2024-12-31 21:14:38.139 [ExpirationReaper-0-ElectLeader]: Shutdown completed
2024-12-31 21:14:38.149 [ReplicaManager broker=0] Shut down completely
2024-12-31 21:14:38.150 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutting down
2024-12-31 21:14:38.150 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Stopped
2024-12-31 21:14:38.150 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutdown completed
2024-12-31 21:14:38.153 Broker to controller channel manager for alterPartition shutdown
2024-12-31 21:14:38.154 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down
2024-12-31 21:14:38.154 [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped
2024-12-31 21:14:38.154 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed
2024-12-31 21:14:38.154 Broker to controller channel manager for forwarding shutdown
2024-12-31 21:14:38.155 Shutting down.
2024-12-31 21:14:38.156 Shutting down the log cleaner.
2024-12-31 21:14:38.156 [kafka-log-cleaner-thread-0]: Shutting down
2024-12-31 21:14:38.157 [kafka-log-cleaner-thread-0]: Stopped
2024-12-31 21:14:38.157 [kafka-log-cleaner-thread-0]: Shutdown completed
2024-12-31 21:14:38.161 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:14:38.161 [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:38.161 [Producer clientId=producer-1] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:38.196 Shutdown complete.
2024-12-31 21:14:38.196 [ControllerEventThread controllerId=0] Shutting down
2024-12-31 21:14:38.197 [ControllerEventThread controllerId=0] Stopped
2024-12-31 21:14:38.197 [ControllerEventThread controllerId=0] Shutdown completed
2024-12-31 21:14:38.199 [PartitionStateMachine controllerId=0] Stopped partition state machine
2024-12-31 21:14:38.200 [ReplicaStateMachine controllerId=0] Stopped replica state machine
2024-12-31 21:14:38.201 [RequestSendThread controllerId=0] Shutting down
2024-12-31 21:14:38.201 [RequestSendThread controllerId=0] Shutdown completed
2024-12-31 21:14:38.201 [RequestSendThread controllerId=0] Stopped
2024-12-31 21:14:38.203 [Controller id=0] Resigned
2024-12-31 21:14:38.203 [feature-zk-node-event-process-thread]: Shutting down
2024-12-31 21:14:38.204 [feature-zk-node-event-process-thread]: Stopped
2024-12-31 21:14:38.204 [feature-zk-node-event-process-thread]: Shutdown completed
2024-12-31 21:14:38.204 [ZooKeeperClient Kafka server] Closing.
2024-12-31 21:14:38.319 EventThread shut down for session: 0x1001775a10e0000
2024-12-31 21:14:38.319 Session: 0x1001775a10e0000 closed
2024-12-31 21:14:38.320 [ZooKeeperClient Kafka server] Closed.
2024-12-31 21:14:38.320 [ThrottledChannelReaper-Fetch]: Shutting down
2024-12-31 21:14:38.324 [ThrottledChannelReaper-Fetch]: Shutdown completed
2024-12-31 21:14:38.324 [ThrottledChannelReaper-Fetch]: Stopped
2024-12-31 21:14:38.324 [ThrottledChannelReaper-Produce]: Shutting down
2024-12-31 21:14:38.324 [ThrottledChannelReaper-Produce]: Stopped
2024-12-31 21:14:38.324 [ThrottledChannelReaper-Produce]: Shutdown completed
2024-12-31 21:14:38.324 [ThrottledChannelReaper-Request]: Shutting down
2024-12-31 21:14:38.324 [ThrottledChannelReaper-Request]: Stopped
2024-12-31 21:14:38.324 [ThrottledChannelReaper-Request]: Shutdown completed
2024-12-31 21:14:38.324 [ThrottledChannelReaper-ControllerMutation]: Shutting down
2024-12-31 21:14:38.324 [ThrottledChannelReaper-ControllerMutation]: Stopped
2024-12-31 21:14:38.324 [ThrottledChannelReaper-ControllerMutation]: Shutdown completed
2024-12-31 21:14:38.327 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server
2024-12-31 21:14:38.343 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed
2024-12-31 21:14:38.345 Metrics scheduler closed
2024-12-31 21:14:38.345 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:14:38.345 Metrics reporters closed
2024-12-31 21:14:38.347 Broker and topic stats closed
2024-12-31 21:14:38.348 App info kafka.server for 0 unregistered
2024-12-31 21:14:38.348 [KafkaServer id=0] shut down completed
2024-12-31 21:14:38.358 ConnnectionExpirerThread interrupted
2024-12-31 21:14:38.358 accept thread exitted run method
2024-12-31 21:14:38.359 selector thread exitted run method
2024-12-31 21:14:38.359 selector thread exitted run method
2024-12-31 21:14:38.359 shutting down
2024-12-31 21:14:38.359 Shutting down
2024-12-31 21:14:38.359 Draining request throttler queue
2024-12-31 21:14:38.359 RequestThrottler shutdown. Dropped 0 requests
2024-12-31 21:14:38.359 Shutting down
2024-12-31 21:14:38.359 Shutting down
2024-12-31 21:14:38.359 Shutting down
2024-12-31 21:14:38.359 PrepRequestProcessor exited loop!
2024-12-31 21:14:38.359 SyncRequestProcessor exited!
2024-12-31 21:14:38.361 shutdown of request processor complete
2024-12-31 21:14:38.426 zookeeper.snapshot.trust.empty : false
2024-12-31 21:14:38.427 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:14:38.428 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:14:38.428 zookeeper.snapshotSizeFactor = 0.33
2024-12-31 21:14:38.428 zookeeper.commitLogCount=500
2024-12-31 21:14:38.428 minSessionTimeout set to 1600
2024-12-31 21:14:38.428 maxSessionTimeout set to 16000
2024-12-31 21:14:38.428 Response cache size is initialized with value 400.
2024-12-31 21:14:38.428 Response cache size is initialized with value 400.
2024-12-31 21:14:38.428 zookeeper.pathStats.slotCapacity = 60
2024-12-31 21:14:38.428 zookeeper.pathStats.slotDuration = 15
2024-12-31 21:14:38.428 zookeeper.pathStats.maxDepth = 6
2024-12-31 21:14:38.428 zookeeper.pathStats.initialDelay = 5
2024-12-31 21:14:38.428 zookeeper.pathStats.delay = 5
2024-12-31 21:14:38.428 zookeeper.pathStats.enabled = false
2024-12-31 21:14:38.428 The max bytes for all large requests are set to 104857600
2024-12-31 21:14:38.428 The large request threshold is set to -1
2024-12-31 21:14:38.429 Created server with tickTime 800 minSessionTimeout 1600 maxSessionTimeout 16000 clientPortListenBacklog -1 datadir C:\Users\joech\AppData\Local\Temp\kafka-5269833494560034552\version-2 snapdir C:\Users\joech\AppData\Local\Temp\kafka-13880579336730890099\version-2
2024-12-31 21:14:38.429 maxCnxns is not configured, using default value 0.
2024-12-31 21:14:38.429 Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers.
2024-12-31 21:14:38.433 binding to port /127.0.0.1:0
2024-12-31 21:14:38.436 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-13880579336730890099\version-2\snapshot.0
2024-12-31 21:14:38.437 Snapshot loaded in 2 ms, highest zxid is 0x0, digest is 1371985504
2024-12-31 21:14:38.437 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-13880579336730890099\version-2\snapshot.0
2024-12-31 21:14:38.438 Snapshot taken in 0 ms
2024-12-31 21:14:38.439 PrepRequestProcessor (sid:0) started, reconfigEnabled=false
2024-12-31 21:14:38.441 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.222493cd-80b9-4417-813b-5dc651a810c23538019782717139501
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59681
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:14:38.446 starting
2024-12-31 21:14:38.446 Connecting to zookeeper on 127.0.0.1:59681
2024-12-31 21:14:38.446 [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:59681.
2024-12-31 21:14:38.446 Initiating client connection, connectString=127.0.0.1:59681 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@368a416f
2024-12-31 21:14:38.449 jute.maxbuffer value is 4194304 Bytes
2024-12-31 21:14:38.449 zookeeper.request.timeout value is 0. feature enabled=false
2024-12-31 21:14:38.450 [ZooKeeperClient Kafka server] Waiting until connected.
2024-12-31 21:14:38.450 Opening socket connection to server /127.0.0.1:59681.
2024-12-31 21:14:38.451 Socket connection established, initiating session, client: /127.0.0.1:59682, server: /127.0.0.1:59681
2024-12-31 21:14:38.451 Creating new log file: log.1
2024-12-31 21:14:38.460 Session establishment complete on server /127.0.0.1:59681, session id = 0x1001775b8a60000, negotiated timeout = 16000
2024-12-31 21:14:38.460 [ZooKeeperClient Kafka server] Connected.
2024-12-31 21:14:38.496 Cluster ID = B_t8wiqdT_OeyTcJxplWEA
2024-12-31 21:14:38.497 No meta.properties file under dir C:\Users\joech\AppData\Local\Temp\spring.kafka.222493cd-80b9-4417-813b-5dc651a810c23538019782717139501\meta.properties
2024-12-31 21:14:38.506 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:38.506 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:38.506 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:38.507 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.222493cd-80b9-4417-813b-5dc651a810c23538019782717139501
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59681
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:14:38.515 [ThrottledChannelReaper-Produce]: Starting
2024-12-31 21:14:38.515 [ThrottledChannelReaper-Fetch]: Starting
2024-12-31 21:14:38.515 [ThrottledChannelReaper-Request]: Starting
2024-12-31 21:14:38.515 [ThrottledChannelReaper-ControllerMutation]: Starting
2024-12-31 21:14:38.526 Loading logs from log dirs ArraySeq(C:\Users\joech\AppData\Local\Temp\spring.kafka.222493cd-80b9-4417-813b-5dc651a810c23538019782717139501)
2024-12-31 21:14:38.526 Attempting recovery for all logs in C:\Users\joech\AppData\Local\Temp\spring.kafka.222493cd-80b9-4417-813b-5dc651a810c23538019782717139501 since no clean shutdown file was found
2024-12-31 21:14:38.528 Loaded 0 logs in 2ms.
2024-12-31 21:14:38.528 Starting log cleanup with a period of 300000 ms.
2024-12-31 21:14:38.529 Starting log flusher with a default period of 9223372036854775807 ms.
2024-12-31 21:14:38.531 Starting the log cleaner
2024-12-31 21:14:38.531 [kafka-log-cleaner-thread-0]: Starting
2024-12-31 21:14:38.532 [feature-zk-node-event-process-thread]: Starting
2024-12-31 21:14:38.534 Feature ZK node at path: /feature does not exist
2024-12-31 21:14:38.537 [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting
2024-12-31 21:14:38.560 Updated connection-accept-rate max connection creation rate to 2147483647
2024-12-31 21:14:38.562 Awaiting socket connections on localhost:59684.
2024-12-31 21:14:38.571 [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT)
2024-12-31 21:14:38.574 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Starting
2024-12-31 21:14:38.575 [ExpirationReaper-0-Produce]: Starting
2024-12-31 21:14:38.575 [ExpirationReaper-0-Fetch]: Starting
2024-12-31 21:14:38.575 [ExpirationReaper-0-DeleteRecords]: Starting
2024-12-31 21:14:38.576 [ExpirationReaper-0-ElectLeader]: Starting
2024-12-31 21:14:38.578 [LogDirFailureHandler]: Starting
2024-12-31 21:14:38.581 Creating /brokers/ids/0 (is it secure? false)
2024-12-31 21:14:38.584 Stat of the created znode at /brokers/ids/0 is: 25,25,1735650878582,1735650878582,1,0,0,72083388414427136,204,0,25

2024-12-31 21:14:38.585 Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:59684, czxid (broker epoch): 25
2024-12-31 21:14:38.596 [ControllerEventThread controllerId=0] Starting
2024-12-31 21:14:38.597 [ExpirationReaper-0-topic]: Starting
2024-12-31 21:14:38.597 [ExpirationReaper-0-Heartbeat]: Starting
2024-12-31 21:14:38.598 [ExpirationReaper-0-Rebalance]: Starting
2024-12-31 21:14:38.598 [GroupCoordinator 0]: Starting up.
2024-12-31 21:14:38.601 [GroupCoordinator 0]: Startup complete.
2024-12-31 21:14:38.604 Successfully created /controller_epoch with initial epoch 0
2024-12-31 21:14:38.605 [TransactionCoordinator id=0] Starting up.
2024-12-31 21:14:38.607 [Controller id=0] 0 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1
2024-12-31 21:14:38.607 [TransactionCoordinator id=0] Startup complete.
2024-12-31 21:14:38.607 [Transaction Marker Channel Manager 0]: Starting
2024-12-31 21:14:38.608 [Controller id=0] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map())
2024-12-31 21:14:38.609 [ExpirationReaper-0-AlterAcls]: Starting
2024-12-31 21:14:38.611 Feature ZK node created at path: /feature
2024-12-31 21:14:38.612 [Controller id=0] Registering handlers
2024-12-31 21:14:38.612 [MetadataCache brokerId=0] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0).
2024-12-31 21:14:38.614 [/config/changes-event-process-thread]: Starting
2024-12-31 21:14:38.614 [Controller id=0] Deleting log dir event notifications
2024-12-31 21:14:38.615 [Controller id=0] Deleting isr change notifications
2024-12-31 21:14:38.616 [Controller id=0] Initializing controller context
2024-12-31 21:14:38.619 [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing.
2024-12-31 21:14:38.619 [Controller id=0] Initialized broker epochs cache: HashMap(0 -> 25)
2024-12-31 21:14:38.619 Kafka version: 3.4.1
2024-12-31 21:14:38.620 Kafka commitId: 8a516edc2755df89
2024-12-31 21:14:38.620 Kafka startTimeMs: 1735650878619
2024-12-31 21:14:38.620 [KafkaServer id=0] started
2024-12-31 21:14:38.621 AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [127.0.0.1:59684]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-31 21:14:38.625 Kafka version: 3.4.1
2024-12-31 21:14:38.625 Kafka commitId: 8a516edc2755df89
2024-12-31 21:14:38.625 Kafka startTimeMs: 1735650878625
2024-12-31 21:14:38.625 [Controller id=0] Currently active brokers in the cluster: Set(0)
2024-12-31 21:14:38.625 [Controller id=0] Currently shutting brokers in the cluster: HashSet()
2024-12-31 21:14:38.625 [Controller id=0] Current list of topics in the cluster: HashSet()
2024-12-31 21:14:38.625 [Controller id=0] Fetching topic deletions in progress
2024-12-31 21:14:38.625 [RequestSendThread controllerId=0] Starting
2024-12-31 21:14:38.627 [Controller id=0] List of topics to be deleted: 
2024-12-31 21:14:38.627 [Controller id=0] List of topics ineligible for deletion: 
2024-12-31 21:14:38.627 [Controller id=0] Initializing topic deletion manager
2024-12-31 21:14:38.627 [Topic Deletion Manager 0] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet()
2024-12-31 21:14:38.627 [Controller id=0] Sending update metadata request
2024-12-31 21:14:38.627 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions
2024-12-31 21:14:38.627 [ReplicaStateMachine controllerId=0] Initializing replica state
2024-12-31 21:14:38.627 [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2024-12-31 21:14:38.628 [ReplicaStateMachine controllerId=0] Triggering offline replica state changes
2024-12-31 21:14:38.628 [PartitionStateMachine controllerId=0] Initializing partition state
2024-12-31 21:14:38.628 [PartitionStateMachine controllerId=0] Triggering online partition state changes
2024-12-31 21:14:38.628 [Controller id=0] Ready to serve as the new controller with epoch 1
2024-12-31 21:14:38.628 [RequestSendThread controllerId=0] Controller 0 connected to localhost:59684 (id: 0 rack: null) for sending state change requests
2024-12-31 21:14:38.632 [Controller id=0] Partitions undergoing preferred replica election: 
2024-12-31 21:14:38.632 [Controller id=0] Partitions that completed preferred replica election: 
2024-12-31 21:14:38.632 [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2024-12-31 21:14:38.632 [Controller id=0] Resuming preferred replica election for partitions: 
2024-12-31 21:14:38.632 [Controller id=0] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered
2024-12-31 21:14:38.635 [Controller id=0] Starting the controller scheduler
2024-12-31 21:14:38.646 [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use node localhost:59684 (id: 0 rack: null)
2024-12-31 21:14:38.677 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Recorded new controller, from now on will use node localhost:59684 (id: 0 rack: null)
2024-12-31 21:14:38.693 SessionTrackerImpl exited loop!
2024-12-31 21:14:38.752 Creating topic pong-message-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0))
2024-12-31 21:14:38.761 [Controller id=0] New topics: [Set(pong-message-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(pong-message-topic,Some(Zq9AiX0ZTT2m_desuaMiOQ),Map(pong-message-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), pong-message-topic-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:14:38.762 [Controller id=0] New partition creation callback for pong-message-topic-0,pong-message-topic-1
2024-12-31 21:14:38.762 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:14:38.762 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:14:38.762 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:14:38.763 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:14:38.771 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:14:38.771 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:14:38.771 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2024-12-31 21:14:38.772 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2024-12-31 21:14:38.772 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:14:38.773 [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 for 2 partitions
2024-12-31 21:14:38.773 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(pong-message-topic-0, pong-message-topic-1)
2024-12-31 21:14:38.774 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2024-12-31 21:14:38.788 [LogLoader partition=pong-message-topic-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.222493cd-80b9-4417-813b-5dc651a810c23538019782717139501] Loading producer state till offset 0 with message format version 2
2024-12-31 21:14:38.789 Created log for partition pong-message-topic-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.222493cd-80b9-4417-813b-5dc651a810c23538019782717139501\pong-message-topic-0 with properties {}
2024-12-31 21:14:38.790 [Partition pong-message-topic-0 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-0
2024-12-31 21:14:38.790 [Partition pong-message-topic-0 broker=0] Log loaded for partition pong-message-topic-0 with initial high watermark 0
2024-12-31 21:14:38.790 [Broker id=0] Leader pong-message-topic-0 with topic id Some(Zq9AiX0ZTT2m_desuaMiOQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:14:38.802 [LogLoader partition=pong-message-topic-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.222493cd-80b9-4417-813b-5dc651a810c23538019782717139501] Loading producer state till offset 0 with message format version 2
2024-12-31 21:14:38.803 Created log for partition pong-message-topic-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.222493cd-80b9-4417-813b-5dc651a810c23538019782717139501\pong-message-topic-1 with properties {}
2024-12-31 21:14:38.803 [Partition pong-message-topic-1 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-1
2024-12-31 21:14:38.803 [Partition pong-message-topic-1 broker=0] Log loaded for partition pong-message-topic-1 with initial high watermark 0
2024-12-31 21:14:38.803 [Broker id=0] Leader pong-message-topic-1 with topic id Some(Zq9AiX0ZTT2m_desuaMiOQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:14:38.807 [Broker id=0] Finished LeaderAndIsr request in 34ms correlationId 1 from controller 0 for 2 partitions
2024-12-31 21:14:38.810 [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2
2024-12-31 21:14:38.812 App info kafka.admin.client for adminclient-3 unregistered
2024-12-31 21:14:38.813 Metrics scheduler closed
2024-12-31 21:14:38.813 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:14:38.813 Metrics reporters closed
2024-12-31 21:14:39.022 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:14:39.022 [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:39.022 [Producer clientId=producer-1] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:39.428 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:39.428 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:39.428 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:39.882 Received ping message: Hello
2024-12-31 21:14:39.882 Received ping message: Hello
2024-12-31 21:14:39.884 Throttling request as too many requests in the same second
2024-12-31 21:14:40.009 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:14:40.010 [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:40.010 [Producer clientId=producer-1] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:40.545 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:40.545 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:40.545 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:40.939 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:14:40.940 [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:40.940 [Producer clientId=producer-1] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:41.480 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:41.482 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:41.482 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:41.878 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:14:41.878 [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:41.878 [Producer clientId=producer-1] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:42.415 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:42.423 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:42.423 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:42.764 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:14:42.765 [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:42.765 [Producer clientId=producer-1] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:43.290 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:43.290 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:43.290 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:43.638 [Controller id=0] Processing automatic preferred replica leader election
2024-12-31 21:14:43.704 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:14:43.704 [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:43.704 [Producer clientId=producer-1] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:44.294 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:44.294 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:44.294 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:44.960 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:14:44.962 [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:44.962 [Producer clientId=producer-1] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:45.308 [KafkaServer id=0] shutting down
2024-12-31 21:14:45.308 [KafkaServer id=0] Starting controlled shutdown
2024-12-31 21:14:45.324 [Controller id=0] Shutting down broker 0
2024-12-31 21:14:45.324 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:14:45.324 [KafkaServer id=0] Controlled shutdown request returned successfully after 0ms
2024-12-31 21:14:45.324 [/config/changes-event-process-thread]: Shutting down
2024-12-31 21:14:45.324 [/config/changes-event-process-thread]: Stopped
2024-12-31 21:14:45.324 [/config/changes-event-process-thread]: Shutdown completed
2024-12-31 21:14:45.324 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
2024-12-31 21:14:45.340 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors
2024-12-31 21:14:45.340 [data-plane Kafka Request Handler on Broker 0], shutting down
2024-12-31 21:14:45.340 [data-plane Kafka Request Handler on Broker 0], shut down completely
2024-12-31 21:14:45.340 [ExpirationReaper-0-AlterAcls]: Shutting down
2024-12-31 21:14:45.340 [ExpirationReaper-0-AlterAcls]: Shutdown completed
2024-12-31 21:14:45.340 [ExpirationReaper-0-AlterAcls]: Stopped
2024-12-31 21:14:45.340 [KafkaApi-0] Shutdown complete.
2024-12-31 21:14:45.340 [ExpirationReaper-0-topic]: Shutting down
2024-12-31 21:14:45.340 [ExpirationReaper-0-topic]: Stopped
2024-12-31 21:14:45.340 [ExpirationReaper-0-topic]: Shutdown completed
2024-12-31 21:14:45.340 [TransactionCoordinator id=0] Shutting down.
2024-12-31 21:14:45.356 [Transaction State Manager 0]: Shutdown complete
2024-12-31 21:14:45.356 [Transaction Marker Channel Manager 0]: Shutting down
2024-12-31 21:14:45.356 [Transaction Marker Channel Manager 0]: Stopped
2024-12-31 21:14:45.356 [Transaction Marker Channel Manager 0]: Shutdown completed
2024-12-31 21:14:45.356 [TransactionCoordinator id=0] Shutdown complete.
2024-12-31 21:14:45.356 [GroupCoordinator 0]: Shutting down.
2024-12-31 21:14:45.356 [ExpirationReaper-0-Heartbeat]: Shutting down
2024-12-31 21:14:45.356 [ExpirationReaper-0-Heartbeat]: Stopped
2024-12-31 21:14:45.356 [ExpirationReaper-0-Heartbeat]: Shutdown completed
2024-12-31 21:14:45.356 [ExpirationReaper-0-Rebalance]: Shutting down
2024-12-31 21:14:45.356 [ExpirationReaper-0-Rebalance]: Stopped
2024-12-31 21:14:45.356 [ExpirationReaper-0-Rebalance]: Shutdown completed
2024-12-31 21:14:45.356 [GroupCoordinator 0]: Shutdown complete.
2024-12-31 21:14:45.356 [ReplicaManager broker=0] Shutting down
2024-12-31 21:14:45.356 [LogDirFailureHandler]: Shutting down
2024-12-31 21:14:45.356 [LogDirFailureHandler]: Shutdown completed
2024-12-31 21:14:45.356 [LogDirFailureHandler]: Stopped
2024-12-31 21:14:45.372 [ReplicaFetcherManager on broker 0] shutting down
2024-12-31 21:14:45.372 [ReplicaFetcherManager on broker 0] shutdown completed
2024-12-31 21:14:45.372 [ReplicaAlterLogDirsManager on broker 0] shutting down
2024-12-31 21:14:45.372 [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2024-12-31 21:14:45.372 [ExpirationReaper-0-Fetch]: Shutting down
2024-12-31 21:14:45.372 [ExpirationReaper-0-Fetch]: Stopped
2024-12-31 21:14:45.372 [ExpirationReaper-0-Fetch]: Shutdown completed
2024-12-31 21:14:45.379 [ExpirationReaper-0-Produce]: Shutting down
2024-12-31 21:14:45.380 [ExpirationReaper-0-Produce]: Shutdown completed
2024-12-31 21:14:45.380 [ExpirationReaper-0-Produce]: Stopped
2024-12-31 21:14:45.380 [ExpirationReaper-0-DeleteRecords]: Shutting down
2024-12-31 21:14:45.380 [ExpirationReaper-0-DeleteRecords]: Stopped
2024-12-31 21:14:45.380 [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2024-12-31 21:14:45.380 [ExpirationReaper-0-ElectLeader]: Shutting down
2024-12-31 21:14:45.380 [ExpirationReaper-0-ElectLeader]: Stopped
2024-12-31 21:14:45.380 [ExpirationReaper-0-ElectLeader]: Shutdown completed
2024-12-31 21:14:45.395 [ReplicaManager broker=0] Shut down completely
2024-12-31 21:14:45.395 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutting down
2024-12-31 21:14:45.400 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Stopped
2024-12-31 21:14:45.400 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutdown completed
2024-12-31 21:14:45.403 Broker to controller channel manager for alterPartition shutdown
2024-12-31 21:14:45.403 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down
2024-12-31 21:14:45.403 [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped
2024-12-31 21:14:45.403 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed
2024-12-31 21:14:45.403 Broker to controller channel manager for forwarding shutdown
2024-12-31 21:14:45.403 Shutting down.
2024-12-31 21:14:45.403 Shutting down the log cleaner.
2024-12-31 21:14:45.403 [kafka-log-cleaner-thread-0]: Shutting down
2024-12-31 21:14:45.403 [kafka-log-cleaner-thread-0]: Stopped
2024-12-31 21:14:45.403 [kafka-log-cleaner-thread-0]: Shutdown completed
2024-12-31 21:14:45.421 Shutdown complete.
2024-12-31 21:14:45.421 [ControllerEventThread controllerId=0] Shutting down
2024-12-31 21:14:45.421 [ControllerEventThread controllerId=0] Shutdown completed
2024-12-31 21:14:45.421 [ControllerEventThread controllerId=0] Stopped
2024-12-31 21:14:45.421 [PartitionStateMachine controllerId=0] Stopped partition state machine
2024-12-31 21:14:45.421 [ReplicaStateMachine controllerId=0] Stopped replica state machine
2024-12-31 21:14:45.436 [RequestSendThread controllerId=0] Shutting down
2024-12-31 21:14:45.436 [RequestSendThread controllerId=0] Shutdown completed
2024-12-31 21:14:45.436 [RequestSendThread controllerId=0] Stopped
2024-12-31 21:14:45.436 [Controller id=0] Resigned
2024-12-31 21:14:45.436 [feature-zk-node-event-process-thread]: Shutting down
2024-12-31 21:14:45.436 [feature-zk-node-event-process-thread]: Stopped
2024-12-31 21:14:45.436 [feature-zk-node-event-process-thread]: Shutdown completed
2024-12-31 21:14:45.436 [ZooKeeperClient Kafka server] Closing.
2024-12-31 21:14:45.483 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:45.488 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:45.488 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:45.546 Session: 0x1001775b8a60000 closed
2024-12-31 21:14:45.546 EventThread shut down for session: 0x1001775b8a60000
2024-12-31 21:14:45.546 [ZooKeeperClient Kafka server] Closed.
2024-12-31 21:14:45.546 [ThrottledChannelReaper-Fetch]: Shutting down
2024-12-31 21:14:45.546 [ThrottledChannelReaper-Fetch]: Stopped
2024-12-31 21:14:45.546 [ThrottledChannelReaper-Fetch]: Shutdown completed
2024-12-31 21:14:45.546 [ThrottledChannelReaper-Produce]: Shutting down
2024-12-31 21:14:45.552 [ThrottledChannelReaper-Produce]: Shutdown completed
2024-12-31 21:14:45.552 [ThrottledChannelReaper-Produce]: Stopped
2024-12-31 21:14:45.552 [ThrottledChannelReaper-Request]: Shutting down
2024-12-31 21:14:45.552 [ThrottledChannelReaper-Request]: Stopped
2024-12-31 21:14:45.552 [ThrottledChannelReaper-Request]: Shutdown completed
2024-12-31 21:14:45.552 [ThrottledChannelReaper-ControllerMutation]: Shutting down
2024-12-31 21:14:45.552 [ThrottledChannelReaper-ControllerMutation]: Shutdown completed
2024-12-31 21:14:45.552 [ThrottledChannelReaper-ControllerMutation]: Stopped
2024-12-31 21:14:45.552 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server
2024-12-31 21:14:45.562 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed
2024-12-31 21:14:45.562 Metrics scheduler closed
2024-12-31 21:14:45.562 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:14:45.578 Metrics reporters closed
2024-12-31 21:14:45.580 Broker and topic stats closed
2024-12-31 21:14:45.580 App info kafka.server for 0 unregistered
2024-12-31 21:14:45.580 [KafkaServer id=0] shut down completed
2024-12-31 21:14:45.580 ConnnectionExpirerThread interrupted
2024-12-31 21:14:45.580 accept thread exitted run method
2024-12-31 21:14:45.580 selector thread exitted run method
2024-12-31 21:14:45.580 selector thread exitted run method
2024-12-31 21:14:45.593 shutting down
2024-12-31 21:14:45.594 Shutting down
2024-12-31 21:14:45.594 Draining request throttler queue
2024-12-31 21:14:45.594 RequestThrottler shutdown. Dropped 0 requests
2024-12-31 21:14:45.594 Shutting down
2024-12-31 21:14:45.594 Shutting down
2024-12-31 21:14:45.594 Shutting down
2024-12-31 21:14:45.594 PrepRequestProcessor exited loop!
2024-12-31 21:14:45.594 SyncRequestProcessor exited!
2024-12-31 21:14:45.594 shutdown of request processor complete
2024-12-31 21:14:45.645 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:14:45.647 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:14:45.647 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Unsubscribed all topics or patterns and assigned partitions
2024-12-31 21:14:45.647 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:14:45.650 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:14:45.651 Metrics scheduler closed
2024-12-31 21:14:45.651 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:14:45.654 Metrics reporters closed
2024-12-31 21:14:45.655 App info kafka.consumer for consumer-pong-service-1 unregistered
2024-12-31 21:14:45.657 pong-service: Consumer stopped
2024-12-31 21:14:45.895 SessionTrackerImpl exited loop!
2024-12-31 21:14:45.961 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:14:45.961 [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:45.961 [Producer clientId=producer-1] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:47.018 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:14:47.018 [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:47.018 [Producer clientId=producer-1] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:48.152 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:14:48.152 [Producer clientId=producer-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2024-12-31 21:14:48.152 [Producer clientId=producer-1] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2024-12-31 21:14:48.680 [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2024-12-31 21:14:48.680 Metrics scheduler closed
2024-12-31 21:14:48.685 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:14:48.685 Metrics reporters closed
2024-12-31 21:14:48.685 App info kafka.producer for producer-1 unregistered
2024-12-31 21:14:48.685 [7979e05e-2]  500 Server Error for HTTP POST "/pong"
org.apache.kafka.common.KafkaException: Producer closed while send in progress
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:999)
	Suppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException: 
Error has been observed at the following site(s):
	*__checkpoint ? HTTP POST "/pong" [ExceptionHandlingWebHandler]
Original Stack Trace:
		at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:999)
		at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:962)
		at org.springframework.kafka.core.DefaultKafkaProducerFactory$CloseSafeProducer.send(DefaultKafkaProducerFactory.java:1062)
		at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:783)
		at org.springframework.kafka.core.KafkaTemplate.observeSend(KafkaTemplate.java:754)
		at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:538)
		at com.demo.kafka.KafkaProducerService.sendMessage(KafkaProducerService.java:22)
		at com.demo.controller.PongController.handle(PongController.java:37)
		at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
		at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.base/java.lang.reflect.Method.invoke(Method.java:568)
		at org.springframework.web.reactive.result.method.InvocableHandlerMethod.lambda$invoke$0(InvocableHandlerMethod.java:145)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:132)
		at reactor.core.publisher.MonoZip$ZipCoordinator.signal(MonoZip.java:293)
		at reactor.core.publisher.MonoZip$ZipInner.onNext(MonoZip.java:474)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
		at reactor.core.publisher.FluxDefaultIfEmpty$DefaultIfEmptySubscriber.onNext(FluxDefaultIfEmpty.java:122)
		at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onNext(FluxSwitchIfEmpty.java:74)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onNext(FluxMapFuseable.java:129)
		at reactor.core.publisher.FluxContextWrite$ContextWriteSubscriber.onNext(FluxContextWrite.java:107)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)
		at reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onNext(FluxFilterFuseable.java:337)
		at reactor.core.publisher.Operators$BaseFluxToMonoOperator.completePossiblyEmpty(Operators.java:2071)
		at reactor.core.publisher.MonoCollect$CollectSubscriber.onComplete(MonoCollect.java:145)
		at reactor.core.publisher.FluxMap$MapSubscriber.onComplete(FluxMap.java:144)
		at reactor.core.publisher.FluxPeek$PeekSubscriber.onComplete(FluxPeek.java:260)
		at reactor.core.publisher.FluxMap$MapSubscriber.onComplete(FluxMap.java:144)
		at reactor.netty.channel.FluxReceive.onInboundComplete(FluxReceive.java:413)
		at reactor.netty.channel.ChannelOperations.onInboundComplete(ChannelOperations.java:431)
		at reactor.netty.http.server.HttpServerOperations.onInboundNext(HttpServerOperations.java:682)
		at reactor.netty.channel.ChannelOperationsHandler.channelRead(ChannelOperationsHandler.java:114)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
		at reactor.netty.http.server.HttpTrafficHandler.channelRead(HttpTrafficHandler.java:284)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
		at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:436)
		at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:346)
		at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:318)
		at io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:251)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
		at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
		at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
		at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
		at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
		at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
		at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
		at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		at java.base/java.lang.Thread.run(Thread.java:842)
Caused by: org.apache.kafka.common.KafkaException: Requested metadata update after close
	at org.apache.kafka.clients.producer.internals.ProducerMetadata.awaitUpdate(ProducerMetadata.java:126)
	at org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata(KafkaProducer.java:1147)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:996)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:962)
	at org.springframework.kafka.core.DefaultKafkaProducerFactory$CloseSafeProducer.send(DefaultKafkaProducerFactory.java:1062)
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:783)
	at org.springframework.kafka.core.KafkaTemplate.observeSend(KafkaTemplate.java:754)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:538)
	at com.demo.kafka.KafkaProducerService.sendMessage(KafkaProducerService.java:22)
	at com.demo.controller.PongController.handle(PongController.java:37)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.web.reactive.result.method.InvocableHandlerMethod.lambda$invoke$0(InvocableHandlerMethod.java:145)
	at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:132)
	at reactor.core.publisher.MonoZip$ZipCoordinator.signal(MonoZip.java:293)
	at reactor.core.publisher.MonoZip$ZipInner.onNext(MonoZip.java:474)
	at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
	at reactor.core.publisher.FluxDefaultIfEmpty$DefaultIfEmptySubscriber.onNext(FluxDefaultIfEmpty.java:122)
	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onNext(FluxSwitchIfEmpty.java:74)
	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
	at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onNext(FluxMapFuseable.java:129)
	at reactor.core.publisher.FluxContextWrite$ContextWriteSubscriber.onNext(FluxContextWrite.java:107)
	at reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)
	at reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onNext(FluxFilterFuseable.java:337)
	at reactor.core.publisher.Operators$BaseFluxToMonoOperator.completePossiblyEmpty(Operators.java:2071)
	at reactor.core.publisher.MonoCollect$CollectSubscriber.onComplete(MonoCollect.java:145)
	at reactor.core.publisher.FluxMap$MapSubscriber.onComplete(FluxMap.java:144)
	at reactor.core.publisher.FluxPeek$PeekSubscriber.onComplete(FluxPeek.java:260)
	at reactor.core.publisher.FluxMap$MapSubscriber.onComplete(FluxMap.java:144)
	at reactor.netty.channel.FluxReceive.onInboundComplete(FluxReceive.java:413)
	at reactor.netty.channel.ChannelOperations.onInboundComplete(ChannelOperations.java:431)
	at reactor.netty.http.server.HttpServerOperations.onInboundNext(HttpServerOperations.java:682)
	at reactor.netty.channel.ChannelOperationsHandler.channelRead(ChannelOperationsHandler.java:114)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
	at reactor.netty.http.server.HttpTrafficHandler.channelRead(HttpTrafficHandler.java:284)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
	at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:436)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:346)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:318)
	at io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:251)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:842)
2024-12-31 21:14:48.685 [395d2f76-1]  500 Server Error for HTTP POST "/pong"
org.apache.kafka.common.KafkaException: Producer closed while send in progress
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:999)
	Suppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException: 
Error has been observed at the following site(s):
	*__checkpoint ? HTTP POST "/pong" [ExceptionHandlingWebHandler]
Original Stack Trace:
		at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:999)
		at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:962)
		at org.springframework.kafka.core.DefaultKafkaProducerFactory$CloseSafeProducer.send(DefaultKafkaProducerFactory.java:1062)
		at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:783)
		at org.springframework.kafka.core.KafkaTemplate.observeSend(KafkaTemplate.java:754)
		at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:538)
		at com.demo.kafka.KafkaProducerService.sendMessage(KafkaProducerService.java:22)
		at com.demo.controller.PongController.handle(PongController.java:37)
		at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
		at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.base/java.lang.reflect.Method.invoke(Method.java:568)
		at org.springframework.web.reactive.result.method.InvocableHandlerMethod.lambda$invoke$0(InvocableHandlerMethod.java:145)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:132)
		at reactor.core.publisher.MonoZip$ZipCoordinator.signal(MonoZip.java:293)
		at reactor.core.publisher.MonoZip$ZipInner.onNext(MonoZip.java:474)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
		at reactor.core.publisher.FluxDefaultIfEmpty$DefaultIfEmptySubscriber.onNext(FluxDefaultIfEmpty.java:122)
		at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onNext(FluxSwitchIfEmpty.java:74)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onNext(FluxMapFuseable.java:129)
		at reactor.core.publisher.FluxContextWrite$ContextWriteSubscriber.onNext(FluxContextWrite.java:107)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)
		at reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onNext(FluxFilterFuseable.java:337)
		at reactor.core.publisher.Operators$BaseFluxToMonoOperator.completePossiblyEmpty(Operators.java:2071)
		at reactor.core.publisher.MonoCollect$CollectSubscriber.onComplete(MonoCollect.java:145)
		at reactor.core.publisher.FluxMap$MapSubscriber.onComplete(FluxMap.java:144)
		at reactor.core.publisher.FluxPeek$PeekSubscriber.onComplete(FluxPeek.java:260)
		at reactor.core.publisher.FluxMap$MapSubscriber.onComplete(FluxMap.java:144)
		at reactor.netty.channel.FluxReceive.onInboundComplete(FluxReceive.java:413)
		at reactor.netty.channel.ChannelOperations.onInboundComplete(ChannelOperations.java:431)
		at reactor.netty.http.server.HttpServerOperations.onInboundNext(HttpServerOperations.java:682)
		at reactor.netty.channel.ChannelOperationsHandler.channelRead(ChannelOperationsHandler.java:114)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
		at reactor.netty.http.server.HttpTrafficHandler.channelRead(HttpTrafficHandler.java:284)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
		at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:436)
		at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:346)
		at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:318)
		at io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:251)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
		at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
		at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
		at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
		at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
		at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
		at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
		at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		at java.base/java.lang.Thread.run(Thread.java:842)
Caused by: org.apache.kafka.common.KafkaException: Requested metadata update after close
	at org.apache.kafka.clients.producer.internals.ProducerMetadata.awaitUpdate(ProducerMetadata.java:126)
	at org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata(KafkaProducer.java:1147)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:996)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:962)
	at org.springframework.kafka.core.DefaultKafkaProducerFactory$CloseSafeProducer.send(DefaultKafkaProducerFactory.java:1062)
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:783)
	at org.springframework.kafka.core.KafkaTemplate.observeSend(KafkaTemplate.java:754)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:538)
	at com.demo.kafka.KafkaProducerService.sendMessage(KafkaProducerService.java:22)
	at com.demo.controller.PongController.handle(PongController.java:37)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.web.reactive.result.method.InvocableHandlerMethod.lambda$invoke$0(InvocableHandlerMethod.java:145)
	at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:132)
	at reactor.core.publisher.MonoZip$ZipCoordinator.signal(MonoZip.java:293)
	at reactor.core.publisher.MonoZip$ZipInner.onNext(MonoZip.java:474)
	at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
	at reactor.core.publisher.FluxDefaultIfEmpty$DefaultIfEmptySubscriber.onNext(FluxDefaultIfEmpty.java:122)
	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onNext(FluxSwitchIfEmpty.java:74)
	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
	at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onNext(FluxMapFuseable.java:129)
	at reactor.core.publisher.FluxContextWrite$ContextWriteSubscriber.onNext(FluxContextWrite.java:107)
	at reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)
	at reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onNext(FluxFilterFuseable.java:337)
	at reactor.core.publisher.Operators$BaseFluxToMonoOperator.completePossiblyEmpty(Operators.java:2071)
	at reactor.core.publisher.MonoCollect$CollectSubscriber.onComplete(MonoCollect.java:145)
	at reactor.core.publisher.FluxMap$MapSubscriber.onComplete(FluxMap.java:144)
	at reactor.core.publisher.FluxPeek$PeekSubscriber.onComplete(FluxPeek.java:260)
	at reactor.core.publisher.FluxMap$MapSubscriber.onComplete(FluxMap.java:144)
	at reactor.netty.channel.FluxReceive.onInboundComplete(FluxReceive.java:413)
	at reactor.netty.channel.ChannelOperations.onInboundComplete(ChannelOperations.java:431)
	at reactor.netty.http.server.HttpServerOperations.onInboundNext(HttpServerOperations.java:682)
	at reactor.netty.channel.ChannelOperationsHandler.channelRead(ChannelOperationsHandler.java:114)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
	at reactor.netty.http.server.HttpTrafficHandler.channelRead(HttpTrafficHandler.java:284)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
	at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:436)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:346)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:318)
	at io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:251)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:842)
2024-12-31 21:14:48.685 [7a0a2841-3]  500 Server Error for HTTP POST "/pong"
org.apache.kafka.common.KafkaException: Producer closed while send in progress
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:999)
	Suppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException: 
Error has been observed at the following site(s):
	*__checkpoint ? HTTP POST "/pong" [ExceptionHandlingWebHandler]
Original Stack Trace:
		at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:999)
		at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:962)
		at org.springframework.kafka.core.DefaultKafkaProducerFactory$CloseSafeProducer.send(DefaultKafkaProducerFactory.java:1062)
		at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:783)
		at org.springframework.kafka.core.KafkaTemplate.observeSend(KafkaTemplate.java:754)
		at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:538)
		at com.demo.kafka.KafkaProducerService.sendMessage(KafkaProducerService.java:22)
		at com.demo.controller.PongController.handle(PongController.java:37)
		at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
		at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
		at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
		at java.base/java.lang.reflect.Method.invoke(Method.java:568)
		at org.springframework.web.reactive.result.method.InvocableHandlerMethod.lambda$invoke$0(InvocableHandlerMethod.java:145)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:132)
		at reactor.core.publisher.MonoZip$ZipCoordinator.signal(MonoZip.java:293)
		at reactor.core.publisher.MonoZip$ZipInner.onNext(MonoZip.java:474)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
		at reactor.core.publisher.FluxDefaultIfEmpty$DefaultIfEmptySubscriber.onNext(FluxDefaultIfEmpty.java:122)
		at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onNext(FluxSwitchIfEmpty.java:74)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onNext(FluxMapFuseable.java:129)
		at reactor.core.publisher.FluxContextWrite$ContextWriteSubscriber.onNext(FluxContextWrite.java:107)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)
		at reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onNext(FluxFilterFuseable.java:337)
		at reactor.core.publisher.Operators$BaseFluxToMonoOperator.completePossiblyEmpty(Operators.java:2071)
		at reactor.core.publisher.MonoCollect$CollectSubscriber.onComplete(MonoCollect.java:145)
		at reactor.core.publisher.FluxMap$MapSubscriber.onComplete(FluxMap.java:144)
		at reactor.core.publisher.FluxPeek$PeekSubscriber.onComplete(FluxPeek.java:260)
		at reactor.core.publisher.FluxMap$MapSubscriber.onComplete(FluxMap.java:144)
		at reactor.netty.channel.FluxReceive.onInboundComplete(FluxReceive.java:413)
		at reactor.netty.channel.ChannelOperations.onInboundComplete(ChannelOperations.java:431)
		at reactor.netty.http.server.HttpServerOperations.onInboundNext(HttpServerOperations.java:682)
		at reactor.netty.channel.ChannelOperationsHandler.channelRead(ChannelOperationsHandler.java:114)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
		at reactor.netty.http.server.HttpTrafficHandler.channelRead(HttpTrafficHandler.java:284)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
		at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:436)
		at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:346)
		at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:318)
		at io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:251)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
		at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
		at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
		at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
		at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
		at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
		at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
		at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		at java.base/java.lang.Thread.run(Thread.java:842)
Caused by: org.apache.kafka.common.KafkaException: Requested metadata update after close
	at org.apache.kafka.clients.producer.internals.ProducerMetadata.awaitUpdate(ProducerMetadata.java:126)
	at org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata(KafkaProducer.java:1147)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:996)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:962)
	at org.springframework.kafka.core.DefaultKafkaProducerFactory$CloseSafeProducer.send(DefaultKafkaProducerFactory.java:1062)
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:783)
	at org.springframework.kafka.core.KafkaTemplate.observeSend(KafkaTemplate.java:754)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:538)
	at com.demo.kafka.KafkaProducerService.sendMessage(KafkaProducerService.java:22)
	at com.demo.controller.PongController.handle(PongController.java:37)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.web.reactive.result.method.InvocableHandlerMethod.lambda$invoke$0(InvocableHandlerMethod.java:145)
	at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:132)
	at reactor.core.publisher.MonoZip$ZipCoordinator.signal(MonoZip.java:293)
	at reactor.core.publisher.MonoZip$ZipInner.onNext(MonoZip.java:474)
	at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
	at reactor.core.publisher.FluxDefaultIfEmpty$DefaultIfEmptySubscriber.onNext(FluxDefaultIfEmpty.java:122)
	at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onNext(FluxSwitchIfEmpty.java:74)
	at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
	at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onNext(FluxMapFuseable.java:129)
	at reactor.core.publisher.FluxContextWrite$ContextWriteSubscriber.onNext(FluxContextWrite.java:107)
	at reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)
	at reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onNext(FluxFilterFuseable.java:337)
	at reactor.core.publisher.Operators$BaseFluxToMonoOperator.completePossiblyEmpty(Operators.java:2071)
	at reactor.core.publisher.MonoCollect$CollectSubscriber.onComplete(MonoCollect.java:145)
	at reactor.core.publisher.FluxMap$MapSubscriber.onComplete(FluxMap.java:144)
	at reactor.core.publisher.FluxPeek$PeekSubscriber.onComplete(FluxPeek.java:260)
	at reactor.core.publisher.FluxMap$MapSubscriber.onComplete(FluxMap.java:144)
	at reactor.netty.channel.FluxReceive.onInboundComplete(FluxReceive.java:413)
	at reactor.netty.channel.ChannelOperations.onInboundComplete(ChannelOperations.java:431)
	at reactor.netty.http.server.HttpServerOperations.onInboundNext(HttpServerOperations.java:682)
	at reactor.netty.channel.ChannelOperationsHandler.channelRead(ChannelOperationsHandler.java:114)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
	at reactor.netty.http.server.HttpTrafficHandler.channelRead(HttpTrafficHandler.java:284)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
	at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:436)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:346)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:318)
	at io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:251)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:842)
2024-12-31 21:14:48.712 Closing JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:14:48.728 HikariPool-1 - Shutdown initiated...
2024-12-31 21:14:48.729 HikariPool-1 - Shutdown completed.
2024-12-31 21:14:50.848 [KafkaServer id=0] shutting down
2024-12-31 21:14:50.849 [/config/changes-event-process-thread]: Shutting down
2024-12-31 21:14:50.850 [/config/changes-event-process-thread]: Stopped
2024-12-31 21:14:50.850 [/config/changes-event-process-thread]: Shutdown completed
2024-12-31 21:14:50.852 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
2024-12-31 21:14:50.855 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors
2024-12-31 21:14:50.856 [data-plane Kafka Request Handler on Broker 0], shutting down
2024-12-31 21:14:50.856 [data-plane Kafka Request Handler on Broker 0], shut down completely
2024-12-31 21:14:50.859 [ExpirationReaper-0-AlterAcls]: Shutting down
2024-12-31 21:14:50.860 [ExpirationReaper-0-AlterAcls]: Stopped
2024-12-31 21:14:50.860 [ExpirationReaper-0-AlterAcls]: Shutdown completed
2024-12-31 21:14:50.861 [KafkaApi-0] Shutdown complete.
2024-12-31 21:14:50.862 [ExpirationReaper-0-topic]: Shutting down
2024-12-31 21:14:50.862 [ExpirationReaper-0-topic]: Stopped
2024-12-31 21:14:50.862 [ExpirationReaper-0-topic]: Shutdown completed
2024-12-31 21:14:50.864 [TransactionCoordinator id=0] Shutting down.
2024-12-31 21:14:50.864 [Transaction State Manager 0]: Shutdown complete
2024-12-31 21:14:50.865 [Transaction Marker Channel Manager 0]: Shutting down
2024-12-31 21:14:50.865 [Transaction Marker Channel Manager 0]: Stopped
2024-12-31 21:14:50.865 [Transaction Marker Channel Manager 0]: Shutdown completed
2024-12-31 21:14:50.868 [TransactionCoordinator id=0] Shutdown complete.
2024-12-31 21:14:50.868 [GroupCoordinator 0]: Shutting down.
2024-12-31 21:14:50.869 [ExpirationReaper-0-Heartbeat]: Shutting down
2024-12-31 21:14:50.869 [ExpirationReaper-0-Heartbeat]: Stopped
2024-12-31 21:14:50.869 [ExpirationReaper-0-Heartbeat]: Shutdown completed
2024-12-31 21:14:50.871 [ExpirationReaper-0-Rebalance]: Shutting down
2024-12-31 21:14:50.872 [ExpirationReaper-0-Rebalance]: Shutdown completed
2024-12-31 21:14:50.872 [ExpirationReaper-0-Rebalance]: Stopped
2024-12-31 21:14:50.872 [GroupCoordinator 0]: Shutdown complete.
2024-12-31 21:14:50.874 [ReplicaManager broker=0] Shutting down
2024-12-31 21:14:50.875 [LogDirFailureHandler]: Shutting down
2024-12-31 21:14:50.876 [LogDirFailureHandler]: Stopped
2024-12-31 21:14:50.876 [LogDirFailureHandler]: Shutdown completed
2024-12-31 21:14:50.877 [ReplicaFetcherManager on broker 0] shutting down
2024-12-31 21:14:50.878 [ReplicaFetcherManager on broker 0] shutdown completed
2024-12-31 21:14:50.878 [ReplicaAlterLogDirsManager on broker 0] shutting down
2024-12-31 21:14:50.879 [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2024-12-31 21:14:50.879 [ExpirationReaper-0-Fetch]: Shutting down
2024-12-31 21:14:50.880 [ExpirationReaper-0-Fetch]: Shutdown completed
2024-12-31 21:14:50.880 [ExpirationReaper-0-Fetch]: Stopped
2024-12-31 21:14:50.881 [ExpirationReaper-0-Produce]: Shutting down
2024-12-31 21:14:50.883 [ExpirationReaper-0-Produce]: Stopped
2024-12-31 21:14:50.883 [ExpirationReaper-0-Produce]: Shutdown completed
2024-12-31 21:14:50.885 [ExpirationReaper-0-DeleteRecords]: Shutting down
2024-12-31 21:14:50.885 [ExpirationReaper-0-DeleteRecords]: Stopped
2024-12-31 21:14:50.885 [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2024-12-31 21:14:50.887 [ExpirationReaper-0-ElectLeader]: Shutting down
2024-12-31 21:14:50.888 [ExpirationReaper-0-ElectLeader]: Shutdown completed
2024-12-31 21:14:50.888 [ExpirationReaper-0-ElectLeader]: Stopped
2024-12-31 21:14:50.897 [ReplicaManager broker=0] Shut down completely
2024-12-31 21:14:50.898 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutting down
2024-12-31 21:14:50.898 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Stopped
2024-12-31 21:14:50.898 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutdown completed
2024-12-31 21:14:50.902 Broker to controller channel manager for alterPartition shutdown
2024-12-31 21:14:50.902 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down
2024-12-31 21:14:50.903 [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped
2024-12-31 21:14:50.903 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed
2024-12-31 21:14:50.904 Broker to controller channel manager for forwarding shutdown
2024-12-31 21:14:50.905 Shutting down.
2024-12-31 21:14:50.906 Shutting down the log cleaner.
2024-12-31 21:14:50.907 [kafka-log-cleaner-thread-0]: Shutting down
2024-12-31 21:14:50.908 [kafka-log-cleaner-thread-0]: Shutdown completed
2024-12-31 21:14:50.908 [kafka-log-cleaner-thread-0]: Stopped
2024-12-31 21:14:50.921 Shutdown complete.
2024-12-31 21:14:50.922 [ControllerEventThread controllerId=0] Shutting down
2024-12-31 21:14:50.922 [ControllerEventThread controllerId=0] Shutdown completed
2024-12-31 21:14:50.922 [ControllerEventThread controllerId=0] Stopped
2024-12-31 21:14:50.923 [PartitionStateMachine controllerId=0] Stopped partition state machine
2024-12-31 21:14:50.925 [ReplicaStateMachine controllerId=0] Stopped replica state machine
2024-12-31 21:14:50.925 [RequestSendThread controllerId=0] Shutting down
2024-12-31 21:14:50.926 [RequestSendThread controllerId=0] Stopped
2024-12-31 21:14:50.926 [RequestSendThread controllerId=0] Shutdown completed
2024-12-31 21:14:50.929 [Controller id=0] Resigned
2024-12-31 21:14:50.930 [feature-zk-node-event-process-thread]: Shutting down
2024-12-31 21:14:50.931 [feature-zk-node-event-process-thread]: Stopped
2024-12-31 21:14:50.931 [feature-zk-node-event-process-thread]: Shutdown completed
2024-12-31 21:14:50.932 [ZooKeeperClient Kafka server] Closing.
2024-12-31 21:14:51.036 Session: 0x100177562050000 closed
2024-12-31 21:14:51.036 EventThread shut down for session: 0x100177562050000
2024-12-31 21:14:51.038 [ZooKeeperClient Kafka server] Closed.
2024-12-31 21:14:51.039 [ThrottledChannelReaper-Fetch]: Shutting down
2024-12-31 21:14:51.039 [ThrottledChannelReaper-Fetch]: Shutdown completed
2024-12-31 21:14:51.039 [ThrottledChannelReaper-Fetch]: Stopped
2024-12-31 21:14:51.040 [ThrottledChannelReaper-Produce]: Shutting down
2024-12-31 21:14:51.041 [ThrottledChannelReaper-Produce]: Shutdown completed
2024-12-31 21:14:51.041 [ThrottledChannelReaper-Produce]: Stopped
2024-12-31 21:14:51.042 [ThrottledChannelReaper-Request]: Shutting down
2024-12-31 21:14:51.043 [ThrottledChannelReaper-Request]: Shutdown completed
2024-12-31 21:14:51.043 [ThrottledChannelReaper-Request]: Stopped
2024-12-31 21:14:51.044 [ThrottledChannelReaper-ControllerMutation]: Shutting down
2024-12-31 21:14:51.045 [ThrottledChannelReaper-ControllerMutation]: Shutdown completed
2024-12-31 21:14:51.045 [ThrottledChannelReaper-ControllerMutation]: Stopped
2024-12-31 21:14:51.045 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server
2024-12-31 21:14:51.056 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed
2024-12-31 21:14:51.057 Metrics scheduler closed
2024-12-31 21:14:51.057 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:14:51.058 Metrics reporters closed
2024-12-31 21:14:51.059 Broker and topic stats closed
2024-12-31 21:14:51.060 App info kafka.server for 0 unregistered
2024-12-31 21:14:51.060 [KafkaServer id=0] shut down completed
2024-12-31 21:14:51.067 ConnnectionExpirerThread interrupted
2024-12-31 21:14:51.067 selector thread exitted run method
2024-12-31 21:14:51.067 selector thread exitted run method
2024-12-31 21:14:51.067 accept thread exitted run method
2024-12-31 21:14:51.071 shutting down
2024-12-31 21:14:51.072 Shutting down
2024-12-31 21:14:51.073 Draining request throttler queue
2024-12-31 21:14:51.073 RequestThrottler shutdown. Dropped 0 requests
2024-12-31 21:14:51.074 Shutting down
2024-12-31 21:14:51.074 Shutting down
2024-12-31 21:14:51.075 Shutting down
2024-12-31 21:14:51.075 PrepRequestProcessor exited loop!
2024-12-31 21:14:51.075 SyncRequestProcessor exited!
2024-12-31 21:14:51.076 shutdown of request processor complete
2024-12-31 21:14:51.491 SessionTrackerImpl exited loop!
2024-12-31 21:14:51.708 

Found multiple occurrences of org.json.JSONObject on the class path:

	jar:file:/C:/work/apache-maven-3.8.8/repo/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar!/org/json/JSONObject.class
	jar:file:/C:/work/apache-maven-3.8.8/repo/org/json/json/20220320/json-20220320.jar!/org/json/JSONObject.class

You may wish to exclude one of them to ensure predictable runtime behavior

2024-12-31 21:14:51.712 Starting MessageRepositorySpec using Java 17.0.12 with PID 24224 (started by joech in C:\code\hsbc\demo\pong)
2024-12-31 21:14:51.713 No active profile set, falling back to 1 default profile: "default"
2024-12-31 21:14:51.878 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:14:51.879 Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2024-12-31 21:14:51.898 Finished Spring Data repository scanning in 17 ms. Found 1 JPA repository interfaces.
2024-12-31 21:14:51.904 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:14:51.905 Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2024-12-31 21:14:51.911 Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.demo.dao.MessageRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2024-12-31 21:14:51.912 Finished Spring Data repository scanning in 6 ms. Found 0 Redis repository interfaces.
2024-12-31 21:14:52.020 HHH000204: Processing PersistenceUnitInfo [name: default]
2024-12-31 21:14:52.030 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:14:52.031 No LoadTimeWeaver setup: ignoring JPA class transformer
2024-12-31 21:14:52.034 HikariPool-2 - Starting...
2024-12-31 21:14:52.039 HikariPool-2 - Added connection conn10: url=jdbc:h2:mem:testdb user=SA
2024-12-31 21:14:52.040 HikariPool-2 - Start completed.
2024-12-31 21:14:52.054 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:14:52.090 HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2024-12-31 21:14:52.123 Initialized JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:14:52.424 ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:59684]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-pong-service-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = pong-service
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2024-12-31 21:14:52.432 These configurations '[spring.json.trusted.packages]' were supplied but are not used yet.
2024-12-31 21:14:52.434 Kafka version: 3.4.1
2024-12-31 21:14:52.435 Kafka commitId: 8a516edc2755df89
2024-12-31 21:14:52.435 Kafka startTimeMs: 1735650892434
2024-12-31 21:14:52.436 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Subscribed to topic(s): pong-message-topic
2024-12-31 21:14:52.441 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:52.442 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:14:52.442 Started MessageRepositorySpec in 0.783 seconds (process running for 44.93)
2024-12-31 21:14:52.443 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:14:52.552 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:52.554 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:14:52.554 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:14:52.641 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:14:52.642 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:14:52.643 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Unsubscribed all topics or patterns and assigned partitions
2024-12-31 21:14:52.644 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:14:52.644 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:14:52.645 Metrics scheduler closed
2024-12-31 21:14:52.645 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:14:52.646 Metrics reporters closed
2024-12-31 21:14:52.647 App info kafka.consumer for consumer-pong-service-2 unregistered
2024-12-31 21:14:52.648 pong-service: Consumer stopped
2024-12-31 21:14:52.655 Closing JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:14:52.657 HikariPool-2 - Shutdown initiated...
2024-12-31 21:14:52.661 HikariPool-2 - Shutdown completed.
2024-12-31 21:14:52.748 

Found multiple occurrences of org.json.JSONObject on the class path:

	jar:file:/C:/work/apache-maven-3.8.8/repo/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar!/org/json/JSONObject.class
	jar:file:/C:/work/apache-maven-3.8.8/repo/org/json/json/20220320/json-20220320.jar!/org/json/JSONObject.class

You may wish to exclude one of them to ensure predictable runtime behavior

2024-12-31 21:14:52.751 Starting KafkaSpec using Java 17.0.12 with PID 24224 (started by joech in C:\code\hsbc\demo\pong)
2024-12-31 21:14:52.753 No active profile set, falling back to 1 default profile: "default"
2024-12-31 21:14:52.934 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:14:52.936 Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2024-12-31 21:14:52.956 Finished Spring Data repository scanning in 19 ms. Found 1 JPA repository interfaces.
2024-12-31 21:14:52.962 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:14:52.963 Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2024-12-31 21:14:52.970 Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.demo.dao.MessageRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2024-12-31 21:14:52.971 Finished Spring Data repository scanning in 6 ms. Found 0 Redis repository interfaces.
2024-12-31 21:14:53.070 HHH000204: Processing PersistenceUnitInfo [name: default]
2024-12-31 21:14:53.084 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:14:53.086 No LoadTimeWeaver setup: ignoring JPA class transformer
2024-12-31 21:14:53.088 HikariPool-3 - Starting...
2024-12-31 21:14:53.092 HikariPool-3 - Added connection conn20: url=jdbc:h2:mem:testdb user=SA
2024-12-31 21:14:53.094 HikariPool-3 - Start completed.
2024-12-31 21:14:53.108 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:14:53.141 HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2024-12-31 21:14:53.166 Initialized JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:14:53.420 ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:59684]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-pong-service-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = pong-service
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2024-12-31 21:14:53.425 These configurations '[spring.json.trusted.packages]' were supplied but are not used yet.
2024-12-31 21:14:53.426 Kafka version: 3.4.1
2024-12-31 21:14:53.427 Kafka commitId: 8a516edc2755df89
2024-12-31 21:14:53.427 Kafka startTimeMs: 1735650893426
2024-12-31 21:14:53.428 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Subscribed to topic(s): pong-message-topic
2024-12-31 21:14:53.432 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:53.433 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:14:53.433 Started KafkaSpec in 0.734 seconds (process running for 45.921)
2024-12-31 21:14:53.433 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:14:53.442 zookeeper.snapshot.trust.empty : false
2024-12-31 21:14:53.443 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:14:53.444 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:14:53.445 zookeeper.snapshotSizeFactor = 0.33
2024-12-31 21:14:53.446 zookeeper.commitLogCount=500
2024-12-31 21:14:53.447 minSessionTimeout set to 1600
2024-12-31 21:14:53.447 maxSessionTimeout set to 16000
2024-12-31 21:14:53.449 Response cache size is initialized with value 400.
2024-12-31 21:14:53.450 Response cache size is initialized with value 400.
2024-12-31 21:14:53.450 zookeeper.pathStats.slotCapacity = 60
2024-12-31 21:14:53.451 zookeeper.pathStats.slotDuration = 15
2024-12-31 21:14:53.452 zookeeper.pathStats.maxDepth = 6
2024-12-31 21:14:53.452 zookeeper.pathStats.initialDelay = 5
2024-12-31 21:14:53.453 zookeeper.pathStats.delay = 5
2024-12-31 21:14:53.454 zookeeper.pathStats.enabled = false
2024-12-31 21:14:53.454 The max bytes for all large requests are set to 104857600
2024-12-31 21:14:53.455 The large request threshold is set to -1
2024-12-31 21:14:53.456 Created server with tickTime 800 minSessionTimeout 1600 maxSessionTimeout 16000 clientPortListenBacklog -1 datadir C:\Users\joech\AppData\Local\Temp\kafka-5950744715474725461\version-2 snapdir C:\Users\joech\AppData\Local\Temp\kafka-10305662574100607820\version-2
2024-12-31 21:14:53.457 maxCnxns is not configured, using default value 0.
2024-12-31 21:14:53.458 Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers.
2024-12-31 21:14:53.461 binding to port /127.0.0.1:0
2024-12-31 21:14:53.466 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-10305662574100607820\version-2\snapshot.0
2024-12-31 21:14:53.467 Snapshot loaded in 2 ms, highest zxid is 0x0, digest is 1371985504
2024-12-31 21:14:53.468 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-10305662574100607820\version-2\snapshot.0
2024-12-31 21:14:53.469 Snapshot taken in 1 ms
2024-12-31 21:14:53.471 PrepRequestProcessor (sid:0) started, reconfigEnabled=false
2024-12-31 21:14:53.472 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.2dbefd93-5af7-4e83-bcab-bd85c305917618226613881880617666
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59714
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:14:53.477 starting
2024-12-31 21:14:53.478 Connecting to zookeeper on 127.0.0.1:59714
2024-12-31 21:14:53.480 [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:59714.
2024-12-31 21:14:53.480 Initiating client connection, connectString=127.0.0.1:59714 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4d13ddc8
2024-12-31 21:14:53.483 jute.maxbuffer value is 4194304 Bytes
2024-12-31 21:14:53.484 zookeeper.request.timeout value is 0. feature enabled=false
2024-12-31 21:14:53.486 [ZooKeeperClient Kafka server] Waiting until connected.
2024-12-31 21:14:53.486 Opening socket connection to server /127.0.0.1:59714.
2024-12-31 21:14:53.487 Socket connection established, initiating session, client: /127.0.0.1:59715, server: /127.0.0.1:59714
2024-12-31 21:14:53.490 Creating new log file: log.1
2024-12-31 21:14:53.497 Session establishment complete on server /127.0.0.1:59714, session id = 0x1001775f35e0000, negotiated timeout = 16000
2024-12-31 21:14:53.498 [ZooKeeperClient Kafka server] Connected.
2024-12-31 21:14:53.535 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:53.536 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:14:53.537 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:14:53.543 Cluster ID = y0JWpvxnQ9Cos0X22E-NqQ
2024-12-31 21:14:53.544 No meta.properties file under dir C:\Users\joech\AppData\Local\Temp\spring.kafka.2dbefd93-5af7-4e83-bcab-bd85c305917618226613881880617666\meta.properties
2024-12-31 21:14:53.554 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.2dbefd93-5af7-4e83-bcab-bd85c305917618226613881880617666
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59714
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:14:53.561 [ThrottledChannelReaper-Fetch]: Starting
2024-12-31 21:14:53.561 [ThrottledChannelReaper-Produce]: Starting
2024-12-31 21:14:53.561 [ThrottledChannelReaper-Request]: Starting
2024-12-31 21:14:53.562 [ThrottledChannelReaper-ControllerMutation]: Starting
2024-12-31 21:14:53.572 Loading logs from log dirs ArraySeq(C:\Users\joech\AppData\Local\Temp\spring.kafka.2dbefd93-5af7-4e83-bcab-bd85c305917618226613881880617666)
2024-12-31 21:14:53.573 Attempting recovery for all logs in C:\Users\joech\AppData\Local\Temp\spring.kafka.2dbefd93-5af7-4e83-bcab-bd85c305917618226613881880617666 since no clean shutdown file was found
2024-12-31 21:14:53.576 Loaded 0 logs in 3ms.
2024-12-31 21:14:53.577 Starting log cleanup with a period of 300000 ms.
2024-12-31 21:14:53.578 Starting log flusher with a default period of 9223372036854775807 ms.
2024-12-31 21:14:53.581 Starting the log cleaner
2024-12-31 21:14:53.582 [kafka-log-cleaner-thread-0]: Starting
2024-12-31 21:14:53.582 [feature-zk-node-event-process-thread]: Starting
2024-12-31 21:14:53.585 Feature ZK node at path: /feature does not exist
2024-12-31 21:14:53.588 [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting
2024-12-31 21:14:53.609 Updated connection-accept-rate max connection creation rate to 2147483647
2024-12-31 21:14:53.613 Awaiting socket connections on localhost:59717.
2024-12-31 21:14:53.623 [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT)
2024-12-31 21:14:53.628 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Starting
2024-12-31 21:14:53.628 [ExpirationReaper-0-Produce]: Starting
2024-12-31 21:14:53.629 [ExpirationReaper-0-Fetch]: Starting
2024-12-31 21:14:53.629 [ExpirationReaper-0-DeleteRecords]: Starting
2024-12-31 21:14:53.629 [ExpirationReaper-0-ElectLeader]: Starting
2024-12-31 21:14:53.630 [LogDirFailureHandler]: Starting
2024-12-31 21:14:53.632 Creating /brokers/ids/0 (is it secure? false)
2024-12-31 21:14:53.635 Stat of the created znode at /brokers/ids/0 is: 25,25,1735650893634,1735650893634,1,0,0,72083389399564288,204,0,25

2024-12-31 21:14:53.636 Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:59717, czxid (broker epoch): 25
2024-12-31 21:14:53.645 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:53.647 [ControllerEventThread controllerId=0] Starting
2024-12-31 21:14:53.647 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:14:53.648 [ExpirationReaper-0-topic]: Starting
2024-12-31 21:14:53.648 [ExpirationReaper-0-Heartbeat]: Starting
2024-12-31 21:14:53.648 [ExpirationReaper-0-Rebalance]: Starting
2024-12-31 21:14:53.648 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:14:53.648 [GroupCoordinator 0]: Starting up.
2024-12-31 21:14:53.651 Successfully created /controller_epoch with initial epoch 0
2024-12-31 21:14:53.653 [GroupCoordinator 0]: Startup complete.
2024-12-31 21:14:53.654 [Controller id=0] 0 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1
2024-12-31 21:14:53.655 [TransactionCoordinator id=0] Starting up.
2024-12-31 21:14:53.655 [Controller id=0] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map())
2024-12-31 21:14:53.657 [TransactionCoordinator id=0] Startup complete.
2024-12-31 21:14:53.657 [Transaction Marker Channel Manager 0]: Starting
2024-12-31 21:14:53.658 Feature ZK node created at path: /feature
2024-12-31 21:14:53.658 [ExpirationReaper-0-AlterAcls]: Starting
2024-12-31 21:14:53.661 [MetadataCache brokerId=0] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0).
2024-12-31 21:14:53.661 [Controller id=0] Registering handlers
2024-12-31 21:14:53.662 [/config/changes-event-process-thread]: Starting
2024-12-31 21:14:53.663 [Controller id=0] Deleting log dir event notifications
2024-12-31 21:14:53.664 [Controller id=0] Deleting isr change notifications
2024-12-31 21:14:53.665 [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing.
2024-12-31 21:14:53.665 [Controller id=0] Initializing controller context
2024-12-31 21:14:53.666 Kafka version: 3.4.1
2024-12-31 21:14:53.667 Kafka commitId: 8a516edc2755df89
2024-12-31 21:14:53.668 Kafka startTimeMs: 1735650893666
2024-12-31 21:14:53.668 [KafkaServer id=0] started
2024-12-31 21:14:53.669 [Controller id=0] Initialized broker epochs cache: HashMap(0 -> 25)
2024-12-31 21:14:53.671 AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [127.0.0.1:59717]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-31 21:14:53.674 Kafka version: 3.4.1
2024-12-31 21:14:53.675 Kafka commitId: 8a516edc2755df89
2024-12-31 21:14:53.675 Kafka startTimeMs: 1735650893674
2024-12-31 21:14:53.676 [Controller id=0] Currently active brokers in the cluster: Set(0)
2024-12-31 21:14:53.676 [RequestSendThread controllerId=0] Starting
2024-12-31 21:14:53.676 [Controller id=0] Currently shutting brokers in the cluster: HashSet()
2024-12-31 21:14:53.677 [Controller id=0] Current list of topics in the cluster: HashSet()
2024-12-31 21:14:53.678 [Controller id=0] Fetching topic deletions in progress
2024-12-31 21:14:53.679 [Controller id=0] List of topics to be deleted: 
2024-12-31 21:14:53.680 [Controller id=0] List of topics ineligible for deletion: 
2024-12-31 21:14:53.680 [Controller id=0] Initializing topic deletion manager
2024-12-31 21:14:53.681 [Topic Deletion Manager 0] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet()
2024-12-31 21:14:53.681 [Controller id=0] Sending update metadata request
2024-12-31 21:14:53.683 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions
2024-12-31 21:14:53.684 [ReplicaStateMachine controllerId=0] Initializing replica state
2024-12-31 21:14:53.684 [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2024-12-31 21:14:53.684 [RequestSendThread controllerId=0] Controller 0 connected to localhost:59717 (id: 0 rack: null) for sending state change requests
2024-12-31 21:14:53.685 [ReplicaStateMachine controllerId=0] Triggering offline replica state changes
2024-12-31 21:14:53.685 [PartitionStateMachine controllerId=0] Initializing partition state
2024-12-31 21:14:53.686 [PartitionStateMachine controllerId=0] Triggering online partition state changes
2024-12-31 21:14:53.687 [Controller id=0] Ready to serve as the new controller with epoch 1
2024-12-31 21:14:53.689 [Controller id=0] Partitions undergoing preferred replica election: 
2024-12-31 21:14:53.689 [Controller id=0] Partitions that completed preferred replica election: 
2024-12-31 21:14:53.690 [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2024-12-31 21:14:53.690 [Controller id=0] Resuming preferred replica election for partitions: 
2024-12-31 21:14:53.691 [Controller id=0] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered
2024-12-31 21:14:53.693 [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use node localhost:59717 (id: 0 rack: null)
2024-12-31 21:14:53.694 [Controller id=0] Starting the controller scheduler
2024-12-31 21:14:53.738 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Recorded new controller, from now on will use node localhost:59717 (id: 0 rack: null)
2024-12-31 21:14:53.795 Creating topic pong-message-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0))
2024-12-31 21:14:53.803 [Controller id=0] New topics: [Set(pong-message-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(pong-message-topic,Some(vL3MwHcIS9SOBL4PO2k9fw),Map(pong-message-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), pong-message-topic-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:14:53.803 [Controller id=0] New partition creation callback for pong-message-topic-0,pong-message-topic-1
2024-12-31 21:14:53.804 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:14:53.805 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:14:53.805 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:14:53.806 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:14:53.813 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:14:53.814 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:14:53.815 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2024-12-31 21:14:53.816 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2024-12-31 21:14:53.817 [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 for 2 partitions
2024-12-31 21:14:53.817 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:14:53.818 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(pong-message-topic-0, pong-message-topic-1)
2024-12-31 21:14:53.819 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2024-12-31 21:14:53.832 [LogLoader partition=pong-message-topic-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.2dbefd93-5af7-4e83-bcab-bd85c305917618226613881880617666] Loading producer state till offset 0 with message format version 2
2024-12-31 21:14:53.834 Created log for partition pong-message-topic-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.2dbefd93-5af7-4e83-bcab-bd85c305917618226613881880617666\pong-message-topic-0 with properties {}
2024-12-31 21:14:53.835 [Partition pong-message-topic-0 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-0
2024-12-31 21:14:53.836 [Partition pong-message-topic-0 broker=0] Log loaded for partition pong-message-topic-0 with initial high watermark 0
2024-12-31 21:14:53.836 [Broker id=0] Leader pong-message-topic-0 with topic id Some(vL3MwHcIS9SOBL4PO2k9fw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:14:53.847 [LogLoader partition=pong-message-topic-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.2dbefd93-5af7-4e83-bcab-bd85c305917618226613881880617666] Loading producer state till offset 0 with message format version 2
2024-12-31 21:14:53.850 Created log for partition pong-message-topic-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.2dbefd93-5af7-4e83-bcab-bd85c305917618226613881880617666\pong-message-topic-1 with properties {}
2024-12-31 21:14:53.850 [Partition pong-message-topic-1 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-1
2024-12-31 21:14:53.851 [Partition pong-message-topic-1 broker=0] Log loaded for partition pong-message-topic-1 with initial high watermark 0
2024-12-31 21:14:53.851 [Broker id=0] Leader pong-message-topic-1 with topic id Some(vL3MwHcIS9SOBL4PO2k9fw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:14:53.855 [Broker id=0] Finished LeaderAndIsr request in 38ms correlationId 1 from controller 0 for 2 partitions
2024-12-31 21:14:53.859 [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2
2024-12-31 21:14:53.863 App info kafka.admin.client for adminclient-4 unregistered
2024-12-31 21:14:53.865 Metrics scheduler closed
2024-12-31 21:14:53.866 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:14:53.866 Metrics reporters closed
2024-12-31 21:14:53.879 Idempotence will be disabled because acks is set to 0, not set to 'all'.
2024-12-31 21:14:53.880 ProducerConfig values: 
	acks = 0
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:59684]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2024-12-31 21:14:53.881 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:53.882 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:14:53.882 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:14:53.885 Kafka version: 3.4.1
2024-12-31 21:14:53.886 Kafka commitId: 8a516edc2755df89
2024-12-31 21:14:53.886 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:14:53.887 Kafka startTimeMs: 1735650893885
2024-12-31 21:14:53.887 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:14:53.888 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:14:53.990 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:14:53.992 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:14:53.993 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:14:54.099 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:14:54.100 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:14:54.101 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:14:54.333 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:14:54.334 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:14:54.334 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:14:54.363 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:54.364 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:14:54.365 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:14:54.695 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:14:54.696 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:14:54.696 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:14:55.289 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:55.290 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:14:55.291 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:14:55.681 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:14:55.682 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:14:55.682 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:14:56.215 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:56.217 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:14:56.218 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:14:56.669 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:14:56.670 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:14:56.671 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:14:57.198 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:57.200 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:14:57.200 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:14:57.844 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:14:57.845 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:14:57.845 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:14:58.315 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:58.315 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:14:58.317 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:14:58.706 [Controller id=0] Processing automatic preferred replica leader election
2024-12-31 21:14:58.896 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:14:58.896 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:14:58.897 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:14:59.507 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:14:59.508 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:14:59.509 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:00.010 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:00.011 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:00.012 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:00.438 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:00.439 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:00.440 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:01.004 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:01.005 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:01.006 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:01.491 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:01.492 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:01.492 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:01.805 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:01.807 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:01.807 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:02.356 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:02.357 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:02.358 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:02.796 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:02.797 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:02.798 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:03.283 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:03.284 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:03.284 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:03.723 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:03.725 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:03.725 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:04.504 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:04.505 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:04.506 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:04.900 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:04.901 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:04.902 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:05.682 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:05.683 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:05.684 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:05.948 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:05.949 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:05.949 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:06.664 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:06.665 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:06.665 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:07.179 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:07.180 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:07.181 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:07.903 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:07.904 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:07.904 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:08.166 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:08.167 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:08.168 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:08.827 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:08.827 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:08.828 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:09.155 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:09.156 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:09.156 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:09.693 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:09.695 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:09.696 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:10.318 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:10.319 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:10.320 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:10.614 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:10.615 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:10.616 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:11.477 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:11.478 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:11.478 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:11.552 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:11.553 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:11.554 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:12.462 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:12.463 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:12.464 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:12.477 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:12.478 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:12.479 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:13.462 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:13.464 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:13.464 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:13.524 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:13.525 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:13.526 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:14.327 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:14.328 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:14.328 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:14.575 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:14.577 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:14.577 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:15.188 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:15.189 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:15.190 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:15.501 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:15.503 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:15.503 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:16.114 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:16.115 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:16.115 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:16.677 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:16.678 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:16.678 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:17.162 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:17.163 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:17.164 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:17.664 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:17.666 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:17.667 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:18.405 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:18.406 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:18.406 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:18.847 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:18.848 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:18.849 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:19.519 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:19.520 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:19.520 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:19.954 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:19.955 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:19.956 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:20.562 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:20.563 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:20.564 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:21.125 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:21.126 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:21.127 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:21.485 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:21.486 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:21.487 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:22.296 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:22.297 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:22.297 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:22.404 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:22.405 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:22.405 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:23.262 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:23.263 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:23.265 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:23.465 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:23.467 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:23.467 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:24.184 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:24.185 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:24.185 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:24.575 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:24.577 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:24.578 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:25.361 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:25.362 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:25.363 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:25.566 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:25.567 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:25.568 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:26.414 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:26.415 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:26.415 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:26.617 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:26.618 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:26.619 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:27.273 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:27.274 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:27.274 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:27.789 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:27.790 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:27.791 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:28.195 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:28.196 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:28.196 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:28.980 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:28.981 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:28.981 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:29.306 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:29.307 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:29.307 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:29.898 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:29.899 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:29.900 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:30.227 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:30.228 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:30.229 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:30.824 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:30.825 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:30.825 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:31.404 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:31.405 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:31.405 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:31.807 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:31.809 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:31.810 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:32.447 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:32.448 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:32.449 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:32.981 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:32.983 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:32.983 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:33.560 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:33.561 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:33.562 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:34.174 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:34.175 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:34.176 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:34.610 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:34.611 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:34.612 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:35.411 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:35.412 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:35.413 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:35.663 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:35.663 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:35.664 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:36.403 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:36.404 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:36.404 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:36.714 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:15:36.715 [Producer clientId=producer-2] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:36.715 [Producer clientId=producer-2] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:15:37.264 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:15:37.266 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node -1 (/127.0.0.1:59684) could not be established. Broker may not be available.
2024-12-31 21:15:37.266 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Bootstrap broker 127.0.0.1:59684 (id: -1 rack: null) disconnected
2024-12-31 21:21:51.386 Could not detect default configuration classes for test class [com.demo.controller.PongControllerSpec]: PongControllerSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:21:51.556 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.controller.PongControllerSpec
2024-12-31 21:21:51.741 Could not detect default configuration classes for test class [com.demo.dao.MessageRepositorySpec]: MessageRepositorySpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:21:51.757 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.dao.MessageRepositorySpec
2024-12-31 21:21:51.757 Could not detect default configuration classes for test class [com.demo.kafka.KafkaSpec]: KafkaSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:21:51.779 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.kafka.KafkaSpec
2024-12-31 21:21:51.821 Could not detect default configuration classes for test class [com.demo.controller.PongControllerSpec]: PongControllerSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:21:51.827 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.controller.PongControllerSpec
2024-12-31 21:21:51.829 Could not detect default configuration classes for test class [com.demo.dao.MessageRepositorySpec]: MessageRepositorySpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:21:51.833 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.dao.MessageRepositorySpec
2024-12-31 21:21:51.836 Could not detect default configuration classes for test class [com.demo.kafka.KafkaSpec]: KafkaSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2024-12-31 21:21:51.836 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.kafka.KafkaSpec
2024-12-31 21:21:52.201 Registered kafka:type=kafka.Log4jController MBean
2024-12-31 21:21:52.279 
2024-12-31 21:21:52.279   ______                  _                                          
2024-12-31 21:21:52.279  |___  /                 | |                                         
2024-12-31 21:21:52.279     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __   
2024-12-31 21:21:52.279    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__|
2024-12-31 21:21:52.279   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |    
2024-12-31 21:21:52.279  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_|
2024-12-31 21:21:52.279                                               | |                     
2024-12-31 21:21:52.279                                               |_|                     
2024-12-31 21:21:52.279 
2024-12-31 21:21:57.599 Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT
2024-12-31 21:21:57.600 Server environment:host.name=Joe
2024-12-31 21:21:57.600 Server environment:java.version=17.0.12
2024-12-31 21:21:57.600 Server environment:java.vendor=Oracle Corporation
2024-12-31 21:21:57.600 Server environment:java.home=C:\work\jdk-17
2024-12-31 21:21:57.600 Server environment:java.class.path=C:\code\hsbc\demo\pong\target\test-classes;C:\code\hsbc\demo\pong\target\classes;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-webflux\3.1.4\spring-boot-starter-webflux-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter\3.1.4\spring-boot-starter-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot\3.1.4\spring-boot-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-autoconfigure\3.1.4\spring-boot-autoconfigure-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-logging\3.1.4\spring-boot-starter-logging-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\ch\qos\logback\logback-classic\1.4.11\logback-classic-1.4.11.jar;C:\work\apache-maven-3.8.8\repo\ch\qos\logback\logback-core\1.4.11\logback-core-1.4.11.jar;C:\work\apache-maven-3.8.8\repo\org\apache\logging\log4j\log4j-to-slf4j\2.20.0\log4j-to-slf4j-2.20.0.jar;C:\work\apache-maven-3.8.8\repo\org\apache\logging\log4j\log4j-api\2.20.0\log4j-api-2.20.0.jar;C:\work\apache-maven-3.8.8\repo\org\slf4j\jul-to-slf4j\2.0.9\jul-to-slf4j-2.0.9.jar;C:\work\apache-maven-3.8.8\repo\jakarta\annotation\jakarta.annotation-api\2.1.1\jakarta.annotation-api-2.1.1.jar;C:\work\apache-maven-3.8.8\repo\org\yaml\snakeyaml\1.33\snakeyaml-1.33.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-json\3.1.4\spring-boot-starter-json-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-databind\2.15.2\jackson-databind-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-annotations\2.15.2\jackson-annotations-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-core\2.15.2\jackson-core-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.15.2\jackson-datatype-jdk8-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.15.2\jackson-datatype-jsr310-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\module\jackson-module-parameter-names\2.15.2\jackson-module-parameter-names-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-reactor-netty\3.1.4\spring-boot-starter-reactor-netty-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\netty\reactor-netty-http\1.1.11\reactor-netty-http-1.1.11.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-http\4.1.97.Final\netty-codec-http-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-http2\4.1.97.Final\netty-codec-http2-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns\4.1.97.Final\netty-resolver-dns-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-dns\4.1.97.Final\netty-codec-dns-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns-native-macos\4.1.97.Final\netty-resolver-dns-native-macos-4.1.97.Final-osx-x86_64.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns-classes-macos\4.1.97.Final\netty-resolver-dns-classes-macos-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final-linux-x86_64.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\netty\reactor-netty-core\1.1.11\reactor-netty-core-1.1.11.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-handler-proxy\4.1.97.Final\netty-handler-proxy-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-socks\4.1.97.Final\netty-codec-socks-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-web\6.0.12\spring-web-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-beans\6.0.12\spring-beans-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-webflux\6.0.12\spring-webflux-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\reactor-core\3.5.10\reactor-core-3.5.10.jar;C:\work\apache-maven-3.8.8\repo\org\reactivestreams\reactive-streams\1.0.4\reactive-streams-1.0.4.jar;C:\work\apache-maven-3.8.8\repo\com\google\guava\guava\19.0\guava-19.0.jar;C:\work\apache-maven-3.8.8\repo\commons-io\commons-io\2.11.0\commons-io-2.11.0.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-data-redis\3.1.4\spring-boot-starter-data-redis-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-redis\3.1.4\spring-data-redis-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-keyvalue\3.1.4\spring-data-keyvalue-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-oxm\6.0.12\spring-oxm-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-aop\6.0.12\spring-aop-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-context-support\6.0.12\spring-context-support-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\io\lettuce\lettuce-core\6.2.6.RELEASE\lettuce-core-6.2.6.RELEASE.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-common\4.1.97.Final\netty-common-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-handler\4.1.97.Final\netty-handler-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver\4.1.97.Final\netty-resolver-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-buffer\4.1.97.Final\netty-buffer-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-unix-common\4.1.97.Final\netty-transport-native-unix-common-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec\4.1.97.Final\netty-codec-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport\4.1.97.Final\netty-transport-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-data-jpa\3.1.4\spring-boot-starter-data-jpa-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-aop\3.1.4\spring-boot-starter-aop-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\aspectj\aspectjweaver\1.9.20\aspectjweaver-1.9.20.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-jdbc\3.1.4\spring-boot-starter-jdbc-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\zaxxer\HikariCP\5.0.1\HikariCP-5.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-jdbc\6.0.12\spring-jdbc-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\hibernate\orm\hibernate-core\6.2.9.Final\hibernate-core-6.2.9.Final.jar;C:\work\apache-maven-3.8.8\repo\jakarta\persistence\jakarta.persistence-api\3.1.0\jakarta.persistence-api-3.1.0.jar;C:\work\apache-maven-3.8.8\repo\jakarta\transaction\jakarta.transaction-api\2.0.1\jakarta.transaction-api-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\jboss\logging\jboss-logging\3.5.3.Final\jboss-logging-3.5.3.Final.jar;C:\work\apache-maven-3.8.8\repo\org\hibernate\common\hibernate-commons-annotations\6.0.6.Final\hibernate-commons-annotations-6.0.6.Final.jar;C:\work\apache-maven-3.8.8\repo\io\smallrye\jandex\3.0.5\jandex-3.0.5.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\classmate\1.5.1\classmate-1.5.1.jar;C:\work\apache-maven-3.8.8\repo\net\bytebuddy\byte-buddy\1.14.8\byte-buddy-1.14.8.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\jaxb-runtime\4.0.3\jaxb-runtime-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\jaxb-core\4.0.3\jaxb-core-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\eclipse\angus\angus-activation\2.0.1\angus-activation-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\txw2\4.0.3\txw2-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\com\sun\istack\istack-commons-runtime\4.1.2\istack-commons-runtime-4.1.2.jar;C:\work\apache-maven-3.8.8\repo\jakarta\inject\jakarta.inject-api\2.0.1\jakarta.inject-api-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\antlr\antlr4-runtime\4.10.1\antlr4-runtime-4.10.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-jpa\3.1.4\spring-data-jpa-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-commons\3.1.4\spring-data-commons-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-orm\6.0.12\spring-orm-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-aspects\6.0.12\spring-aspects-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\postgresql\postgresql\42.6.0\postgresql-42.6.0.jar;C:\work\apache-maven-3.8.8\repo\org\checkerframework\checker-qual\3.31.0\checker-qual-3.31.0.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\kafka\spring-kafka\3.0.11\spring-kafka-3.0.11.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-context\6.0.12\spring-context-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-expression\6.0.12\spring-expression-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-messaging\6.0.12\spring-messaging-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-tx\6.0.12\spring-tx-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\retry\spring-retry\2.0.3\spring-retry-2.0.3.jar;C:\work\apache-maven-3.8.8\repo\io\micrometer\micrometer-observation\1.11.4\micrometer-observation-1.11.4.jar;C:\work\apache-maven-3.8.8\repo\io\micrometer\micrometer-commons\1.11.4\micrometer-commons-1.11.4.jar;C:\work\apache-maven-3.8.8\repo\com\google\code\findbugs\jsr305\3.0.2\jsr305-3.0.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\com\github\luben\zstd-jni\1.5.2-1\zstd-jni-1.5.2-1.jar;C:\work\apache-maven-3.8.8\repo\org\lz4\lz4-java\1.8.0\lz4-java-1.8.0.jar;C:\work\apache-maven-3.8.8\repo\org\xerial\snappy\snappy-java\1.1.8.4\snappy-java-1.1.8.4.jar;C:\work\apache-maven-3.8.8\repo\org\slf4j\slf4j-api\2.0.9\slf4j-api-2.0.9.jar;C:\work\apache-maven-3.8.8\repo\com\h2database\h2\1.4.200\h2-1.4.200.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-test\3.1.4\spring-boot-starter-test-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-test\3.1.4\spring-boot-test-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-test-autoconfigure\3.1.4\spring-boot-test-autoconfigure-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\jayway\jsonpath\json-path\2.8.0\json-path-2.8.0.jar;C:\work\apache-maven-3.8.8\repo\jakarta\xml\bind\jakarta.xml.bind-api\4.0.1\jakarta.xml.bind-api-4.0.1.jar;C:\work\apache-maven-3.8.8\repo\jakarta\activation\jakarta.activation-api\2.1.2\jakarta.activation-api-2.1.2.jar;C:\work\apache-maven-3.8.8\repo\net\minidev\json-smart\2.4.11\json-smart-2.4.11.jar;C:\work\apache-maven-3.8.8\repo\net\minidev\accessors-smart\2.4.11\accessors-smart-2.4.11.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm\9.3\asm-9.3.jar;C:\work\apache-maven-3.8.8\repo\org\assertj\assertj-core\3.24.2\assertj-core-3.24.2.jar;C:\work\apache-maven-3.8.8\repo\org\hamcrest\hamcrest\2.2\hamcrest-2.2.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter\5.9.3\junit-jupiter-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-params\5.9.3\junit-jupiter-params-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-engine\5.9.3\junit-jupiter-engine-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\mockito\mockito-core\5.3.1\mockito-core-5.3.1.jar;C:\work\apache-maven-3.8.8\repo\net\bytebuddy\byte-buddy-agent\1.14.8\byte-buddy-agent-1.14.8.jar;C:\work\apache-maven-3.8.8\repo\org\objenesis\objenesis\3.3\objenesis-3.3.jar;C:\work\apache-maven-3.8.8\repo\org\mockito\mockito-junit-jupiter\5.3.1\mockito-junit-jupiter-5.3.1.jar;C:\work\apache-maven-3.8.8\repo\org\skyscreamer\jsonassert\1.5.1\jsonassert-1.5.1.jar;C:\work\apache-maven-3.8.8\repo\com\vaadin\external\google\android-json\0.0.20131108.vaadin1\android-json-0.0.20131108.vaadin1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-core\6.0.12\spring-core-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-jcl\6.0.12\spring-jcl-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-test\6.0.12\spring-test-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\xmlunit\xmlunit-core\2.9.1\xmlunit-core-2.9.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy\4.0.15\groovy-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-ant\4.0.15\groovy-ant-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant\1.10.14\ant-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-junit\1.10.14\ant-junit-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-launcher\1.10.14\ant-launcher-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-antlr\1.10.14\ant-antlr-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-cli-picocli\4.0.15\groovy-cli-picocli-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\info\picocli\picocli\4.7.5\picocli-4.7.5.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-console\4.0.15\groovy-console-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\github\javaparser\javaparser-core\3.25.5\javaparser-core-3.25.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-util\9.5\asm-util-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-tree\9.5\asm-tree-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-analysis\9.5\asm-analysis-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\abego\treelayout\org.abego.treelayout.core\1.0.3\org.abego.treelayout.core-1.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ivy\ivy\2.5.2\ivy-2.5.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-datetime\4.0.15\groovy-datetime-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-docgenerator\4.0.15\groovy-docgenerator-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\thoughtworks\qdox\qdox\1.12.1\qdox-1.12.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-groovydoc\4.0.15\groovy-groovydoc-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-groovysh\4.0.15\groovy-groovysh-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\jline\jline\2.14.6\jline-2.14.6.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-jmx\4.0.15\groovy-jmx-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-json\4.0.15\groovy-json-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-jsr223\4.0.15\groovy-jsr223-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-macro\4.0.15\groovy-macro-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-nio\4.0.15\groovy-nio-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-servlet\4.0.15\groovy-servlet-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-sql\4.0.15\groovy-sql-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-swing\4.0.15\groovy-swing-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-templates\4.0.15\groovy-templates-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-test\4.0.15\groovy-test-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\junit\junit\4.13.2\junit-4.13.2.jar;C:\work\apache-maven-3.8.8\repo\org\hamcrest\hamcrest-core\2.2\hamcrest-core-2.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-test-junit5\4.0.15\groovy-test-junit5-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-xml\4.0.15\groovy-xml-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-yaml\4.0.15\groovy-yaml-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\dataformat\jackson-dataformat-yaml\2.15.2\jackson-dataformat-yaml-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\org\spockframework\spock-core\2.4-M1-groovy-4.0\spock-core-2.4-M1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-engine\1.9.3\junit-platform-engine-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\opentest4j\opentest4j\1.2.0\opentest4j-1.2.0.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-commons\1.9.3\junit-platform-commons-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\apiguardian\apiguardian-api\1.1.2\apiguardian-api-1.1.2.jar;C:\work\apache-maven-3.8.8\repo\org\spockframework\spock-spring\2.4-M1-groovy-4.0\spock-spring-2.4-M1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\com\athaydes\spock-reports\2.5.1-groovy-4.0\spock-reports-2.5.1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\com\github\codemonstur\embedded-redis\1.4.2\embedded-redis-1.4.2.jar;C:\work\apache-maven-3.8.8\repo\redis\clients\jedis\4.3.2\jedis-4.3.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\commons\commons-pool2\2.11.1\commons-pool2-2.11.1.jar;C:\work\apache-maven-3.8.8\repo\org\json\json\20220320\json-20220320.jar;C:\work\apache-maven-3.8.8\repo\com\google\code\gson\gson\2.10.1\gson-2.10.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\kafka\spring-kafka-test\3.0.11\spring-kafka-test-3.0.11.jar;C:\work\apache-maven-3.8.8\repo\org\apache\zookeeper\zookeeper\3.6.3\zookeeper-3.6.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\zookeeper\zookeeper-jute\3.6.3\zookeeper-jute-3.6.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-classes-epoll\4.1.97.Final\netty-transport-classes-epoll-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1-test.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-metadata\3.4.1\kafka-metadata-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-server-common\3.4.1\kafka-server-common-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-raft\3.4.1\kafka-raft-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-streams-test-utils\3.4.1\kafka-streams-test-utils-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-streams\3.4.1\kafka-streams-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\rocksdb\rocksdbjni\7.1.2\rocksdbjni-7.1.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\scala-library\2.13.10\scala-library-2.13.10.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-group-coordinator\3.4.1\kafka-group-coordinator-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-storage\3.4.1\kafka-storage-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-storage-api\3.4.1\kafka-storage-api-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\net\sourceforge\argparse4j\argparse4j\0.7.0\argparse4j-0.7.0.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\module\jackson-module-scala_2.13\2.15.2\jackson-module-scala_2.13-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\thoughtworks\paranamer\paranamer\2.8\paranamer-2.8.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\dataformat\jackson-dataformat-csv\2.15.2\jackson-dataformat-csv-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\net\sf\jopt-simple\jopt-simple\5.0.4\jopt-simple-5.0.4.jar;C:\work\apache-maven-3.8.8\repo\org\bitbucket\b_c\jose4j\0.9.3\jose4j-0.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\modules\scala-collection-compat_2.13\2.10.0\scala-collection-compat_2.13-2.10.0.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\modules\scala-java8-compat_2.13\1.0.2\scala-java8-compat_2.13-1.0.2.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\scala-reflect\2.13.10\scala-reflect-2.13.10.jar;C:\work\apache-maven-3.8.8\repo\com\typesafe\scala-logging\scala-logging_2.13\3.9.4\scala-logging_2.13-3.9.4.jar;C:\work\apache-maven-3.8.8\repo\io\dropwizard\metrics\metrics-core\4.2.19\metrics-core-4.2.19.jar;C:\work\apache-maven-3.8.8\repo\commons-cli\commons-cli\1.4\commons-cli-1.4.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1-test.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-api\5.9.3\junit-jupiter-api-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-launcher\1.9.3\junit-platform-launcher-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\awaitility\awaitility\4.2.0\awaitility-4.2.0.jar;
2024-12-31 21:21:57.602 Server environment:java.library.path=C:\work\jdk-17\bin;C:\windows\Sun\Java\bin;C:\windows\system32;C:\windows;C:\work\python312\Scripts\;C:\work\python312\;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program\Git\cmd;C:\Program\PowerShell\7\;C:\Program Files\dotnet\;C:\Users\joech\AppData\Local\Microsoft\WindowsApps;C:\Users\joech\AppData\Local\GitHubDesktop\bin;C:\Program\Microsoft VS Code\bin;C:\work\apache-maven-3.8.8\bin;C:\Program Files\Tesseract-OCR;C:\work\jdk-17\bin;;.
2024-12-31 21:21:57.602 Server environment:java.io.tmpdir=C:\Users\joech\AppData\Local\Temp\
2024-12-31 21:21:57.602 Server environment:java.compiler=<NA>
2024-12-31 21:21:57.602 Server environment:os.name=Windows 11
2024-12-31 21:21:57.602 Server environment:os.arch=amd64
2024-12-31 21:21:57.602 Server environment:os.version=10.0
2024-12-31 21:21:57.602 Server environment:user.name=joech
2024-12-31 21:21:57.602 Server environment:user.home=C:\Users\joech
2024-12-31 21:21:57.602 Server environment:user.dir=C:\code\hsbc\demo\pong
2024-12-31 21:21:57.602 Server environment:os.memory.free=73MB
2024-12-31 21:21:57.602 Server environment:os.memory.max=15816MB
2024-12-31 21:21:57.602 Server environment:os.memory.total=136MB
2024-12-31 21:21:57.602 zookeeper.enableEagerACLCheck = false
2024-12-31 21:21:57.602 zookeeper.digest.enabled = true
2024-12-31 21:21:57.602 zookeeper.closeSessionTxn.enabled = true
2024-12-31 21:21:57.602 zookeeper.flushDelay=0
2024-12-31 21:21:57.602 zookeeper.maxWriteQueuePollTime=0
2024-12-31 21:21:57.602 zookeeper.maxBatchSize=1000
2024-12-31 21:21:57.602 zookeeper.intBufferStartingSizeBytes = 1024
2024-12-31 21:21:57.610 zookeeper.snapshot.trust.empty : false
2024-12-31 21:21:57.633 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:21:57.633 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:21:57.633 zookeeper.snapshotSizeFactor = 0.33
2024-12-31 21:21:57.633 zookeeper.commitLogCount=500
2024-12-31 21:21:57.648 Weighed connection throttling is disabled
2024-12-31 21:21:57.648 minSessionTimeout set to 1600
2024-12-31 21:21:57.648 maxSessionTimeout set to 16000
2024-12-31 21:21:57.648 Response cache size is initialized with value 400.
2024-12-31 21:21:57.648 Response cache size is initialized with value 400.
2024-12-31 21:21:57.648 zookeeper.pathStats.slotCapacity = 60
2024-12-31 21:21:57.648 zookeeper.pathStats.slotDuration = 15
2024-12-31 21:21:57.648 zookeeper.pathStats.maxDepth = 6
2024-12-31 21:21:57.648 zookeeper.pathStats.initialDelay = 5
2024-12-31 21:21:57.648 zookeeper.pathStats.delay = 5
2024-12-31 21:21:57.648 zookeeper.pathStats.enabled = false
2024-12-31 21:21:57.663 The max bytes for all large requests are set to 104857600
2024-12-31 21:21:57.664 The large request threshold is set to -1
2024-12-31 21:21:57.664 Created server with tickTime 800 minSessionTimeout 1600 maxSessionTimeout 16000 clientPortListenBacklog -1 datadir C:\Users\joech\AppData\Local\Temp\kafka-3294233400948063465\version-2 snapdir C:\Users\joech\AppData\Local\Temp\kafka-6394647617806143615\version-2
2024-12-31 21:21:57.727 maxCnxns is not configured, using default value 0.
2024-12-31 21:21:57.727 Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers.
2024-12-31 21:21:57.727 binding to port /127.0.0.1:0
2024-12-31 21:21:57.758 zookeeper.snapshot.compression.method = CHECKED
2024-12-31 21:21:57.758 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-6394647617806143615\version-2\snapshot.0
2024-12-31 21:21:57.774 Snapshot loaded in 31 ms, highest zxid is 0x0, digest is 1371985504
2024-12-31 21:21:57.774 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-6394647617806143615\version-2\snapshot.0
2024-12-31 21:21:57.780 Snapshot taken in 1 ms
2024-12-31 21:21:57.800 PrepRequestProcessor (sid:0) started, reconfigEnabled=false
2024-12-31 21:21:57.800 zookeeper.request_throttler.shutdownTimeout = 10000
2024-12-31 21:21:58.270 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.239c0e38-5827-4a7f-9fd5-5dd56bdc959a10919128081073841115
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59836
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:21:58.327 Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
2024-12-31 21:21:58.421 starting
2024-12-31 21:21:58.421 Connecting to zookeeper on 127.0.0.1:59836
2024-12-31 21:21:58.453 [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:59836.
2024-12-31 21:22:03.724 Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT
2024-12-31 21:22:03.724 Client environment:host.name=Joe
2024-12-31 21:22:03.724 Client environment:java.version=17.0.12
2024-12-31 21:22:03.724 Client environment:java.vendor=Oracle Corporation
2024-12-31 21:22:03.725 Client environment:java.home=C:\work\jdk-17
2024-12-31 21:22:03.725 Client environment:java.class.path=C:\code\hsbc\demo\pong\target\test-classes;C:\code\hsbc\demo\pong\target\classes;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-webflux\3.1.4\spring-boot-starter-webflux-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter\3.1.4\spring-boot-starter-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot\3.1.4\spring-boot-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-autoconfigure\3.1.4\spring-boot-autoconfigure-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-logging\3.1.4\spring-boot-starter-logging-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\ch\qos\logback\logback-classic\1.4.11\logback-classic-1.4.11.jar;C:\work\apache-maven-3.8.8\repo\ch\qos\logback\logback-core\1.4.11\logback-core-1.4.11.jar;C:\work\apache-maven-3.8.8\repo\org\apache\logging\log4j\log4j-to-slf4j\2.20.0\log4j-to-slf4j-2.20.0.jar;C:\work\apache-maven-3.8.8\repo\org\apache\logging\log4j\log4j-api\2.20.0\log4j-api-2.20.0.jar;C:\work\apache-maven-3.8.8\repo\org\slf4j\jul-to-slf4j\2.0.9\jul-to-slf4j-2.0.9.jar;C:\work\apache-maven-3.8.8\repo\jakarta\annotation\jakarta.annotation-api\2.1.1\jakarta.annotation-api-2.1.1.jar;C:\work\apache-maven-3.8.8\repo\org\yaml\snakeyaml\1.33\snakeyaml-1.33.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-json\3.1.4\spring-boot-starter-json-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-databind\2.15.2\jackson-databind-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-annotations\2.15.2\jackson-annotations-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-core\2.15.2\jackson-core-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.15.2\jackson-datatype-jdk8-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.15.2\jackson-datatype-jsr310-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\module\jackson-module-parameter-names\2.15.2\jackson-module-parameter-names-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-reactor-netty\3.1.4\spring-boot-starter-reactor-netty-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\netty\reactor-netty-http\1.1.11\reactor-netty-http-1.1.11.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-http\4.1.97.Final\netty-codec-http-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-http2\4.1.97.Final\netty-codec-http2-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns\4.1.97.Final\netty-resolver-dns-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-dns\4.1.97.Final\netty-codec-dns-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns-native-macos\4.1.97.Final\netty-resolver-dns-native-macos-4.1.97.Final-osx-x86_64.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns-classes-macos\4.1.97.Final\netty-resolver-dns-classes-macos-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final-linux-x86_64.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\netty\reactor-netty-core\1.1.11\reactor-netty-core-1.1.11.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-handler-proxy\4.1.97.Final\netty-handler-proxy-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-socks\4.1.97.Final\netty-codec-socks-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-web\6.0.12\spring-web-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-beans\6.0.12\spring-beans-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-webflux\6.0.12\spring-webflux-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\reactor-core\3.5.10\reactor-core-3.5.10.jar;C:\work\apache-maven-3.8.8\repo\org\reactivestreams\reactive-streams\1.0.4\reactive-streams-1.0.4.jar;C:\work\apache-maven-3.8.8\repo\com\google\guava\guava\19.0\guava-19.0.jar;C:\work\apache-maven-3.8.8\repo\commons-io\commons-io\2.11.0\commons-io-2.11.0.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-data-redis\3.1.4\spring-boot-starter-data-redis-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-redis\3.1.4\spring-data-redis-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-keyvalue\3.1.4\spring-data-keyvalue-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-oxm\6.0.12\spring-oxm-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-aop\6.0.12\spring-aop-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-context-support\6.0.12\spring-context-support-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\io\lettuce\lettuce-core\6.2.6.RELEASE\lettuce-core-6.2.6.RELEASE.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-common\4.1.97.Final\netty-common-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-handler\4.1.97.Final\netty-handler-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver\4.1.97.Final\netty-resolver-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-buffer\4.1.97.Final\netty-buffer-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-unix-common\4.1.97.Final\netty-transport-native-unix-common-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec\4.1.97.Final\netty-codec-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport\4.1.97.Final\netty-transport-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-data-jpa\3.1.4\spring-boot-starter-data-jpa-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-aop\3.1.4\spring-boot-starter-aop-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\aspectj\aspectjweaver\1.9.20\aspectjweaver-1.9.20.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-jdbc\3.1.4\spring-boot-starter-jdbc-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\zaxxer\HikariCP\5.0.1\HikariCP-5.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-jdbc\6.0.12\spring-jdbc-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\hibernate\orm\hibernate-core\6.2.9.Final\hibernate-core-6.2.9.Final.jar;C:\work\apache-maven-3.8.8\repo\jakarta\persistence\jakarta.persistence-api\3.1.0\jakarta.persistence-api-3.1.0.jar;C:\work\apache-maven-3.8.8\repo\jakarta\transaction\jakarta.transaction-api\2.0.1\jakarta.transaction-api-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\jboss\logging\jboss-logging\3.5.3.Final\jboss-logging-3.5.3.Final.jar;C:\work\apache-maven-3.8.8\repo\org\hibernate\common\hibernate-commons-annotations\6.0.6.Final\hibernate-commons-annotations-6.0.6.Final.jar;C:\work\apache-maven-3.8.8\repo\io\smallrye\jandex\3.0.5\jandex-3.0.5.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\classmate\1.5.1\classmate-1.5.1.jar;C:\work\apache-maven-3.8.8\repo\net\bytebuddy\byte-buddy\1.14.8\byte-buddy-1.14.8.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\jaxb-runtime\4.0.3\jaxb-runtime-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\jaxb-core\4.0.3\jaxb-core-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\eclipse\angus\angus-activation\2.0.1\angus-activation-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\txw2\4.0.3\txw2-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\com\sun\istack\istack-commons-runtime\4.1.2\istack-commons-runtime-4.1.2.jar;C:\work\apache-maven-3.8.8\repo\jakarta\inject\jakarta.inject-api\2.0.1\jakarta.inject-api-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\antlr\antlr4-runtime\4.10.1\antlr4-runtime-4.10.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-jpa\3.1.4\spring-data-jpa-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-commons\3.1.4\spring-data-commons-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-orm\6.0.12\spring-orm-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-aspects\6.0.12\spring-aspects-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\postgresql\postgresql\42.6.0\postgresql-42.6.0.jar;C:\work\apache-maven-3.8.8\repo\org\checkerframework\checker-qual\3.31.0\checker-qual-3.31.0.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\kafka\spring-kafka\3.0.11\spring-kafka-3.0.11.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-context\6.0.12\spring-context-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-expression\6.0.12\spring-expression-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-messaging\6.0.12\spring-messaging-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-tx\6.0.12\spring-tx-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\retry\spring-retry\2.0.3\spring-retry-2.0.3.jar;C:\work\apache-maven-3.8.8\repo\io\micrometer\micrometer-observation\1.11.4\micrometer-observation-1.11.4.jar;C:\work\apache-maven-3.8.8\repo\io\micrometer\micrometer-commons\1.11.4\micrometer-commons-1.11.4.jar;C:\work\apache-maven-3.8.8\repo\com\google\code\findbugs\jsr305\3.0.2\jsr305-3.0.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\com\github\luben\zstd-jni\1.5.2-1\zstd-jni-1.5.2-1.jar;C:\work\apache-maven-3.8.8\repo\org\lz4\lz4-java\1.8.0\lz4-java-1.8.0.jar;C:\work\apache-maven-3.8.8\repo\org\xerial\snappy\snappy-java\1.1.8.4\snappy-java-1.1.8.4.jar;C:\work\apache-maven-3.8.8\repo\org\slf4j\slf4j-api\2.0.9\slf4j-api-2.0.9.jar;C:\work\apache-maven-3.8.8\repo\com\h2database\h2\1.4.200\h2-1.4.200.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-test\3.1.4\spring-boot-starter-test-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-test\3.1.4\spring-boot-test-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-test-autoconfigure\3.1.4\spring-boot-test-autoconfigure-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\jayway\jsonpath\json-path\2.8.0\json-path-2.8.0.jar;C:\work\apache-maven-3.8.8\repo\jakarta\xml\bind\jakarta.xml.bind-api\4.0.1\jakarta.xml.bind-api-4.0.1.jar;C:\work\apache-maven-3.8.8\repo\jakarta\activation\jakarta.activation-api\2.1.2\jakarta.activation-api-2.1.2.jar;C:\work\apache-maven-3.8.8\repo\net\minidev\json-smart\2.4.11\json-smart-2.4.11.jar;C:\work\apache-maven-3.8.8\repo\net\minidev\accessors-smart\2.4.11\accessors-smart-2.4.11.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm\9.3\asm-9.3.jar;C:\work\apache-maven-3.8.8\repo\org\assertj\assertj-core\3.24.2\assertj-core-3.24.2.jar;C:\work\apache-maven-3.8.8\repo\org\hamcrest\hamcrest\2.2\hamcrest-2.2.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter\5.9.3\junit-jupiter-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-params\5.9.3\junit-jupiter-params-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-engine\5.9.3\junit-jupiter-engine-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\mockito\mockito-core\5.3.1\mockito-core-5.3.1.jar;C:\work\apache-maven-3.8.8\repo\net\bytebuddy\byte-buddy-agent\1.14.8\byte-buddy-agent-1.14.8.jar;C:\work\apache-maven-3.8.8\repo\org\objenesis\objenesis\3.3\objenesis-3.3.jar;C:\work\apache-maven-3.8.8\repo\org\mockito\mockito-junit-jupiter\5.3.1\mockito-junit-jupiter-5.3.1.jar;C:\work\apache-maven-3.8.8\repo\org\skyscreamer\jsonassert\1.5.1\jsonassert-1.5.1.jar;C:\work\apache-maven-3.8.8\repo\com\vaadin\external\google\android-json\0.0.20131108.vaadin1\android-json-0.0.20131108.vaadin1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-core\6.0.12\spring-core-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-jcl\6.0.12\spring-jcl-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-test\6.0.12\spring-test-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\xmlunit\xmlunit-core\2.9.1\xmlunit-core-2.9.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy\4.0.15\groovy-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-ant\4.0.15\groovy-ant-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant\1.10.14\ant-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-junit\1.10.14\ant-junit-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-launcher\1.10.14\ant-launcher-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-antlr\1.10.14\ant-antlr-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-cli-picocli\4.0.15\groovy-cli-picocli-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\info\picocli\picocli\4.7.5\picocli-4.7.5.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-console\4.0.15\groovy-console-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\github\javaparser\javaparser-core\3.25.5\javaparser-core-3.25.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-util\9.5\asm-util-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-tree\9.5\asm-tree-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-analysis\9.5\asm-analysis-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\abego\treelayout\org.abego.treelayout.core\1.0.3\org.abego.treelayout.core-1.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ivy\ivy\2.5.2\ivy-2.5.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-datetime\4.0.15\groovy-datetime-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-docgenerator\4.0.15\groovy-docgenerator-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\thoughtworks\qdox\qdox\1.12.1\qdox-1.12.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-groovydoc\4.0.15\groovy-groovydoc-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-groovysh\4.0.15\groovy-groovysh-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\jline\jline\2.14.6\jline-2.14.6.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-jmx\4.0.15\groovy-jmx-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-json\4.0.15\groovy-json-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-jsr223\4.0.15\groovy-jsr223-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-macro\4.0.15\groovy-macro-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-nio\4.0.15\groovy-nio-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-servlet\4.0.15\groovy-servlet-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-sql\4.0.15\groovy-sql-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-swing\4.0.15\groovy-swing-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-templates\4.0.15\groovy-templates-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-test\4.0.15\groovy-test-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\junit\junit\4.13.2\junit-4.13.2.jar;C:\work\apache-maven-3.8.8\repo\org\hamcrest\hamcrest-core\2.2\hamcrest-core-2.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-test-junit5\4.0.15\groovy-test-junit5-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-xml\4.0.15\groovy-xml-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-yaml\4.0.15\groovy-yaml-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\dataformat\jackson-dataformat-yaml\2.15.2\jackson-dataformat-yaml-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\org\spockframework\spock-core\2.4-M1-groovy-4.0\spock-core-2.4-M1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-engine\1.9.3\junit-platform-engine-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\opentest4j\opentest4j\1.2.0\opentest4j-1.2.0.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-commons\1.9.3\junit-platform-commons-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\apiguardian\apiguardian-api\1.1.2\apiguardian-api-1.1.2.jar;C:\work\apache-maven-3.8.8\repo\org\spockframework\spock-spring\2.4-M1-groovy-4.0\spock-spring-2.4-M1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\com\athaydes\spock-reports\2.5.1-groovy-4.0\spock-reports-2.5.1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\com\github\codemonstur\embedded-redis\1.4.2\embedded-redis-1.4.2.jar;C:\work\apache-maven-3.8.8\repo\redis\clients\jedis\4.3.2\jedis-4.3.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\commons\commons-pool2\2.11.1\commons-pool2-2.11.1.jar;C:\work\apache-maven-3.8.8\repo\org\json\json\20220320\json-20220320.jar;C:\work\apache-maven-3.8.8\repo\com\google\code\gson\gson\2.10.1\gson-2.10.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\kafka\spring-kafka-test\3.0.11\spring-kafka-test-3.0.11.jar;C:\work\apache-maven-3.8.8\repo\org\apache\zookeeper\zookeeper\3.6.3\zookeeper-3.6.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\zookeeper\zookeeper-jute\3.6.3\zookeeper-jute-3.6.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-classes-epoll\4.1.97.Final\netty-transport-classes-epoll-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1-test.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-metadata\3.4.1\kafka-metadata-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-server-common\3.4.1\kafka-server-common-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-raft\3.4.1\kafka-raft-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-streams-test-utils\3.4.1\kafka-streams-test-utils-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-streams\3.4.1\kafka-streams-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\rocksdb\rocksdbjni\7.1.2\rocksdbjni-7.1.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\scala-library\2.13.10\scala-library-2.13.10.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-group-coordinator\3.4.1\kafka-group-coordinator-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-storage\3.4.1\kafka-storage-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-storage-api\3.4.1\kafka-storage-api-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\net\sourceforge\argparse4j\argparse4j\0.7.0\argparse4j-0.7.0.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\module\jackson-module-scala_2.13\2.15.2\jackson-module-scala_2.13-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\thoughtworks\paranamer\paranamer\2.8\paranamer-2.8.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\dataformat\jackson-dataformat-csv\2.15.2\jackson-dataformat-csv-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\net\sf\jopt-simple\jopt-simple\5.0.4\jopt-simple-5.0.4.jar;C:\work\apache-maven-3.8.8\repo\org\bitbucket\b_c\jose4j\0.9.3\jose4j-0.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\modules\scala-collection-compat_2.13\2.10.0\scala-collection-compat_2.13-2.10.0.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\modules\scala-java8-compat_2.13\1.0.2\scala-java8-compat_2.13-1.0.2.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\scala-reflect\2.13.10\scala-reflect-2.13.10.jar;C:\work\apache-maven-3.8.8\repo\com\typesafe\scala-logging\scala-logging_2.13\3.9.4\scala-logging_2.13-3.9.4.jar;C:\work\apache-maven-3.8.8\repo\io\dropwizard\metrics\metrics-core\4.2.19\metrics-core-4.2.19.jar;C:\work\apache-maven-3.8.8\repo\commons-cli\commons-cli\1.4\commons-cli-1.4.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1-test.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-api\5.9.3\junit-jupiter-api-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-launcher\1.9.3\junit-platform-launcher-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\awaitility\awaitility\4.2.0\awaitility-4.2.0.jar;
2024-12-31 21:22:03.728 Client environment:java.library.path=C:\work\jdk-17\bin;C:\windows\Sun\Java\bin;C:\windows\system32;C:\windows;C:\work\python312\Scripts\;C:\work\python312\;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program\Git\cmd;C:\Program\PowerShell\7\;C:\Program Files\dotnet\;C:\Users\joech\AppData\Local\Microsoft\WindowsApps;C:\Users\joech\AppData\Local\GitHubDesktop\bin;C:\Program\Microsoft VS Code\bin;C:\work\apache-maven-3.8.8\bin;C:\Program Files\Tesseract-OCR;C:\work\jdk-17\bin;;.
2024-12-31 21:22:03.728 Client environment:java.io.tmpdir=C:\Users\joech\AppData\Local\Temp\
2024-12-31 21:22:03.729 Client environment:java.compiler=<NA>
2024-12-31 21:22:03.729 Client environment:os.name=Windows 11
2024-12-31 21:22:03.729 Client environment:os.arch=amd64
2024-12-31 21:22:03.729 Client environment:os.version=10.0
2024-12-31 21:22:03.729 Client environment:user.name=joech
2024-12-31 21:22:03.729 Client environment:user.home=C:\Users\joech
2024-12-31 21:22:03.729 Client environment:user.dir=C:\code\hsbc\demo\pong
2024-12-31 21:22:03.729 Client environment:os.memory.free=84MB
2024-12-31 21:22:03.729 Client environment:os.memory.max=15816MB
2024-12-31 21:22:03.729 Client environment:os.memory.total=136MB
2024-12-31 21:22:03.735 Initiating client connection, connectString=127.0.0.1:59836 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@3bc2146c
2024-12-31 21:22:03.742 jute.maxbuffer value is 4194304 Bytes
2024-12-31 21:22:03.751 zookeeper.request.timeout value is 0. feature enabled=false
2024-12-31 21:22:03.754 Opening socket connection to server /127.0.0.1:59836.
2024-12-31 21:22:03.754 [ZooKeeperClient Kafka server] Waiting until connected.
2024-12-31 21:22:03.756 Socket connection established, initiating session, client: /127.0.0.1:59837, server: /127.0.0.1:59836
2024-12-31 21:22:03.767 Creating new log file: log.1
2024-12-31 21:22:03.781 ZooKeeper audit is disabled.
2024-12-31 21:22:03.786 Session establishment complete on server /127.0.0.1:59836, session id = 0x100177c6cd70000, negotiated timeout = 16000
2024-12-31 21:22:03.791 [ZooKeeperClient Kafka server] Connected.
2024-12-31 21:22:04.308 Cluster ID = KNbEW-4XQ1GFuDVi83iLDQ
2024-12-31 21:22:04.313 No meta.properties file under dir C:\Users\joech\AppData\Local\Temp\spring.kafka.239c0e38-5827-4a7f-9fd5-5dd56bdc959a10919128081073841115\meta.properties
2024-12-31 21:22:04.376 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.239c0e38-5827-4a7f-9fd5-5dd56bdc959a10919128081073841115
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59836
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:22:04.425 [ThrottledChannelReaper-Fetch]: Starting
2024-12-31 21:22:04.425 [ThrottledChannelReaper-Produce]: Starting
2024-12-31 21:22:04.427 [ThrottledChannelReaper-Request]: Starting
2024-12-31 21:22:04.431 [ThrottledChannelReaper-ControllerMutation]: Starting
2024-12-31 21:22:04.471 Loading logs from log dirs ArraySeq(C:\Users\joech\AppData\Local\Temp\spring.kafka.239c0e38-5827-4a7f-9fd5-5dd56bdc959a10919128081073841115)
2024-12-31 21:22:04.474 Attempting recovery for all logs in C:\Users\joech\AppData\Local\Temp\spring.kafka.239c0e38-5827-4a7f-9fd5-5dd56bdc959a10919128081073841115 since no clean shutdown file was found
2024-12-31 21:22:04.490 Loaded 0 logs in 20ms.
2024-12-31 21:22:04.491 Starting log cleanup with a period of 300000 ms.
2024-12-31 21:22:04.495 Starting log flusher with a default period of 9223372036854775807 ms.
2024-12-31 21:22:04.521 Starting the log cleaner
2024-12-31 21:22:04.540 [kafka-log-cleaner-thread-0]: Starting
2024-12-31 21:22:04.566 [feature-zk-node-event-process-thread]: Starting
2024-12-31 21:22:04.582 Feature ZK node at path: /feature does not exist
2024-12-31 21:22:04.633 [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting
2024-12-31 21:22:05.135 Updated connection-accept-rate max connection creation rate to 2147483647
2024-12-31 21:22:05.144 Awaiting socket connections on localhost:59838.
2024-12-31 21:22:05.185 [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT)
2024-12-31 21:22:05.198 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Starting
2024-12-31 21:22:05.220 [ExpirationReaper-0-Produce]: Starting
2024-12-31 21:22:05.221 [ExpirationReaper-0-Fetch]: Starting
2024-12-31 21:22:05.221 [ExpirationReaper-0-DeleteRecords]: Starting
2024-12-31 21:22:05.222 [ExpirationReaper-0-ElectLeader]: Starting
2024-12-31 21:22:05.248 [LogDirFailureHandler]: Starting
2024-12-31 21:22:05.274 Creating /brokers/ids/0 (is it secure? false)
2024-12-31 21:22:05.301 Stat of the created znode at /brokers/ids/0 is: 25,25,1735651325289,1735651325289,1,0,0,72083417207341056,204,0,25

2024-12-31 21:22:05.302 Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:59838, czxid (broker epoch): 25
2024-12-31 21:22:05.380 [ControllerEventThread controllerId=0] Starting
2024-12-31 21:22:05.385 [ExpirationReaper-0-topic]: Starting
2024-12-31 21:22:05.395 [ExpirationReaper-0-Heartbeat]: Starting
2024-12-31 21:22:05.396 [ExpirationReaper-0-Rebalance]: Starting
2024-12-31 21:22:05.406 Successfully created /controller_epoch with initial epoch 0
2024-12-31 21:22:05.415 [Controller id=0] 0 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1
2024-12-31 21:22:05.420 [Controller id=0] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map())
2024-12-31 21:22:05.424 [GroupCoordinator 0]: Starting up.
2024-12-31 21:22:05.427 Feature ZK node created at path: /feature
2024-12-31 21:22:05.432 [GroupCoordinator 0]: Startup complete.
2024-12-31 21:22:05.468 [TransactionCoordinator id=0] Starting up.
2024-12-31 21:22:05.471 [TransactionCoordinator id=0] Startup complete.
2024-12-31 21:22:05.473 [Transaction Marker Channel Manager 0]: Starting
2024-12-31 21:22:05.479 [MetadataCache brokerId=0] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0).
2024-12-31 21:22:05.479 [Controller id=0] Registering handlers
2024-12-31 21:22:05.484 [Controller id=0] Deleting log dir event notifications
2024-12-31 21:22:05.487 [Controller id=0] Deleting isr change notifications
2024-12-31 21:22:05.489 [Controller id=0] Initializing controller context
2024-12-31 21:22:05.513 [Controller id=0] Initialized broker epochs cache: HashMap(0 -> 25)
2024-12-31 21:22:05.521 [ExpirationReaper-0-AlterAcls]: Starting
2024-12-31 21:22:05.538 [RequestSendThread controllerId=0] Starting
2024-12-31 21:22:05.540 [Controller id=0] Currently active brokers in the cluster: Set(0)
2024-12-31 21:22:05.540 [Controller id=0] Currently shutting brokers in the cluster: HashSet()
2024-12-31 21:22:05.540 [Controller id=0] Current list of topics in the cluster: HashSet()
2024-12-31 21:22:05.542 [Controller id=0] Fetching topic deletions in progress
2024-12-31 21:22:05.545 [Controller id=0] List of topics to be deleted: 
2024-12-31 21:22:05.545 [Controller id=0] List of topics ineligible for deletion: 
2024-12-31 21:22:05.545 [Controller id=0] Initializing topic deletion manager
2024-12-31 21:22:05.546 [Topic Deletion Manager 0] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet()
2024-12-31 21:22:05.548 [Controller id=0] Sending update metadata request
2024-12-31 21:22:05.560 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions
2024-12-31 21:22:05.568 [ReplicaStateMachine controllerId=0] Initializing replica state
2024-12-31 21:22:05.569 [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2024-12-31 21:22:05.569 [/config/changes-event-process-thread]: Starting
2024-12-31 21:22:05.575 [ReplicaStateMachine controllerId=0] Triggering offline replica state changes
2024-12-31 21:22:05.576 [PartitionStateMachine controllerId=0] Initializing partition state
2024-12-31 21:22:05.576 [PartitionStateMachine controllerId=0] Triggering online partition state changes
2024-12-31 21:22:05.581 [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing.
2024-12-31 21:22:05.584 [RequestSendThread controllerId=0] Controller 0 connected to localhost:59838 (id: 0 rack: null) for sending state change requests
2024-12-31 21:22:05.584 [Controller id=0] Ready to serve as the new controller with epoch 1
2024-12-31 21:22:05.587 Kafka version: 3.4.1
2024-12-31 21:22:05.587 Kafka commitId: 8a516edc2755df89
2024-12-31 21:22:05.587 Kafka startTimeMs: 1735651325584
2024-12-31 21:22:05.589 [KafkaServer id=0] started
2024-12-31 21:22:05.590 [Controller id=0] Partitions undergoing preferred replica election: 
2024-12-31 21:22:05.590 [Controller id=0] Partitions that completed preferred replica election: 
2024-12-31 21:22:05.590 [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2024-12-31 21:22:05.590 [Controller id=0] Resuming preferred replica election for partitions: 
2024-12-31 21:22:05.592 [Controller id=0] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered
2024-12-31 21:22:05.596 AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [127.0.0.1:59838]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-31 21:22:05.606 [Controller id=0] Starting the controller scheduler
2024-12-31 21:22:05.640 Kafka version: 3.4.1
2024-12-31 21:22:05.641 Kafka commitId: 8a516edc2755df89
2024-12-31 21:22:05.641 Kafka startTimeMs: 1735651325640
2024-12-31 21:22:05.661 [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use node localhost:59838 (id: 0 rack: null)
2024-12-31 21:22:05.702 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Recorded new controller, from now on will use node localhost:59838 (id: 0 rack: null)
2024-12-31 21:22:05.763 Creating topic pong-message-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0))
2024-12-31 21:22:05.791 [Controller id=0] New topics: [Set(pong-message-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(pong-message-topic,Some(YsEVUHXnS5qLuTh7xtM3MA),Map(pong-message-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), pong-message-topic-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:22:05.792 [Controller id=0] New partition creation callback for pong-message-topic-0,pong-message-topic-1
2024-12-31 21:22:05.794 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:22:05.796 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:22:05.796 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:22:05.800 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:22:05.828 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:22:05.828 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:22:05.831 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2024-12-31 21:22:05.834 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2024-12-31 21:22:05.835 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:22:05.842 [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 for 2 partitions
2024-12-31 21:22:05.880 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(pong-message-topic-0, pong-message-topic-1)
2024-12-31 21:22:05.881 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2024-12-31 21:22:05.978 [LogLoader partition=pong-message-topic-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.239c0e38-5827-4a7f-9fd5-5dd56bdc959a10919128081073841115] Loading producer state till offset 0 with message format version 2
2024-12-31 21:22:06.004 Created log for partition pong-message-topic-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.239c0e38-5827-4a7f-9fd5-5dd56bdc959a10919128081073841115\pong-message-topic-0 with properties {}
2024-12-31 21:22:06.007 [Partition pong-message-topic-0 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-0
2024-12-31 21:22:06.008 [Partition pong-message-topic-0 broker=0] Log loaded for partition pong-message-topic-0 with initial high watermark 0
2024-12-31 21:22:06.008 [Broker id=0] Leader pong-message-topic-0 with topic id Some(YsEVUHXnS5qLuTh7xtM3MA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:22:06.028 [LogLoader partition=pong-message-topic-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.239c0e38-5827-4a7f-9fd5-5dd56bdc959a10919128081073841115] Loading producer state till offset 0 with message format version 2
2024-12-31 21:22:06.028 Created log for partition pong-message-topic-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.239c0e38-5827-4a7f-9fd5-5dd56bdc959a10919128081073841115\pong-message-topic-1 with properties {}
2024-12-31 21:22:06.028 [Partition pong-message-topic-1 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-1
2024-12-31 21:22:06.028 [Partition pong-message-topic-1 broker=0] Log loaded for partition pong-message-topic-1 with initial high watermark 0
2024-12-31 21:22:06.028 [Broker id=0] Leader pong-message-topic-1 with topic id Some(YsEVUHXnS5qLuTh7xtM3MA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:22:06.039 [Broker id=0] Finished LeaderAndIsr request in 201ms correlationId 1 from controller 0 for 2 partitions
2024-12-31 21:22:06.048 [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2
2024-12-31 21:22:06.058 App info kafka.admin.client for adminclient-1 unregistered
2024-12-31 21:22:06.061 Metrics scheduler closed
2024-12-31 21:22:06.061 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:22:06.061 Metrics reporters closed
2024-12-31 21:22:06.412 

Found multiple occurrences of org.json.JSONObject on the class path:

	jar:file:/C:/work/apache-maven-3.8.8/repo/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar!/org/json/JSONObject.class
	jar:file:/C:/work/apache-maven-3.8.8/repo/org/json/json/20220320/json-20220320.jar!/org/json/JSONObject.class

You may wish to exclude one of them to ensure predictable runtime behavior

2024-12-31 21:22:06.430 zookeeper.snapshot.trust.empty : false
2024-12-31 21:22:06.436 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:22:06.436 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:22:06.436 zookeeper.snapshotSizeFactor = 0.33
2024-12-31 21:22:06.436 zookeeper.commitLogCount=500
2024-12-31 21:22:06.436 minSessionTimeout set to 1600
2024-12-31 21:22:06.436 maxSessionTimeout set to 16000
2024-12-31 21:22:06.436 Response cache size is initialized with value 400.
2024-12-31 21:22:06.436 Response cache size is initialized with value 400.
2024-12-31 21:22:06.436 zookeeper.pathStats.slotCapacity = 60
2024-12-31 21:22:06.436 zookeeper.pathStats.slotDuration = 15
2024-12-31 21:22:06.436 zookeeper.pathStats.maxDepth = 6
2024-12-31 21:22:06.436 zookeeper.pathStats.initialDelay = 5
2024-12-31 21:22:06.436 zookeeper.pathStats.delay = 5
2024-12-31 21:22:06.436 zookeeper.pathStats.enabled = false
2024-12-31 21:22:06.436 The max bytes for all large requests are set to 104857600
2024-12-31 21:22:06.436 The large request threshold is set to -1
2024-12-31 21:22:06.436 Created server with tickTime 800 minSessionTimeout 1600 maxSessionTimeout 16000 clientPortListenBacklog -1 datadir C:\Users\joech\AppData\Local\Temp\kafka-1753426049784779434\version-2 snapdir C:\Users\joech\AppData\Local\Temp\kafka-5884682363666256124\version-2
2024-12-31 21:22:06.436 maxCnxns is not configured, using default value 0.
2024-12-31 21:22:06.436 Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers.
2024-12-31 21:22:06.441 binding to port /127.0.0.1:0
2024-12-31 21:22:06.443 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-5884682363666256124\version-2\snapshot.0
2024-12-31 21:22:06.443 Snapshot loaded in 2 ms, highest zxid is 0x0, digest is 1371985504
2024-12-31 21:22:06.443 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-5884682363666256124\version-2\snapshot.0
2024-12-31 21:22:06.444 Snapshot taken in 0 ms
2024-12-31 21:22:06.444 PrepRequestProcessor (sid:0) started, reconfigEnabled=false
2024-12-31 21:22:06.447 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.af8c9535-4bea-4862-98a9-e307eefd3d145213641681946135822
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59842
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:22:06.450 starting
2024-12-31 21:22:06.450 Connecting to zookeeper on 127.0.0.1:59842
2024-12-31 21:22:06.452 [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:59842.
2024-12-31 21:22:06.452 Initiating client connection, connectString=127.0.0.1:59842 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@637ae337
2024-12-31 21:22:06.453 jute.maxbuffer value is 4194304 Bytes
2024-12-31 21:22:06.453 zookeeper.request.timeout value is 0. feature enabled=false
2024-12-31 21:22:06.454 [ZooKeeperClient Kafka server] Waiting until connected.
2024-12-31 21:22:06.454 Opening socket connection to server /127.0.0.1:59842.
2024-12-31 21:22:06.454 Socket connection established, initiating session, client: /127.0.0.1:59843, server: /127.0.0.1:59842
2024-12-31 21:22:06.456 Creating new log file: log.1
2024-12-31 21:22:06.457 Session establishment complete on server /127.0.0.1:59842, session id = 0x100177c8eac0000, negotiated timeout = 16000
2024-12-31 21:22:06.458 [ZooKeeperClient Kafka server] Connected.
2024-12-31 21:22:06.487 Cluster ID = sPdKxXcOTyOGAsm5LarLCw
2024-12-31 21:22:06.487 No meta.properties file under dir C:\Users\joech\AppData\Local\Temp\spring.kafka.af8c9535-4bea-4862-98a9-e307eefd3d145213641681946135822\meta.properties
2024-12-31 21:22:06.495 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.af8c9535-4bea-4862-98a9-e307eefd3d145213641681946135822
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59842
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:22:06.508 [ThrottledChannelReaper-Produce]: Starting
2024-12-31 21:22:06.508 [ThrottledChannelReaper-Fetch]: Starting
2024-12-31 21:22:06.508 [ThrottledChannelReaper-Request]: Starting
2024-12-31 21:22:06.508 [ThrottledChannelReaper-ControllerMutation]: Starting
2024-12-31 21:22:06.518 Loading logs from log dirs ArraySeq(C:\Users\joech\AppData\Local\Temp\spring.kafka.af8c9535-4bea-4862-98a9-e307eefd3d145213641681946135822)
2024-12-31 21:22:06.518 Attempting recovery for all logs in C:\Users\joech\AppData\Local\Temp\spring.kafka.af8c9535-4bea-4862-98a9-e307eefd3d145213641681946135822 since no clean shutdown file was found
2024-12-31 21:22:06.519 Loaded 0 logs in 1ms.
2024-12-31 21:22:06.519 Starting log cleanup with a period of 300000 ms.
2024-12-31 21:22:06.519 Starting log flusher with a default period of 9223372036854775807 ms.
2024-12-31 21:22:06.520 Starting the log cleaner
2024-12-31 21:22:06.521 [kafka-log-cleaner-thread-0]: Starting
2024-12-31 21:22:06.521 [feature-zk-node-event-process-thread]: Starting
2024-12-31 21:22:06.523 Feature ZK node at path: /feature does not exist
2024-12-31 21:22:06.525 [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting
2024-12-31 21:22:06.541 Updated connection-accept-rate max connection creation rate to 2147483647
2024-12-31 21:22:06.543 Awaiting socket connections on localhost:59844.
2024-12-31 21:22:06.550 [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT)
2024-12-31 21:22:06.552 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Starting
2024-12-31 21:22:06.553 [ExpirationReaper-0-Produce]: Starting
2024-12-31 21:22:06.554 [ExpirationReaper-0-Fetch]: Starting
2024-12-31 21:22:06.554 [ExpirationReaper-0-DeleteRecords]: Starting
2024-12-31 21:22:06.555 [ExpirationReaper-0-ElectLeader]: Starting
2024-12-31 21:22:06.556 [LogDirFailureHandler]: Starting
2024-12-31 21:22:06.559 Creating /brokers/ids/0 (is it secure? false)
2024-12-31 21:22:06.562 Stat of the created znode at /brokers/ids/0 is: 25,25,1735651326560,1735651326560,1,0,0,72083417774948352,204,0,25

2024-12-31 21:22:06.562 Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:59844, czxid (broker epoch): 25
2024-12-31 21:22:06.571 [ControllerEventThread controllerId=0] Starting
2024-12-31 21:22:06.571 [ExpirationReaper-0-topic]: Starting
2024-12-31 21:22:06.572 [ExpirationReaper-0-Heartbeat]: Starting
2024-12-31 21:22:06.572 [ExpirationReaper-0-Rebalance]: Starting
2024-12-31 21:22:06.572 [GroupCoordinator 0]: Starting up.
2024-12-31 21:22:06.574 [GroupCoordinator 0]: Startup complete.
2024-12-31 21:22:06.575 Successfully created /controller_epoch with initial epoch 0
2024-12-31 21:22:06.576 [TransactionCoordinator id=0] Starting up.
2024-12-31 21:22:06.578 [Controller id=0] 0 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1
2024-12-31 21:22:06.578 [TransactionCoordinator id=0] Startup complete.
2024-12-31 21:22:06.578 [Controller id=0] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map())
2024-12-31 21:22:06.578 [Transaction Marker Channel Manager 0]: Starting
2024-12-31 21:22:06.579 Feature ZK node created at path: /feature
2024-12-31 21:22:06.579 [ExpirationReaper-0-AlterAcls]: Starting
2024-12-31 21:22:06.580 [Controller id=0] Registering handlers
2024-12-31 21:22:06.580 [MetadataCache brokerId=0] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0).
2024-12-31 21:22:06.582 [Controller id=0] Deleting log dir event notifications
2024-12-31 21:22:06.583 [Controller id=0] Deleting isr change notifications
2024-12-31 21:22:06.583 [/config/changes-event-process-thread]: Starting
2024-12-31 21:22:06.583 [Controller id=0] Initializing controller context
2024-12-31 21:22:06.586 [Controller id=0] Initialized broker epochs cache: HashMap(0 -> 25)
2024-12-31 21:22:06.586 [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing.
2024-12-31 21:22:06.588 Kafka version: 3.4.1
2024-12-31 21:22:06.588 Kafka commitId: 8a516edc2755df89
2024-12-31 21:22:06.588 Kafka startTimeMs: 1735651326588
2024-12-31 21:22:06.592 [Controller id=0] Currently active brokers in the cluster: Set(0)
2024-12-31 21:22:06.592 [RequestSendThread controllerId=0] Starting
2024-12-31 21:22:06.592 [Controller id=0] Currently shutting brokers in the cluster: HashSet()
2024-12-31 21:22:06.592 [Controller id=0] Current list of topics in the cluster: HashSet()
2024-12-31 21:22:06.592 [Controller id=0] Fetching topic deletions in progress
2024-12-31 21:22:06.594 [Controller id=0] List of topics to be deleted: 
2024-12-31 21:22:06.588 Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.server:type=app-info,id=0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1865)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:960)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:895)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:523)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:563)
	at kafka.utils.TestUtils$.createServer(TestUtils.scala:188)
	at kafka.utils.TestUtils$.createServer(TestUtils.scala:182)
	at kafka.utils.TestUtils.createServer(TestUtils.scala)
	at org.springframework.kafka.test.EmbeddedKafkaBroker.afterPropertiesSet(EmbeddedKafkaBroker.java:369)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1817)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1766)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:410)
	at org.springframework.kafka.test.context.EmbeddedKafkaContextCustomizer.customizeContext(EmbeddedKafkaContextCustomizer.java:116)
	at org.springframework.boot.test.context.SpringBootContextLoader$ContextCustomizerAdapter.initialize(SpringBootContextLoader.java:435)
	at org.springframework.boot.SpringApplication.applyInitializers(SpringApplication.java:610)
	at org.springframework.boot.SpringApplication.prepareContext(SpringApplication.java:390)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:314)
	at org.springframework.boot.test.context.SpringBootContextLoader.lambda$loadContext$3(SpringBootContextLoader.java:137)
	at org.springframework.util.function.ThrowingSupplier.get(ThrowingSupplier.java:58)
	at org.springframework.util.function.ThrowingSupplier.get(ThrowingSupplier.java:46)
	at org.springframework.boot.SpringApplication.withHook(SpringApplication.java:1409)
	at org.springframework.boot.test.context.SpringBootContextLoader$ContextLoaderHook.run(SpringBootContextLoader.java:545)
	at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:137)
	at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:108)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:187)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:119)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:127)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:141)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:97)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:241)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:56)
	at org.spockframework.spring.SpringInterceptor.interceptInitializerMethod(SpringInterceptor.java:46)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:24)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:101)
	at org.spockframework.runtime.PlatformSpecRunner.invoke(PlatformSpecRunner.java:398)
	at org.spockframework.runtime.PlatformSpecRunner.runInitializer(PlatformSpecRunner.java:259)
	at org.spockframework.runtime.PlatformSpecRunner.runInitializer(PlatformSpecRunner.java:254)
	at org.spockframework.runtime.IterationNode.prepare(IterationNode.java:31)
	at org.spockframework.runtime.IterationNode.prepare(IterationNode.java:13)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$prepare$2(NodeTestTask.java:123)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.prepare(NodeTestTask.java:123)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:90)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:226)
	at org.spockframework.runtime.ParameterizedFeatureChildExecutor.execute(ParameterizedFeatureChildExecutor.java:104)
	at org.spockframework.runtime.PlatformParameterizedSpecRunner$1.runIteration(PlatformParameterizedSpecRunner.java:72)
	at org.spockframework.runtime.extension.IDataDriver.lambda$static$0(IDataDriver.java:37)
	at org.spockframework.runtime.PlatformParameterizedSpecRunner.runParameterizedFeature(PlatformParameterizedSpecRunner.java:47)
	at org.spockframework.runtime.ParameterizedFeatureNode.execute(ParameterizedFeatureNode.java:40)
	at org.spockframework.runtime.ParameterizedFeatureNode.execute(ParameterizedFeatureNode.java:16)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.spockframework.runtime.SpockNode.sneakyInvoke(SpockNode.java:40)
	at org.spockframework.runtime.FeatureNode.lambda$around$0(FeatureNode.java:41)
	at org.spockframework.runtime.PlatformSpecRunner.lambda$createMethodInfoForDoRunFeature$4(PlatformSpecRunner.java:199)
	at org.spockframework.runtime.model.MethodInfo.invoke(MethodInfo.java:156)
	at org.spockframework.runtime.PlatformSpecRunner.invokeRaw(PlatformSpecRunner.java:407)
	at org.spockframework.runtime.PlatformSpecRunner.invoke(PlatformSpecRunner.java:390)
	at org.spockframework.runtime.PlatformSpecRunner.runFeature(PlatformSpecRunner.java:192)
	at org.spockframework.runtime.FeatureNode.around(FeatureNode.java:41)
	at org.spockframework.runtime.FeatureNode.around(FeatureNode.java:12)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1511)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.spockframework.runtime.SpockNode.sneakyInvoke(SpockNode.java:40)
	at org.spockframework.runtime.SpecNode.lambda$around$0(SpecNode.java:63)
	at org.spockframework.runtime.PlatformSpecRunner.lambda$createMethodInfoForDoRunSpec$0(PlatformSpecRunner.java:61)
	at org.spockframework.runtime.model.MethodInfo.invoke(MethodInfo.java:156)
	at org.spockframework.runtime.PlatformSpecRunner.invokeRaw(PlatformSpecRunner.java:407)
	at org.spockframework.runtime.PlatformSpecRunner.invoke(PlatformSpecRunner.java:390)
	at org.spockframework.runtime.PlatformSpecRunner.runSpec(PlatformSpecRunner.java:55)
	at org.spockframework.runtime.SpecNode.around(SpecNode.java:63)
	at org.spockframework.runtime.SpecNode.around(SpecNode.java:11)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1511)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:147)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:127)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:90)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:55)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:102)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:150)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2024-12-31 21:22:06.594 [KafkaServer id=0] started
2024-12-31 21:22:06.594 [Controller id=0] List of topics ineligible for deletion: 
2024-12-31 21:22:06.594 [Controller id=0] Initializing topic deletion manager
2024-12-31 21:22:06.594 [Topic Deletion Manager 0] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet()
2024-12-31 21:22:06.594 [Controller id=0] Sending update metadata request
2024-12-31 21:22:06.594 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions
2024-12-31 21:22:06.595 [ReplicaStateMachine controllerId=0] Initializing replica state
2024-12-31 21:22:06.595 [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2024-12-31 21:22:06.595 AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [127.0.0.1:59844]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-31 21:22:06.595 [ReplicaStateMachine controllerId=0] Triggering offline replica state changes
2024-12-31 21:22:06.595 [PartitionStateMachine controllerId=0] Initializing partition state
2024-12-31 21:22:06.595 [PartitionStateMachine controllerId=0] Triggering online partition state changes
2024-12-31 21:22:06.595 [Controller id=0] Ready to serve as the new controller with epoch 1
2024-12-31 21:22:06.595 [RequestSendThread controllerId=0] Controller 0 connected to localhost:59844 (id: 0 rack: null) for sending state change requests
2024-12-31 21:22:06.598 [Controller id=0] Partitions undergoing preferred replica election: 
2024-12-31 21:22:06.598 Kafka version: 3.4.1
2024-12-31 21:22:06.598 [Controller id=0] Partitions that completed preferred replica election: 
2024-12-31 21:22:06.598 Kafka commitId: 8a516edc2755df89
2024-12-31 21:22:06.598 [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2024-12-31 21:22:06.598 Kafka startTimeMs: 1735651326598
2024-12-31 21:22:06.598 [Controller id=0] Resuming preferred replica election for partitions: 
2024-12-31 21:22:06.598 [Controller id=0] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered
2024-12-31 21:22:06.601 [Controller id=0] Starting the controller scheduler
2024-12-31 21:22:06.613 Creating topic pong-message-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2024-12-31 21:22:06.620 [Controller id=0] New topics: [Set(pong-message-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(pong-message-topic,Some(2BBSSGA2Ry2cOLoLkrM7PQ),Map(pong-message-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:22:06.620 [Controller id=0] New partition creation callback for pong-message-topic-0
2024-12-31 21:22:06.620 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:22:06.621 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:22:06.621 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:22:06.625 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:22:06.625 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions
2024-12-31 21:22:06.625 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 1 partitions
2024-12-31 21:22:06.626 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:22:06.626 [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 for 1 partitions
2024-12-31 21:22:06.626 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(pong-message-topic-0)
2024-12-31 21:22:06.628 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions
2024-12-31 21:22:06.628 [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use node localhost:59844 (id: 0 rack: null)
2024-12-31 21:22:06.638 [LogLoader partition=pong-message-topic-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.af8c9535-4bea-4862-98a9-e307eefd3d145213641681946135822] Loading producer state till offset 0 with message format version 2
2024-12-31 21:22:06.639 Created log for partition pong-message-topic-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.af8c9535-4bea-4862-98a9-e307eefd3d145213641681946135822\pong-message-topic-0 with properties {}
2024-12-31 21:22:06.640 [Partition pong-message-topic-0 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-0
2024-12-31 21:22:06.640 [Partition pong-message-topic-0 broker=0] Log loaded for partition pong-message-topic-0 with initial high watermark 0
2024-12-31 21:22:06.640 [Broker id=0] Leader pong-message-topic-0 with topic id Some(2BBSSGA2Ry2cOLoLkrM7PQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:22:06.643 [Broker id=0] Finished LeaderAndIsr request in 17ms correlationId 1 from controller 0 for 1 partitions
2024-12-31 21:22:06.645 [Broker id=0] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2
2024-12-31 21:22:06.647 App info kafka.admin.client for adminclient-2 unregistered
2024-12-31 21:22:06.648 Metrics scheduler closed
2024-12-31 21:22:06.648 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:22:06.648 Metrics reporters closed
2024-12-31 21:22:06.654 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Recorded new controller, from now on will use node localhost:59844 (id: 0 rack: null)
2024-12-31 21:22:06.657 Starting PongControllerSpec using Java 17.0.12 with PID 2608 (started by joech in C:\code\hsbc\demo\pong)
2024-12-31 21:22:06.658 No active profile set, falling back to 1 default profile: "default"
2024-12-31 21:22:07.322 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:22:07.325 Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2024-12-31 21:22:07.479 Finished Spring Data repository scanning in 142 ms. Found 1 JPA repository interfaces.
2024-12-31 21:22:07.502 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:22:07.504 Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2024-12-31 21:22:07.524 Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.demo.dao.MessageRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2024-12-31 21:22:07.524 Finished Spring Data repository scanning in 7 ms. Found 0 Redis repository interfaces.
2024-12-31 21:22:08.277 HHH000204: Processing PersistenceUnitInfo [name: default]
2024-12-31 21:22:08.355 HHH000412: Hibernate ORM core version 6.2.9.Final
2024-12-31 21:22:08.359 HHH000406: Using bytecode reflection optimizer
2024-12-31 21:22:08.563 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:22:08.764 No LoadTimeWeaver setup: ignoring JPA class transformer
2024-12-31 21:22:08.795 HikariPool-1 - Starting...
2024-12-31 21:22:09.106 HikariPool-1 - Added connection conn0: url=jdbc:h2:mem:testdb user=SA
2024-12-31 21:22:09.109 HikariPool-1 - Start completed.
2024-12-31 21:22:09.480 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:22:10.287 HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2024-12-31 21:22:10.399 Initialized JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:22:10.608 [Controller id=0] Processing automatic preferred replica leader election
2024-12-31 21:22:11.602 [Controller id=0] Processing automatic preferred replica leader election
2024-12-31 21:22:11.864 Netty started on port 59848
2024-12-31 21:22:11.898 ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:59838]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-pong-service-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = pong-service
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2024-12-31 21:22:11.945 These configurations '[spring.json.trusted.packages]' were supplied but are not used yet.
2024-12-31 21:22:11.945 Kafka version: 3.4.1
2024-12-31 21:22:11.945 Kafka commitId: 8a516edc2755df89
2024-12-31 21:22:11.945 Kafka startTimeMs: 1735651331945
2024-12-31 21:22:11.946 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Subscribed to topic(s): pong-message-topic
2024-12-31 21:22:11.964 Started PongControllerSpec in 5.82 seconds (process running for 22.695)
2024-12-31 21:22:11.976 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting the last seen epoch of partition pong-message-topic-0 to 0 since the associated topicId changed from null to YsEVUHXnS5qLuTh7xtM3MA
2024-12-31 21:22:11.976 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting the last seen epoch of partition pong-message-topic-1 to 0 since the associated topicId changed from null to YsEVUHXnS5qLuTh7xtM3MA
2024-12-31 21:22:11.978 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Cluster ID: KNbEW-4XQ1GFuDVi83iLDQ
2024-12-31 21:22:11.978 Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0))
2024-12-31 21:22:11.986 [Controller id=0] New topics: [Set(__consumer_offsets)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(__consumer_offsets,Some(iuKTVPiyRzqEazEqIizaNg),HashMap(__consumer_offsets-4 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-3 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-2 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:22:11.986 [Controller id=0] New partition creation callback for __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2024-12-31 21:22:11.986 [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:22:11.986 [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:22:11.986 [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:22:11.986 [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:22:11.987 [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:22:11.987 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:22:11.987 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:22:11.996 [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:22:11.996 [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:22:11.996 [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:22:11.996 [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:22:11.996 [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:22:11.996 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 5 become-leader and 0 become-follower partitions
2024-12-31 21:22:11.997 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 5 partitions
2024-12-31 21:22:11.997 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:22:11.998 [Broker id=0] Handling LeaderAndIsr request correlationId 3 from controller 0 for 5 partitions
2024-12-31 21:22:12.001 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-4, __consumer_offsets-3, __consumer_offsets-2, __consumer_offsets-0, __consumer_offsets-1)
2024-12-31 21:22:12.001 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 3 from controller 0 epoch 1 as part of the become-leader transition for 5 partitions
2024-12-31 21:22:12.012 [LogLoader partition=__consumer_offsets-3, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.239c0e38-5827-4a7f-9fd5-5dd56bdc959a10919128081073841115] Loading producer state till offset 0 with message format version 2
2024-12-31 21:22:12.013 Created log for partition __consumer_offsets-3 in C:\Users\joech\AppData\Local\Temp\spring.kafka.239c0e38-5827-4a7f-9fd5-5dd56bdc959a10919128081073841115\__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:22:12.014 [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
2024-12-31 21:22:12.014 [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0
2024-12-31 21:22:12.015 [Broker id=0] Leader __consumer_offsets-3 with topic id Some(iuKTVPiyRzqEazEqIizaNg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:22:12.023 [LogLoader partition=__consumer_offsets-2, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.239c0e38-5827-4a7f-9fd5-5dd56bdc959a10919128081073841115] Loading producer state till offset 0 with message format version 2
2024-12-31 21:22:12.024 Created log for partition __consumer_offsets-2 in C:\Users\joech\AppData\Local\Temp\spring.kafka.239c0e38-5827-4a7f-9fd5-5dd56bdc959a10919128081073841115\__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:22:12.024 [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
2024-12-31 21:22:12.024 [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0
2024-12-31 21:22:12.024 [Broker id=0] Leader __consumer_offsets-2 with topic id Some(iuKTVPiyRzqEazEqIizaNg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:22:12.032 [LogLoader partition=__consumer_offsets-4, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.239c0e38-5827-4a7f-9fd5-5dd56bdc959a10919128081073841115] Loading producer state till offset 0 with message format version 2
2024-12-31 21:22:12.033 Created log for partition __consumer_offsets-4 in C:\Users\joech\AppData\Local\Temp\spring.kafka.239c0e38-5827-4a7f-9fd5-5dd56bdc959a10919128081073841115\__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:22:12.033 [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
2024-12-31 21:22:12.033 [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0
2024-12-31 21:22:12.033 [Broker id=0] Leader __consumer_offsets-4 with topic id Some(iuKTVPiyRzqEazEqIizaNg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:22:12.042 [LogLoader partition=__consumer_offsets-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.239c0e38-5827-4a7f-9fd5-5dd56bdc959a10919128081073841115] Loading producer state till offset 0 with message format version 2
2024-12-31 21:22:12.043 Created log for partition __consumer_offsets-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.239c0e38-5827-4a7f-9fd5-5dd56bdc959a10919128081073841115\__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:22:12.043 [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
2024-12-31 21:22:12.043 [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0
2024-12-31 21:22:12.043 [Broker id=0] Leader __consumer_offsets-1 with topic id Some(iuKTVPiyRzqEazEqIizaNg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:22:12.052 [LogLoader partition=__consumer_offsets-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.239c0e38-5827-4a7f-9fd5-5dd56bdc959a10919128081073841115] Loading producer state till offset 0 with message format version 2
2024-12-31 21:22:12.053 Created log for partition __consumer_offsets-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.239c0e38-5827-4a7f-9fd5-5dd56bdc959a10919128081073841115\__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:22:12.053 [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
2024-12-31 21:22:12.054 [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0
2024-12-31 21:22:12.054 [Broker id=0] Leader __consumer_offsets-0 with topic id Some(iuKTVPiyRzqEazEqIizaNg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:22:12.056 [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 0
2024-12-31 21:22:12.057 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0
2024-12-31 21:22:12.058 [GroupCoordinator 0]: Elected as the group coordinator for partition 2 in epoch 0
2024-12-31 21:22:12.058 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0
2024-12-31 21:22:12.058 [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 0
2024-12-31 21:22:12.058 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0
2024-12-31 21:22:12.058 [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 0
2024-12-31 21:22:12.058 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0
2024-12-31 21:22:12.058 [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 0
2024-12-31 21:22:12.059 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0
2024-12-31 21:22:12.059 [Broker id=0] Finished LeaderAndIsr request in 62ms correlationId 3 from controller 0 for 5 partitions
2024-12-31 21:22:12.061 [Broker id=0] Add 5 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 4
2024-12-31 21:22:12.062 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 5 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler.
2024-12-31 21:22:12.063 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 5 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler.
2024-12-31 21:22:12.063 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler.
2024-12-31 21:22:12.063 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler.
2024-12-31 21:22:12.063 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler.
2024-12-31 21:22:12.078 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Discovered group coordinator localhost:59838 (id: 2147483647 rack: null)
2024-12-31 21:22:12.081 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] (Re-)joining group
2024-12-31 21:22:12.099 [GroupCoordinator 0]: Dynamic member with unknown member id joins group pong-service in Empty state. Created a new member id consumer-pong-service-1-d06e15a6-521c-424f-8a25-fd50a2acbfb0 and request the member to rejoin with this id.
2024-12-31 21:22:12.102 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: need to re-join with the given member-id: consumer-pong-service-1-d06e15a6-521c-424f-8a25-fd50a2acbfb0
2024-12-31 21:22:12.102 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2024-12-31 21:22:12.102 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] (Re-)joining group
2024-12-31 21:22:12.108 [GroupCoordinator 0]: Preparing to rebalance group pong-service in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-pong-service-1-d06e15a6-521c-424f-8a25-fd50a2acbfb0 with group instance id None; client reason: rebalance failed due to MemberIdRequiredException)
2024-12-31 21:22:12.113 [GroupCoordinator 0]: Stabilized group pong-service generation 1 (__consumer_offsets-2) with 1 members
2024-12-31 21:22:12.115 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Successfully joined group with generation Generation{generationId=1, memberId='consumer-pong-service-1-d06e15a6-521c-424f-8a25-fd50a2acbfb0', protocol='range'}
2024-12-31 21:22:12.117 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Finished assignment for group at generation 1: {consumer-pong-service-1-d06e15a6-521c-424f-8a25-fd50a2acbfb0=Assignment(partitions=[pong-message-topic-0, pong-message-topic-1])}
2024-12-31 21:22:12.124 [GroupCoordinator 0]: Assignment received from leader consumer-pong-service-1-d06e15a6-521c-424f-8a25-fd50a2acbfb0 for group pong-service for generation 1. The group has 1 members, 0 of which are static.
2024-12-31 21:22:12.169 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Successfully synced group in generation Generation{generationId=1, memberId='consumer-pong-service-1-d06e15a6-521c-424f-8a25-fd50a2acbfb0', protocol='range'}
2024-12-31 21:22:12.169 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Notifying assignor about the new Assignment(partitions=[pong-message-topic-0, pong-message-topic-1])
2024-12-31 21:22:12.173 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Adding newly assigned partitions: pong-message-topic-0, pong-message-topic-1
2024-12-31 21:22:12.180 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-0
2024-12-31 21:22:12.180 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-1
2024-12-31 21:22:12.183 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-0
2024-12-31 21:22:12.183 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-1
2024-12-31 21:22:12.195 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting offset for partition pong-message-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:59838 (id: 0 rack: null)], epoch=0}}.
2024-12-31 21:22:12.196 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting offset for partition pong-message-topic-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:59838 (id: 0 rack: null)], epoch=0}}.
2024-12-31 21:22:12.212 pong-service: partitions assigned: [pong-message-topic-0, pong-message-topic-1]
2024-12-31 21:22:12.970 Received ping message: Hello
2024-12-31 21:22:12.980 Idempotence will be disabled because acks is set to 0, not set to 'all'.
2024-12-31 21:22:12.981 ProducerConfig values: 
	acks = 0
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:59838]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2024-12-31 21:22:13.004 Kafka version: 3.4.1
2024-12-31 21:22:13.004 Kafka commitId: 8a516edc2755df89
2024-12-31 21:22:13.004 Kafka startTimeMs: 1735651333004
2024-12-31 21:22:13.009 [Producer clientId=producer-1] Cluster ID: KNbEW-4XQ1GFuDVi83iLDQ
2024-12-31 21:22:13.012 [Producer clientId=producer-1] Resetting the last seen epoch of partition pong-message-topic-0 to 0 since the associated topicId changed from null to YsEVUHXnS5qLuTh7xtM3MA
2024-12-31 21:22:13.012 [Producer clientId=producer-1] Resetting the last seen epoch of partition pong-message-topic-1 to 0 since the associated topicId changed from null to YsEVUHXnS5qLuTh7xtM3MA
2024-12-31 21:22:14.318 Received ping message: Hello
2024-12-31 21:22:14.321 Received ping message: Hello
2024-12-31 21:22:14.321 Throttling request as too many requests in the same second
2024-12-31 21:22:14.832 [KafkaServer id=0] shutting down
2024-12-31 21:22:14.833 [KafkaServer id=0] Starting controlled shutdown
2024-12-31 21:22:14.845 [Controller id=0] Shutting down broker 0
2024-12-31 21:22:14.850 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:22:14.856 [KafkaServer id=0] Controlled shutdown request returned successfully after 16ms
2024-12-31 21:22:14.859 [/config/changes-event-process-thread]: Shutting down
2024-12-31 21:22:14.860 [/config/changes-event-process-thread]: Shutdown completed
2024-12-31 21:22:14.860 [/config/changes-event-process-thread]: Stopped
2024-12-31 21:22:14.860 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
2024-12-31 21:22:14.864 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:22:14.864 [Producer clientId=producer-1] Node 0 disconnected.
2024-12-31 21:22:14.867 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Cancelled in-flight FETCH request with correlation id 24 due to node 0 being disconnected (elapsed time since creation: 22ms, elapsed time since send: 22ms, request timeout: 30000ms)
2024-12-31 21:22:14.867 [Producer clientId=producer-1] Node -1 disconnected.
2024-12-31 21:22:14.867 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 2147483647 disconnected.
2024-12-31 21:22:14.867 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Error sending fetch request (sessionId=1486322865, epoch=7) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2024-12-31 21:22:14.868 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Group coordinator localhost:59838 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
2024-12-31 21:22:14.868 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors
2024-12-31 21:22:14.868 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:22:14.869 [data-plane Kafka Request Handler on Broker 0], shutting down
2024-12-31 21:22:14.869 [data-plane Kafka Request Handler on Broker 0], shut down completely
2024-12-31 21:22:14.872 [ExpirationReaper-0-AlterAcls]: Shutting down
2024-12-31 21:22:14.877 [ExpirationReaper-0-AlterAcls]: Shutdown completed
2024-12-31 21:22:14.877 [ExpirationReaper-0-AlterAcls]: Stopped
2024-12-31 21:22:14.878 [KafkaApi-0] Shutdown complete.
2024-12-31 21:22:14.879 [ExpirationReaper-0-topic]: Shutting down
2024-12-31 21:22:14.879 [ExpirationReaper-0-topic]: Stopped
2024-12-31 21:22:14.879 [ExpirationReaper-0-topic]: Shutdown completed
2024-12-31 21:22:14.882 [TransactionCoordinator id=0] Shutting down.
2024-12-31 21:22:14.882 [Transaction State Manager 0]: Shutdown complete
2024-12-31 21:22:14.882 [Transaction Marker Channel Manager 0]: Shutting down
2024-12-31 21:22:14.883 [Transaction Marker Channel Manager 0]: Shutdown completed
2024-12-31 21:22:14.883 [Transaction Marker Channel Manager 0]: Stopped
2024-12-31 21:22:14.883 [TransactionCoordinator id=0] Shutdown complete.
2024-12-31 21:22:14.884 [GroupCoordinator 0]: Shutting down.
2024-12-31 21:22:14.884 [ExpirationReaper-0-Heartbeat]: Shutting down
2024-12-31 21:22:14.884 [ExpirationReaper-0-Heartbeat]: Shutdown completed
2024-12-31 21:22:14.884 [ExpirationReaper-0-Heartbeat]: Stopped
2024-12-31 21:22:14.885 [ExpirationReaper-0-Rebalance]: Shutting down
2024-12-31 21:22:14.886 [ExpirationReaper-0-Rebalance]: Stopped
2024-12-31 21:22:14.886 [ExpirationReaper-0-Rebalance]: Shutdown completed
2024-12-31 21:22:14.886 [GroupCoordinator 0]: Shutdown complete.
2024-12-31 21:22:14.887 [ReplicaManager broker=0] Shutting down
2024-12-31 21:22:14.887 [LogDirFailureHandler]: Shutting down
2024-12-31 21:22:14.887 [LogDirFailureHandler]: Stopped
2024-12-31 21:22:14.887 [LogDirFailureHandler]: Shutdown completed
2024-12-31 21:22:14.888 [ReplicaFetcherManager on broker 0] shutting down
2024-12-31 21:22:14.889 [ReplicaFetcherManager on broker 0] shutdown completed
2024-12-31 21:22:14.889 [ReplicaAlterLogDirsManager on broker 0] shutting down
2024-12-31 21:22:14.890 [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2024-12-31 21:22:14.890 [ExpirationReaper-0-Fetch]: Shutting down
2024-12-31 21:22:14.890 [ExpirationReaper-0-Fetch]: Shutdown completed
2024-12-31 21:22:14.890 [ExpirationReaper-0-Fetch]: Stopped
2024-12-31 21:22:14.890 [ExpirationReaper-0-Produce]: Shutting down
2024-12-31 21:22:14.891 [ExpirationReaper-0-Produce]: Stopped
2024-12-31 21:22:14.891 [ExpirationReaper-0-Produce]: Shutdown completed
2024-12-31 21:22:14.892 [ExpirationReaper-0-DeleteRecords]: Shutting down
2024-12-31 21:22:14.892 [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2024-12-31 21:22:14.892 [ExpirationReaper-0-DeleteRecords]: Stopped
2024-12-31 21:22:14.892 [ExpirationReaper-0-ElectLeader]: Shutting down
2024-12-31 21:22:14.893 [ExpirationReaper-0-ElectLeader]: Shutdown completed
2024-12-31 21:22:14.893 [ExpirationReaper-0-ElectLeader]: Stopped
2024-12-31 21:22:14.900 [ReplicaManager broker=0] Shut down completely
2024-12-31 21:22:14.902 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutting down
2024-12-31 21:22:14.902 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Stopped
2024-12-31 21:22:14.902 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutdown completed
2024-12-31 21:22:14.904 Broker to controller channel manager for alterPartition shutdown
2024-12-31 21:22:14.905 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down
2024-12-31 21:22:14.905 [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped
2024-12-31 21:22:14.905 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed
2024-12-31 21:22:14.906 Broker to controller channel manager for forwarding shutdown
2024-12-31 21:22:14.908 Shutting down.
2024-12-31 21:22:14.910 Shutting down the log cleaner.
2024-12-31 21:22:14.912 [kafka-log-cleaner-thread-0]: Shutting down
2024-12-31 21:22:14.916 [kafka-log-cleaner-thread-0]: Stopped
2024-12-31 21:22:14.916 [kafka-log-cleaner-thread-0]: Shutdown completed
2024-12-31 21:22:14.966 [Producer clientId=producer-1] Node 0 disconnected.
2024-12-31 21:22:14.966 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:22:14.966 [ProducerStateManager partition=pong-message-topic-1] Wrote producer snapshot at offset 3 with 0 producer ids in 5 ms.
2024-12-31 21:22:14.966 [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:59838) could not be established. Broker may not be available.
2024-12-31 21:22:14.966 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node 0 (localhost/127.0.0.1:59838) could not be established. Broker may not be available.
2024-12-31 21:22:14.980 [ProducerStateManager partition=__consumer_offsets-2] Wrote producer snapshot at offset 6 with 0 producer ids in 3 ms.
2024-12-31 21:22:15.000 Shutdown complete.
2024-12-31 21:22:15.001 [ControllerEventThread controllerId=0] Shutting down
2024-12-31 21:22:15.001 [ControllerEventThread controllerId=0] Stopped
2024-12-31 21:22:15.001 [ControllerEventThread controllerId=0] Shutdown completed
2024-12-31 21:22:15.003 [PartitionStateMachine controllerId=0] Stopped partition state machine
2024-12-31 21:22:15.003 [ReplicaStateMachine controllerId=0] Stopped replica state machine
2024-12-31 21:22:15.004 [RequestSendThread controllerId=0] Shutting down
2024-12-31 21:22:15.005 [RequestSendThread controllerId=0] Shutdown completed
2024-12-31 21:22:15.005 [RequestSendThread controllerId=0] Stopped
2024-12-31 21:22:15.007 [Controller id=0] Resigned
2024-12-31 21:22:15.008 [feature-zk-node-event-process-thread]: Shutting down
2024-12-31 21:22:15.009 [feature-zk-node-event-process-thread]: Shutdown completed
2024-12-31 21:22:15.009 [feature-zk-node-event-process-thread]: Stopped
2024-12-31 21:22:15.010 [ZooKeeperClient Kafka server] Closing.
2024-12-31 21:22:15.068 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:22:15.068 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node 0 (localhost/127.0.0.1:59838) could not be established. Broker may not be available.
2024-12-31 21:22:15.118 EventThread shut down for session: 0x100177c6cd70000
2024-12-31 21:22:15.118 Session: 0x100177c6cd70000 closed
2024-12-31 21:22:15.119 [Producer clientId=producer-1] Node 0 disconnected.
2024-12-31 21:22:15.119 [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:59838) could not be established. Broker may not be available.
2024-12-31 21:22:15.120 [ZooKeeperClient Kafka server] Closed.
2024-12-31 21:22:15.120 [ThrottledChannelReaper-Fetch]: Shutting down
2024-12-31 21:22:15.123 [ThrottledChannelReaper-Fetch]: Stopped
2024-12-31 21:22:15.123 [ThrottledChannelReaper-Fetch]: Shutdown completed
2024-12-31 21:22:15.123 [ThrottledChannelReaper-Produce]: Shutting down
2024-12-31 21:22:15.123 [ThrottledChannelReaper-Produce]: Stopped
2024-12-31 21:22:15.123 [ThrottledChannelReaper-Produce]: Shutdown completed
2024-12-31 21:22:15.123 [ThrottledChannelReaper-Request]: Shutting down
2024-12-31 21:22:15.123 [ThrottledChannelReaper-Request]: Shutdown completed
2024-12-31 21:22:15.123 [ThrottledChannelReaper-Request]: Stopped
2024-12-31 21:22:15.123 [ThrottledChannelReaper-ControllerMutation]: Shutting down
2024-12-31 21:22:15.124 [ThrottledChannelReaper-ControllerMutation]: Stopped
2024-12-31 21:22:15.124 [ThrottledChannelReaper-ControllerMutation]: Shutdown completed
2024-12-31 21:22:15.125 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server
2024-12-31 21:22:15.146 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed
2024-12-31 21:22:15.146 Metrics scheduler closed
2024-12-31 21:22:15.148 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:22:15.148 Metrics reporters closed
2024-12-31 21:22:15.149 Broker and topic stats closed
2024-12-31 21:22:15.150 App info kafka.server for 0 unregistered
2024-12-31 21:22:15.150 [KafkaServer id=0] shut down completed
2024-12-31 21:22:15.166 ConnnectionExpirerThread interrupted
2024-12-31 21:22:15.166 selector thread exitted run method
2024-12-31 21:22:15.166 selector thread exitted run method
2024-12-31 21:22:15.168 accept thread exitted run method
2024-12-31 21:22:15.168 shutting down
2024-12-31 21:22:15.168 Shutting down
2024-12-31 21:22:15.168 Draining request throttler queue
2024-12-31 21:22:15.168 RequestThrottler shutdown. Dropped 0 requests
2024-12-31 21:22:15.168 Shutting down
2024-12-31 21:22:15.168 Shutting down
2024-12-31 21:22:15.168 Shutting down
2024-12-31 21:22:15.168 PrepRequestProcessor exited loop!
2024-12-31 21:22:15.168 SyncRequestProcessor exited!
2024-12-31 21:22:15.168 shutdown of request processor complete
2024-12-31 21:22:15.202 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Revoke previously assigned partitions pong-message-topic-0, pong-message-topic-1
2024-12-31 21:22:15.203 pong-service: partitions revoked: [pong-message-topic-0, pong-message-topic-1]
2024-12-31 21:22:15.203 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:22:15.203 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:22:15.203 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Unsubscribed all topics or patterns and assigned partitions
2024-12-31 21:22:15.204 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:22:15.204 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:22:15.204 Metrics scheduler closed
2024-12-31 21:22:15.204 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:22:15.204 Metrics reporters closed
2024-12-31 21:22:15.206 App info kafka.consumer for consumer-pong-service-1 unregistered
2024-12-31 21:22:15.206 pong-service: Consumer stopped
2024-12-31 21:22:15.214 [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2024-12-31 21:22:15.219 Metrics scheduler closed
2024-12-31 21:22:15.220 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:22:15.220 Metrics reporters closed
2024-12-31 21:22:15.220 App info kafka.producer for producer-1 unregistered
2024-12-31 21:22:15.244 Closing JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:22:15.247 HikariPool-1 - Shutdown initiated...
2024-12-31 21:22:15.250 HikariPool-1 - Shutdown completed.
2024-12-31 21:22:15.491 SessionTrackerImpl exited loop!
2024-12-31 21:22:17.277 [KafkaServer id=0] shutting down
2024-12-31 21:22:17.277 [/config/changes-event-process-thread]: Shutting down
2024-12-31 21:22:17.277 [/config/changes-event-process-thread]: Stopped
2024-12-31 21:22:17.277 [/config/changes-event-process-thread]: Shutdown completed
2024-12-31 21:22:17.277 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
2024-12-31 21:22:17.281 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors
2024-12-31 21:22:17.282 [data-plane Kafka Request Handler on Broker 0], shutting down
2024-12-31 21:22:17.282 [data-plane Kafka Request Handler on Broker 0], shut down completely
2024-12-31 21:22:17.283 [ExpirationReaper-0-AlterAcls]: Shutting down
2024-12-31 21:22:17.283 [ExpirationReaper-0-AlterAcls]: Stopped
2024-12-31 21:22:17.283 [ExpirationReaper-0-AlterAcls]: Shutdown completed
2024-12-31 21:22:17.285 [KafkaApi-0] Shutdown complete.
2024-12-31 21:22:17.285 [ExpirationReaper-0-topic]: Shutting down
2024-12-31 21:22:17.285 [ExpirationReaper-0-topic]: Stopped
2024-12-31 21:22:17.285 [ExpirationReaper-0-topic]: Shutdown completed
2024-12-31 21:22:17.285 [TransactionCoordinator id=0] Shutting down.
2024-12-31 21:22:17.285 [Transaction State Manager 0]: Shutdown complete
2024-12-31 21:22:17.285 [Transaction Marker Channel Manager 0]: Shutting down
2024-12-31 21:22:17.286 [Transaction Marker Channel Manager 0]: Stopped
2024-12-31 21:22:17.286 [Transaction Marker Channel Manager 0]: Shutdown completed
2024-12-31 21:22:17.286 [TransactionCoordinator id=0] Shutdown complete.
2024-12-31 21:22:17.286 [GroupCoordinator 0]: Shutting down.
2024-12-31 21:22:17.287 [ExpirationReaper-0-Heartbeat]: Shutting down
2024-12-31 21:22:17.287 [ExpirationReaper-0-Heartbeat]: Shutdown completed
2024-12-31 21:22:17.287 [ExpirationReaper-0-Heartbeat]: Stopped
2024-12-31 21:22:17.287 [ExpirationReaper-0-Rebalance]: Shutting down
2024-12-31 21:22:17.287 [ExpirationReaper-0-Rebalance]: Shutdown completed
2024-12-31 21:22:17.287 [ExpirationReaper-0-Rebalance]: Stopped
2024-12-31 21:22:17.287 [GroupCoordinator 0]: Shutdown complete.
2024-12-31 21:22:17.287 [ReplicaManager broker=0] Shutting down
2024-12-31 21:22:17.287 [LogDirFailureHandler]: Shutting down
2024-12-31 21:22:17.287 [LogDirFailureHandler]: Shutdown completed
2024-12-31 21:22:17.287 [LogDirFailureHandler]: Stopped
2024-12-31 21:22:17.287 [ReplicaFetcherManager on broker 0] shutting down
2024-12-31 21:22:17.287 [ReplicaFetcherManager on broker 0] shutdown completed
2024-12-31 21:22:17.287 [ReplicaAlterLogDirsManager on broker 0] shutting down
2024-12-31 21:22:17.287 [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2024-12-31 21:22:17.287 [ExpirationReaper-0-Fetch]: Shutting down
2024-12-31 21:22:17.288 [ExpirationReaper-0-Fetch]: Stopped
2024-12-31 21:22:17.288 [ExpirationReaper-0-Fetch]: Shutdown completed
2024-12-31 21:22:17.288 [ExpirationReaper-0-Produce]: Shutting down
2024-12-31 21:22:17.288 [ExpirationReaper-0-Produce]: Stopped
2024-12-31 21:22:17.288 [ExpirationReaper-0-Produce]: Shutdown completed
2024-12-31 21:22:17.288 [ExpirationReaper-0-DeleteRecords]: Shutting down
2024-12-31 21:22:17.288 [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2024-12-31 21:22:17.288 [ExpirationReaper-0-DeleteRecords]: Stopped
2024-12-31 21:22:17.288 [ExpirationReaper-0-ElectLeader]: Shutting down
2024-12-31 21:22:17.290 [ExpirationReaper-0-ElectLeader]: Shutdown completed
2024-12-31 21:22:17.290 [ExpirationReaper-0-ElectLeader]: Stopped
2024-12-31 21:22:17.298 [ReplicaManager broker=0] Shut down completely
2024-12-31 21:22:17.298 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutting down
2024-12-31 21:22:17.298 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Stopped
2024-12-31 21:22:17.298 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutdown completed
2024-12-31 21:22:17.299 Broker to controller channel manager for alterPartition shutdown
2024-12-31 21:22:17.299 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down
2024-12-31 21:22:17.299 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed
2024-12-31 21:22:17.299 [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped
2024-12-31 21:22:17.299 Broker to controller channel manager for forwarding shutdown
2024-12-31 21:22:17.299 Shutting down.
2024-12-31 21:22:17.299 Shutting down the log cleaner.
2024-12-31 21:22:17.299 [kafka-log-cleaner-thread-0]: Shutting down
2024-12-31 21:22:17.300 [kafka-log-cleaner-thread-0]: Shutdown completed
2024-12-31 21:22:17.300 [kafka-log-cleaner-thread-0]: Stopped
2024-12-31 21:22:17.310 Shutdown complete.
2024-12-31 21:22:17.310 [ControllerEventThread controllerId=0] Shutting down
2024-12-31 21:22:17.311 [ControllerEventThread controllerId=0] Shutdown completed
2024-12-31 21:22:17.311 [ControllerEventThread controllerId=0] Stopped
2024-12-31 21:22:17.311 [PartitionStateMachine controllerId=0] Stopped partition state machine
2024-12-31 21:22:17.311 [ReplicaStateMachine controllerId=0] Stopped replica state machine
2024-12-31 21:22:17.311 [RequestSendThread controllerId=0] Shutting down
2024-12-31 21:22:17.311 [RequestSendThread controllerId=0] Stopped
2024-12-31 21:22:17.311 [RequestSendThread controllerId=0] Shutdown completed
2024-12-31 21:22:17.313 [Controller id=0] Resigned
2024-12-31 21:22:17.313 [feature-zk-node-event-process-thread]: Shutting down
2024-12-31 21:22:17.313 [feature-zk-node-event-process-thread]: Stopped
2024-12-31 21:22:17.313 [feature-zk-node-event-process-thread]: Shutdown completed
2024-12-31 21:22:17.313 [ZooKeeperClient Kafka server] Closing.
2024-12-31 21:22:17.416 Session: 0x100177c8eac0000 closed
2024-12-31 21:22:17.416 EventThread shut down for session: 0x100177c8eac0000
2024-12-31 21:22:17.416 [ZooKeeperClient Kafka server] Closed.
2024-12-31 21:22:17.416 [ThrottledChannelReaper-Fetch]: Shutting down
2024-12-31 21:22:17.416 [ThrottledChannelReaper-Fetch]: Stopped
2024-12-31 21:22:17.416 [ThrottledChannelReaper-Fetch]: Shutdown completed
2024-12-31 21:22:17.416 [ThrottledChannelReaper-Produce]: Shutting down
2024-12-31 21:22:17.417 [ThrottledChannelReaper-Produce]: Shutdown completed
2024-12-31 21:22:17.417 [ThrottledChannelReaper-Produce]: Stopped
2024-12-31 21:22:17.417 [ThrottledChannelReaper-Request]: Shutting down
2024-12-31 21:22:17.417 [ThrottledChannelReaper-Request]: Stopped
2024-12-31 21:22:17.417 [ThrottledChannelReaper-Request]: Shutdown completed
2024-12-31 21:22:17.417 [ThrottledChannelReaper-ControllerMutation]: Shutting down
2024-12-31 21:22:17.417 [ThrottledChannelReaper-ControllerMutation]: Shutdown completed
2024-12-31 21:22:17.417 [ThrottledChannelReaper-ControllerMutation]: Stopped
2024-12-31 21:22:17.417 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server
2024-12-31 21:22:17.431 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed
2024-12-31 21:22:17.431 Metrics scheduler closed
2024-12-31 21:22:17.431 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:22:17.431 Metrics reporters closed
2024-12-31 21:22:17.431 Broker and topic stats closed
2024-12-31 21:22:17.431 App info kafka.server for 0 unregistered
2024-12-31 21:22:17.431 [KafkaServer id=0] shut down completed
2024-12-31 21:22:17.437 ConnnectionExpirerThread interrupted
2024-12-31 21:22:17.437 accept thread exitted run method
2024-12-31 21:22:17.437 selector thread exitted run method
2024-12-31 21:22:17.437 selector thread exitted run method
2024-12-31 21:22:17.439 shutting down
2024-12-31 21:22:17.441 Shutting down
2024-12-31 21:22:17.441 Draining request throttler queue
2024-12-31 21:22:17.441 RequestThrottler shutdown. Dropped 0 requests
2024-12-31 21:22:17.441 Shutting down
2024-12-31 21:22:17.441 Shutting down
2024-12-31 21:22:17.441 Shutting down
2024-12-31 21:22:17.441 SyncRequestProcessor exited!
2024-12-31 21:22:17.441 PrepRequestProcessor exited loop!
2024-12-31 21:22:17.441 shutdown of request processor complete
2024-12-31 21:22:17.901 SessionTrackerImpl exited loop!
2024-12-31 21:22:17.948 

Found multiple occurrences of org.json.JSONObject on the class path:

	jar:file:/C:/work/apache-maven-3.8.8/repo/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar!/org/json/JSONObject.class
	jar:file:/C:/work/apache-maven-3.8.8/repo/org/json/json/20220320/json-20220320.jar!/org/json/JSONObject.class

You may wish to exclude one of them to ensure predictable runtime behavior

2024-12-31 21:22:17.948 Starting MessageRepositorySpec using Java 17.0.12 with PID 2608 (started by joech in C:\code\hsbc\demo\pong)
2024-12-31 21:22:17.948 No active profile set, falling back to 1 default profile: "default"
2024-12-31 21:22:18.082 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:22:18.082 Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2024-12-31 21:22:18.097 Finished Spring Data repository scanning in 13 ms. Found 1 JPA repository interfaces.
2024-12-31 21:22:18.112 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:22:18.112 Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2024-12-31 21:22:18.116 Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.demo.dao.MessageRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2024-12-31 21:22:18.116 Finished Spring Data repository scanning in 4 ms. Found 0 Redis repository interfaces.
2024-12-31 21:22:18.208 HHH000204: Processing PersistenceUnitInfo [name: default]
2024-12-31 21:22:18.224 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:22:18.224 No LoadTimeWeaver setup: ignoring JPA class transformer
2024-12-31 21:22:18.224 HikariPool-2 - Starting...
2024-12-31 21:22:18.231 HikariPool-2 - Added connection conn10: url=jdbc:h2:mem:testdb user=SA
2024-12-31 21:22:18.231 HikariPool-2 - Start completed.
2024-12-31 21:22:18.239 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:22:18.272 HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2024-12-31 21:22:18.298 Initialized JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:22:18.549 ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:59838]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-pong-service-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = pong-service
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2024-12-31 21:22:18.557 These configurations '[spring.json.trusted.packages]' were supplied but are not used yet.
2024-12-31 21:22:18.557 Kafka version: 3.4.1
2024-12-31 21:22:18.557 Kafka commitId: 8a516edc2755df89
2024-12-31 21:22:18.557 Kafka startTimeMs: 1735651338557
2024-12-31 21:22:18.557 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Subscribed to topic(s): pong-message-topic
2024-12-31 21:22:18.559 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:22:18.559 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Connection to node -1 (/127.0.0.1:59838) could not be established. Broker may not be available.
2024-12-31 21:22:18.559 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Bootstrap broker 127.0.0.1:59838 (id: -1 rack: null) disconnected
2024-12-31 21:22:18.559 Started MessageRepositorySpec in 0.65 seconds (process running for 29.293)
2024-12-31 21:22:18.607 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:22:18.607 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:22:18.607 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Unsubscribed all topics or patterns and assigned partitions
2024-12-31 21:22:18.607 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:22:18.607 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:22:18.607 Metrics scheduler closed
2024-12-31 21:22:18.607 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:22:18.607 Metrics reporters closed
2024-12-31 21:22:18.611 App info kafka.consumer for consumer-pong-service-2 unregistered
2024-12-31 21:22:18.611 pong-service: Consumer stopped
2024-12-31 21:22:18.615 Closing JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:22:18.615 HikariPool-2 - Shutdown initiated...
2024-12-31 21:22:18.615 HikariPool-2 - Shutdown completed.
2024-12-31 21:22:18.644 zookeeper.snapshot.trust.empty : false
2024-12-31 21:22:18.644 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:22:18.644 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2024-12-31 21:22:18.644 zookeeper.snapshotSizeFactor = 0.33
2024-12-31 21:22:18.644 zookeeper.commitLogCount=500
2024-12-31 21:22:18.644 minSessionTimeout set to 1600
2024-12-31 21:22:18.644 maxSessionTimeout set to 16000
2024-12-31 21:22:18.644 Response cache size is initialized with value 400.
2024-12-31 21:22:18.644 Response cache size is initialized with value 400.
2024-12-31 21:22:18.644 zookeeper.pathStats.slotCapacity = 60
2024-12-31 21:22:18.644 zookeeper.pathStats.slotDuration = 15
2024-12-31 21:22:18.644 zookeeper.pathStats.maxDepth = 6
2024-12-31 21:22:18.644 zookeeper.pathStats.initialDelay = 5
2024-12-31 21:22:18.644 zookeeper.pathStats.delay = 5
2024-12-31 21:22:18.644 zookeeper.pathStats.enabled = false
2024-12-31 21:22:18.644 The max bytes for all large requests are set to 104857600
2024-12-31 21:22:18.644 The large request threshold is set to -1
2024-12-31 21:22:18.644 Created server with tickTime 800 minSessionTimeout 1600 maxSessionTimeout 16000 clientPortListenBacklog -1 datadir C:\Users\joech\AppData\Local\Temp\kafka-8782041697651106014\version-2 snapdir C:\Users\joech\AppData\Local\Temp\kafka-6894326521264627571\version-2
2024-12-31 21:22:18.644 maxCnxns is not configured, using default value 0.
2024-12-31 21:22:18.644 Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers.
2024-12-31 21:22:18.644 binding to port /127.0.0.1:0
2024-12-31 21:22:18.654 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-6894326521264627571\version-2\snapshot.0
2024-12-31 21:22:18.655 Snapshot loaded in 2 ms, highest zxid is 0x0, digest is 1371985504
2024-12-31 21:22:18.655 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-6894326521264627571\version-2\snapshot.0
2024-12-31 21:22:18.656 Snapshot taken in 0 ms
2024-12-31 21:22:18.657 PrepRequestProcessor (sid:0) started, reconfigEnabled=false
2024-12-31 21:22:18.660 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.e09e53d3-0823-4ee1-a6fa-a6970ab9f9ad3972579820972232185
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59865
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:22:18.663 starting
2024-12-31 21:22:18.665 Connecting to zookeeper on 127.0.0.1:59865
2024-12-31 21:22:18.665 [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:59865.
2024-12-31 21:22:18.665 Initiating client connection, connectString=127.0.0.1:59865 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@662e6d47
2024-12-31 21:22:18.667 jute.maxbuffer value is 4194304 Bytes
2024-12-31 21:22:18.667 zookeeper.request.timeout value is 0. feature enabled=false
2024-12-31 21:22:18.669 [ZooKeeperClient Kafka server] Waiting until connected.
2024-12-31 21:22:18.669 Opening socket connection to server /127.0.0.1:59865.
2024-12-31 21:22:18.669 Socket connection established, initiating session, client: /127.0.0.1:59866, server: /127.0.0.1:59865
2024-12-31 21:22:18.670 Creating new log file: log.1
2024-12-31 21:22:18.677 Session establishment complete on server /127.0.0.1:59865, session id = 0x100177cbe600000, negotiated timeout = 16000
2024-12-31 21:22:18.678 [ZooKeeperClient Kafka server] Connected.
2024-12-31 21:22:18.714 Cluster ID = _c_USp2ITvmmzqxj9tXvvQ
2024-12-31 21:22:18.714 No meta.properties file under dir C:\Users\joech\AppData\Local\Temp\spring.kafka.e09e53d3-0823-4ee1-a6fa-a6970ab9f9ad3972579820972232185\meta.properties
2024-12-31 21:22:18.726 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.e09e53d3-0823-4ee1-a6fa-a6970ab9f9ad3972579820972232185
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:59865
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2024-12-31 21:22:18.732 [ThrottledChannelReaper-Produce]: Starting
2024-12-31 21:22:18.732 [ThrottledChannelReaper-Fetch]: Starting
2024-12-31 21:22:18.732 [ThrottledChannelReaper-Request]: Starting
2024-12-31 21:22:18.733 [ThrottledChannelReaper-ControllerMutation]: Starting
2024-12-31 21:22:18.743 Loading logs from log dirs ArraySeq(C:\Users\joech\AppData\Local\Temp\spring.kafka.e09e53d3-0823-4ee1-a6fa-a6970ab9f9ad3972579820972232185)
2024-12-31 21:22:18.744 Attempting recovery for all logs in C:\Users\joech\AppData\Local\Temp\spring.kafka.e09e53d3-0823-4ee1-a6fa-a6970ab9f9ad3972579820972232185 since no clean shutdown file was found
2024-12-31 21:22:18.746 Loaded 0 logs in 1ms.
2024-12-31 21:22:18.746 Starting log cleanup with a period of 300000 ms.
2024-12-31 21:22:18.746 Starting log flusher with a default period of 9223372036854775807 ms.
2024-12-31 21:22:18.748 Starting the log cleaner
2024-12-31 21:22:18.749 [kafka-log-cleaner-thread-0]: Starting
2024-12-31 21:22:18.749 [feature-zk-node-event-process-thread]: Starting
2024-12-31 21:22:18.750 Feature ZK node at path: /feature does not exist
2024-12-31 21:22:18.754 [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting
2024-12-31 21:22:18.770 Updated connection-accept-rate max connection creation rate to 2147483647
2024-12-31 21:22:18.774 Awaiting socket connections on localhost:59867.
2024-12-31 21:22:18.783 [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT)
2024-12-31 21:22:18.786 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Starting
2024-12-31 21:22:18.787 [ExpirationReaper-0-Produce]: Starting
2024-12-31 21:22:18.787 [ExpirationReaper-0-Fetch]: Starting
2024-12-31 21:22:18.787 [ExpirationReaper-0-DeleteRecords]: Starting
2024-12-31 21:22:18.789 [ExpirationReaper-0-ElectLeader]: Starting
2024-12-31 21:22:18.792 [LogDirFailureHandler]: Starting
2024-12-31 21:22:18.794 Creating /brokers/ids/0 (is it secure? false)
2024-12-31 21:22:18.797 Stat of the created znode at /brokers/ids/0 is: 25,25,1735651338794,1735651338794,1,0,0,72083418575273984,204,0,25

2024-12-31 21:22:18.797 Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:59867, czxid (broker epoch): 25
2024-12-31 21:22:18.807 [ControllerEventThread controllerId=0] Starting
2024-12-31 21:22:18.808 [ExpirationReaper-0-topic]: Starting
2024-12-31 21:22:18.809 [ExpirationReaper-0-Heartbeat]: Starting
2024-12-31 21:22:18.809 [ExpirationReaper-0-Rebalance]: Starting
2024-12-31 21:22:18.809 [GroupCoordinator 0]: Starting up.
2024-12-31 21:22:18.810 [GroupCoordinator 0]: Startup complete.
2024-12-31 21:22:18.812 Successfully created /controller_epoch with initial epoch 0
2024-12-31 21:22:18.814 [TransactionCoordinator id=0] Starting up.
2024-12-31 21:22:18.816 [TransactionCoordinator id=0] Startup complete.
2024-12-31 21:22:18.815 [Controller id=0] 0 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1
2024-12-31 21:22:18.816 [Transaction Marker Channel Manager 0]: Starting
2024-12-31 21:22:18.817 [Controller id=0] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map())
2024-12-31 21:22:18.817 [ExpirationReaper-0-AlterAcls]: Starting
2024-12-31 21:22:18.818 Feature ZK node created at path: /feature
2024-12-31 21:22:18.820 [Controller id=0] Registering handlers
2024-12-31 21:22:18.820 [MetadataCache brokerId=0] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0).
2024-12-31 21:22:18.820 [/config/changes-event-process-thread]: Starting
2024-12-31 21:22:18.822 [Controller id=0] Deleting log dir event notifications
2024-12-31 21:22:18.823 [Controller id=0] Deleting isr change notifications
2024-12-31 21:22:18.823 [Controller id=0] Initializing controller context
2024-12-31 21:22:18.825 [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing.
2024-12-31 21:22:18.826 Kafka version: 3.4.1
2024-12-31 21:22:18.826 Kafka commitId: 8a516edc2755df89
2024-12-31 21:22:18.826 Kafka startTimeMs: 1735651338826
2024-12-31 21:22:18.826 [KafkaServer id=0] started
2024-12-31 21:22:18.827 [Controller id=0] Initialized broker epochs cache: HashMap(0 -> 25)
2024-12-31 21:22:18.827 AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [127.0.0.1:59867]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-12-31 21:22:18.832 Kafka version: 3.4.1
2024-12-31 21:22:18.832 Kafka commitId: 8a516edc2755df89
2024-12-31 21:22:18.832 Kafka startTimeMs: 1735651338832
2024-12-31 21:22:18.833 [RequestSendThread controllerId=0] Starting
2024-12-31 21:22:18.833 [Controller id=0] Currently active brokers in the cluster: Set(0)
2024-12-31 21:22:18.833 [Controller id=0] Currently shutting brokers in the cluster: HashSet()
2024-12-31 21:22:18.833 [Controller id=0] Current list of topics in the cluster: HashSet()
2024-12-31 21:22:18.833 [Controller id=0] Fetching topic deletions in progress
2024-12-31 21:22:18.834 [Controller id=0] List of topics to be deleted: 
2024-12-31 21:22:18.834 [Controller id=0] List of topics ineligible for deletion: 
2024-12-31 21:22:18.834 [Controller id=0] Initializing topic deletion manager
2024-12-31 21:22:18.834 [Topic Deletion Manager 0] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet()
2024-12-31 21:22:18.834 [Controller id=0] Sending update metadata request
2024-12-31 21:22:18.834 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions
2024-12-31 21:22:18.836 [ReplicaStateMachine controllerId=0] Initializing replica state
2024-12-31 21:22:18.836 [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2024-12-31 21:22:18.836 [ReplicaStateMachine controllerId=0] Triggering offline replica state changes
2024-12-31 21:22:18.836 [PartitionStateMachine controllerId=0] Initializing partition state
2024-12-31 21:22:18.836 [PartitionStateMachine controllerId=0] Triggering online partition state changes
2024-12-31 21:22:18.836 [Controller id=0] Ready to serve as the new controller with epoch 1
2024-12-31 21:22:18.837 [RequestSendThread controllerId=0] Controller 0 connected to localhost:59867 (id: 0 rack: null) for sending state change requests
2024-12-31 21:22:18.838 [Controller id=0] Partitions undergoing preferred replica election: 
2024-12-31 21:22:18.838 [Controller id=0] Partitions that completed preferred replica election: 
2024-12-31 21:22:18.838 [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2024-12-31 21:22:18.838 [Controller id=0] Resuming preferred replica election for partitions: 
2024-12-31 21:22:18.838 [Controller id=0] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered
2024-12-31 21:22:18.839 [Controller id=0] Starting the controller scheduler
2024-12-31 21:22:18.855 [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use node localhost:59867 (id: 0 rack: null)
2024-12-31 21:22:18.886 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Recorded new controller, from now on will use node localhost:59867 (id: 0 rack: null)
2024-12-31 21:22:18.941 Creating topic pong-message-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0))
2024-12-31 21:22:18.950 [Controller id=0] New topics: [Set(pong-message-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(pong-message-topic,Some(2jtBc0wxSL-yqdsRkM25fQ),Map(pong-message-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), pong-message-topic-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:22:18.950 [Controller id=0] New partition creation callback for pong-message-topic-0,pong-message-topic-1
2024-12-31 21:22:18.950 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:22:18.950 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:22:18.950 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:22:18.950 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:22:18.956 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:22:18.956 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:22:18.956 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2024-12-31 21:22:18.956 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2024-12-31 21:22:18.957 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:22:18.957 [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 for 2 partitions
2024-12-31 21:22:18.959 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(pong-message-topic-0, pong-message-topic-1)
2024-12-31 21:22:18.959 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2024-12-31 21:22:18.972 [LogLoader partition=pong-message-topic-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.e09e53d3-0823-4ee1-a6fa-a6970ab9f9ad3972579820972232185] Loading producer state till offset 0 with message format version 2
2024-12-31 21:22:18.973 Created log for partition pong-message-topic-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.e09e53d3-0823-4ee1-a6fa-a6970ab9f9ad3972579820972232185\pong-message-topic-0 with properties {}
2024-12-31 21:22:18.973 [Partition pong-message-topic-0 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-0
2024-12-31 21:22:18.974 [Partition pong-message-topic-0 broker=0] Log loaded for partition pong-message-topic-0 with initial high watermark 0
2024-12-31 21:22:18.974 [Broker id=0] Leader pong-message-topic-0 with topic id Some(2jtBc0wxSL-yqdsRkM25fQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:22:18.984 [LogLoader partition=pong-message-topic-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.e09e53d3-0823-4ee1-a6fa-a6970ab9f9ad3972579820972232185] Loading producer state till offset 0 with message format version 2
2024-12-31 21:22:18.985 Created log for partition pong-message-topic-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.e09e53d3-0823-4ee1-a6fa-a6970ab9f9ad3972579820972232185\pong-message-topic-1 with properties {}
2024-12-31 21:22:18.985 [Partition pong-message-topic-1 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-1
2024-12-31 21:22:18.985 [Partition pong-message-topic-1 broker=0] Log loaded for partition pong-message-topic-1 with initial high watermark 0
2024-12-31 21:22:18.985 [Broker id=0] Leader pong-message-topic-1 with topic id Some(2jtBc0wxSL-yqdsRkM25fQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:22:18.989 [Broker id=0] Finished LeaderAndIsr request in 32ms correlationId 1 from controller 0 for 2 partitions
2024-12-31 21:22:18.992 [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2
2024-12-31 21:22:18.994 App info kafka.admin.client for adminclient-3 unregistered
2024-12-31 21:22:18.995 Metrics scheduler closed
2024-12-31 21:22:18.995 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:22:18.995 Metrics reporters closed
2024-12-31 21:22:19.037 

Found multiple occurrences of org.json.JSONObject on the class path:

	jar:file:/C:/work/apache-maven-3.8.8/repo/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar!/org/json/JSONObject.class
	jar:file:/C:/work/apache-maven-3.8.8/repo/org/json/json/20220320/json-20220320.jar!/org/json/JSONObject.class

You may wish to exclude one of them to ensure predictable runtime behavior

2024-12-31 21:22:19.040 Starting KafkaSpec using Java 17.0.12 with PID 2608 (started by joech in C:\code\hsbc\demo\pong)
2024-12-31 21:22:19.040 No active profile set, falling back to 1 default profile: "default"
2024-12-31 21:22:19.175 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:22:19.175 Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2024-12-31 21:22:19.192 Finished Spring Data repository scanning in 17 ms. Found 1 JPA repository interfaces.
2024-12-31 21:22:19.195 Multiple Spring Data modules found, entering strict repository configuration mode
2024-12-31 21:22:19.195 Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2024-12-31 21:22:19.201 Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.demo.dao.MessageRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2024-12-31 21:22:19.201 Finished Spring Data repository scanning in 4 ms. Found 0 Redis repository interfaces.
2024-12-31 21:22:19.270 HHH000204: Processing PersistenceUnitInfo [name: default]
2024-12-31 21:22:19.281 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:22:19.281 No LoadTimeWeaver setup: ignoring JPA class transformer
2024-12-31 21:22:19.282 HikariPool-3 - Starting...
2024-12-31 21:22:19.285 HikariPool-3 - Added connection conn20: url=jdbc:h2:mem:testdb user=SA
2024-12-31 21:22:19.286 HikariPool-3 - Start completed.
2024-12-31 21:22:19.295 HHH000021: Bytecode provider name : bytebuddy
2024-12-31 21:22:19.321 HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2024-12-31 21:22:19.342 Initialized JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:22:19.511 ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:59867]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-pong-service-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = pong-service
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2024-12-31 21:22:19.515 These configurations '[spring.json.trusted.packages]' were supplied but are not used yet.
2024-12-31 21:22:19.516 Kafka version: 3.4.1
2024-12-31 21:22:19.516 Kafka commitId: 8a516edc2755df89
2024-12-31 21:22:19.516 Kafka startTimeMs: 1735651339516
2024-12-31 21:22:19.516 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Subscribed to topic(s): pong-message-topic
2024-12-31 21:22:19.521 Started KafkaSpec in 0.519 seconds (process running for 30.251)
2024-12-31 21:22:19.524 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting the last seen epoch of partition pong-message-topic-0 to 0 since the associated topicId changed from null to 2jtBc0wxSL-yqdsRkM25fQ
2024-12-31 21:22:19.524 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting the last seen epoch of partition pong-message-topic-1 to 0 since the associated topicId changed from null to 2jtBc0wxSL-yqdsRkM25fQ
2024-12-31 21:22:19.525 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Cluster ID: _c_USp2ITvmmzqxj9tXvvQ
2024-12-31 21:22:19.529 Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0))
2024-12-31 21:22:19.538 [Controller id=0] New topics: [Set(__consumer_offsets)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(__consumer_offsets,Some(djBUo9lUQRGkhuHRu3q6vQ),HashMap(__consumer_offsets-4 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-3 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-2 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2024-12-31 21:22:19.539 [Controller id=0] New partition creation callback for __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2024-12-31 21:22:19.539 [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:22:19.539 [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:22:19.539 [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:22:19.539 [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:22:19.539 [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2024-12-31 21:22:19.539 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:22:19.539 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:22:19.541 Idempotence will be disabled because acks is set to 0, not set to 'all'.
2024-12-31 21:22:19.541 ProducerConfig values: 
	acks = 0
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:59867]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2024-12-31 21:22:19.547 Kafka version: 3.4.1
2024-12-31 21:22:19.547 Kafka commitId: 8a516edc2755df89
2024-12-31 21:22:19.547 Kafka startTimeMs: 1735651339547
2024-12-31 21:22:19.551 [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:22:19.551 [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:22:19.551 [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:22:19.551 [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:22:19.551 [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2024-12-31 21:22:19.551 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 5 become-leader and 0 become-follower partitions
2024-12-31 21:22:19.551 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 5 partitions
2024-12-31 21:22:19.552 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:22:19.552 [Producer clientId=producer-2] Resetting the last seen epoch of partition pong-message-topic-0 to 0 since the associated topicId changed from null to 2jtBc0wxSL-yqdsRkM25fQ
2024-12-31 21:22:19.552 [Producer clientId=producer-2] Resetting the last seen epoch of partition pong-message-topic-1 to 0 since the associated topicId changed from null to 2jtBc0wxSL-yqdsRkM25fQ
2024-12-31 21:22:19.552 [Broker id=0] Handling LeaderAndIsr request correlationId 3 from controller 0 for 5 partitions
2024-12-31 21:22:19.552 [Producer clientId=producer-2] Cluster ID: _c_USp2ITvmmzqxj9tXvvQ
2024-12-31 21:22:19.553 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-4, __consumer_offsets-3, __consumer_offsets-2, __consumer_offsets-0, __consumer_offsets-1)
2024-12-31 21:22:19.553 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 3 from controller 0 epoch 1 as part of the become-leader transition for 5 partitions
2024-12-31 21:22:19.568 [LogLoader partition=__consumer_offsets-3, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.e09e53d3-0823-4ee1-a6fa-a6970ab9f9ad3972579820972232185] Loading producer state till offset 0 with message format version 2
2024-12-31 21:22:19.569 Created log for partition __consumer_offsets-3 in C:\Users\joech\AppData\Local\Temp\spring.kafka.e09e53d3-0823-4ee1-a6fa-a6970ab9f9ad3972579820972232185\__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:22:19.570 [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
2024-12-31 21:22:19.572 [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0
2024-12-31 21:22:19.572 [Broker id=0] Leader __consumer_offsets-3 with topic id Some(djBUo9lUQRGkhuHRu3q6vQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:22:19.584 [LogLoader partition=__consumer_offsets-2, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.e09e53d3-0823-4ee1-a6fa-a6970ab9f9ad3972579820972232185] Loading producer state till offset 0 with message format version 2
2024-12-31 21:22:19.585 Created log for partition __consumer_offsets-2 in C:\Users\joech\AppData\Local\Temp\spring.kafka.e09e53d3-0823-4ee1-a6fa-a6970ab9f9ad3972579820972232185\__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:22:19.585 [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
2024-12-31 21:22:19.585 [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0
2024-12-31 21:22:19.585 [Broker id=0] Leader __consumer_offsets-2 with topic id Some(djBUo9lUQRGkhuHRu3q6vQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:22:19.598 [LogLoader partition=__consumer_offsets-4, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.e09e53d3-0823-4ee1-a6fa-a6970ab9f9ad3972579820972232185] Loading producer state till offset 0 with message format version 2
2024-12-31 21:22:19.599 Created log for partition __consumer_offsets-4 in C:\Users\joech\AppData\Local\Temp\spring.kafka.e09e53d3-0823-4ee1-a6fa-a6970ab9f9ad3972579820972232185\__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:22:19.599 [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
2024-12-31 21:22:19.599 [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0
2024-12-31 21:22:19.599 [Broker id=0] Leader __consumer_offsets-4 with topic id Some(djBUo9lUQRGkhuHRu3q6vQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:22:19.611 [LogLoader partition=__consumer_offsets-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.e09e53d3-0823-4ee1-a6fa-a6970ab9f9ad3972579820972232185] Loading producer state till offset 0 with message format version 2
2024-12-31 21:22:19.612 Created log for partition __consumer_offsets-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.e09e53d3-0823-4ee1-a6fa-a6970ab9f9ad3972579820972232185\__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:22:19.612 [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
2024-12-31 21:22:19.612 [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0
2024-12-31 21:22:19.612 [Broker id=0] Leader __consumer_offsets-1 with topic id Some(djBUo9lUQRGkhuHRu3q6vQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:22:19.623 [LogLoader partition=__consumer_offsets-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.e09e53d3-0823-4ee1-a6fa-a6970ab9f9ad3972579820972232185] Loading producer state till offset 0 with message format version 2
2024-12-31 21:22:19.623 Created log for partition __consumer_offsets-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.e09e53d3-0823-4ee1-a6fa-a6970ab9f9ad3972579820972232185\__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2024-12-31 21:22:19.624 [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
2024-12-31 21:22:19.624 [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0
2024-12-31 21:22:19.624 [Broker id=0] Leader __consumer_offsets-0 with topic id Some(djBUo9lUQRGkhuHRu3q6vQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2024-12-31 21:22:19.627 [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 0
2024-12-31 21:22:19.627 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0
2024-12-31 21:22:19.627 [GroupCoordinator 0]: Elected as the group coordinator for partition 2 in epoch 0
2024-12-31 21:22:19.627 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0
2024-12-31 21:22:19.627 [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 0
2024-12-31 21:22:19.627 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0
2024-12-31 21:22:19.627 [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 0
2024-12-31 21:22:19.627 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0
2024-12-31 21:22:19.627 [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 0
2024-12-31 21:22:19.627 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0
2024-12-31 21:22:19.627 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler.
2024-12-31 21:22:19.627 [Broker id=0] Finished LeaderAndIsr request in 75ms correlationId 3 from controller 0 for 5 partitions
2024-12-31 21:22:19.627 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler.
2024-12-31 21:22:19.629 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler.
2024-12-31 21:22:19.629 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler.
2024-12-31 21:22:19.629 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler.
2024-12-31 21:22:19.630 [Broker id=0] Add 5 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 4
2024-12-31 21:22:19.730 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Discovered group coordinator localhost:59867 (id: 2147483647 rack: null)
2024-12-31 21:22:19.731 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] (Re-)joining group
2024-12-31 21:22:19.735 [GroupCoordinator 0]: Dynamic member with unknown member id joins group pong-service in Empty state. Created a new member id consumer-pong-service-3-2390d4ca-57b6-4495-a154-34f581633d3d and request the member to rejoin with this id.
2024-12-31 21:22:19.736 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Request joining group due to: need to re-join with the given member-id: consumer-pong-service-3-2390d4ca-57b6-4495-a154-34f581633d3d
2024-12-31 21:22:19.736 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2024-12-31 21:22:19.736 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] (Re-)joining group
2024-12-31 21:22:19.737 [GroupCoordinator 0]: Preparing to rebalance group pong-service in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-pong-service-3-2390d4ca-57b6-4495-a154-34f581633d3d with group instance id None; client reason: rebalance failed due to MemberIdRequiredException)
2024-12-31 21:22:19.738 [GroupCoordinator 0]: Stabilized group pong-service generation 1 (__consumer_offsets-2) with 1 members
2024-12-31 21:22:19.739 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Successfully joined group with generation Generation{generationId=1, memberId='consumer-pong-service-3-2390d4ca-57b6-4495-a154-34f581633d3d', protocol='range'}
2024-12-31 21:22:19.739 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Finished assignment for group at generation 1: {consumer-pong-service-3-2390d4ca-57b6-4495-a154-34f581633d3d=Assignment(partitions=[pong-message-topic-0, pong-message-topic-1])}
2024-12-31 21:22:19.741 [GroupCoordinator 0]: Assignment received from leader consumer-pong-service-3-2390d4ca-57b6-4495-a154-34f581633d3d for group pong-service for generation 1. The group has 1 members, 0 of which are static.
2024-12-31 21:22:19.742 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Successfully synced group in generation Generation{generationId=1, memberId='consumer-pong-service-3-2390d4ca-57b6-4495-a154-34f581633d3d', protocol='range'}
2024-12-31 21:22:19.743 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Notifying assignor about the new Assignment(partitions=[pong-message-topic-0, pong-message-topic-1])
2024-12-31 21:22:19.743 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Adding newly assigned partitions: pong-message-topic-0, pong-message-topic-1
2024-12-31 21:22:19.746 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Found no committed offset for partition pong-message-topic-0
2024-12-31 21:22:19.746 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Found no committed offset for partition pong-message-topic-1
2024-12-31 21:22:19.747 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Found no committed offset for partition pong-message-topic-0
2024-12-31 21:22:19.747 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Found no committed offset for partition pong-message-topic-1
2024-12-31 21:22:19.749 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting offset for partition pong-message-topic-0 to position FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:59867 (id: 0 rack: null)], epoch=0}}.
2024-12-31 21:22:19.749 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting offset for partition pong-message-topic-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:59867 (id: 0 rack: null)], epoch=0}}.
2024-12-31 21:22:19.758 pong-service: partitions assigned: [pong-message-topic-0, pong-message-topic-1]
2024-12-31 21:22:19.864 [KafkaServer id=0] shutting down
2024-12-31 21:22:19.864 [KafkaServer id=0] Starting controlled shutdown
2024-12-31 21:22:19.869 [Controller id=0] Shutting down broker 0
2024-12-31 21:22:19.869 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2024-12-31 21:22:19.870 [KafkaServer id=0] Controlled shutdown request returned successfully after 2ms
2024-12-31 21:22:19.870 [/config/changes-event-process-thread]: Shutting down
2024-12-31 21:22:19.871 [/config/changes-event-process-thread]: Shutdown completed
2024-12-31 21:22:19.871 [/config/changes-event-process-thread]: Stopped
2024-12-31 21:22:19.871 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
2024-12-31 21:22:19.872 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2024-12-31 21:22:19.872 [Producer clientId=producer-2] Node 0 disconnected.
2024-12-31 21:22:19.872 [Producer clientId=producer-2] Node -1 disconnected.
2024-12-31 21:22:19.872 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:22:19.872 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Cancelled in-flight FETCH request with correlation id 16 due to node 0 being disconnected (elapsed time since creation: 113ms, elapsed time since send: 113ms, request timeout: 30000ms)
2024-12-31 21:22:19.872 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Cancelled in-flight METADATA request with correlation id 17 due to node 0 being disconnected (elapsed time since creation: 32ms, elapsed time since send: 32ms, request timeout: 30000ms)
2024-12-31 21:22:19.872 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node 2147483647 disconnected.
2024-12-31 21:22:19.872 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2024-12-31 21:22:19.872 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Group coordinator localhost:59867 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
2024-12-31 21:22:19.872 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors
2024-12-31 21:22:19.872 [data-plane Kafka Request Handler on Broker 0], shutting down
2024-12-31 21:22:19.873 [data-plane Kafka Request Handler on Broker 0], shut down completely
2024-12-31 21:22:19.873 [ExpirationReaper-0-AlterAcls]: Shutting down
2024-12-31 21:22:19.873 [ExpirationReaper-0-AlterAcls]: Stopped
2024-12-31 21:22:19.873 [ExpirationReaper-0-AlterAcls]: Shutdown completed
2024-12-31 21:22:19.874 [KafkaApi-0] Shutdown complete.
2024-12-31 21:22:19.874 [ExpirationReaper-0-topic]: Shutting down
2024-12-31 21:22:19.874 [ExpirationReaper-0-topic]: Stopped
2024-12-31 21:22:19.874 [ExpirationReaper-0-topic]: Shutdown completed
2024-12-31 21:22:19.874 [TransactionCoordinator id=0] Shutting down.
2024-12-31 21:22:19.874 [Transaction State Manager 0]: Shutdown complete
2024-12-31 21:22:19.874 [Transaction Marker Channel Manager 0]: Shutting down
2024-12-31 21:22:19.874 [Transaction Marker Channel Manager 0]: Shutdown completed
2024-12-31 21:22:19.874 [Transaction Marker Channel Manager 0]: Stopped
2024-12-31 21:22:19.874 [TransactionCoordinator id=0] Shutdown complete.
2024-12-31 21:22:19.874 [GroupCoordinator 0]: Shutting down.
2024-12-31 21:22:19.874 [ExpirationReaper-0-Heartbeat]: Shutting down
2024-12-31 21:22:19.876 [ExpirationReaper-0-Heartbeat]: Shutdown completed
2024-12-31 21:22:19.876 [ExpirationReaper-0-Heartbeat]: Stopped
2024-12-31 21:22:19.876 [ExpirationReaper-0-Rebalance]: Shutting down
2024-12-31 21:22:19.876 [ExpirationReaper-0-Rebalance]: Stopped
2024-12-31 21:22:19.876 [ExpirationReaper-0-Rebalance]: Shutdown completed
2024-12-31 21:22:19.876 [GroupCoordinator 0]: Shutdown complete.
2024-12-31 21:22:19.876 [ReplicaManager broker=0] Shutting down
2024-12-31 21:22:19.876 [LogDirFailureHandler]: Shutting down
2024-12-31 21:22:19.876 [LogDirFailureHandler]: Shutdown completed
2024-12-31 21:22:19.876 [LogDirFailureHandler]: Stopped
2024-12-31 21:22:19.876 [ReplicaFetcherManager on broker 0] shutting down
2024-12-31 21:22:19.876 [ReplicaFetcherManager on broker 0] shutdown completed
2024-12-31 21:22:19.876 [ReplicaAlterLogDirsManager on broker 0] shutting down
2024-12-31 21:22:19.876 [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2024-12-31 21:22:19.876 [ExpirationReaper-0-Fetch]: Shutting down
2024-12-31 21:22:19.876 [ExpirationReaper-0-Fetch]: Stopped
2024-12-31 21:22:19.876 [ExpirationReaper-0-Fetch]: Shutdown completed
2024-12-31 21:22:19.876 [ExpirationReaper-0-Produce]: Shutting down
2024-12-31 21:22:19.877 [ExpirationReaper-0-Produce]: Stopped
2024-12-31 21:22:19.877 [ExpirationReaper-0-Produce]: Shutdown completed
2024-12-31 21:22:19.877 [ExpirationReaper-0-DeleteRecords]: Shutting down
2024-12-31 21:22:19.877 [ExpirationReaper-0-DeleteRecords]: Stopped
2024-12-31 21:22:19.877 [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2024-12-31 21:22:19.877 [ExpirationReaper-0-ElectLeader]: Shutting down
2024-12-31 21:22:19.877 [ExpirationReaper-0-ElectLeader]: Shutdown completed
2024-12-31 21:22:19.877 [ExpirationReaper-0-ElectLeader]: Stopped
2024-12-31 21:22:19.886 [ReplicaManager broker=0] Shut down completely
2024-12-31 21:22:19.886 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutting down
2024-12-31 21:22:19.886 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Stopped
2024-12-31 21:22:19.886 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutdown completed
2024-12-31 21:22:19.887 Broker to controller channel manager for alterPartition shutdown
2024-12-31 21:22:19.887 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down
2024-12-31 21:22:19.887 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed
2024-12-31 21:22:19.887 [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped
2024-12-31 21:22:19.887 Broker to controller channel manager for forwarding shutdown
2024-12-31 21:22:19.887 Shutting down.
2024-12-31 21:22:19.887 Shutting down the log cleaner.
2024-12-31 21:22:19.887 [kafka-log-cleaner-thread-0]: Shutting down
2024-12-31 21:22:19.887 [kafka-log-cleaner-thread-0]: Stopped
2024-12-31 21:22:19.887 [kafka-log-cleaner-thread-0]: Shutdown completed
2024-12-31 21:22:19.901 [ProducerStateManager partition=pong-message-topic-0] Wrote producer snapshot at offset 1 with 0 producer ids in 2 ms.
2024-12-31 21:22:19.914 [ProducerStateManager partition=__consumer_offsets-2] Wrote producer snapshot at offset 3 with 0 producer ids in 1 ms.
2024-12-31 21:22:19.922 Shutdown complete.
2024-12-31 21:22:19.922 [ControllerEventThread controllerId=0] Shutting down
2024-12-31 21:22:19.922 [ControllerEventThread controllerId=0] Stopped
2024-12-31 21:22:19.922 [ControllerEventThread controllerId=0] Shutdown completed
2024-12-31 21:22:19.923 [PartitionStateMachine controllerId=0] Stopped partition state machine
2024-12-31 21:22:19.923 [ReplicaStateMachine controllerId=0] Stopped replica state machine
2024-12-31 21:22:19.923 [RequestSendThread controllerId=0] Shutting down
2024-12-31 21:22:19.923 [RequestSendThread controllerId=0] Shutdown completed
2024-12-31 21:22:19.923 [RequestSendThread controllerId=0] Stopped
2024-12-31 21:22:19.924 [Controller id=0] Resigned
2024-12-31 21:22:19.924 [feature-zk-node-event-process-thread]: Shutting down
2024-12-31 21:22:19.924 [feature-zk-node-event-process-thread]: Stopped
2024-12-31 21:22:19.924 [feature-zk-node-event-process-thread]: Shutdown completed
2024-12-31 21:22:19.924 [ZooKeeperClient Kafka server] Closing.
2024-12-31 21:22:19.972 [Producer clientId=producer-2] Node 0 disconnected.
2024-12-31 21:22:19.973 [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:59867) could not be established. Broker may not be available.
2024-12-31 21:22:19.973 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:22:19.973 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node 0 (localhost/127.0.0.1:59867) could not be established. Broker may not be available.
2024-12-31 21:22:20.027 EventThread shut down for session: 0x100177cbe600000
2024-12-31 21:22:20.027 Session: 0x100177cbe600000 closed
2024-12-31 21:22:20.027 [ZooKeeperClient Kafka server] Closed.
2024-12-31 21:22:20.027 [ThrottledChannelReaper-Fetch]: Shutting down
2024-12-31 21:22:20.028 [ThrottledChannelReaper-Fetch]: Stopped
2024-12-31 21:22:20.028 [ThrottledChannelReaper-Fetch]: Shutdown completed
2024-12-31 21:22:20.028 [ThrottledChannelReaper-Produce]: Shutting down
2024-12-31 21:22:20.028 [ThrottledChannelReaper-Produce]: Shutdown completed
2024-12-31 21:22:20.028 [ThrottledChannelReaper-Request]: Shutting down
2024-12-31 21:22:20.028 [ThrottledChannelReaper-Produce]: Stopped
2024-12-31 21:22:20.028 [ThrottledChannelReaper-Request]: Stopped
2024-12-31 21:22:20.028 [ThrottledChannelReaper-Request]: Shutdown completed
2024-12-31 21:22:20.028 [ThrottledChannelReaper-ControllerMutation]: Shutting down
2024-12-31 21:22:20.028 [ThrottledChannelReaper-ControllerMutation]: Stopped
2024-12-31 21:22:20.028 [ThrottledChannelReaper-ControllerMutation]: Shutdown completed
2024-12-31 21:22:20.028 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server
2024-12-31 21:22:20.046 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed
2024-12-31 21:22:20.046 Metrics scheduler closed
2024-12-31 21:22:20.046 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:22:20.046 Metrics reporters closed
2024-12-31 21:22:20.046 Broker and topic stats closed
2024-12-31 21:22:20.047 App info kafka.server for 0 unregistered
2024-12-31 21:22:20.047 [KafkaServer id=0] shut down completed
2024-12-31 21:22:20.057 ConnnectionExpirerThread interrupted
2024-12-31 21:22:20.058 selector thread exitted run method
2024-12-31 21:22:20.058 selector thread exitted run method
2024-12-31 21:22:20.058 accept thread exitted run method
2024-12-31 21:22:20.058 shutting down
2024-12-31 21:22:20.058 Shutting down
2024-12-31 21:22:20.058 Draining request throttler queue
2024-12-31 21:22:20.058 RequestThrottler shutdown. Dropped 0 requests
2024-12-31 21:22:20.058 Shutting down
2024-12-31 21:22:20.058 Shutting down
2024-12-31 21:22:20.058 Shutting down
2024-12-31 21:22:20.058 SyncRequestProcessor exited!
2024-12-31 21:22:20.058 PrepRequestProcessor exited loop!
2024-12-31 21:22:20.060 shutdown of request processor complete
2024-12-31 21:22:20.098 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node 0 disconnected.
2024-12-31 21:22:20.098 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node 0 (localhost/127.0.0.1:59867) could not be established. Broker may not be available.
2024-12-31 21:22:20.099 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Revoke previously assigned partitions pong-message-topic-0, pong-message-topic-1
2024-12-31 21:22:20.099 pong-service: partitions revoked: [pong-message-topic-0, pong-message-topic-1]
2024-12-31 21:22:20.099 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:22:20.099 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:22:20.099 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Unsubscribed all topics or patterns and assigned partitions
2024-12-31 21:22:20.099 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-12-31 21:22:20.099 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2024-12-31 21:22:20.100 Metrics scheduler closed
2024-12-31 21:22:20.100 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:22:20.100 Metrics reporters closed
2024-12-31 21:22:20.101 App info kafka.consumer for consumer-pong-service-3 unregistered
2024-12-31 21:22:20.101 pong-service: Consumer stopped
2024-12-31 21:22:20.102 [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 30000 ms.
2024-12-31 21:22:20.102 Metrics scheduler closed
2024-12-31 21:22:20.102 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-12-31 21:22:20.102 Metrics reporters closed
2024-12-31 21:22:20.102 App info kafka.producer for producer-2 unregistered
2024-12-31 21:22:20.108 Closing JPA EntityManagerFactory for persistence unit 'default'
2024-12-31 21:22:20.108 HikariPool-3 - Shutdown initiated...
2024-12-31 21:22:20.109 HikariPool-3 - Shutdown completed.
