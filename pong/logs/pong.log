2025-01-04 00:11:32.618 Could not detect default configuration classes for test class [com.demo.controller.PongControllerSpec]: PongControllerSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2025-01-04 00:11:32.884 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.controller.PongControllerSpec
2025-01-04 00:11:33.096 Could not detect default configuration classes for test class [com.demo.dao.MessageRepositorySpec]: MessageRepositorySpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2025-01-04 00:11:33.105 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.dao.MessageRepositorySpec
2025-01-04 00:11:33.130 Could not detect default configuration classes for test class [com.demo.kafka.KafkaSpec]: KafkaSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2025-01-04 00:11:33.165 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.kafka.KafkaSpec
2025-01-04 00:11:33.211 Could not detect default configuration classes for test class [com.demo.kafka.KafkaSpec]: KafkaSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2025-01-04 00:11:33.214 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.kafka.KafkaSpec
2025-01-04 00:11:33.217 Could not detect default configuration classes for test class [com.demo.dao.MessageRepositorySpec]: MessageRepositorySpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2025-01-04 00:11:33.218 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.dao.MessageRepositorySpec
2025-01-04 00:11:33.222 Could not detect default configuration classes for test class [com.demo.controller.PongControllerSpec]: PongControllerSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2025-01-04 00:11:33.225 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.controller.PongControllerSpec
2025-01-04 00:11:34.211 Registered kafka:type=kafka.Log4jController MBean
2025-01-04 00:11:34.296 
2025-01-04 00:11:34.296   ______                  _                                          
2025-01-04 00:11:34.296  |___  /                 | |                                         
2025-01-04 00:11:34.296     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __   
2025-01-04 00:11:34.296    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__|
2025-01-04 00:11:34.296   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |    
2025-01-04 00:11:34.296  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_|
2025-01-04 00:11:34.296                                               | |                     
2025-01-04 00:11:34.296                                               |_|                     
2025-01-04 00:11:34.296 
2025-01-04 00:11:34.302 Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT
2025-01-04 00:11:34.303 Server environment:host.name=host.docker.internal
2025-01-04 00:11:34.303 Server environment:java.version=17.0.12
2025-01-04 00:11:34.303 Server environment:java.vendor=Oracle Corporation
2025-01-04 00:11:34.303 Server environment:java.home=C:\work\jdk-17
2025-01-04 00:11:34.303 Server environment:java.class.path=C:\code\hsbc\demo\pong\target\test-classes;C:\code\hsbc\demo\pong\target\classes;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-webflux\3.1.4\spring-boot-starter-webflux-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter\3.1.4\spring-boot-starter-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot\3.1.4\spring-boot-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-autoconfigure\3.1.4\spring-boot-autoconfigure-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-logging\3.1.4\spring-boot-starter-logging-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\ch\qos\logback\logback-classic\1.4.11\logback-classic-1.4.11.jar;C:\work\apache-maven-3.8.8\repo\ch\qos\logback\logback-core\1.4.11\logback-core-1.4.11.jar;C:\work\apache-maven-3.8.8\repo\org\apache\logging\log4j\log4j-to-slf4j\2.20.0\log4j-to-slf4j-2.20.0.jar;C:\work\apache-maven-3.8.8\repo\org\apache\logging\log4j\log4j-api\2.20.0\log4j-api-2.20.0.jar;C:\work\apache-maven-3.8.8\repo\org\slf4j\jul-to-slf4j\2.0.9\jul-to-slf4j-2.0.9.jar;C:\work\apache-maven-3.8.8\repo\jakarta\annotation\jakarta.annotation-api\2.1.1\jakarta.annotation-api-2.1.1.jar;C:\work\apache-maven-3.8.8\repo\org\yaml\snakeyaml\1.33\snakeyaml-1.33.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-json\3.1.4\spring-boot-starter-json-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-databind\2.15.2\jackson-databind-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-annotations\2.15.2\jackson-annotations-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-core\2.15.2\jackson-core-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.15.2\jackson-datatype-jdk8-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.15.2\jackson-datatype-jsr310-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\module\jackson-module-parameter-names\2.15.2\jackson-module-parameter-names-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-reactor-netty\3.1.4\spring-boot-starter-reactor-netty-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\netty\reactor-netty-http\1.1.11\reactor-netty-http-1.1.11.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-http\4.1.97.Final\netty-codec-http-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-http2\4.1.97.Final\netty-codec-http2-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns\4.1.97.Final\netty-resolver-dns-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-dns\4.1.97.Final\netty-codec-dns-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns-native-macos\4.1.97.Final\netty-resolver-dns-native-macos-4.1.97.Final-osx-x86_64.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns-classes-macos\4.1.97.Final\netty-resolver-dns-classes-macos-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final-linux-x86_64.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\netty\reactor-netty-core\1.1.11\reactor-netty-core-1.1.11.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-handler-proxy\4.1.97.Final\netty-handler-proxy-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-socks\4.1.97.Final\netty-codec-socks-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-web\6.0.12\spring-web-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-beans\6.0.12\spring-beans-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-webflux\6.0.12\spring-webflux-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\reactor-core\3.5.10\reactor-core-3.5.10.jar;C:\work\apache-maven-3.8.8\repo\org\reactivestreams\reactive-streams\1.0.4\reactive-streams-1.0.4.jar;C:\work\apache-maven-3.8.8\repo\com\google\guava\guava\19.0\guava-19.0.jar;C:\work\apache-maven-3.8.8\repo\commons-io\commons-io\2.11.0\commons-io-2.11.0.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-data-redis\3.1.4\spring-boot-starter-data-redis-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-redis\3.1.4\spring-data-redis-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-keyvalue\3.1.4\spring-data-keyvalue-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-oxm\6.0.12\spring-oxm-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-aop\6.0.12\spring-aop-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-context-support\6.0.12\spring-context-support-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\io\lettuce\lettuce-core\6.2.6.RELEASE\lettuce-core-6.2.6.RELEASE.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-common\4.1.97.Final\netty-common-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-handler\4.1.97.Final\netty-handler-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver\4.1.97.Final\netty-resolver-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-buffer\4.1.97.Final\netty-buffer-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-unix-common\4.1.97.Final\netty-transport-native-unix-common-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec\4.1.97.Final\netty-codec-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport\4.1.97.Final\netty-transport-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-data-jpa\3.1.4\spring-boot-starter-data-jpa-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-aop\3.1.4\spring-boot-starter-aop-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\aspectj\aspectjweaver\1.9.20\aspectjweaver-1.9.20.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-jdbc\3.1.4\spring-boot-starter-jdbc-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\zaxxer\HikariCP\5.0.1\HikariCP-5.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-jdbc\6.0.12\spring-jdbc-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\hibernate\orm\hibernate-core\6.2.9.Final\hibernate-core-6.2.9.Final.jar;C:\work\apache-maven-3.8.8\repo\jakarta\persistence\jakarta.persistence-api\3.1.0\jakarta.persistence-api-3.1.0.jar;C:\work\apache-maven-3.8.8\repo\jakarta\transaction\jakarta.transaction-api\2.0.1\jakarta.transaction-api-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\jboss\logging\jboss-logging\3.5.3.Final\jboss-logging-3.5.3.Final.jar;C:\work\apache-maven-3.8.8\repo\org\hibernate\common\hibernate-commons-annotations\6.0.6.Final\hibernate-commons-annotations-6.0.6.Final.jar;C:\work\apache-maven-3.8.8\repo\io\smallrye\jandex\3.0.5\jandex-3.0.5.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\classmate\1.5.1\classmate-1.5.1.jar;C:\work\apache-maven-3.8.8\repo\net\bytebuddy\byte-buddy\1.14.8\byte-buddy-1.14.8.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\jaxb-runtime\4.0.3\jaxb-runtime-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\jaxb-core\4.0.3\jaxb-core-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\eclipse\angus\angus-activation\2.0.1\angus-activation-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\txw2\4.0.3\txw2-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\com\sun\istack\istack-commons-runtime\4.1.2\istack-commons-runtime-4.1.2.jar;C:\work\apache-maven-3.8.8\repo\jakarta\inject\jakarta.inject-api\2.0.1\jakarta.inject-api-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\antlr\antlr4-runtime\4.10.1\antlr4-runtime-4.10.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-jpa\3.1.4\spring-data-jpa-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-commons\3.1.4\spring-data-commons-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-orm\6.0.12\spring-orm-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-aspects\6.0.12\spring-aspects-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\postgresql\postgresql\42.6.0\postgresql-42.6.0.jar;C:\work\apache-maven-3.8.8\repo\org\checkerframework\checker-qual\3.31.0\checker-qual-3.31.0.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\kafka\spring-kafka\3.0.11\spring-kafka-3.0.11.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-context\6.0.12\spring-context-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-expression\6.0.12\spring-expression-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-messaging\6.0.12\spring-messaging-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-tx\6.0.12\spring-tx-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\retry\spring-retry\2.0.3\spring-retry-2.0.3.jar;C:\work\apache-maven-3.8.8\repo\io\micrometer\micrometer-observation\1.11.4\micrometer-observation-1.11.4.jar;C:\work\apache-maven-3.8.8\repo\io\micrometer\micrometer-commons\1.11.4\micrometer-commons-1.11.4.jar;C:\work\apache-maven-3.8.8\repo\com\google\code\findbugs\jsr305\3.0.2\jsr305-3.0.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\com\github\luben\zstd-jni\1.5.2-1\zstd-jni-1.5.2-1.jar;C:\work\apache-maven-3.8.8\repo\org\lz4\lz4-java\1.8.0\lz4-java-1.8.0.jar;C:\work\apache-maven-3.8.8\repo\org\xerial\snappy\snappy-java\1.1.8.4\snappy-java-1.1.8.4.jar;C:\work\apache-maven-3.8.8\repo\org\slf4j\slf4j-api\2.0.9\slf4j-api-2.0.9.jar;C:\work\apache-maven-3.8.8\repo\com\h2database\h2\1.4.200\h2-1.4.200.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-test\3.1.4\spring-boot-starter-test-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-test\3.1.4\spring-boot-test-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-test-autoconfigure\3.1.4\spring-boot-test-autoconfigure-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\jayway\jsonpath\json-path\2.8.0\json-path-2.8.0.jar;C:\work\apache-maven-3.8.8\repo\jakarta\xml\bind\jakarta.xml.bind-api\4.0.1\jakarta.xml.bind-api-4.0.1.jar;C:\work\apache-maven-3.8.8\repo\jakarta\activation\jakarta.activation-api\2.1.2\jakarta.activation-api-2.1.2.jar;C:\work\apache-maven-3.8.8\repo\net\minidev\json-smart\2.4.11\json-smart-2.4.11.jar;C:\work\apache-maven-3.8.8\repo\net\minidev\accessors-smart\2.4.11\accessors-smart-2.4.11.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm\9.3\asm-9.3.jar;C:\work\apache-maven-3.8.8\repo\org\assertj\assertj-core\3.24.2\assertj-core-3.24.2.jar;C:\work\apache-maven-3.8.8\repo\org\hamcrest\hamcrest\2.2\hamcrest-2.2.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter\5.9.3\junit-jupiter-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-params\5.9.3\junit-jupiter-params-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-engine\5.9.3\junit-jupiter-engine-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\mockito\mockito-core\5.3.1\mockito-core-5.3.1.jar;C:\work\apache-maven-3.8.8\repo\net\bytebuddy\byte-buddy-agent\1.14.8\byte-buddy-agent-1.14.8.jar;C:\work\apache-maven-3.8.8\repo\org\objenesis\objenesis\3.3\objenesis-3.3.jar;C:\work\apache-maven-3.8.8\repo\org\mockito\mockito-junit-jupiter\5.3.1\mockito-junit-jupiter-5.3.1.jar;C:\work\apache-maven-3.8.8\repo\org\skyscreamer\jsonassert\1.5.1\jsonassert-1.5.1.jar;C:\work\apache-maven-3.8.8\repo\com\vaadin\external\google\android-json\0.0.20131108.vaadin1\android-json-0.0.20131108.vaadin1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-core\6.0.12\spring-core-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-jcl\6.0.12\spring-jcl-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-test\6.0.12\spring-test-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\xmlunit\xmlunit-core\2.9.1\xmlunit-core-2.9.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy\4.0.15\groovy-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-ant\4.0.15\groovy-ant-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant\1.10.14\ant-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-junit\1.10.14\ant-junit-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-launcher\1.10.14\ant-launcher-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-antlr\1.10.14\ant-antlr-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-cli-picocli\4.0.15\groovy-cli-picocli-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\info\picocli\picocli\4.7.5\picocli-4.7.5.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-console\4.0.15\groovy-console-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\github\javaparser\javaparser-core\3.25.5\javaparser-core-3.25.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-util\9.5\asm-util-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-tree\9.5\asm-tree-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-analysis\9.5\asm-analysis-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\abego\treelayout\org.abego.treelayout.core\1.0.3\org.abego.treelayout.core-1.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ivy\ivy\2.5.2\ivy-2.5.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-datetime\4.0.15\groovy-datetime-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-docgenerator\4.0.15\groovy-docgenerator-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\thoughtworks\qdox\qdox\1.12.1\qdox-1.12.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-groovydoc\4.0.15\groovy-groovydoc-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-groovysh\4.0.15\groovy-groovysh-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\jline\jline\2.14.6\jline-2.14.6.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-jmx\4.0.15\groovy-jmx-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-json\4.0.15\groovy-json-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-jsr223\4.0.15\groovy-jsr223-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-macro\4.0.15\groovy-macro-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-nio\4.0.15\groovy-nio-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-servlet\4.0.15\groovy-servlet-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-sql\4.0.15\groovy-sql-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-swing\4.0.15\groovy-swing-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-templates\4.0.15\groovy-templates-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-test\4.0.15\groovy-test-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\junit\junit\4.13.2\junit-4.13.2.jar;C:\work\apache-maven-3.8.8\repo\org\hamcrest\hamcrest-core\2.2\hamcrest-core-2.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-test-junit5\4.0.15\groovy-test-junit5-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-xml\4.0.15\groovy-xml-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-yaml\4.0.15\groovy-yaml-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\dataformat\jackson-dataformat-yaml\2.15.2\jackson-dataformat-yaml-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\org\spockframework\spock-core\2.4-M1-groovy-4.0\spock-core-2.4-M1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-engine\1.9.3\junit-platform-engine-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\opentest4j\opentest4j\1.2.0\opentest4j-1.2.0.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-commons\1.9.3\junit-platform-commons-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\apiguardian\apiguardian-api\1.1.2\apiguardian-api-1.1.2.jar;C:\work\apache-maven-3.8.8\repo\org\spockframework\spock-spring\2.4-M1-groovy-4.0\spock-spring-2.4-M1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\com\athaydes\spock-reports\2.5.1-groovy-4.0\spock-reports-2.5.1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\com\github\codemonstur\embedded-redis\1.4.2\embedded-redis-1.4.2.jar;C:\work\apache-maven-3.8.8\repo\redis\clients\jedis\4.3.2\jedis-4.3.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\commons\commons-pool2\2.11.1\commons-pool2-2.11.1.jar;C:\work\apache-maven-3.8.8\repo\org\json\json\20220320\json-20220320.jar;C:\work\apache-maven-3.8.8\repo\com\google\code\gson\gson\2.10.1\gson-2.10.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\kafka\spring-kafka-test\3.0.11\spring-kafka-test-3.0.11.jar;C:\work\apache-maven-3.8.8\repo\org\apache\zookeeper\zookeeper\3.6.3\zookeeper-3.6.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\zookeeper\zookeeper-jute\3.6.3\zookeeper-jute-3.6.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-classes-epoll\4.1.97.Final\netty-transport-classes-epoll-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1-test.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-metadata\3.4.1\kafka-metadata-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-server-common\3.4.1\kafka-server-common-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-raft\3.4.1\kafka-raft-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-streams-test-utils\3.4.1\kafka-streams-test-utils-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-streams\3.4.1\kafka-streams-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\rocksdb\rocksdbjni\7.1.2\rocksdbjni-7.1.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\scala-library\2.13.10\scala-library-2.13.10.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-group-coordinator\3.4.1\kafka-group-coordinator-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-storage\3.4.1\kafka-storage-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-storage-api\3.4.1\kafka-storage-api-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\net\sourceforge\argparse4j\argparse4j\0.7.0\argparse4j-0.7.0.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\module\jackson-module-scala_2.13\2.15.2\jackson-module-scala_2.13-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\thoughtworks\paranamer\paranamer\2.8\paranamer-2.8.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\dataformat\jackson-dataformat-csv\2.15.2\jackson-dataformat-csv-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\net\sf\jopt-simple\jopt-simple\5.0.4\jopt-simple-5.0.4.jar;C:\work\apache-maven-3.8.8\repo\org\bitbucket\b_c\jose4j\0.9.3\jose4j-0.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\modules\scala-collection-compat_2.13\2.10.0\scala-collection-compat_2.13-2.10.0.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\modules\scala-java8-compat_2.13\1.0.2\scala-java8-compat_2.13-1.0.2.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\scala-reflect\2.13.10\scala-reflect-2.13.10.jar;C:\work\apache-maven-3.8.8\repo\com\typesafe\scala-logging\scala-logging_2.13\3.9.4\scala-logging_2.13-3.9.4.jar;C:\work\apache-maven-3.8.8\repo\io\dropwizard\metrics\metrics-core\4.2.19\metrics-core-4.2.19.jar;C:\work\apache-maven-3.8.8\repo\commons-cli\commons-cli\1.4\commons-cli-1.4.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1-test.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-api\5.9.3\junit-jupiter-api-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-launcher\1.9.3\junit-platform-launcher-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\awaitility\awaitility\4.2.0\awaitility-4.2.0.jar;
2025-01-04 00:11:34.304 Server environment:java.library.path=C:\work\jdk-17\bin;C:\windows\Sun\Java\bin;C:\windows\system32;C:\windows;C:\work\python312\Scripts\;C:\work\python312\;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program\Git\cmd;C:\Program\PowerShell\7\;C:\Program Files\dotnet\;;C:\Program Files\Docker\Docker\resources\bin;C:\Users\joech\AppData\Local\Microsoft\WindowsApps;C:\Users\joech\AppData\Local\GitHubDesktop\bin;C:\Program\Microsoft VS Code\bin;C:\work\apache-maven-3.8.8\bin;C:\Program Files\Tesseract-OCR;C:\work\jdk-17\bin;;.
2025-01-04 00:11:34.304 Server environment:java.io.tmpdir=C:\Users\joech\AppData\Local\Temp\
2025-01-04 00:11:34.305 Server environment:java.compiler=<NA>
2025-01-04 00:11:34.305 Server environment:os.name=Windows 11
2025-01-04 00:11:34.305 Server environment:os.arch=amd64
2025-01-04 00:11:34.305 Server environment:os.version=10.0
2025-01-04 00:11:34.305 Server environment:user.name=joech
2025-01-04 00:11:34.305 Server environment:user.home=C:\Users\joech
2025-01-04 00:11:34.305 Server environment:user.dir=C:\code\hsbc\demo\pong
2025-01-04 00:11:34.305 Server environment:os.memory.free=510MB
2025-01-04 00:11:34.305 Server environment:os.memory.max=15816MB
2025-01-04 00:11:34.305 Server environment:os.memory.total=568MB
2025-01-04 00:11:34.305 zookeeper.enableEagerACLCheck = false
2025-01-04 00:11:34.310 zookeeper.digest.enabled = true
2025-01-04 00:11:34.310 zookeeper.closeSessionTxn.enabled = true
2025-01-04 00:11:34.310 zookeeper.flushDelay=0
2025-01-04 00:11:34.310 zookeeper.maxWriteQueuePollTime=0
2025-01-04 00:11:34.310 zookeeper.maxBatchSize=1000
2025-01-04 00:11:34.310 zookeeper.intBufferStartingSizeBytes = 1024
2025-01-04 00:11:34.314 zookeeper.snapshot.trust.empty : false
2025-01-04 00:11:34.345 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2025-01-04 00:11:34.346 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2025-01-04 00:11:34.346 zookeeper.snapshotSizeFactor = 0.33
2025-01-04 00:11:34.346 zookeeper.commitLogCount=500
2025-01-04 00:11:34.352 Weighed connection throttling is disabled
2025-01-04 00:11:34.355 minSessionTimeout set to 1600
2025-01-04 00:11:34.355 maxSessionTimeout set to 16000
2025-01-04 00:11:34.356 Response cache size is initialized with value 400.
2025-01-04 00:11:34.357 Response cache size is initialized with value 400.
2025-01-04 00:11:34.358 zookeeper.pathStats.slotCapacity = 60
2025-01-04 00:11:34.358 zookeeper.pathStats.slotDuration = 15
2025-01-04 00:11:34.358 zookeeper.pathStats.maxDepth = 6
2025-01-04 00:11:34.358 zookeeper.pathStats.initialDelay = 5
2025-01-04 00:11:34.358 zookeeper.pathStats.delay = 5
2025-01-04 00:11:34.358 zookeeper.pathStats.enabled = false
2025-01-04 00:11:34.361 The max bytes for all large requests are set to 104857600
2025-01-04 00:11:34.361 The large request threshold is set to -1
2025-01-04 00:11:34.361 Created server with tickTime 800 minSessionTimeout 1600 maxSessionTimeout 16000 clientPortListenBacklog -1 datadir C:\Users\joech\AppData\Local\Temp\kafka-1075883919670012222\version-2 snapdir C:\Users\joech\AppData\Local\Temp\kafka-7707710762984273741\version-2
2025-01-04 00:11:34.409 maxCnxns is not configured, using default value 0.
2025-01-04 00:11:34.412 Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers.
2025-01-04 00:11:34.419 binding to port /127.0.0.1:0
2025-01-04 00:11:34.446 zookeeper.snapshot.compression.method = CHECKED
2025-01-04 00:11:34.447 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-7707710762984273741\version-2\snapshot.0
2025-01-04 00:11:34.454 Snapshot loaded in 29 ms, highest zxid is 0x0, digest is 1371985504
2025-01-04 00:11:34.455 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-7707710762984273741\version-2\snapshot.0
2025-01-04 00:11:34.456 Snapshot taken in 1 ms
2025-01-04 00:11:34.473 PrepRequestProcessor (sid:0) started, reconfigEnabled=false
2025-01-04 00:11:34.474 zookeeper.request_throttler.shutdownTimeout = 10000
2025-01-04 00:11:34.791 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.575df12b-aff4-406a-b0cb-423f0751455b3635952113307784600
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:51105
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2025-01-04 00:11:34.816 Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
2025-01-04 00:11:34.890 starting
2025-01-04 00:11:34.890 Connecting to zookeeper on 127.0.0.1:51105
2025-01-04 00:11:34.911 [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:51105.
2025-01-04 00:11:34.916 Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT
2025-01-04 00:11:34.916 Client environment:host.name=host.docker.internal
2025-01-04 00:11:34.916 Client environment:java.version=17.0.12
2025-01-04 00:11:34.916 Client environment:java.vendor=Oracle Corporation
2025-01-04 00:11:34.916 Client environment:java.home=C:\work\jdk-17
2025-01-04 00:11:34.916 Client environment:java.class.path=C:\code\hsbc\demo\pong\target\test-classes;C:\code\hsbc\demo\pong\target\classes;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-webflux\3.1.4\spring-boot-starter-webflux-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter\3.1.4\spring-boot-starter-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot\3.1.4\spring-boot-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-autoconfigure\3.1.4\spring-boot-autoconfigure-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-logging\3.1.4\spring-boot-starter-logging-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\ch\qos\logback\logback-classic\1.4.11\logback-classic-1.4.11.jar;C:\work\apache-maven-3.8.8\repo\ch\qos\logback\logback-core\1.4.11\logback-core-1.4.11.jar;C:\work\apache-maven-3.8.8\repo\org\apache\logging\log4j\log4j-to-slf4j\2.20.0\log4j-to-slf4j-2.20.0.jar;C:\work\apache-maven-3.8.8\repo\org\apache\logging\log4j\log4j-api\2.20.0\log4j-api-2.20.0.jar;C:\work\apache-maven-3.8.8\repo\org\slf4j\jul-to-slf4j\2.0.9\jul-to-slf4j-2.0.9.jar;C:\work\apache-maven-3.8.8\repo\jakarta\annotation\jakarta.annotation-api\2.1.1\jakarta.annotation-api-2.1.1.jar;C:\work\apache-maven-3.8.8\repo\org\yaml\snakeyaml\1.33\snakeyaml-1.33.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-json\3.1.4\spring-boot-starter-json-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-databind\2.15.2\jackson-databind-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-annotations\2.15.2\jackson-annotations-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-core\2.15.2\jackson-core-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.15.2\jackson-datatype-jdk8-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.15.2\jackson-datatype-jsr310-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\module\jackson-module-parameter-names\2.15.2\jackson-module-parameter-names-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-reactor-netty\3.1.4\spring-boot-starter-reactor-netty-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\netty\reactor-netty-http\1.1.11\reactor-netty-http-1.1.11.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-http\4.1.97.Final\netty-codec-http-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-http2\4.1.97.Final\netty-codec-http2-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns\4.1.97.Final\netty-resolver-dns-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-dns\4.1.97.Final\netty-codec-dns-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns-native-macos\4.1.97.Final\netty-resolver-dns-native-macos-4.1.97.Final-osx-x86_64.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns-classes-macos\4.1.97.Final\netty-resolver-dns-classes-macos-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final-linux-x86_64.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\netty\reactor-netty-core\1.1.11\reactor-netty-core-1.1.11.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-handler-proxy\4.1.97.Final\netty-handler-proxy-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-socks\4.1.97.Final\netty-codec-socks-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-web\6.0.12\spring-web-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-beans\6.0.12\spring-beans-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-webflux\6.0.12\spring-webflux-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\reactor-core\3.5.10\reactor-core-3.5.10.jar;C:\work\apache-maven-3.8.8\repo\org\reactivestreams\reactive-streams\1.0.4\reactive-streams-1.0.4.jar;C:\work\apache-maven-3.8.8\repo\com\google\guava\guava\19.0\guava-19.0.jar;C:\work\apache-maven-3.8.8\repo\commons-io\commons-io\2.11.0\commons-io-2.11.0.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-data-redis\3.1.4\spring-boot-starter-data-redis-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-redis\3.1.4\spring-data-redis-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-keyvalue\3.1.4\spring-data-keyvalue-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-oxm\6.0.12\spring-oxm-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-aop\6.0.12\spring-aop-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-context-support\6.0.12\spring-context-support-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\io\lettuce\lettuce-core\6.2.6.RELEASE\lettuce-core-6.2.6.RELEASE.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-common\4.1.97.Final\netty-common-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-handler\4.1.97.Final\netty-handler-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver\4.1.97.Final\netty-resolver-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-buffer\4.1.97.Final\netty-buffer-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-unix-common\4.1.97.Final\netty-transport-native-unix-common-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec\4.1.97.Final\netty-codec-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport\4.1.97.Final\netty-transport-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-data-jpa\3.1.4\spring-boot-starter-data-jpa-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-aop\3.1.4\spring-boot-starter-aop-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\aspectj\aspectjweaver\1.9.20\aspectjweaver-1.9.20.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-jdbc\3.1.4\spring-boot-starter-jdbc-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\zaxxer\HikariCP\5.0.1\HikariCP-5.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-jdbc\6.0.12\spring-jdbc-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\hibernate\orm\hibernate-core\6.2.9.Final\hibernate-core-6.2.9.Final.jar;C:\work\apache-maven-3.8.8\repo\jakarta\persistence\jakarta.persistence-api\3.1.0\jakarta.persistence-api-3.1.0.jar;C:\work\apache-maven-3.8.8\repo\jakarta\transaction\jakarta.transaction-api\2.0.1\jakarta.transaction-api-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\jboss\logging\jboss-logging\3.5.3.Final\jboss-logging-3.5.3.Final.jar;C:\work\apache-maven-3.8.8\repo\org\hibernate\common\hibernate-commons-annotations\6.0.6.Final\hibernate-commons-annotations-6.0.6.Final.jar;C:\work\apache-maven-3.8.8\repo\io\smallrye\jandex\3.0.5\jandex-3.0.5.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\classmate\1.5.1\classmate-1.5.1.jar;C:\work\apache-maven-3.8.8\repo\net\bytebuddy\byte-buddy\1.14.8\byte-buddy-1.14.8.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\jaxb-runtime\4.0.3\jaxb-runtime-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\jaxb-core\4.0.3\jaxb-core-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\eclipse\angus\angus-activation\2.0.1\angus-activation-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\txw2\4.0.3\txw2-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\com\sun\istack\istack-commons-runtime\4.1.2\istack-commons-runtime-4.1.2.jar;C:\work\apache-maven-3.8.8\repo\jakarta\inject\jakarta.inject-api\2.0.1\jakarta.inject-api-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\antlr\antlr4-runtime\4.10.1\antlr4-runtime-4.10.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-jpa\3.1.4\spring-data-jpa-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-commons\3.1.4\spring-data-commons-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-orm\6.0.12\spring-orm-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-aspects\6.0.12\spring-aspects-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\postgresql\postgresql\42.6.0\postgresql-42.6.0.jar;C:\work\apache-maven-3.8.8\repo\org\checkerframework\checker-qual\3.31.0\checker-qual-3.31.0.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\kafka\spring-kafka\3.0.11\spring-kafka-3.0.11.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-context\6.0.12\spring-context-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-expression\6.0.12\spring-expression-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-messaging\6.0.12\spring-messaging-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-tx\6.0.12\spring-tx-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\retry\spring-retry\2.0.3\spring-retry-2.0.3.jar;C:\work\apache-maven-3.8.8\repo\io\micrometer\micrometer-observation\1.11.4\micrometer-observation-1.11.4.jar;C:\work\apache-maven-3.8.8\repo\io\micrometer\micrometer-commons\1.11.4\micrometer-commons-1.11.4.jar;C:\work\apache-maven-3.8.8\repo\com\google\code\findbugs\jsr305\3.0.2\jsr305-3.0.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\com\github\luben\zstd-jni\1.5.2-1\zstd-jni-1.5.2-1.jar;C:\work\apache-maven-3.8.8\repo\org\lz4\lz4-java\1.8.0\lz4-java-1.8.0.jar;C:\work\apache-maven-3.8.8\repo\org\xerial\snappy\snappy-java\1.1.8.4\snappy-java-1.1.8.4.jar;C:\work\apache-maven-3.8.8\repo\org\slf4j\slf4j-api\2.0.9\slf4j-api-2.0.9.jar;C:\work\apache-maven-3.8.8\repo\com\h2database\h2\1.4.200\h2-1.4.200.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-test\3.1.4\spring-boot-starter-test-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-test\3.1.4\spring-boot-test-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-test-autoconfigure\3.1.4\spring-boot-test-autoconfigure-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\jayway\jsonpath\json-path\2.8.0\json-path-2.8.0.jar;C:\work\apache-maven-3.8.8\repo\jakarta\xml\bind\jakarta.xml.bind-api\4.0.1\jakarta.xml.bind-api-4.0.1.jar;C:\work\apache-maven-3.8.8\repo\jakarta\activation\jakarta.activation-api\2.1.2\jakarta.activation-api-2.1.2.jar;C:\work\apache-maven-3.8.8\repo\net\minidev\json-smart\2.4.11\json-smart-2.4.11.jar;C:\work\apache-maven-3.8.8\repo\net\minidev\accessors-smart\2.4.11\accessors-smart-2.4.11.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm\9.3\asm-9.3.jar;C:\work\apache-maven-3.8.8\repo\org\assertj\assertj-core\3.24.2\assertj-core-3.24.2.jar;C:\work\apache-maven-3.8.8\repo\org\hamcrest\hamcrest\2.2\hamcrest-2.2.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter\5.9.3\junit-jupiter-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-params\5.9.3\junit-jupiter-params-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-engine\5.9.3\junit-jupiter-engine-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\mockito\mockito-core\5.3.1\mockito-core-5.3.1.jar;C:\work\apache-maven-3.8.8\repo\net\bytebuddy\byte-buddy-agent\1.14.8\byte-buddy-agent-1.14.8.jar;C:\work\apache-maven-3.8.8\repo\org\objenesis\objenesis\3.3\objenesis-3.3.jar;C:\work\apache-maven-3.8.8\repo\org\mockito\mockito-junit-jupiter\5.3.1\mockito-junit-jupiter-5.3.1.jar;C:\work\apache-maven-3.8.8\repo\org\skyscreamer\jsonassert\1.5.1\jsonassert-1.5.1.jar;C:\work\apache-maven-3.8.8\repo\com\vaadin\external\google\android-json\0.0.20131108.vaadin1\android-json-0.0.20131108.vaadin1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-core\6.0.12\spring-core-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-jcl\6.0.12\spring-jcl-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-test\6.0.12\spring-test-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\xmlunit\xmlunit-core\2.9.1\xmlunit-core-2.9.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy\4.0.15\groovy-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-ant\4.0.15\groovy-ant-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant\1.10.14\ant-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-junit\1.10.14\ant-junit-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-launcher\1.10.14\ant-launcher-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-antlr\1.10.14\ant-antlr-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-cli-picocli\4.0.15\groovy-cli-picocli-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\info\picocli\picocli\4.7.5\picocli-4.7.5.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-console\4.0.15\groovy-console-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\github\javaparser\javaparser-core\3.25.5\javaparser-core-3.25.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-util\9.5\asm-util-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-tree\9.5\asm-tree-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-analysis\9.5\asm-analysis-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\abego\treelayout\org.abego.treelayout.core\1.0.3\org.abego.treelayout.core-1.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ivy\ivy\2.5.2\ivy-2.5.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-datetime\4.0.15\groovy-datetime-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-docgenerator\4.0.15\groovy-docgenerator-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\thoughtworks\qdox\qdox\1.12.1\qdox-1.12.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-groovydoc\4.0.15\groovy-groovydoc-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-groovysh\4.0.15\groovy-groovysh-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\jline\jline\2.14.6\jline-2.14.6.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-jmx\4.0.15\groovy-jmx-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-json\4.0.15\groovy-json-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-jsr223\4.0.15\groovy-jsr223-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-macro\4.0.15\groovy-macro-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-nio\4.0.15\groovy-nio-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-servlet\4.0.15\groovy-servlet-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-sql\4.0.15\groovy-sql-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-swing\4.0.15\groovy-swing-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-templates\4.0.15\groovy-templates-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-test\4.0.15\groovy-test-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\junit\junit\4.13.2\junit-4.13.2.jar;C:\work\apache-maven-3.8.8\repo\org\hamcrest\hamcrest-core\2.2\hamcrest-core-2.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-test-junit5\4.0.15\groovy-test-junit5-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-xml\4.0.15\groovy-xml-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-yaml\4.0.15\groovy-yaml-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\dataformat\jackson-dataformat-yaml\2.15.2\jackson-dataformat-yaml-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\org\spockframework\spock-core\2.4-M1-groovy-4.0\spock-core-2.4-M1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-engine\1.9.3\junit-platform-engine-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\opentest4j\opentest4j\1.2.0\opentest4j-1.2.0.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-commons\1.9.3\junit-platform-commons-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\apiguardian\apiguardian-api\1.1.2\apiguardian-api-1.1.2.jar;C:\work\apache-maven-3.8.8\repo\org\spockframework\spock-spring\2.4-M1-groovy-4.0\spock-spring-2.4-M1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\com\athaydes\spock-reports\2.5.1-groovy-4.0\spock-reports-2.5.1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\com\github\codemonstur\embedded-redis\1.4.2\embedded-redis-1.4.2.jar;C:\work\apache-maven-3.8.8\repo\redis\clients\jedis\4.3.2\jedis-4.3.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\commons\commons-pool2\2.11.1\commons-pool2-2.11.1.jar;C:\work\apache-maven-3.8.8\repo\org\json\json\20220320\json-20220320.jar;C:\work\apache-maven-3.8.8\repo\com\google\code\gson\gson\2.10.1\gson-2.10.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\kafka\spring-kafka-test\3.0.11\spring-kafka-test-3.0.11.jar;C:\work\apache-maven-3.8.8\repo\org\apache\zookeeper\zookeeper\3.6.3\zookeeper-3.6.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\zookeeper\zookeeper-jute\3.6.3\zookeeper-jute-3.6.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-classes-epoll\4.1.97.Final\netty-transport-classes-epoll-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1-test.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-metadata\3.4.1\kafka-metadata-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-server-common\3.4.1\kafka-server-common-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-raft\3.4.1\kafka-raft-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-streams-test-utils\3.4.1\kafka-streams-test-utils-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-streams\3.4.1\kafka-streams-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\rocksdb\rocksdbjni\7.1.2\rocksdbjni-7.1.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\scala-library\2.13.10\scala-library-2.13.10.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-group-coordinator\3.4.1\kafka-group-coordinator-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-storage\3.4.1\kafka-storage-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-storage-api\3.4.1\kafka-storage-api-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\net\sourceforge\argparse4j\argparse4j\0.7.0\argparse4j-0.7.0.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\module\jackson-module-scala_2.13\2.15.2\jackson-module-scala_2.13-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\thoughtworks\paranamer\paranamer\2.8\paranamer-2.8.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\dataformat\jackson-dataformat-csv\2.15.2\jackson-dataformat-csv-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\net\sf\jopt-simple\jopt-simple\5.0.4\jopt-simple-5.0.4.jar;C:\work\apache-maven-3.8.8\repo\org\bitbucket\b_c\jose4j\0.9.3\jose4j-0.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\modules\scala-collection-compat_2.13\2.10.0\scala-collection-compat_2.13-2.10.0.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\modules\scala-java8-compat_2.13\1.0.2\scala-java8-compat_2.13-1.0.2.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\scala-reflect\2.13.10\scala-reflect-2.13.10.jar;C:\work\apache-maven-3.8.8\repo\com\typesafe\scala-logging\scala-logging_2.13\3.9.4\scala-logging_2.13-3.9.4.jar;C:\work\apache-maven-3.8.8\repo\io\dropwizard\metrics\metrics-core\4.2.19\metrics-core-4.2.19.jar;C:\work\apache-maven-3.8.8\repo\commons-cli\commons-cli\1.4\commons-cli-1.4.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1-test.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-api\5.9.3\junit-jupiter-api-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-launcher\1.9.3\junit-platform-launcher-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\awaitility\awaitility\4.2.0\awaitility-4.2.0.jar;
2025-01-04 00:11:34.917 Client environment:java.library.path=C:\work\jdk-17\bin;C:\windows\Sun\Java\bin;C:\windows\system32;C:\windows;C:\work\python312\Scripts\;C:\work\python312\;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program\Git\cmd;C:\Program\PowerShell\7\;C:\Program Files\dotnet\;;C:\Program Files\Docker\Docker\resources\bin;C:\Users\joech\AppData\Local\Microsoft\WindowsApps;C:\Users\joech\AppData\Local\GitHubDesktop\bin;C:\Program\Microsoft VS Code\bin;C:\work\apache-maven-3.8.8\bin;C:\Program Files\Tesseract-OCR;C:\work\jdk-17\bin;;.
2025-01-04 00:11:34.917 Client environment:java.io.tmpdir=C:\Users\joech\AppData\Local\Temp\
2025-01-04 00:11:34.917 Client environment:java.compiler=<NA>
2025-01-04 00:11:34.917 Client environment:os.name=Windows 11
2025-01-04 00:11:34.917 Client environment:os.arch=amd64
2025-01-04 00:11:34.917 Client environment:os.version=10.0
2025-01-04 00:11:34.917 Client environment:user.name=joech
2025-01-04 00:11:34.917 Client environment:user.home=C:\Users\joech
2025-01-04 00:11:34.917 Client environment:user.dir=C:\code\hsbc\demo\pong
2025-01-04 00:11:34.917 Client environment:os.memory.free=43MB
2025-01-04 00:11:34.917 Client environment:os.memory.max=15816MB
2025-01-04 00:11:34.917 Client environment:os.memory.total=136MB
2025-01-04 00:11:34.923 Initiating client connection, connectString=127.0.0.1:51105 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1228a579
2025-01-04 00:11:34.929 jute.maxbuffer value is 4194304 Bytes
2025-01-04 00:11:34.937 zookeeper.request.timeout value is 0. feature enabled=false
2025-01-04 00:11:34.938 [ZooKeeperClient Kafka server] Waiting until connected.
2025-01-04 00:11:34.939 Opening socket connection to server /127.0.0.1:51105.
2025-01-04 00:11:34.940 Socket connection established, initiating session, client: /127.0.0.1:51106, server: /127.0.0.1:51105
2025-01-04 00:11:34.950 Creating new log file: log.1
2025-01-04 00:11:34.958 ZooKeeper audit is disabled.
2025-01-04 00:11:34.962 Session establishment complete on server /127.0.0.1:51105, session id = 0x1000a9c3c810000, negotiated timeout = 16000
2025-01-04 00:11:34.965 [ZooKeeperClient Kafka server] Connected.
2025-01-04 00:11:35.348 Cluster ID = vll67lrZQ7iw9aJBislcOg
2025-01-04 00:11:35.351 No meta.properties file under dir C:\Users\joech\AppData\Local\Temp\spring.kafka.575df12b-aff4-406a-b0cb-423f0751455b3635952113307784600\meta.properties
2025-01-04 00:11:35.393 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.575df12b-aff4-406a-b0cb-423f0751455b3635952113307784600
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:51105
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2025-01-04 00:11:35.424 [ThrottledChannelReaper-Fetch]: Starting
2025-01-04 00:11:35.424 [ThrottledChannelReaper-Produce]: Starting
2025-01-04 00:11:35.426 [ThrottledChannelReaper-Request]: Starting
2025-01-04 00:11:35.429 [ThrottledChannelReaper-ControllerMutation]: Starting
2025-01-04 00:11:35.458 Loading logs from log dirs ArraySeq(C:\Users\joech\AppData\Local\Temp\spring.kafka.575df12b-aff4-406a-b0cb-423f0751455b3635952113307784600)
2025-01-04 00:11:35.461 Attempting recovery for all logs in C:\Users\joech\AppData\Local\Temp\spring.kafka.575df12b-aff4-406a-b0cb-423f0751455b3635952113307784600 since no clean shutdown file was found
2025-01-04 00:11:35.468 Loaded 0 logs in 10ms.
2025-01-04 00:11:35.469 Starting log cleanup with a period of 300000 ms.
2025-01-04 00:11:35.472 Starting log flusher with a default period of 9223372036854775807 ms.
2025-01-04 00:11:35.486 Starting the log cleaner
2025-01-04 00:11:35.498 [kafka-log-cleaner-thread-0]: Starting
2025-01-04 00:11:35.515 [feature-zk-node-event-process-thread]: Starting
2025-01-04 00:11:35.525 Feature ZK node at path: /feature does not exist
2025-01-04 00:11:35.562 [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting
2025-01-04 00:11:36.050 Updated connection-accept-rate max connection creation rate to 2147483647
2025-01-04 00:11:36.057 Awaiting socket connections on localhost:51108.
2025-01-04 00:11:36.094 [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT)
2025-01-04 00:11:36.103 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Starting
2025-01-04 00:11:36.127 [ExpirationReaper-0-Produce]: Starting
2025-01-04 00:11:36.129 [ExpirationReaper-0-Fetch]: Starting
2025-01-04 00:11:36.130 [ExpirationReaper-0-DeleteRecords]: Starting
2025-01-04 00:11:36.130 [ExpirationReaper-0-ElectLeader]: Starting
2025-01-04 00:11:36.152 [LogDirFailureHandler]: Starting
2025-01-04 00:11:36.185 Creating /brokers/ids/0 (is it secure? false)
2025-01-04 00:11:36.204 Stat of the created znode at /brokers/ids/0 is: 25,25,1735920696197,1735920696197,1,0,0,72069260184190976,204,0,25

2025-01-04 00:11:36.205 Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:51108, czxid (broker epoch): 25
2025-01-04 00:11:36.287 [ControllerEventThread controllerId=0] Starting
2025-01-04 00:11:36.295 [ExpirationReaper-0-topic]: Starting
2025-01-04 00:11:36.305 [ExpirationReaper-0-Heartbeat]: Starting
2025-01-04 00:11:36.306 [ExpirationReaper-0-Rebalance]: Starting
2025-01-04 00:11:36.323 Successfully created /controller_epoch with initial epoch 0
2025-01-04 00:11:36.330 [Controller id=0] 0 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1
2025-01-04 00:11:36.333 [GroupCoordinator 0]: Starting up.
2025-01-04 00:11:36.334 [Controller id=0] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map())
2025-01-04 00:11:36.338 Feature ZK node created at path: /feature
2025-01-04 00:11:36.340 [GroupCoordinator 0]: Startup complete.
2025-01-04 00:11:36.366 [TransactionCoordinator id=0] Starting up.
2025-01-04 00:11:36.370 [Transaction Marker Channel Manager 0]: Starting
2025-01-04 00:11:36.370 [TransactionCoordinator id=0] Startup complete.
2025-01-04 00:11:36.386 [Controller id=0] Registering handlers
2025-01-04 00:11:36.387 [MetadataCache brokerId=0] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0).
2025-01-04 00:11:36.390 [Controller id=0] Deleting log dir event notifications
2025-01-04 00:11:36.393 [Controller id=0] Deleting isr change notifications
2025-01-04 00:11:36.397 [Controller id=0] Initializing controller context
2025-01-04 00:11:36.420 [Controller id=0] Initialized broker epochs cache: HashMap(0 -> 25)
2025-01-04 00:11:36.424 [ExpirationReaper-0-AlterAcls]: Starting
2025-01-04 00:11:36.457 [RequestSendThread controllerId=0] Starting
2025-01-04 00:11:36.461 [Controller id=0] Currently active brokers in the cluster: Set(0)
2025-01-04 00:11:36.461 [Controller id=0] Currently shutting brokers in the cluster: HashSet()
2025-01-04 00:11:36.462 [Controller id=0] Current list of topics in the cluster: HashSet()
2025-01-04 00:11:36.462 [Controller id=0] Fetching topic deletions in progress
2025-01-04 00:11:36.465 [Controller id=0] List of topics to be deleted: 
2025-01-04 00:11:36.466 [Controller id=0] List of topics ineligible for deletion: 
2025-01-04 00:11:36.466 [Controller id=0] Initializing topic deletion manager
2025-01-04 00:11:36.467 [Topic Deletion Manager 0] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet()
2025-01-04 00:11:36.469 [Controller id=0] Sending update metadata request
2025-01-04 00:11:36.472 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions
2025-01-04 00:11:36.475 [/config/changes-event-process-thread]: Starting
2025-01-04 00:11:36.480 [ReplicaStateMachine controllerId=0] Initializing replica state
2025-01-04 00:11:36.480 [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2025-01-04 00:11:36.484 [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing.
2025-01-04 00:11:36.485 [ReplicaStateMachine controllerId=0] Triggering offline replica state changes
2025-01-04 00:11:36.485 [PartitionStateMachine controllerId=0] Initializing partition state
2025-01-04 00:11:36.486 [PartitionStateMachine controllerId=0] Triggering online partition state changes
2025-01-04 00:11:36.488 Kafka version: 3.4.1
2025-01-04 00:11:36.488 Kafka commitId: 8a516edc2755df89
2025-01-04 00:11:36.488 Kafka startTimeMs: 1735920696486
2025-01-04 00:11:36.490 [RequestSendThread controllerId=0] Controller 0 connected to localhost:51108 (id: 0 rack: null) for sending state change requests
2025-01-04 00:11:36.490 [KafkaServer id=0] started
2025-01-04 00:11:36.491 [Controller id=0] Ready to serve as the new controller with epoch 1
2025-01-04 00:11:36.498 [Controller id=0] Partitions undergoing preferred replica election: 
2025-01-04 00:11:36.498 [Controller id=0] Partitions that completed preferred replica election: 
2025-01-04 00:11:36.499 [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2025-01-04 00:11:36.499 [Controller id=0] Resuming preferred replica election for partitions: 
2025-01-04 00:11:36.500 AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [127.0.0.1:51108]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-01-04 00:11:36.501 [Controller id=0] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered
2025-01-04 00:11:36.516 [Controller id=0] Starting the controller scheduler
2025-01-04 00:11:36.560 Kafka version: 3.4.1
2025-01-04 00:11:36.560 Kafka commitId: 8a516edc2755df89
2025-01-04 00:11:36.560 Kafka startTimeMs: 1735920696560
2025-01-04 00:11:36.572 [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use node localhost:51108 (id: 0 rack: null)
2025-01-04 00:11:36.607 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Recorded new controller, from now on will use node localhost:51108 (id: 0 rack: null)
2025-01-04 00:11:36.705 Creating topic pong-message-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0))
2025-01-04 00:11:36.724 [Controller id=0] New topics: [Set(pong-message-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(pong-message-topic,Some(xXFHgAhBRnaScD4rZIhO4w),Map(pong-message-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), pong-message-topic-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-01-04 00:11:36.725 [Controller id=0] New partition creation callback for pong-message-topic-0,pong-message-topic-1
2025-01-04 00:11:36.727 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-04 00:11:36.728 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-04 00:11:36.728 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:11:36.733 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:11:36.755 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-04 00:11:36.755 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-04 00:11:36.757 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2025-01-04 00:11:36.758 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2025-01-04 00:11:36.759 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:11:36.762 [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 for 2 partitions
2025-01-04 00:11:36.797 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(pong-message-topic-0, pong-message-topic-1)
2025-01-04 00:11:36.798 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2025-01-04 00:11:36.861 [LogLoader partition=pong-message-topic-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.575df12b-aff4-406a-b0cb-423f0751455b3635952113307784600] Loading producer state till offset 0 with message format version 2
2025-01-04 00:11:36.873 Created log for partition pong-message-topic-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.575df12b-aff4-406a-b0cb-423f0751455b3635952113307784600\pong-message-topic-0 with properties {}
2025-01-04 00:11:36.875 [Partition pong-message-topic-0 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-0
2025-01-04 00:11:36.875 [Partition pong-message-topic-0 broker=0] Log loaded for partition pong-message-topic-0 with initial high watermark 0
2025-01-04 00:11:36.877 [Broker id=0] Leader pong-message-topic-0 with topic id Some(xXFHgAhBRnaScD4rZIhO4w) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2025-01-04 00:11:36.888 [LogLoader partition=pong-message-topic-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.575df12b-aff4-406a-b0cb-423f0751455b3635952113307784600] Loading producer state till offset 0 with message format version 2
2025-01-04 00:11:36.889 Created log for partition pong-message-topic-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.575df12b-aff4-406a-b0cb-423f0751455b3635952113307784600\pong-message-topic-1 with properties {}
2025-01-04 00:11:36.890 [Partition pong-message-topic-1 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-1
2025-01-04 00:11:36.890 [Partition pong-message-topic-1 broker=0] Log loaded for partition pong-message-topic-1 with initial high watermark 0
2025-01-04 00:11:36.890 [Broker id=0] Leader pong-message-topic-1 with topic id Some(xXFHgAhBRnaScD4rZIhO4w) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2025-01-04 00:11:36.897 [Broker id=0] Finished LeaderAndIsr request in 136ms correlationId 1 from controller 0 for 2 partitions
2025-01-04 00:11:36.903 [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2
2025-01-04 00:11:36.908 App info kafka.admin.client for adminclient-1 unregistered
2025-01-04 00:11:36.910 Metrics scheduler closed
2025-01-04 00:11:36.910 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-04 00:11:36.910 Metrics reporters closed
2025-01-04 00:11:37.165 

Found multiple occurrences of org.json.JSONObject on the class path:

	jar:file:/C:/work/apache-maven-3.8.8/repo/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar!/org/json/JSONObject.class
	jar:file:/C:/work/apache-maven-3.8.8/repo/org/json/json/20220320/json-20220320.jar!/org/json/JSONObject.class

You may wish to exclude one of them to ensure predictable runtime behavior

2025-01-04 00:11:37.186 Starting KafkaSpec using Java 17.0.12 with PID 29972 (started by joech in C:\code\hsbc\demo\pong)
2025-01-04 00:11:37.187 No active profile set, falling back to 1 default profile: "default"
2025-01-04 00:11:37.838 Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-04 00:11:37.840 Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-04 00:11:38.047 Finished Spring Data repository scanning in 194 ms. Found 1 JPA repository interfaces.
2025-01-04 00:11:38.077 Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-04 00:11:38.078 Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-04 00:11:38.101 Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.demo.dao.MessageRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-04 00:11:38.101 Finished Spring Data repository scanning in 6 ms. Found 0 Redis repository interfaces.
2025-01-04 00:11:38.597 HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-04 00:11:38.693 HHH000412: Hibernate ORM core version 6.2.9.Final
2025-01-04 00:11:38.696 HHH000406: Using bytecode reflection optimizer
2025-01-04 00:11:38.900 HHH000021: Bytecode provider name : bytebuddy
2025-01-04 00:11:39.126 No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-04 00:11:39.176 HikariPool-1 - Starting...
2025-01-04 00:11:40.086 HikariPool-1 - Added connection conn0: url=jdbc:h2:mem:testdb user=SA
2025-01-04 00:11:40.092 HikariPool-1 - Start completed.
2025-01-04 00:11:40.666 HHH000021: Bytecode provider name : bytebuddy
2025-01-04 00:11:41.517 [Controller id=0] Processing automatic preferred replica leader election
2025-01-04 00:11:41.976 HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2025-01-04 00:11:42.232 Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-04 00:11:45.413 ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:51108]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-pong-service-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = pong-service
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-04 00:11:45.492 These configurations '[spring.json.trusted.packages]' were supplied but are not used yet.
2025-01-04 00:11:45.493 Kafka version: 3.4.1
2025-01-04 00:11:45.493 Kafka commitId: 8a516edc2755df89
2025-01-04 00:11:45.493 Kafka startTimeMs: 1735920705493
2025-01-04 00:11:45.495 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Subscribed to topic(s): pong-message-topic
2025-01-04 00:11:45.520 Started KafkaSpec in 8.567 seconds (process running for 18.202)
2025-01-04 00:11:45.542 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting the last seen epoch of partition pong-message-topic-0 to 0 since the associated topicId changed from null to xXFHgAhBRnaScD4rZIhO4w
2025-01-04 00:11:45.544 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting the last seen epoch of partition pong-message-topic-1 to 0 since the associated topicId changed from null to xXFHgAhBRnaScD4rZIhO4w
2025-01-04 00:11:45.549 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Cluster ID: vll67lrZQ7iw9aJBislcOg
2025-01-04 00:11:45.549 Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0))
2025-01-04 00:11:45.562 [Controller id=0] New topics: [Set(__consumer_offsets)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(__consumer_offsets,Some(vld8pAl_Q5-nmB_85E-UCg),HashMap(__consumer_offsets-4 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-3 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-2 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-01-04 00:11:45.562 [Controller id=0] New partition creation callback for __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2025-01-04 00:11:45.563 [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-04 00:11:45.563 [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-04 00:11:45.563 [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-04 00:11:45.563 [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-04 00:11:45.563 [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-04 00:11:45.563 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:11:45.564 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:11:45.578 [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-04 00:11:45.578 [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-04 00:11:45.579 [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-04 00:11:45.579 [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-04 00:11:45.579 [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-04 00:11:45.579 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 5 become-leader and 0 become-follower partitions
2025-01-04 00:11:45.579 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 5 partitions
2025-01-04 00:11:45.579 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:11:45.581 [Broker id=0] Handling LeaderAndIsr request correlationId 3 from controller 0 for 5 partitions
2025-01-04 00:11:45.584 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-4, __consumer_offsets-3, __consumer_offsets-2, __consumer_offsets-0, __consumer_offsets-1)
2025-01-04 00:11:45.584 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 3 from controller 0 epoch 1 as part of the become-leader transition for 5 partitions
2025-01-04 00:11:45.596 [LogLoader partition=__consumer_offsets-3, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.575df12b-aff4-406a-b0cb-423f0751455b3635952113307784600] Loading producer state till offset 0 with message format version 2
2025-01-04 00:11:45.598 Created log for partition __consumer_offsets-3 in C:\Users\joech\AppData\Local\Temp\spring.kafka.575df12b-aff4-406a-b0cb-423f0751455b3635952113307784600\__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-01-04 00:11:45.612 [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
2025-01-04 00:11:45.613 [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0
2025-01-04 00:11:45.613 [Broker id=0] Leader __consumer_offsets-3 with topic id Some(vld8pAl_Q5-nmB_85E-UCg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2025-01-04 00:11:45.628 [LogLoader partition=__consumer_offsets-2, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.575df12b-aff4-406a-b0cb-423f0751455b3635952113307784600] Loading producer state till offset 0 with message format version 2
2025-01-04 00:11:45.631 Created log for partition __consumer_offsets-2 in C:\Users\joech\AppData\Local\Temp\spring.kafka.575df12b-aff4-406a-b0cb-423f0751455b3635952113307784600\__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-01-04 00:11:45.631 [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
2025-01-04 00:11:45.631 [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0
2025-01-04 00:11:45.632 [Broker id=0] Leader __consumer_offsets-2 with topic id Some(vld8pAl_Q5-nmB_85E-UCg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2025-01-04 00:11:45.650 [LogLoader partition=__consumer_offsets-4, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.575df12b-aff4-406a-b0cb-423f0751455b3635952113307784600] Loading producer state till offset 0 with message format version 2
2025-01-04 00:11:45.652 Created log for partition __consumer_offsets-4 in C:\Users\joech\AppData\Local\Temp\spring.kafka.575df12b-aff4-406a-b0cb-423f0751455b3635952113307784600\__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-01-04 00:11:45.653 [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
2025-01-04 00:11:45.653 [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0
2025-01-04 00:11:45.653 [Broker id=0] Leader __consumer_offsets-4 with topic id Some(vld8pAl_Q5-nmB_85E-UCg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2025-01-04 00:11:45.673 [LogLoader partition=__consumer_offsets-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.575df12b-aff4-406a-b0cb-423f0751455b3635952113307784600] Loading producer state till offset 0 with message format version 2
2025-01-04 00:11:45.674 Created log for partition __consumer_offsets-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.575df12b-aff4-406a-b0cb-423f0751455b3635952113307784600\__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-01-04 00:11:45.674 [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
2025-01-04 00:11:45.674 [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0
2025-01-04 00:11:45.674 [Broker id=0] Leader __consumer_offsets-1 with topic id Some(vld8pAl_Q5-nmB_85E-UCg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2025-01-04 00:11:45.691 [LogLoader partition=__consumer_offsets-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.575df12b-aff4-406a-b0cb-423f0751455b3635952113307784600] Loading producer state till offset 0 with message format version 2
2025-01-04 00:11:45.692 Created log for partition __consumer_offsets-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.575df12b-aff4-406a-b0cb-423f0751455b3635952113307784600\__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-01-04 00:11:45.692 [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
2025-01-04 00:11:45.692 [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0
2025-01-04 00:11:45.694 [Broker id=0] Leader __consumer_offsets-0 with topic id Some(vld8pAl_Q5-nmB_85E-UCg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2025-01-04 00:11:45.699 [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 0
2025-01-04 00:11:45.700 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0
2025-01-04 00:11:45.703 [GroupCoordinator 0]: Elected as the group coordinator for partition 2 in epoch 0
2025-01-04 00:11:45.703 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0
2025-01-04 00:11:45.703 [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 0
2025-01-04 00:11:45.703 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0
2025-01-04 00:11:45.703 [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 0
2025-01-04 00:11:45.704 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0
2025-01-04 00:11:45.704 [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 0
2025-01-04 00:11:45.704 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0
2025-01-04 00:11:45.704 [Broker id=0] Finished LeaderAndIsr request in 123ms correlationId 3 from controller 0 for 5 partitions
2025-01-04 00:11:45.708 [Broker id=0] Add 5 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 4
2025-01-04 00:11:45.712 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 10 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler.
2025-01-04 00:11:45.712 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler.
2025-01-04 00:11:45.713 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 10 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler.
2025-01-04 00:11:45.713 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler.
2025-01-04 00:11:45.714 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 10 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler.
2025-01-04 00:11:45.757 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Discovered group coordinator localhost:51108 (id: 2147483647 rack: null)
2025-01-04 00:11:45.759 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] (Re-)joining group
2025-01-04 00:11:45.808 [GroupCoordinator 0]: Dynamic member with unknown member id joins group pong-service in Empty state. Created a new member id consumer-pong-service-1-0234c5aa-e931-4675-8ba3-7ffda24f6c05 and request the member to rejoin with this id.
2025-01-04 00:11:45.816 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: need to re-join with the given member-id: consumer-pong-service-1-0234c5aa-e931-4675-8ba3-7ffda24f6c05
2025-01-04 00:11:45.816 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2025-01-04 00:11:45.816 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] (Re-)joining group
2025-01-04 00:11:45.828 [GroupCoordinator 0]: Preparing to rebalance group pong-service in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-pong-service-1-0234c5aa-e931-4675-8ba3-7ffda24f6c05 with group instance id None; client reason: rebalance failed due to MemberIdRequiredException)
2025-01-04 00:11:45.837 [GroupCoordinator 0]: Stabilized group pong-service generation 1 (__consumer_offsets-2) with 1 members
2025-01-04 00:11:45.840 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Successfully joined group with generation Generation{generationId=1, memberId='consumer-pong-service-1-0234c5aa-e931-4675-8ba3-7ffda24f6c05', protocol='range'}
2025-01-04 00:11:45.843 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Finished assignment for group at generation 1: {consumer-pong-service-1-0234c5aa-e931-4675-8ba3-7ffda24f6c05=Assignment(partitions=[pong-message-topic-0, pong-message-topic-1])}
2025-01-04 00:11:45.856 [GroupCoordinator 0]: Assignment received from leader consumer-pong-service-1-0234c5aa-e931-4675-8ba3-7ffda24f6c05 for group pong-service for generation 1. The group has 1 members, 0 of which are static.
2025-01-04 00:11:45.959 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Successfully synced group in generation Generation{generationId=1, memberId='consumer-pong-service-1-0234c5aa-e931-4675-8ba3-7ffda24f6c05', protocol='range'}
2025-01-04 00:11:45.960 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Notifying assignor about the new Assignment(partitions=[pong-message-topic-0, pong-message-topic-1])
2025-01-04 00:11:45.964 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Adding newly assigned partitions: pong-message-topic-0, pong-message-topic-1
2025-01-04 00:11:45.981 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-0
2025-01-04 00:11:45.981 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-1
2025-01-04 00:11:45.988 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-0
2025-01-04 00:11:45.989 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-1
2025-01-04 00:11:46.007 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting offset for partition pong-message-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:51108 (id: 0 rack: null)], epoch=0}}.
2025-01-04 00:11:46.009 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting offset for partition pong-message-topic-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:51108 (id: 0 rack: null)], epoch=0}}.
2025-01-04 00:11:46.033 pong-service: partitions assigned: [pong-message-topic-0, pong-message-topic-1]
2025-01-04 00:11:46.457 Idempotence will be disabled because acks is set to 0, not set to 'all'.
2025-01-04 00:11:46.457 ProducerConfig values: 
	acks = 0
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:51108]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2025-01-04 00:11:46.486 Kafka version: 3.4.1
2025-01-04 00:11:46.486 Kafka commitId: 8a516edc2755df89
2025-01-04 00:11:46.486 Kafka startTimeMs: 1735920706486
2025-01-04 00:11:46.491 [Producer clientId=producer-1] Cluster ID: vll67lrZQ7iw9aJBislcOg
2025-01-04 00:11:46.495 [Producer clientId=producer-1] Resetting the last seen epoch of partition pong-message-topic-0 to 0 since the associated topicId changed from null to xXFHgAhBRnaScD4rZIhO4w
2025-01-04 00:11:46.495 [Producer clientId=producer-1] Resetting the last seen epoch of partition pong-message-topic-1 to 0 since the associated topicId changed from null to xXFHgAhBRnaScD4rZIhO4w
2025-01-04 00:11:46.661 [KafkaServer id=0] shutting down
2025-01-04 00:11:46.661 [KafkaServer id=0] Starting controlled shutdown
2025-01-04 00:11:46.666 [Controller id=0] Shutting down broker 0
2025-01-04 00:11:46.667 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:11:46.669 [KafkaServer id=0] Controlled shutdown request returned successfully after 6ms
2025-01-04 00:11:46.670 [/config/changes-event-process-thread]: Shutting down
2025-01-04 00:11:46.671 [/config/changes-event-process-thread]: Shutdown completed
2025-01-04 00:11:46.671 [/config/changes-event-process-thread]: Stopped
2025-01-04 00:11:46.671 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
2025-01-04 00:11:46.672 [Producer clientId=producer-1] Node 0 disconnected.
2025-01-04 00:11:46.672 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 2147483647 disconnected.
2025-01-04 00:11:46.674 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2025-01-04 00:11:46.675 [Producer clientId=producer-1] Node -1 disconnected.
2025-01-04 00:11:46.675 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 0 disconnected.
2025-01-04 00:11:46.676 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Cancelled in-flight FETCH request with correlation id 17 due to node 0 being disconnected (elapsed time since creation: 130ms, elapsed time since send: 130ms, request timeout: 30000ms)
2025-01-04 00:11:46.677 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors
2025-01-04 00:11:46.677 [data-plane Kafka Request Handler on Broker 0], shutting down
2025-01-04 00:11:46.678 [data-plane Kafka Request Handler on Broker 0], shut down completely
2025-01-04 00:11:46.676 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Error sending fetch request (sessionId=1639997631, epoch=1) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2025-01-04 00:11:46.679 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Group coordinator localhost:51108 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
2025-01-04 00:11:46.679 [ExpirationReaper-0-AlterAcls]: Shutting down
2025-01-04 00:11:46.682 [ExpirationReaper-0-AlterAcls]: Stopped
2025-01-04 00:11:46.682 [ExpirationReaper-0-AlterAcls]: Shutdown completed
2025-01-04 00:11:46.682 [KafkaApi-0] Shutdown complete.
2025-01-04 00:11:46.683 [ExpirationReaper-0-topic]: Shutting down
2025-01-04 00:11:46.683 [ExpirationReaper-0-topic]: Stopped
2025-01-04 00:11:46.683 [ExpirationReaper-0-topic]: Shutdown completed
2025-01-04 00:11:46.684 [TransactionCoordinator id=0] Shutting down.
2025-01-04 00:11:46.685 [Transaction State Manager 0]: Shutdown complete
2025-01-04 00:11:46.685 [Transaction Marker Channel Manager 0]: Shutting down
2025-01-04 00:11:46.685 [Transaction Marker Channel Manager 0]: Shutdown completed
2025-01-04 00:11:46.685 [Transaction Marker Channel Manager 0]: Stopped
2025-01-04 00:11:46.686 [TransactionCoordinator id=0] Shutdown complete.
2025-01-04 00:11:46.686 [GroupCoordinator 0]: Shutting down.
2025-01-04 00:11:46.686 [ExpirationReaper-0-Heartbeat]: Shutting down
2025-01-04 00:11:46.688 [ExpirationReaper-0-Heartbeat]: Shutdown completed
2025-01-04 00:11:46.688 [ExpirationReaper-0-Heartbeat]: Stopped
2025-01-04 00:11:46.689 [ExpirationReaper-0-Rebalance]: Shutting down
2025-01-04 00:11:46.689 [ExpirationReaper-0-Rebalance]: Stopped
2025-01-04 00:11:46.689 [ExpirationReaper-0-Rebalance]: Shutdown completed
2025-01-04 00:11:46.689 [GroupCoordinator 0]: Shutdown complete.
2025-01-04 00:11:46.689 [ReplicaManager broker=0] Shutting down
2025-01-04 00:11:46.690 [LogDirFailureHandler]: Shutting down
2025-01-04 00:11:46.690 [LogDirFailureHandler]: Shutdown completed
2025-01-04 00:11:46.690 [LogDirFailureHandler]: Stopped
2025-01-04 00:11:46.690 [ReplicaFetcherManager on broker 0] shutting down
2025-01-04 00:11:46.690 [ReplicaFetcherManager on broker 0] shutdown completed
2025-01-04 00:11:46.690 [ReplicaAlterLogDirsManager on broker 0] shutting down
2025-01-04 00:11:46.691 [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2025-01-04 00:11:46.691 [ExpirationReaper-0-Fetch]: Shutting down
2025-01-04 00:11:46.691 [ExpirationReaper-0-Fetch]: Stopped
2025-01-04 00:11:46.691 [ExpirationReaper-0-Fetch]: Shutdown completed
2025-01-04 00:11:46.691 [ExpirationReaper-0-Produce]: Shutting down
2025-01-04 00:11:46.691 [ExpirationReaper-0-Produce]: Stopped
2025-01-04 00:11:46.691 [ExpirationReaper-0-Produce]: Shutdown completed
2025-01-04 00:11:46.691 [ExpirationReaper-0-DeleteRecords]: Shutting down
2025-01-04 00:11:46.692 [ExpirationReaper-0-DeleteRecords]: Stopped
2025-01-04 00:11:46.692 [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2025-01-04 00:11:46.692 [ExpirationReaper-0-ElectLeader]: Shutting down
2025-01-04 00:11:46.693 [ExpirationReaper-0-ElectLeader]: Shutdown completed
2025-01-04 00:11:46.693 [ExpirationReaper-0-ElectLeader]: Stopped
2025-01-04 00:11:46.696 [ReplicaManager broker=0] Shut down completely
2025-01-04 00:11:46.696 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutting down
2025-01-04 00:11:46.696 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutdown completed
2025-01-04 00:11:46.696 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Stopped
2025-01-04 00:11:46.697 Broker to controller channel manager for alterPartition shutdown
2025-01-04 00:11:46.697 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down
2025-01-04 00:11:46.697 [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped
2025-01-04 00:11:46.697 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed
2025-01-04 00:11:46.698 Broker to controller channel manager for forwarding shutdown
2025-01-04 00:11:46.698 Shutting down.
2025-01-04 00:11:46.699 Shutting down the log cleaner.
2025-01-04 00:11:46.699 [kafka-log-cleaner-thread-0]: Shutting down
2025-01-04 00:11:46.700 [kafka-log-cleaner-thread-0]: Shutdown completed
2025-01-04 00:11:46.700 [kafka-log-cleaner-thread-0]: Stopped
2025-01-04 00:11:46.726 [ProducerStateManager partition=pong-message-topic-1] Wrote producer snapshot at offset 1 with 0 producer ids in 4 ms.
2025-01-04 00:11:46.735 [ProducerStateManager partition=__consumer_offsets-2] Wrote producer snapshot at offset 4 with 0 producer ids in 1 ms.
2025-01-04 00:11:46.746 Shutdown complete.
2025-01-04 00:11:46.747 [ControllerEventThread controllerId=0] Shutting down
2025-01-04 00:11:46.747 [ControllerEventThread controllerId=0] Stopped
2025-01-04 00:11:46.747 [ControllerEventThread controllerId=0] Shutdown completed
2025-01-04 00:11:46.748 [PartitionStateMachine controllerId=0] Stopped partition state machine
2025-01-04 00:11:46.749 [ReplicaStateMachine controllerId=0] Stopped replica state machine
2025-01-04 00:11:46.749 [RequestSendThread controllerId=0] Shutting down
2025-01-04 00:11:46.749 [RequestSendThread controllerId=0] Stopped
2025-01-04 00:11:46.749 [RequestSendThread controllerId=0] Shutdown completed
2025-01-04 00:11:46.751 [Controller id=0] Resigned
2025-01-04 00:11:46.751 [feature-zk-node-event-process-thread]: Shutting down
2025-01-04 00:11:46.751 [feature-zk-node-event-process-thread]: Shutdown completed
2025-01-04 00:11:46.751 [feature-zk-node-event-process-thread]: Stopped
2025-01-04 00:11:46.752 [ZooKeeperClient Kafka server] Closing.
2025-01-04 00:11:46.774 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 0 disconnected.
2025-01-04 00:11:46.774 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node 0 (localhost/127.0.0.1:51108) could not be established. Broker may not be available.
2025-01-04 00:11:46.776 [Producer clientId=producer-1] Node 0 disconnected.
2025-01-04 00:11:46.776 [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:51108) could not be established. Broker may not be available.
2025-01-04 00:11:46.856 EventThread shut down for session: 0x1000a9c3c810000
2025-01-04 00:11:46.856 Session: 0x1000a9c3c810000 closed
2025-01-04 00:11:46.858 [ZooKeeperClient Kafka server] Closed.
2025-01-04 00:11:46.858 [ThrottledChannelReaper-Fetch]: Shutting down
2025-01-04 00:11:46.860 [ThrottledChannelReaper-Fetch]: Stopped
2025-01-04 00:11:46.860 [ThrottledChannelReaper-Fetch]: Shutdown completed
2025-01-04 00:11:46.860 [ThrottledChannelReaper-Produce]: Shutting down
2025-01-04 00:11:46.860 [ThrottledChannelReaper-Produce]: Stopped
2025-01-04 00:11:46.860 [ThrottledChannelReaper-Produce]: Shutdown completed
2025-01-04 00:11:46.860 [ThrottledChannelReaper-Request]: Shutting down
2025-01-04 00:11:46.860 [ThrottledChannelReaper-Request]: Stopped
2025-01-04 00:11:46.860 [ThrottledChannelReaper-Request]: Shutdown completed
2025-01-04 00:11:46.860 [ThrottledChannelReaper-ControllerMutation]: Shutting down
2025-01-04 00:11:46.860 [ThrottledChannelReaper-ControllerMutation]: Stopped
2025-01-04 00:11:46.860 [ThrottledChannelReaper-ControllerMutation]: Shutdown completed
2025-01-04 00:11:46.860 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server
2025-01-04 00:11:46.877 [Producer clientId=producer-1] Node 0 disconnected.
2025-01-04 00:11:46.877 [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:51108) could not be established. Broker may not be available.
2025-01-04 00:11:46.878 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed
2025-01-04 00:11:46.878 Metrics scheduler closed
2025-01-04 00:11:46.878 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-04 00:11:46.878 Metrics reporters closed
2025-01-04 00:11:46.881 Broker and topic stats closed
2025-01-04 00:11:46.883 App info kafka.server for 0 unregistered
2025-01-04 00:11:46.883 [KafkaServer id=0] shut down completed
2025-01-04 00:11:46.898 ConnnectionExpirerThread interrupted
2025-01-04 00:11:46.900 selector thread exitted run method
2025-01-04 00:11:46.900 selector thread exitted run method
2025-01-04 00:11:46.900 accept thread exitted run method
2025-01-04 00:11:46.901 shutting down
2025-01-04 00:11:46.901 Shutting down
2025-01-04 00:11:46.901 Draining request throttler queue
2025-01-04 00:11:46.901 RequestThrottler shutdown. Dropped 0 requests
2025-01-04 00:11:46.901 Shutting down
2025-01-04 00:11:46.901 Shutting down
2025-01-04 00:11:46.901 Shutting down
2025-01-04 00:11:46.901 PrepRequestProcessor exited loop!
2025-01-04 00:11:46.901 SyncRequestProcessor exited!
2025-01-04 00:11:46.901 shutdown of request processor complete
2025-01-04 00:11:46.925 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 0 disconnected.
2025-01-04 00:11:46.927 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node 0 (localhost/127.0.0.1:51108) could not be established. Broker may not be available.
2025-01-04 00:11:46.930 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Revoke previously assigned partitions pong-message-topic-0, pong-message-topic-1
2025-01-04 00:11:46.931 pong-service: partitions revoked: [pong-message-topic-0, pong-message-topic-1]
2025-01-04 00:11:46.931 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-04 00:11:46.931 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2025-01-04 00:11:46.931 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Unsubscribed all topics or patterns and assigned partitions
2025-01-04 00:11:46.932 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-04 00:11:46.932 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2025-01-04 00:11:46.932 Metrics scheduler closed
2025-01-04 00:11:46.932 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-04 00:11:46.932 Metrics reporters closed
2025-01-04 00:11:46.932 App info kafka.consumer for consumer-pong-service-1 unregistered
2025-01-04 00:11:46.934 pong-service: Consumer stopped
2025-01-04 00:11:46.935 [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2025-01-04 00:11:46.937 Metrics scheduler closed
2025-01-04 00:11:46.937 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-04 00:11:46.937 Metrics reporters closed
2025-01-04 00:11:46.937 App info kafka.producer for producer-1 unregistered
2025-01-04 00:11:46.973 Closing JPA EntityManagerFactory for persistence unit 'default'
2025-01-04 00:11:46.977 HikariPool-1 - Shutdown initiated...
2025-01-04 00:11:46.979 HikariPool-1 - Shutdown completed.
2025-01-04 00:11:47.052 

Found multiple occurrences of org.json.JSONObject on the class path:

	jar:file:/C:/work/apache-maven-3.8.8/repo/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar!/org/json/JSONObject.class
	jar:file:/C:/work/apache-maven-3.8.8/repo/org/json/json/20220320/json-20220320.jar!/org/json/JSONObject.class

You may wish to exclude one of them to ensure predictable runtime behavior

2025-01-04 00:11:47.057 Starting MessageRepositorySpec using Java 17.0.12 with PID 29972 (started by joech in C:\code\hsbc\demo\pong)
2025-01-04 00:11:47.057 No active profile set, falling back to 1 default profile: "default"
2025-01-04 00:11:47.195 SessionTrackerImpl exited loop!
2025-01-04 00:11:47.373 Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-04 00:11:47.374 Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-04 00:11:47.406 Finished Spring Data repository scanning in 31 ms. Found 1 JPA repository interfaces.
2025-01-04 00:11:47.417 Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-04 00:11:47.418 Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-04 00:11:47.429 Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.demo.dao.MessageRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-04 00:11:47.429 Finished Spring Data repository scanning in 10 ms. Found 0 Redis repository interfaces.
2025-01-04 00:11:47.671 HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-04 00:11:47.690 HHH000021: Bytecode provider name : bytebuddy
2025-01-04 00:11:47.691 No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-04 00:11:47.692 HikariPool-2 - Starting...
2025-01-04 00:11:47.699 HikariPool-2 - Added connection conn10: url=jdbc:h2:mem:testdb user=SA
2025-01-04 00:11:47.699 HikariPool-2 - Start completed.
2025-01-04 00:11:47.723 HHH000021: Bytecode provider name : bytebuddy
2025-01-04 00:11:47.788 HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2025-01-04 00:11:47.824 Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-04 00:11:48.202 ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:51108]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-pong-service-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = pong-service
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-04 00:11:48.208 These configurations '[spring.json.trusted.packages]' were supplied but are not used yet.
2025-01-04 00:11:48.209 Kafka version: 3.4.1
2025-01-04 00:11:48.209 Kafka commitId: 8a516edc2755df89
2025-01-04 00:11:48.209 Kafka startTimeMs: 1735920708209
2025-01-04 00:11:48.209 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Subscribed to topic(s): pong-message-topic
2025-01-04 00:11:48.212 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Node -1 disconnected.
2025-01-04 00:11:48.212 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Connection to node -1 (/127.0.0.1:51108) could not be established. Broker may not be available.
2025-01-04 00:11:48.213 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Bootstrap broker 127.0.0.1:51108 (id: -1 rack: null) disconnected
2025-01-04 00:11:48.213 Started MessageRepositorySpec in 1.208 seconds (process running for 20.896)
2025-01-04 00:11:48.275 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-04 00:11:48.275 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2025-01-04 00:11:48.275 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Unsubscribed all topics or patterns and assigned partitions
2025-01-04 00:11:48.275 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-04 00:11:48.275 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2025-01-04 00:11:48.275 Metrics scheduler closed
2025-01-04 00:11:48.275 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-04 00:11:48.275 Metrics reporters closed
2025-01-04 00:11:48.275 App info kafka.consumer for consumer-pong-service-2 unregistered
2025-01-04 00:11:48.275 pong-service: Consumer stopped
2025-01-04 00:11:48.280 Closing JPA EntityManagerFactory for persistence unit 'default'
2025-01-04 00:11:48.281 HikariPool-2 - Shutdown initiated...
2025-01-04 00:11:48.282 HikariPool-2 - Shutdown completed.
2025-01-04 00:11:48.303 zookeeper.snapshot.trust.empty : false
2025-01-04 00:11:48.304 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2025-01-04 00:11:48.304 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2025-01-04 00:11:48.304 zookeeper.snapshotSizeFactor = 0.33
2025-01-04 00:11:48.304 zookeeper.commitLogCount=500
2025-01-04 00:11:48.304 minSessionTimeout set to 1600
2025-01-04 00:11:48.304 maxSessionTimeout set to 16000
2025-01-04 00:11:48.304 Response cache size is initialized with value 400.
2025-01-04 00:11:48.304 Response cache size is initialized with value 400.
2025-01-04 00:11:48.304 zookeeper.pathStats.slotCapacity = 60
2025-01-04 00:11:48.304 zookeeper.pathStats.slotDuration = 15
2025-01-04 00:11:48.304 zookeeper.pathStats.maxDepth = 6
2025-01-04 00:11:48.304 zookeeper.pathStats.initialDelay = 5
2025-01-04 00:11:48.304 zookeeper.pathStats.delay = 5
2025-01-04 00:11:48.304 zookeeper.pathStats.enabled = false
2025-01-04 00:11:48.304 The max bytes for all large requests are set to 104857600
2025-01-04 00:11:48.304 The large request threshold is set to -1
2025-01-04 00:11:48.304 Created server with tickTime 800 minSessionTimeout 1600 maxSessionTimeout 16000 clientPortListenBacklog -1 datadir C:\Users\joech\AppData\Local\Temp\kafka-13186335933911169850\version-2 snapdir C:\Users\joech\AppData\Local\Temp\kafka-409689969371261670\version-2
2025-01-04 00:11:48.304 maxCnxns is not configured, using default value 0.
2025-01-04 00:11:48.304 Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers.
2025-01-04 00:11:48.307 binding to port /127.0.0.1:0
2025-01-04 00:11:48.308 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-409689969371261670\version-2\snapshot.0
2025-01-04 00:11:48.310 Snapshot loaded in 1 ms, highest zxid is 0x0, digest is 1371985504
2025-01-04 00:11:48.310 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-409689969371261670\version-2\snapshot.0
2025-01-04 00:11:48.311 Snapshot taken in 0 ms
2025-01-04 00:11:48.311 PrepRequestProcessor (sid:0) started, reconfigEnabled=false
2025-01-04 00:11:48.314 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.48875d21-67f3-4f70-90af-e7660afa4fd018034500664795457898
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:51129
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2025-01-04 00:11:48.316 starting
2025-01-04 00:11:48.316 Connecting to zookeeper on 127.0.0.1:51129
2025-01-04 00:11:48.316 [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:51129.
2025-01-04 00:11:48.317 Initiating client connection, connectString=127.0.0.1:51129 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@3ea102
2025-01-04 00:11:48.317 jute.maxbuffer value is 4194304 Bytes
2025-01-04 00:11:48.319 zookeeper.request.timeout value is 0. feature enabled=false
2025-01-04 00:11:48.319 Opening socket connection to server /127.0.0.1:51129.
2025-01-04 00:11:48.319 [ZooKeeperClient Kafka server] Waiting until connected.
2025-01-04 00:11:48.320 Socket connection established, initiating session, client: /127.0.0.1:51130, server: /127.0.0.1:51129
2025-01-04 00:11:48.320 Creating new log file: log.1
2025-01-04 00:11:48.322 Session establishment complete on server /127.0.0.1:51129, session id = 0x1000a9c729d0000, negotiated timeout = 16000
2025-01-04 00:11:48.322 [ZooKeeperClient Kafka server] Connected.
2025-01-04 00:11:48.364 Cluster ID = 6ptT-2PeSMuQSk4ZBKQmxg
2025-01-04 00:11:48.364 No meta.properties file under dir C:\Users\joech\AppData\Local\Temp\spring.kafka.48875d21-67f3-4f70-90af-e7660afa4fd018034500664795457898\meta.properties
2025-01-04 00:11:48.372 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.48875d21-67f3-4f70-90af-e7660afa4fd018034500664795457898
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:51129
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2025-01-04 00:11:48.379 [ThrottledChannelReaper-Fetch]: Starting
2025-01-04 00:11:48.379 [ThrottledChannelReaper-Produce]: Starting
2025-01-04 00:11:48.379 [ThrottledChannelReaper-Request]: Starting
2025-01-04 00:11:48.379 [ThrottledChannelReaper-ControllerMutation]: Starting
2025-01-04 00:11:48.383 Loading logs from log dirs ArraySeq(C:\Users\joech\AppData\Local\Temp\spring.kafka.48875d21-67f3-4f70-90af-e7660afa4fd018034500664795457898)
2025-01-04 00:11:48.383 Attempting recovery for all logs in C:\Users\joech\AppData\Local\Temp\spring.kafka.48875d21-67f3-4f70-90af-e7660afa4fd018034500664795457898 since no clean shutdown file was found
2025-01-04 00:11:48.385 Loaded 0 logs in 2ms.
2025-01-04 00:11:48.385 Starting log cleanup with a period of 300000 ms.
2025-01-04 00:11:48.385 Starting log flusher with a default period of 9223372036854775807 ms.
2025-01-04 00:11:48.395 Starting the log cleaner
2025-01-04 00:11:48.397 [kafka-log-cleaner-thread-0]: Starting
2025-01-04 00:11:48.397 [feature-zk-node-event-process-thread]: Starting
2025-01-04 00:11:48.398 Feature ZK node at path: /feature does not exist
2025-01-04 00:11:48.402 [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting
2025-01-04 00:11:48.423 Updated connection-accept-rate max connection creation rate to 2147483647
2025-01-04 00:11:48.424 Awaiting socket connections on localhost:51131.
2025-01-04 00:11:48.433 [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT)
2025-01-04 00:11:48.434 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Starting
2025-01-04 00:11:48.436 [ExpirationReaper-0-Produce]: Starting
2025-01-04 00:11:48.437 [ExpirationReaper-0-Fetch]: Starting
2025-01-04 00:11:48.437 [ExpirationReaper-0-DeleteRecords]: Starting
2025-01-04 00:11:48.438 [ExpirationReaper-0-ElectLeader]: Starting
2025-01-04 00:11:48.440 [LogDirFailureHandler]: Starting
2025-01-04 00:11:48.443 Creating /brokers/ids/0 (is it secure? false)
2025-01-04 00:11:48.444 Stat of the created znode at /brokers/ids/0 is: 25,25,1735920708443,1735920708443,1,0,0,72069261091995648,204,0,25

2025-01-04 00:11:48.444 Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:51131, czxid (broker epoch): 25
2025-01-04 00:11:48.448 [ControllerEventThread controllerId=0] Starting
2025-01-04 00:11:48.449 [ExpirationReaper-0-topic]: Starting
2025-01-04 00:11:48.450 [ExpirationReaper-0-Heartbeat]: Starting
2025-01-04 00:11:48.450 [ExpirationReaper-0-Rebalance]: Starting
2025-01-04 00:11:48.450 [GroupCoordinator 0]: Starting up.
2025-01-04 00:11:48.451 [GroupCoordinator 0]: Startup complete.
2025-01-04 00:11:48.452 Successfully created /controller_epoch with initial epoch 0
2025-01-04 00:11:48.454 [TransactionCoordinator id=0] Starting up.
2025-01-04 00:11:48.454 [Controller id=0] 0 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1
2025-01-04 00:11:48.456 [Controller id=0] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map())
2025-01-04 00:11:48.456 [TransactionCoordinator id=0] Startup complete.
2025-01-04 00:11:48.456 [Transaction Marker Channel Manager 0]: Starting
2025-01-04 00:11:48.457 [ExpirationReaper-0-AlterAcls]: Starting
2025-01-04 00:11:48.457 Feature ZK node created at path: /feature
2025-01-04 00:11:48.459 [MetadataCache brokerId=0] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0).
2025-01-04 00:11:48.459 [Controller id=0] Registering handlers
2025-01-04 00:11:48.460 [Controller id=0] Deleting log dir event notifications
2025-01-04 00:11:48.461 [/config/changes-event-process-thread]: Starting
2025-01-04 00:11:48.461 [Controller id=0] Deleting isr change notifications
2025-01-04 00:11:48.461 [Controller id=0] Initializing controller context
2025-01-04 00:11:48.464 [Controller id=0] Initialized broker epochs cache: HashMap(0 -> 25)
2025-01-04 00:11:48.464 [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing.
2025-01-04 00:11:48.465 Kafka version: 3.4.1
2025-01-04 00:11:48.465 Kafka commitId: 8a516edc2755df89
2025-01-04 00:11:48.465 Kafka startTimeMs: 1735920708465
2025-01-04 00:11:48.465 [KafkaServer id=0] started
2025-01-04 00:11:48.467 AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [127.0.0.1:51131]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-01-04 00:11:48.468 Kafka version: 3.4.1
2025-01-04 00:11:48.468 [RequestSendThread controllerId=0] Starting
2025-01-04 00:11:48.468 Kafka commitId: 8a516edc2755df89
2025-01-04 00:11:48.468 [Controller id=0] Currently active brokers in the cluster: Set(0)
2025-01-04 00:11:48.468 Kafka startTimeMs: 1735920708468
2025-01-04 00:11:48.468 [Controller id=0] Currently shutting brokers in the cluster: HashSet()
2025-01-04 00:11:48.468 [Controller id=0] Current list of topics in the cluster: HashSet()
2025-01-04 00:11:48.468 [Controller id=0] Fetching topic deletions in progress
2025-01-04 00:11:48.471 [Controller id=0] List of topics to be deleted: 
2025-01-04 00:11:48.471 [Controller id=0] List of topics ineligible for deletion: 
2025-01-04 00:11:48.471 [Controller id=0] Initializing topic deletion manager
2025-01-04 00:11:48.471 [Topic Deletion Manager 0] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet()
2025-01-04 00:11:48.471 [Controller id=0] Sending update metadata request
2025-01-04 00:11:48.471 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions
2025-01-04 00:11:48.471 [ReplicaStateMachine controllerId=0] Initializing replica state
2025-01-04 00:11:48.471 [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2025-01-04 00:11:48.471 [ReplicaStateMachine controllerId=0] Triggering offline replica state changes
2025-01-04 00:11:48.471 [PartitionStateMachine controllerId=0] Initializing partition state
2025-01-04 00:11:48.472 [PartitionStateMachine controllerId=0] Triggering online partition state changes
2025-01-04 00:11:48.472 [Controller id=0] Ready to serve as the new controller with epoch 1
2025-01-04 00:11:48.472 [RequestSendThread controllerId=0] Controller 0 connected to localhost:51131 (id: 0 rack: null) for sending state change requests
2025-01-04 00:11:48.474 [Controller id=0] Partitions undergoing preferred replica election: 
2025-01-04 00:11:48.474 [Controller id=0] Partitions that completed preferred replica election: 
2025-01-04 00:11:48.474 [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2025-01-04 00:11:48.474 [Controller id=0] Resuming preferred replica election for partitions: 
2025-01-04 00:11:48.474 [Controller id=0] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered
2025-01-04 00:11:48.475 [Controller id=0] Starting the controller scheduler
2025-01-04 00:11:48.481 Creating topic pong-message-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0))
2025-01-04 00:11:48.490 [Controller id=0] New topics: [Set(pong-message-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(pong-message-topic,Some(8YW_Ou3TRnuKkA6HyEvyQg),Map(pong-message-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), pong-message-topic-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-01-04 00:11:48.490 [Controller id=0] New partition creation callback for pong-message-topic-0,pong-message-topic-1
2025-01-04 00:11:48.490 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-04 00:11:48.490 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-04 00:11:48.490 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:11:48.490 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:11:48.497 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-04 00:11:48.497 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-04 00:11:48.497 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2025-01-04 00:11:48.497 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2025-01-04 00:11:48.497 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:11:48.498 [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 for 2 partitions
2025-01-04 00:11:48.498 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(pong-message-topic-0, pong-message-topic-1)
2025-01-04 00:11:48.498 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2025-01-04 00:11:48.502 [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use node localhost:51131 (id: 0 rack: null)
2025-01-04 00:11:48.505 [LogLoader partition=pong-message-topic-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.48875d21-67f3-4f70-90af-e7660afa4fd018034500664795457898] Loading producer state till offset 0 with message format version 2
2025-01-04 00:11:48.507 Created log for partition pong-message-topic-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.48875d21-67f3-4f70-90af-e7660afa4fd018034500664795457898\pong-message-topic-0 with properties {}
2025-01-04 00:11:48.507 [Partition pong-message-topic-0 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-0
2025-01-04 00:11:48.507 [Partition pong-message-topic-0 broker=0] Log loaded for partition pong-message-topic-0 with initial high watermark 0
2025-01-04 00:11:48.507 [Broker id=0] Leader pong-message-topic-0 with topic id Some(8YW_Ou3TRnuKkA6HyEvyQg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2025-01-04 00:11:48.519 [LogLoader partition=pong-message-topic-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.48875d21-67f3-4f70-90af-e7660afa4fd018034500664795457898] Loading producer state till offset 0 with message format version 2
2025-01-04 00:11:48.520 Created log for partition pong-message-topic-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.48875d21-67f3-4f70-90af-e7660afa4fd018034500664795457898\pong-message-topic-1 with properties {}
2025-01-04 00:11:48.520 [Partition pong-message-topic-1 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-1
2025-01-04 00:11:48.520 [Partition pong-message-topic-1 broker=0] Log loaded for partition pong-message-topic-1 with initial high watermark 0
2025-01-04 00:11:48.520 [Broker id=0] Leader pong-message-topic-1 with topic id Some(8YW_Ou3TRnuKkA6HyEvyQg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2025-01-04 00:11:48.523 [Broker id=0] Finished LeaderAndIsr request in 25ms correlationId 1 from controller 0 for 2 partitions
2025-01-04 00:11:48.526 [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2
2025-01-04 00:11:48.528 App info kafka.admin.client for adminclient-2 unregistered
2025-01-04 00:11:48.528 Metrics scheduler closed
2025-01-04 00:11:48.528 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-04 00:11:48.528 Metrics reporters closed
2025-01-04 00:11:48.537 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Recorded new controller, from now on will use node localhost:51131 (id: 0 rack: null)
2025-01-04 00:11:48.604 

Found multiple occurrences of org.json.JSONObject on the class path:

	jar:file:/C:/work/apache-maven-3.8.8/repo/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar!/org/json/JSONObject.class
	jar:file:/C:/work/apache-maven-3.8.8/repo/org/json/json/20220320/json-20220320.jar!/org/json/JSONObject.class

You may wish to exclude one of them to ensure predictable runtime behavior

2025-01-04 00:11:48.611 zookeeper.snapshot.trust.empty : false
2025-01-04 00:11:48.613 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2025-01-04 00:11:48.613 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2025-01-04 00:11:48.613 zookeeper.snapshotSizeFactor = 0.33
2025-01-04 00:11:48.613 zookeeper.commitLogCount=500
2025-01-04 00:11:48.613 minSessionTimeout set to 1600
2025-01-04 00:11:48.613 maxSessionTimeout set to 16000
2025-01-04 00:11:48.613 Response cache size is initialized with value 400.
2025-01-04 00:11:48.613 Response cache size is initialized with value 400.
2025-01-04 00:11:48.613 zookeeper.pathStats.slotCapacity = 60
2025-01-04 00:11:48.613 zookeeper.pathStats.slotDuration = 15
2025-01-04 00:11:48.613 zookeeper.pathStats.maxDepth = 6
2025-01-04 00:11:48.613 zookeeper.pathStats.initialDelay = 5
2025-01-04 00:11:48.613 zookeeper.pathStats.delay = 5
2025-01-04 00:11:48.613 zookeeper.pathStats.enabled = false
2025-01-04 00:11:48.613 The max bytes for all large requests are set to 104857600
2025-01-04 00:11:48.613 The large request threshold is set to -1
2025-01-04 00:11:48.613 Created server with tickTime 800 minSessionTimeout 1600 maxSessionTimeout 16000 clientPortListenBacklog -1 datadir C:\Users\joech\AppData\Local\Temp\kafka-7076402719274139731\version-2 snapdir C:\Users\joech\AppData\Local\Temp\kafka-13097380934334836025\version-2
2025-01-04 00:11:48.613 maxCnxns is not configured, using default value 0.
2025-01-04 00:11:48.613 Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers.
2025-01-04 00:11:48.615 binding to port /127.0.0.1:0
2025-01-04 00:11:48.619 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-13097380934334836025\version-2\snapshot.0
2025-01-04 00:11:48.619 Snapshot loaded in 1 ms, highest zxid is 0x0, digest is 1371985504
2025-01-04 00:11:48.620 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-13097380934334836025\version-2\snapshot.0
2025-01-04 00:11:48.620 Snapshot taken in 1 ms
2025-01-04 00:11:48.621 PrepRequestProcessor (sid:0) started, reconfigEnabled=false
2025-01-04 00:11:48.625 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.4d55f2f8-26f5-4b81-8b7d-69d7785bccde14079828386429354231
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:51135
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2025-01-04 00:11:48.627 starting
2025-01-04 00:11:48.627 Connecting to zookeeper on 127.0.0.1:51135
2025-01-04 00:11:48.627 [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:51135.
2025-01-04 00:11:48.627 Initiating client connection, connectString=127.0.0.1:51135 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@5ed312a3
2025-01-04 00:11:48.628 jute.maxbuffer value is 4194304 Bytes
2025-01-04 00:11:48.628 zookeeper.request.timeout value is 0. feature enabled=false
2025-01-04 00:11:48.630 [ZooKeeperClient Kafka server] Waiting until connected.
2025-01-04 00:11:48.630 Opening socket connection to server /127.0.0.1:51135.
2025-01-04 00:11:48.630 Socket connection established, initiating session, client: /127.0.0.1:51136, server: /127.0.0.1:51135
2025-01-04 00:11:48.631 Creating new log file: log.1
2025-01-04 00:11:48.634 Session establishment complete on server /127.0.0.1:51135, session id = 0x1000a9c73d20000, negotiated timeout = 16000
2025-01-04 00:11:48.634 [ZooKeeperClient Kafka server] Connected.
2025-01-04 00:11:48.679 Cluster ID = eL_tEjI_Q720IAeCRY4m-Q
2025-01-04 00:11:48.680 No meta.properties file under dir C:\Users\joech\AppData\Local\Temp\spring.kafka.4d55f2f8-26f5-4b81-8b7d-69d7785bccde14079828386429354231\meta.properties
2025-01-04 00:11:48.686 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.4d55f2f8-26f5-4b81-8b7d-69d7785bccde14079828386429354231
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:51135
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2025-01-04 00:11:48.696 [ThrottledChannelReaper-Fetch]: Starting
2025-01-04 00:11:48.697 [ThrottledChannelReaper-Produce]: Starting
2025-01-04 00:11:48.697 [ThrottledChannelReaper-Request]: Starting
2025-01-04 00:11:48.697 [ThrottledChannelReaper-ControllerMutation]: Starting
2025-01-04 00:11:48.701 Loading logs from log dirs ArraySeq(C:\Users\joech\AppData\Local\Temp\spring.kafka.4d55f2f8-26f5-4b81-8b7d-69d7785bccde14079828386429354231)
2025-01-04 00:11:48.701 Attempting recovery for all logs in C:\Users\joech\AppData\Local\Temp\spring.kafka.4d55f2f8-26f5-4b81-8b7d-69d7785bccde14079828386429354231 since no clean shutdown file was found
2025-01-04 00:11:48.702 Loaded 0 logs in 2ms.
2025-01-04 00:11:48.704 Starting log cleanup with a period of 300000 ms.
2025-01-04 00:11:48.704 Starting log flusher with a default period of 9223372036854775807 ms.
2025-01-04 00:11:48.705 Starting the log cleaner
2025-01-04 00:11:48.706 [kafka-log-cleaner-thread-0]: Starting
2025-01-04 00:11:48.706 [feature-zk-node-event-process-thread]: Starting
2025-01-04 00:11:48.708 Feature ZK node at path: /feature does not exist
2025-01-04 00:11:48.710 [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting
2025-01-04 00:11:48.720 Updated connection-accept-rate max connection creation rate to 2147483647
2025-01-04 00:11:48.722 Awaiting socket connections on localhost:51137.
2025-01-04 00:11:48.732 [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT)
2025-01-04 00:11:48.735 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Starting
2025-01-04 00:11:48.736 [ExpirationReaper-0-Produce]: Starting
2025-01-04 00:11:48.736 [ExpirationReaper-0-Fetch]: Starting
2025-01-04 00:11:48.736 [ExpirationReaper-0-DeleteRecords]: Starting
2025-01-04 00:11:48.738 [ExpirationReaper-0-ElectLeader]: Starting
2025-01-04 00:11:48.739 [LogDirFailureHandler]: Starting
2025-01-04 00:11:48.741 Creating /brokers/ids/0 (is it secure? false)
2025-01-04 00:11:48.744 Stat of the created znode at /brokers/ids/0 is: 25,25,1735920708741,1735920708741,1,0,0,72069261112246272,204,0,25

2025-01-04 00:11:48.744 Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:51137, czxid (broker epoch): 25
2025-01-04 00:11:48.747 [ControllerEventThread controllerId=0] Starting
2025-01-04 00:11:48.748 [ExpirationReaper-0-topic]: Starting
2025-01-04 00:11:48.748 [ExpirationReaper-0-Heartbeat]: Starting
2025-01-04 00:11:48.750 [ExpirationReaper-0-Rebalance]: Starting
2025-01-04 00:11:48.751 [GroupCoordinator 0]: Starting up.
2025-01-04 00:11:48.751 Successfully created /controller_epoch with initial epoch 0
2025-01-04 00:11:48.752 [GroupCoordinator 0]: Startup complete.
2025-01-04 00:11:48.753 [Controller id=0] 0 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1
2025-01-04 00:11:48.754 [TransactionCoordinator id=0] Starting up.
2025-01-04 00:11:48.754 [Controller id=0] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map())
2025-01-04 00:11:48.756 Feature ZK node created at path: /feature
2025-01-04 00:11:48.757 [TransactionCoordinator id=0] Startup complete.
2025-01-04 00:11:48.757 [Transaction Marker Channel Manager 0]: Starting
2025-01-04 00:11:48.757 [MetadataCache brokerId=0] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0).
2025-01-04 00:11:48.757 [Controller id=0] Registering handlers
2025-01-04 00:11:48.758 [ExpirationReaper-0-AlterAcls]: Starting
2025-01-04 00:11:48.758 [Controller id=0] Deleting log dir event notifications
2025-01-04 00:11:48.760 [Controller id=0] Deleting isr change notifications
2025-01-04 00:11:48.760 [Controller id=0] Initializing controller context
2025-01-04 00:11:48.762 [Controller id=0] Initialized broker epochs cache: HashMap(0 -> 25)
2025-01-04 00:11:48.762 [/config/changes-event-process-thread]: Starting
2025-01-04 00:11:48.768 [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing.
2025-01-04 00:11:48.768 [Controller id=0] Currently active brokers in the cluster: Set(0)
2025-01-04 00:11:48.768 [Controller id=0] Currently shutting brokers in the cluster: HashSet()
2025-01-04 00:11:48.768 [Controller id=0] Current list of topics in the cluster: HashSet()
2025-01-04 00:11:48.768 [Controller id=0] Fetching topic deletions in progress
2025-01-04 00:11:48.768 [RequestSendThread controllerId=0] Starting
2025-01-04 00:11:48.769 Kafka version: 3.4.1
2025-01-04 00:11:48.769 [Controller id=0] List of topics to be deleted: 
2025-01-04 00:11:48.769 Kafka commitId: 8a516edc2755df89
2025-01-04 00:11:48.769 [Controller id=0] List of topics ineligible for deletion: 
2025-01-04 00:11:48.769 Kafka startTimeMs: 1735920708769
2025-01-04 00:11:48.769 [Controller id=0] Initializing topic deletion manager
2025-01-04 00:11:48.769 [Topic Deletion Manager 0] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet()
2025-01-04 00:11:48.769 [Controller id=0] Sending update metadata request
2025-01-04 00:11:48.770 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions
2025-01-04 00:11:48.770 [ReplicaStateMachine controllerId=0] Initializing replica state
2025-01-04 00:11:48.770 [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2025-01-04 00:11:48.770 [ReplicaStateMachine controllerId=0] Triggering offline replica state changes
2025-01-04 00:11:48.770 [PartitionStateMachine controllerId=0] Initializing partition state
2025-01-04 00:11:48.770 [PartitionStateMachine controllerId=0] Triggering online partition state changes
2025-01-04 00:11:48.770 [Controller id=0] Ready to serve as the new controller with epoch 1
2025-01-04 00:11:48.771 [RequestSendThread controllerId=0] Controller 0 connected to localhost:51137 (id: 0 rack: null) for sending state change requests
2025-01-04 00:11:48.773 [Controller id=0] Partitions undergoing preferred replica election: 
2025-01-04 00:11:48.773 [Controller id=0] Partitions that completed preferred replica election: 
2025-01-04 00:11:48.773 [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2025-01-04 00:11:48.773 [Controller id=0] Resuming preferred replica election for partitions: 
2025-01-04 00:11:48.773 [Controller id=0] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered
2025-01-04 00:11:48.770 Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.server:type=app-info,id=0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1865)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:960)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:895)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:523)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:563)
	at kafka.utils.TestUtils$.createServer(TestUtils.scala:188)
	at kafka.utils.TestUtils$.createServer(TestUtils.scala:182)
	at kafka.utils.TestUtils.createServer(TestUtils.scala)
	at org.springframework.kafka.test.EmbeddedKafkaBroker.afterPropertiesSet(EmbeddedKafkaBroker.java:369)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1817)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1766)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:410)
	at org.springframework.kafka.test.context.EmbeddedKafkaContextCustomizer.customizeContext(EmbeddedKafkaContextCustomizer.java:116)
	at org.springframework.boot.test.context.SpringBootContextLoader$ContextCustomizerAdapter.initialize(SpringBootContextLoader.java:435)
	at org.springframework.boot.SpringApplication.applyInitializers(SpringApplication.java:610)
	at org.springframework.boot.SpringApplication.prepareContext(SpringApplication.java:390)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:314)
	at org.springframework.boot.test.context.SpringBootContextLoader.lambda$loadContext$3(SpringBootContextLoader.java:137)
	at org.springframework.util.function.ThrowingSupplier.get(ThrowingSupplier.java:58)
	at org.springframework.util.function.ThrowingSupplier.get(ThrowingSupplier.java:46)
	at org.springframework.boot.SpringApplication.withHook(SpringApplication.java:1409)
	at org.springframework.boot.test.context.SpringBootContextLoader$ContextLoaderHook.run(SpringBootContextLoader.java:545)
	at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:137)
	at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:108)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:187)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:119)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:127)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:141)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:97)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:241)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:56)
	at org.spockframework.spring.SpringInterceptor.interceptInitializerMethod(SpringInterceptor.java:46)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:24)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:101)
	at org.spockframework.runtime.PlatformSpecRunner.invoke(PlatformSpecRunner.java:398)
	at org.spockframework.runtime.PlatformSpecRunner.runInitializer(PlatformSpecRunner.java:259)
	at org.spockframework.runtime.PlatformSpecRunner.runInitializer(PlatformSpecRunner.java:254)
	at org.spockframework.runtime.IterationNode.prepare(IterationNode.java:31)
	at org.spockframework.runtime.IterationNode.prepare(IterationNode.java:13)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$prepare$2(NodeTestTask.java:123)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.prepare(NodeTestTask.java:123)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:90)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:226)
	at org.spockframework.runtime.ParameterizedFeatureChildExecutor.execute(ParameterizedFeatureChildExecutor.java:104)
	at org.spockframework.runtime.PlatformParameterizedSpecRunner$1.runIteration(PlatformParameterizedSpecRunner.java:72)
	at org.spockframework.runtime.extension.IDataDriver.lambda$static$0(IDataDriver.java:37)
	at org.spockframework.runtime.PlatformParameterizedSpecRunner.runParameterizedFeature(PlatformParameterizedSpecRunner.java:47)
	at org.spockframework.runtime.ParameterizedFeatureNode.execute(ParameterizedFeatureNode.java:40)
	at org.spockframework.runtime.ParameterizedFeatureNode.execute(ParameterizedFeatureNode.java:16)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.spockframework.runtime.SpockNode.sneakyInvoke(SpockNode.java:40)
	at org.spockframework.runtime.FeatureNode.lambda$around$0(FeatureNode.java:41)
	at org.spockframework.runtime.PlatformSpecRunner.lambda$createMethodInfoForDoRunFeature$4(PlatformSpecRunner.java:199)
	at org.spockframework.runtime.model.MethodInfo.invoke(MethodInfo.java:156)
	at org.spockframework.runtime.PlatformSpecRunner.invokeRaw(PlatformSpecRunner.java:407)
	at org.spockframework.runtime.PlatformSpecRunner.invoke(PlatformSpecRunner.java:390)
	at org.spockframework.runtime.PlatformSpecRunner.runFeature(PlatformSpecRunner.java:192)
	at org.spockframework.runtime.FeatureNode.around(FeatureNode.java:41)
	at org.spockframework.runtime.FeatureNode.around(FeatureNode.java:12)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1511)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.spockframework.runtime.SpockNode.sneakyInvoke(SpockNode.java:40)
	at org.spockframework.runtime.SpecNode.lambda$around$0(SpecNode.java:63)
	at org.spockframework.runtime.PlatformSpecRunner.lambda$createMethodInfoForDoRunSpec$0(PlatformSpecRunner.java:61)
	at org.spockframework.runtime.model.MethodInfo.invoke(MethodInfo.java:156)
	at org.spockframework.runtime.PlatformSpecRunner.invokeRaw(PlatformSpecRunner.java:407)
	at org.spockframework.runtime.PlatformSpecRunner.invoke(PlatformSpecRunner.java:390)
	at org.spockframework.runtime.PlatformSpecRunner.runSpec(PlatformSpecRunner.java:55)
	at org.spockframework.runtime.SpecNode.around(SpecNode.java:63)
	at org.spockframework.runtime.SpecNode.around(SpecNode.java:11)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1511)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:147)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:127)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:90)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:55)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:102)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:150)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2025-01-04 00:11:48.774 [KafkaServer id=0] started
2025-01-04 00:11:48.774 [Controller id=0] Starting the controller scheduler
2025-01-04 00:11:48.775 AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [127.0.0.1:51137]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-01-04 00:11:48.777 Kafka version: 3.4.1
2025-01-04 00:11:48.777 Kafka commitId: 8a516edc2755df89
2025-01-04 00:11:48.777 Kafka startTimeMs: 1735920708777
2025-01-04 00:11:48.793 Creating topic pong-message-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-01-04 00:11:48.802 [Controller id=0] New topics: [Set(pong-message-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(pong-message-topic,Some(K2CgXQkJTaynKieg-Cnibw),Map(pong-message-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-01-04 00:11:48.802 [Controller id=0] New partition creation callback for pong-message-topic-0
2025-01-04 00:11:48.802 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-04 00:11:48.802 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:11:48.802 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:11:48.811 [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use node localhost:51137 (id: 0 rack: null)
2025-01-04 00:11:48.811 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-04 00:11:48.811 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions
2025-01-04 00:11:48.812 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 1 partitions
2025-01-04 00:11:48.812 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:11:48.812 [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 for 1 partitions
2025-01-04 00:11:48.813 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(pong-message-topic-0)
2025-01-04 00:11:48.813 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions
2025-01-04 00:11:48.823 [LogLoader partition=pong-message-topic-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.4d55f2f8-26f5-4b81-8b7d-69d7785bccde14079828386429354231] Loading producer state till offset 0 with message format version 2
2025-01-04 00:11:48.826 Created log for partition pong-message-topic-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.4d55f2f8-26f5-4b81-8b7d-69d7785bccde14079828386429354231\pong-message-topic-0 with properties {}
2025-01-04 00:11:48.827 [Partition pong-message-topic-0 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-0
2025-01-04 00:11:48.827 [Partition pong-message-topic-0 broker=0] Log loaded for partition pong-message-topic-0 with initial high watermark 0
2025-01-04 00:11:48.827 [Broker id=0] Leader pong-message-topic-0 with topic id Some(K2CgXQkJTaynKieg-Cnibw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2025-01-04 00:11:48.832 [Broker id=0] Finished LeaderAndIsr request in 20ms correlationId 1 from controller 0 for 1 partitions
2025-01-04 00:11:48.835 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Recorded new controller, from now on will use node localhost:51137 (id: 0 rack: null)
2025-01-04 00:11:48.835 [Broker id=0] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2
2025-01-04 00:11:48.838 App info kafka.admin.client for adminclient-3 unregistered
2025-01-04 00:11:48.839 Metrics scheduler closed
2025-01-04 00:11:48.839 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-04 00:11:48.839 Metrics reporters closed
2025-01-04 00:11:48.841 Starting PongControllerSpec using Java 17.0.12 with PID 29972 (started by joech in C:\code\hsbc\demo\pong)
2025-01-04 00:11:48.842 No active profile set, falling back to 1 default profile: "default"
2025-01-04 00:11:49.052 Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-04 00:11:49.052 Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-04 00:11:49.070 Finished Spring Data repository scanning in 18 ms. Found 1 JPA repository interfaces.
2025-01-04 00:11:49.074 Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-04 00:11:49.074 Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-04 00:11:49.081 Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.demo.dao.MessageRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-04 00:11:49.081 Finished Spring Data repository scanning in 5 ms. Found 0 Redis repository interfaces.
2025-01-04 00:11:49.494 HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-04 00:11:49.506 HHH000021: Bytecode provider name : bytebuddy
2025-01-04 00:11:49.506 No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-04 00:11:49.508 HikariPool-3 - Starting...
2025-01-04 00:11:49.510 HikariPool-3 - Added connection conn20: url=jdbc:h2:mem:testdb user=SA
2025-01-04 00:11:49.511 HikariPool-3 - Start completed.
2025-01-04 00:11:49.522 HHH000021: Bytecode provider name : bytebuddy
2025-01-04 00:11:49.554 HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2025-01-04 00:11:49.587 Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-04 00:11:50.069 Netty started on port 51141
2025-01-04 00:11:50.072 ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:51131]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-pong-service-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = pong-service
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-04 00:11:50.076 These configurations '[spring.json.trusted.packages]' were supplied but are not used yet.
2025-01-04 00:11:50.076 Kafka version: 3.4.1
2025-01-04 00:11:50.076 Kafka commitId: 8a516edc2755df89
2025-01-04 00:11:50.076 Kafka startTimeMs: 1735920710076
2025-01-04 00:11:50.076 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Subscribed to topic(s): pong-message-topic
2025-01-04 00:11:50.079 Started PongControllerSpec in 1.52 seconds (process running for 22.762)
2025-01-04 00:11:50.084 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting the last seen epoch of partition pong-message-topic-0 to 0 since the associated topicId changed from null to 8YW_Ou3TRnuKkA6HyEvyQg
2025-01-04 00:11:50.084 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting the last seen epoch of partition pong-message-topic-1 to 0 since the associated topicId changed from null to 8YW_Ou3TRnuKkA6HyEvyQg
2025-01-04 00:11:50.084 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Cluster ID: 6ptT-2PeSMuQSk4ZBKQmxg
2025-01-04 00:11:50.090 Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0))
2025-01-04 00:11:50.099 [Controller id=0] New topics: [Set(__consumer_offsets)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(__consumer_offsets,Some(8Jv2Q1hSTSyTFGJWXcWbVQ),HashMap(__consumer_offsets-4 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-3 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-2 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-01-04 00:11:50.099 [Controller id=0] New partition creation callback for __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2025-01-04 00:11:50.099 [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-04 00:11:50.099 [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-04 00:11:50.099 [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-04 00:11:50.099 [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-04 00:11:50.099 [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-04 00:11:50.099 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:11:50.099 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:11:50.111 [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-04 00:11:50.111 [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-04 00:11:50.111 [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-04 00:11:50.111 [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-04 00:11:50.111 [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-04 00:11:50.111 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 5 become-leader and 0 become-follower partitions
2025-01-04 00:11:50.111 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 5 partitions
2025-01-04 00:11:50.112 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:11:50.112 [Broker id=0] Handling LeaderAndIsr request correlationId 3 from controller 0 for 5 partitions
2025-01-04 00:11:50.114 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-4, __consumer_offsets-3, __consumer_offsets-2, __consumer_offsets-0, __consumer_offsets-1)
2025-01-04 00:11:50.114 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 3 from controller 0 epoch 1 as part of the become-leader transition for 5 partitions
2025-01-04 00:11:50.122 [LogLoader partition=__consumer_offsets-3, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.48875d21-67f3-4f70-90af-e7660afa4fd018034500664795457898] Loading producer state till offset 0 with message format version 2
2025-01-04 00:11:50.123 Created log for partition __consumer_offsets-3 in C:\Users\joech\AppData\Local\Temp\spring.kafka.48875d21-67f3-4f70-90af-e7660afa4fd018034500664795457898\__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-01-04 00:11:50.126 [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
2025-01-04 00:11:50.126 [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0
2025-01-04 00:11:50.127 [Broker id=0] Leader __consumer_offsets-3 with topic id Some(8Jv2Q1hSTSyTFGJWXcWbVQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2025-01-04 00:11:50.138 [LogLoader partition=__consumer_offsets-2, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.48875d21-67f3-4f70-90af-e7660afa4fd018034500664795457898] Loading producer state till offset 0 with message format version 2
2025-01-04 00:11:50.140 Created log for partition __consumer_offsets-2 in C:\Users\joech\AppData\Local\Temp\spring.kafka.48875d21-67f3-4f70-90af-e7660afa4fd018034500664795457898\__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-01-04 00:11:50.141 [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
2025-01-04 00:11:50.141 [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0
2025-01-04 00:11:50.141 [Broker id=0] Leader __consumer_offsets-2 with topic id Some(8Jv2Q1hSTSyTFGJWXcWbVQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2025-01-04 00:11:50.152 [LogLoader partition=__consumer_offsets-4, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.48875d21-67f3-4f70-90af-e7660afa4fd018034500664795457898] Loading producer state till offset 0 with message format version 2
2025-01-04 00:11:50.154 Created log for partition __consumer_offsets-4 in C:\Users\joech\AppData\Local\Temp\spring.kafka.48875d21-67f3-4f70-90af-e7660afa4fd018034500664795457898\__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-01-04 00:11:50.154 [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
2025-01-04 00:11:50.155 [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0
2025-01-04 00:11:50.155 [Broker id=0] Leader __consumer_offsets-4 with topic id Some(8Jv2Q1hSTSyTFGJWXcWbVQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2025-01-04 00:11:50.167 [LogLoader partition=__consumer_offsets-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.48875d21-67f3-4f70-90af-e7660afa4fd018034500664795457898] Loading producer state till offset 0 with message format version 2
2025-01-04 00:11:50.168 Created log for partition __consumer_offsets-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.48875d21-67f3-4f70-90af-e7660afa4fd018034500664795457898\__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-01-04 00:11:50.168 [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
2025-01-04 00:11:50.169 [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0
2025-01-04 00:11:50.169 [Broker id=0] Leader __consumer_offsets-1 with topic id Some(8Jv2Q1hSTSyTFGJWXcWbVQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2025-01-04 00:11:50.182 [LogLoader partition=__consumer_offsets-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.48875d21-67f3-4f70-90af-e7660afa4fd018034500664795457898] Loading producer state till offset 0 with message format version 2
2025-01-04 00:11:50.184 Created log for partition __consumer_offsets-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.48875d21-67f3-4f70-90af-e7660afa4fd018034500664795457898\__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-01-04 00:11:50.184 [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
2025-01-04 00:11:50.184 [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0
2025-01-04 00:11:50.185 [Broker id=0] Leader __consumer_offsets-0 with topic id Some(8Jv2Q1hSTSyTFGJWXcWbVQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2025-01-04 00:11:50.190 [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 0
2025-01-04 00:11:50.190 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0
2025-01-04 00:11:50.190 [GroupCoordinator 0]: Elected as the group coordinator for partition 2 in epoch 0
2025-01-04 00:11:50.190 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0
2025-01-04 00:11:50.190 [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 0
2025-01-04 00:11:50.190 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0
2025-01-04 00:11:50.190 [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 0
2025-01-04 00:11:50.190 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0
2025-01-04 00:11:50.190 [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 0
2025-01-04 00:11:50.190 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0
2025-01-04 00:11:50.190 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler.
2025-01-04 00:11:50.192 [Broker id=0] Finished LeaderAndIsr request in 80ms correlationId 3 from controller 0 for 5 partitions
2025-01-04 00:11:50.192 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler.
2025-01-04 00:11:50.192 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler.
2025-01-04 00:11:50.192 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler.
2025-01-04 00:11:50.192 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler.
2025-01-04 00:11:50.193 [Broker id=0] Add 5 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 4
2025-01-04 00:11:50.295 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Discovered group coordinator localhost:51131 (id: 2147483647 rack: null)
2025-01-04 00:11:50.296 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] (Re-)joining group
2025-01-04 00:11:50.299 [GroupCoordinator 0]: Dynamic member with unknown member id joins group pong-service in Empty state. Created a new member id consumer-pong-service-3-0567a5f6-d3e5-4f3d-b488-c6ecdde7c0cd and request the member to rejoin with this id.
2025-01-04 00:11:50.300 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Request joining group due to: need to re-join with the given member-id: consumer-pong-service-3-0567a5f6-d3e5-4f3d-b488-c6ecdde7c0cd
2025-01-04 00:11:50.300 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2025-01-04 00:11:50.300 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] (Re-)joining group
2025-01-04 00:11:50.302 [GroupCoordinator 0]: Preparing to rebalance group pong-service in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-pong-service-3-0567a5f6-d3e5-4f3d-b488-c6ecdde7c0cd with group instance id None; client reason: rebalance failed due to MemberIdRequiredException)
2025-01-04 00:11:50.303 [GroupCoordinator 0]: Stabilized group pong-service generation 1 (__consumer_offsets-2) with 1 members
2025-01-04 00:11:50.304 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Successfully joined group with generation Generation{generationId=1, memberId='consumer-pong-service-3-0567a5f6-d3e5-4f3d-b488-c6ecdde7c0cd', protocol='range'}
2025-01-04 00:11:50.304 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Finished assignment for group at generation 1: {consumer-pong-service-3-0567a5f6-d3e5-4f3d-b488-c6ecdde7c0cd=Assignment(partitions=[pong-message-topic-0, pong-message-topic-1])}
2025-01-04 00:11:50.305 [GroupCoordinator 0]: Assignment received from leader consumer-pong-service-3-0567a5f6-d3e5-4f3d-b488-c6ecdde7c0cd for group pong-service for generation 1. The group has 1 members, 0 of which are static.
2025-01-04 00:11:50.309 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Successfully synced group in generation Generation{generationId=1, memberId='consumer-pong-service-3-0567a5f6-d3e5-4f3d-b488-c6ecdde7c0cd', protocol='range'}
2025-01-04 00:11:50.309 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Notifying assignor about the new Assignment(partitions=[pong-message-topic-0, pong-message-topic-1])
2025-01-04 00:11:50.309 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Adding newly assigned partitions: pong-message-topic-0, pong-message-topic-1
2025-01-04 00:11:50.312 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Found no committed offset for partition pong-message-topic-0
2025-01-04 00:11:50.312 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Found no committed offset for partition pong-message-topic-1
2025-01-04 00:11:50.313 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Found no committed offset for partition pong-message-topic-0
2025-01-04 00:11:50.313 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Found no committed offset for partition pong-message-topic-1
2025-01-04 00:11:50.315 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting offset for partition pong-message-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:51131 (id: 0 rack: null)], epoch=0}}.
2025-01-04 00:11:50.315 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting offset for partition pong-message-topic-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:51131 (id: 0 rack: null)], epoch=0}}.
2025-01-04 00:11:50.319 pong-service: partitions assigned: [pong-message-topic-0, pong-message-topic-1]
2025-01-04 00:11:50.601 Ping success, handling ping message: Hello
2025-01-04 00:11:50.601 Idempotence will be disabled because acks is set to 0, not set to 'all'.
2025-01-04 00:11:50.601 ProducerConfig values: 
	acks = 0
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:51131]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2025-01-04 00:11:50.608 Kafka version: 3.4.1
2025-01-04 00:11:50.608 Kafka commitId: 8a516edc2755df89
2025-01-04 00:11:50.608 Kafka startTimeMs: 1735920710608
2025-01-04 00:11:50.614 [Producer clientId=producer-2] Resetting the last seen epoch of partition pong-message-topic-0 to 0 since the associated topicId changed from null to 8YW_Ou3TRnuKkA6HyEvyQg
2025-01-04 00:11:50.614 [Producer clientId=producer-2] Resetting the last seen epoch of partition pong-message-topic-1 to 0 since the associated topicId changed from null to 8YW_Ou3TRnuKkA6HyEvyQg
2025-01-04 00:11:50.614 [Producer clientId=producer-2] Cluster ID: 6ptT-2PeSMuQSk4ZBKQmxg
2025-01-04 00:11:51.930 Ping success, handling ping message: Hello
2025-01-04 00:11:51.940 Ping success, handling ping message: Hello
2025-01-04 00:11:51.941 Throttling request as too many requests in the same second
2025-01-04 00:11:52.762 [KafkaServer id=0] shutting down
2025-01-04 00:11:52.762 [KafkaServer id=0] Starting controlled shutdown
2025-01-04 00:11:52.776 [Controller id=0] Shutting down broker 0
2025-01-04 00:11:52.777 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:11:52.779 [KafkaServer id=0] Controlled shutdown request returned successfully after 5ms
2025-01-04 00:11:52.783 [/config/changes-event-process-thread]: Shutting down
2025-01-04 00:11:52.783 [/config/changes-event-process-thread]: Shutdown completed
2025-01-04 00:11:52.783 [/config/changes-event-process-thread]: Stopped
2025-01-04 00:11:52.784 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
2025-01-04 00:11:52.786 [Producer clientId=producer-2] Node 0 disconnected.
2025-01-04 00:11:52.786 [Producer clientId=producer-2] Node -1 disconnected.
2025-01-04 00:11:52.787 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node 2147483647 disconnected.
2025-01-04 00:11:52.787 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2025-01-04 00:11:52.787 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node 0 disconnected.
2025-01-04 00:11:52.789 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Cancelled in-flight FETCH request with correlation id 25 due to node 0 being disconnected (elapsed time since creation: 317ms, elapsed time since send: 317ms, request timeout: 30000ms)
2025-01-04 00:11:52.789 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Error sending fetch request (sessionId=1129888882, epoch=6) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2025-01-04 00:11:52.789 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Group coordinator localhost:51131 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
2025-01-04 00:11:52.794 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors
2025-01-04 00:11:52.794 [data-plane Kafka Request Handler on Broker 0], shutting down
2025-01-04 00:11:52.795 [data-plane Kafka Request Handler on Broker 0], shut down completely
2025-01-04 00:11:52.800 [ExpirationReaper-0-AlterAcls]: Shutting down
2025-01-04 00:11:52.802 [ExpirationReaper-0-AlterAcls]: Stopped
2025-01-04 00:11:52.802 [ExpirationReaper-0-AlterAcls]: Shutdown completed
2025-01-04 00:11:52.803 [KafkaApi-0] Shutdown complete.
2025-01-04 00:11:52.803 [ExpirationReaper-0-topic]: Shutting down
2025-01-04 00:11:52.810 [ExpirationReaper-0-topic]: Stopped
2025-01-04 00:11:52.810 [ExpirationReaper-0-topic]: Shutdown completed
2025-01-04 00:11:52.810 [TransactionCoordinator id=0] Shutting down.
2025-01-04 00:11:52.811 [Transaction State Manager 0]: Shutdown complete
2025-01-04 00:11:52.811 [Transaction Marker Channel Manager 0]: Shutting down
2025-01-04 00:11:52.815 [Transaction Marker Channel Manager 0]: Stopped
2025-01-04 00:11:52.815 [Transaction Marker Channel Manager 0]: Shutdown completed
2025-01-04 00:11:52.818 [TransactionCoordinator id=0] Shutdown complete.
2025-01-04 00:11:52.818 [GroupCoordinator 0]: Shutting down.
2025-01-04 00:11:52.819 [ExpirationReaper-0-Heartbeat]: Shutting down
2025-01-04 00:11:52.820 [ExpirationReaper-0-Heartbeat]: Shutdown completed
2025-01-04 00:11:52.820 [ExpirationReaper-0-Heartbeat]: Stopped
2025-01-04 00:11:52.820 [ExpirationReaper-0-Rebalance]: Shutting down
2025-01-04 00:11:52.821 [ExpirationReaper-0-Rebalance]: Shutdown completed
2025-01-04 00:11:52.821 [ExpirationReaper-0-Rebalance]: Stopped
2025-01-04 00:11:52.822 [GroupCoordinator 0]: Shutdown complete.
2025-01-04 00:11:52.822 [ReplicaManager broker=0] Shutting down
2025-01-04 00:11:52.822 [LogDirFailureHandler]: Shutting down
2025-01-04 00:11:52.823 [LogDirFailureHandler]: Stopped
2025-01-04 00:11:52.823 [LogDirFailureHandler]: Shutdown completed
2025-01-04 00:11:52.823 [ReplicaFetcherManager on broker 0] shutting down
2025-01-04 00:11:52.823 [ReplicaFetcherManager on broker 0] shutdown completed
2025-01-04 00:11:52.823 [ReplicaAlterLogDirsManager on broker 0] shutting down
2025-01-04 00:11:52.824 [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2025-01-04 00:11:52.824 [ExpirationReaper-0-Fetch]: Shutting down
2025-01-04 00:11:52.825 [ExpirationReaper-0-Fetch]: Stopped
2025-01-04 00:11:52.825 [ExpirationReaper-0-Fetch]: Shutdown completed
2025-01-04 00:11:52.825 [ExpirationReaper-0-Produce]: Shutting down
2025-01-04 00:11:52.826 [ExpirationReaper-0-Produce]: Stopped
2025-01-04 00:11:52.826 [ExpirationReaper-0-Produce]: Shutdown completed
2025-01-04 00:11:52.827 [ExpirationReaper-0-DeleteRecords]: Shutting down
2025-01-04 00:11:52.829 [ExpirationReaper-0-DeleteRecords]: Stopped
2025-01-04 00:11:52.829 [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2025-01-04 00:11:52.832 [ExpirationReaper-0-ElectLeader]: Shutting down
2025-01-04 00:11:52.833 [ExpirationReaper-0-ElectLeader]: Shutdown completed
2025-01-04 00:11:52.833 [ExpirationReaper-0-ElectLeader]: Stopped
2025-01-04 00:11:52.842 [ReplicaManager broker=0] Shut down completely
2025-01-04 00:11:52.844 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutting down
2025-01-04 00:11:52.844 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Stopped
2025-01-04 00:11:52.844 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutdown completed
2025-01-04 00:11:52.847 Broker to controller channel manager for alterPartition shutdown
2025-01-04 00:11:52.847 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down
2025-01-04 00:11:52.848 [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped
2025-01-04 00:11:52.849 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed
2025-01-04 00:11:52.849 Broker to controller channel manager for forwarding shutdown
2025-01-04 00:11:52.849 Shutting down.
2025-01-04 00:11:52.849 Shutting down the log cleaner.
2025-01-04 00:11:52.850 [kafka-log-cleaner-thread-0]: Shutting down
2025-01-04 00:11:52.850 [kafka-log-cleaner-thread-0]: Shutdown completed
2025-01-04 00:11:52.850 [kafka-log-cleaner-thread-0]: Stopped
2025-01-04 00:11:52.889 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node 0 disconnected.
2025-01-04 00:11:52.889 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node 0 (localhost/127.0.0.1:51131) could not be established. Broker may not be available.
2025-01-04 00:11:52.890 [Producer clientId=producer-2] Node 0 disconnected.
2025-01-04 00:11:52.891 [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:51131) could not be established. Broker may not be available.
2025-01-04 00:11:52.897 [ProducerStateManager partition=pong-message-topic-0] Wrote producer snapshot at offset 3 with 0 producer ids in 4 ms.
2025-01-04 00:11:52.933 [ProducerStateManager partition=__consumer_offsets-2] Wrote producer snapshot at offset 6 with 0 producer ids in 6 ms.
2025-01-04 00:11:52.957 Shutdown complete.
2025-01-04 00:11:52.957 [ControllerEventThread controllerId=0] Shutting down
2025-01-04 00:11:52.958 [ControllerEventThread controllerId=0] Stopped
2025-01-04 00:11:52.958 [ControllerEventThread controllerId=0] Shutdown completed
2025-01-04 00:11:52.958 [PartitionStateMachine controllerId=0] Stopped partition state machine
2025-01-04 00:11:52.959 [ReplicaStateMachine controllerId=0] Stopped replica state machine
2025-01-04 00:11:52.959 [RequestSendThread controllerId=0] Shutting down
2025-01-04 00:11:52.959 [RequestSendThread controllerId=0] Stopped
2025-01-04 00:11:52.959 [RequestSendThread controllerId=0] Shutdown completed
2025-01-04 00:11:52.961 [Controller id=0] Resigned
2025-01-04 00:11:52.963 [feature-zk-node-event-process-thread]: Shutting down
2025-01-04 00:11:52.963 [feature-zk-node-event-process-thread]: Stopped
2025-01-04 00:11:52.963 [feature-zk-node-event-process-thread]: Shutdown completed
2025-01-04 00:11:52.964 [ZooKeeperClient Kafka server] Closing.
2025-01-04 00:11:52.968 An exception was thrown while closing send thread for session 0x1000a9c729d0000.
org.apache.zookeeper.ClientCnxn$EndOfStreamException: Unable to read additional data from server sessionid 0x1000a9c729d0000, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
2025-01-04 00:11:52.993 [Producer clientId=producer-2] Node 0 disconnected.
2025-01-04 00:11:52.993 [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:51131) could not be established. Broker may not be available.
2025-01-04 00:11:53.045 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node 0 disconnected.
2025-01-04 00:11:53.045 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node 0 (localhost/127.0.0.1:51131) could not be established. Broker may not be available.
2025-01-04 00:11:53.071 EventThread shut down for session: 0x1000a9c729d0000
2025-01-04 00:11:53.071 Session: 0x1000a9c729d0000 closed
2025-01-04 00:11:53.071 [ZooKeeperClient Kafka server] Closed.
2025-01-04 00:11:53.071 [ThrottledChannelReaper-Fetch]: Shutting down
2025-01-04 00:11:53.072 [ThrottledChannelReaper-Fetch]: Stopped
2025-01-04 00:11:53.072 [ThrottledChannelReaper-Fetch]: Shutdown completed
2025-01-04 00:11:53.072 [ThrottledChannelReaper-Produce]: Shutting down
2025-01-04 00:11:53.072 [ThrottledChannelReaper-Produce]: Stopped
2025-01-04 00:11:53.072 [ThrottledChannelReaper-Produce]: Shutdown completed
2025-01-04 00:11:53.072 [ThrottledChannelReaper-Request]: Shutting down
2025-01-04 00:11:53.072 [ThrottledChannelReaper-Request]: Stopped
2025-01-04 00:11:53.072 [ThrottledChannelReaper-Request]: Shutdown completed
2025-01-04 00:11:53.072 [ThrottledChannelReaper-ControllerMutation]: Shutting down
2025-01-04 00:11:53.072 [ThrottledChannelReaper-ControllerMutation]: Stopped
2025-01-04 00:11:53.072 [ThrottledChannelReaper-ControllerMutation]: Shutdown completed
2025-01-04 00:11:53.072 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server
2025-01-04 00:11:53.086 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed
2025-01-04 00:11:53.086 Metrics scheduler closed
2025-01-04 00:11:53.086 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-04 00:11:53.086 Metrics reporters closed
2025-01-04 00:11:53.087 Broker and topic stats closed
2025-01-04 00:11:53.087 App info kafka.server for 0 unregistered
2025-01-04 00:11:53.087 [KafkaServer id=0] shut down completed
2025-01-04 00:11:53.104 ConnnectionExpirerThread interrupted
2025-01-04 00:11:53.105 accept thread exitted run method
2025-01-04 00:11:53.105 selector thread exitted run method
2025-01-04 00:11:53.106 selector thread exitted run method
2025-01-04 00:11:53.106 shutting down
2025-01-04 00:11:53.106 Shutting down
2025-01-04 00:11:53.107 Draining request throttler queue
2025-01-04 00:11:53.107 RequestThrottler shutdown. Dropped 0 requests
2025-01-04 00:11:53.107 Shutting down
2025-01-04 00:11:53.107 Shutting down
2025-01-04 00:11:53.107 Shutting down
2025-01-04 00:11:53.107 SyncRequestProcessor exited!
2025-01-04 00:11:53.107 PrepRequestProcessor exited loop!
2025-01-04 00:11:53.107 shutdown of request processor complete
2025-01-04 00:11:53.130 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Revoke previously assigned partitions pong-message-topic-0, pong-message-topic-1
2025-01-04 00:11:53.130 pong-service: partitions revoked: [pong-message-topic-0, pong-message-topic-1]
2025-01-04 00:11:53.130 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-04 00:11:53.130 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2025-01-04 00:11:53.130 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Unsubscribed all topics or patterns and assigned partitions
2025-01-04 00:11:53.131 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-04 00:11:53.131 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2025-01-04 00:11:53.131 Metrics scheduler closed
2025-01-04 00:11:53.131 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-04 00:11:53.131 Metrics reporters closed
2025-01-04 00:11:53.132 App info kafka.consumer for consumer-pong-service-3 unregistered
2025-01-04 00:11:53.132 pong-service: Consumer stopped
2025-01-04 00:11:53.144 [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 30000 ms.
2025-01-04 00:11:53.146 Metrics scheduler closed
2025-01-04 00:11:53.147 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-04 00:11:53.147 Metrics reporters closed
2025-01-04 00:11:53.147 App info kafka.producer for producer-2 unregistered
2025-01-04 00:11:53.153 Closing JPA EntityManagerFactory for persistence unit 'default'
2025-01-04 00:11:53.154 HikariPool-3 - Shutdown initiated...
2025-01-04 00:11:53.156 HikariPool-3 - Shutdown completed.
2025-01-04 00:11:53.595 SessionTrackerImpl exited loop!
2025-01-04 00:11:53.776 [Controller id=0] Processing automatic preferred replica leader election
2025-01-04 00:11:55.228 [KafkaServer id=0] shutting down
2025-01-04 00:11:55.229 [/config/changes-event-process-thread]: Shutting down
2025-01-04 00:11:55.229 [/config/changes-event-process-thread]: Stopped
2025-01-04 00:11:55.229 [/config/changes-event-process-thread]: Shutdown completed
2025-01-04 00:11:55.229 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
2025-01-04 00:11:55.230 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors
2025-01-04 00:11:55.230 [data-plane Kafka Request Handler on Broker 0], shutting down
2025-01-04 00:11:55.230 [data-plane Kafka Request Handler on Broker 0], shut down completely
2025-01-04 00:11:55.230 [ExpirationReaper-0-AlterAcls]: Shutting down
2025-01-04 00:11:55.231 [ExpirationReaper-0-AlterAcls]: Stopped
2025-01-04 00:11:55.231 [ExpirationReaper-0-AlterAcls]: Shutdown completed
2025-01-04 00:11:55.231 [KafkaApi-0] Shutdown complete.
2025-01-04 00:11:55.231 [ExpirationReaper-0-topic]: Shutting down
2025-01-04 00:11:55.231 [ExpirationReaper-0-topic]: Stopped
2025-01-04 00:11:55.231 [ExpirationReaper-0-topic]: Shutdown completed
2025-01-04 00:11:55.231 [TransactionCoordinator id=0] Shutting down.
2025-01-04 00:11:55.231 [Transaction State Manager 0]: Shutdown complete
2025-01-04 00:11:55.231 [Transaction Marker Channel Manager 0]: Shutting down
2025-01-04 00:11:55.231 [Transaction Marker Channel Manager 0]: Stopped
2025-01-04 00:11:55.231 [Transaction Marker Channel Manager 0]: Shutdown completed
2025-01-04 00:11:55.231 [TransactionCoordinator id=0] Shutdown complete.
2025-01-04 00:11:55.231 [GroupCoordinator 0]: Shutting down.
2025-01-04 00:11:55.231 [ExpirationReaper-0-Heartbeat]: Shutting down
2025-01-04 00:11:55.233 [ExpirationReaper-0-Heartbeat]: Shutdown completed
2025-01-04 00:11:55.233 [ExpirationReaper-0-Heartbeat]: Stopped
2025-01-04 00:11:55.233 [ExpirationReaper-0-Rebalance]: Shutting down
2025-01-04 00:11:55.233 [ExpirationReaper-0-Rebalance]: Stopped
2025-01-04 00:11:55.233 [ExpirationReaper-0-Rebalance]: Shutdown completed
2025-01-04 00:11:55.233 [GroupCoordinator 0]: Shutdown complete.
2025-01-04 00:11:55.233 [ReplicaManager broker=0] Shutting down
2025-01-04 00:11:55.233 [LogDirFailureHandler]: Shutting down
2025-01-04 00:11:55.233 [LogDirFailureHandler]: Stopped
2025-01-04 00:11:55.233 [LogDirFailureHandler]: Shutdown completed
2025-01-04 00:11:55.233 [ReplicaFetcherManager on broker 0] shutting down
2025-01-04 00:11:55.233 [ReplicaFetcherManager on broker 0] shutdown completed
2025-01-04 00:11:55.233 [ReplicaAlterLogDirsManager on broker 0] shutting down
2025-01-04 00:11:55.233 [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2025-01-04 00:11:55.233 [ExpirationReaper-0-Fetch]: Shutting down
2025-01-04 00:11:55.233 [ExpirationReaper-0-Fetch]: Stopped
2025-01-04 00:11:55.233 [ExpirationReaper-0-Fetch]: Shutdown completed
2025-01-04 00:11:55.233 [ExpirationReaper-0-Produce]: Shutting down
2025-01-04 00:11:55.234 [ExpirationReaper-0-Produce]: Stopped
2025-01-04 00:11:55.234 [ExpirationReaper-0-Produce]: Shutdown completed
2025-01-04 00:11:55.234 [ExpirationReaper-0-DeleteRecords]: Shutting down
2025-01-04 00:11:55.234 [ExpirationReaper-0-DeleteRecords]: Stopped
2025-01-04 00:11:55.234 [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2025-01-04 00:11:55.234 [ExpirationReaper-0-ElectLeader]: Shutting down
2025-01-04 00:11:55.234 [ExpirationReaper-0-ElectLeader]: Shutdown completed
2025-01-04 00:11:55.234 [ExpirationReaper-0-ElectLeader]: Stopped
2025-01-04 00:11:55.238 [ReplicaManager broker=0] Shut down completely
2025-01-04 00:11:55.238 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutting down
2025-01-04 00:11:55.238 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Stopped
2025-01-04 00:11:55.238 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutdown completed
2025-01-04 00:11:55.239 Broker to controller channel manager for alterPartition shutdown
2025-01-04 00:11:55.239 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down
2025-01-04 00:11:55.239 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed
2025-01-04 00:11:55.239 [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped
2025-01-04 00:11:55.239 Broker to controller channel manager for forwarding shutdown
2025-01-04 00:11:55.239 Shutting down.
2025-01-04 00:11:55.239 Shutting down the log cleaner.
2025-01-04 00:11:55.239 [kafka-log-cleaner-thread-0]: Shutting down
2025-01-04 00:11:55.239 [kafka-log-cleaner-thread-0]: Stopped
2025-01-04 00:11:55.239 [kafka-log-cleaner-thread-0]: Shutdown completed
2025-01-04 00:11:55.248 Shutdown complete.
2025-01-04 00:11:55.248 [ControllerEventThread controllerId=0] Shutting down
2025-01-04 00:11:55.248 [ControllerEventThread controllerId=0] Stopped
2025-01-04 00:11:55.248 [ControllerEventThread controllerId=0] Shutdown completed
2025-01-04 00:11:55.249 [PartitionStateMachine controllerId=0] Stopped partition state machine
2025-01-04 00:11:55.249 [ReplicaStateMachine controllerId=0] Stopped replica state machine
2025-01-04 00:11:55.249 [RequestSendThread controllerId=0] Shutting down
2025-01-04 00:11:55.249 [RequestSendThread controllerId=0] Stopped
2025-01-04 00:11:55.249 [RequestSendThread controllerId=0] Shutdown completed
2025-01-04 00:11:55.249 [Controller id=0] Resigned
2025-01-04 00:11:55.251 [feature-zk-node-event-process-thread]: Shutting down
2025-01-04 00:11:55.251 [feature-zk-node-event-process-thread]: Stopped
2025-01-04 00:11:55.251 [feature-zk-node-event-process-thread]: Shutdown completed
2025-01-04 00:11:55.251 [ZooKeeperClient Kafka server] Closing.
2025-01-04 00:11:55.353 Session: 0x1000a9c73d20000 closed
2025-01-04 00:11:55.353 EventThread shut down for session: 0x1000a9c73d20000
2025-01-04 00:11:55.353 [ZooKeeperClient Kafka server] Closed.
2025-01-04 00:11:55.353 [ThrottledChannelReaper-Fetch]: Shutting down
2025-01-04 00:11:55.353 [ThrottledChannelReaper-Fetch]: Stopped
2025-01-04 00:11:55.353 [ThrottledChannelReaper-Fetch]: Shutdown completed
2025-01-04 00:11:55.353 [ThrottledChannelReaper-Produce]: Shutting down
2025-01-04 00:11:55.353 [ThrottledChannelReaper-Produce]: Stopped
2025-01-04 00:11:55.353 [ThrottledChannelReaper-Produce]: Shutdown completed
2025-01-04 00:11:55.354 [ThrottledChannelReaper-Request]: Shutting down
2025-01-04 00:11:55.354 [ThrottledChannelReaper-Request]: Stopped
2025-01-04 00:11:55.354 [ThrottledChannelReaper-Request]: Shutdown completed
2025-01-04 00:11:55.354 [ThrottledChannelReaper-ControllerMutation]: Shutting down
2025-01-04 00:11:55.354 [ThrottledChannelReaper-ControllerMutation]: Stopped
2025-01-04 00:11:55.354 [ThrottledChannelReaper-ControllerMutation]: Shutdown completed
2025-01-04 00:11:55.354 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server
2025-01-04 00:11:55.359 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed
2025-01-04 00:11:55.359 Metrics scheduler closed
2025-01-04 00:11:55.359 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-04 00:11:55.359 Metrics reporters closed
2025-01-04 00:11:55.359 Broker and topic stats closed
2025-01-04 00:11:55.359 App info kafka.server for 0 unregistered
2025-01-04 00:11:55.359 [KafkaServer id=0] shut down completed
2025-01-04 00:11:55.361 ConnnectionExpirerThread interrupted
2025-01-04 00:11:55.361 selector thread exitted run method
2025-01-04 00:11:55.362 selector thread exitted run method
2025-01-04 00:11:55.362 accept thread exitted run method
2025-01-04 00:11:55.362 shutting down
2025-01-04 00:11:55.362 Shutting down
2025-01-04 00:11:55.362 Draining request throttler queue
2025-01-04 00:11:55.362 RequestThrottler shutdown. Dropped 0 requests
2025-01-04 00:11:55.362 Shutting down
2025-01-04 00:11:55.362 Shutting down
2025-01-04 00:11:55.362 Shutting down
2025-01-04 00:11:55.362 PrepRequestProcessor exited loop!
2025-01-04 00:11:55.362 SyncRequestProcessor exited!
2025-01-04 00:11:55.362 shutdown of request processor complete
2025-01-04 00:12:39.954 Could not detect default configuration classes for test class [com.demo.controller.PongControllerSpec]: PongControllerSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2025-01-04 00:12:40.130 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.controller.PongControllerSpec
2025-01-04 00:12:40.349 Could not detect default configuration classes for test class [com.demo.dao.MessageRepositorySpec]: MessageRepositorySpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2025-01-04 00:12:40.362 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.dao.MessageRepositorySpec
2025-01-04 00:12:40.375 Could not detect default configuration classes for test class [com.demo.kafka.KafkaSpec]: KafkaSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2025-01-04 00:12:40.398 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.kafka.KafkaSpec
2025-01-04 00:12:40.435 Could not detect default configuration classes for test class [com.demo.kafka.KafkaSpec]: KafkaSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2025-01-04 00:12:40.438 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.kafka.KafkaSpec
2025-01-04 00:12:40.445 Could not detect default configuration classes for test class [com.demo.dao.MessageRepositorySpec]: MessageRepositorySpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2025-01-04 00:12:40.447 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.dao.MessageRepositorySpec
2025-01-04 00:12:40.452 Could not detect default configuration classes for test class [com.demo.controller.PongControllerSpec]: PongControllerSpec does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2025-01-04 00:12:40.457 Found @SpringBootConfiguration com.demo.PongApplication for test class com.demo.controller.PongControllerSpec
2025-01-04 00:12:41.302 Registered kafka:type=kafka.Log4jController MBean
2025-01-04 00:12:41.372 
2025-01-04 00:12:41.373   ______                  _                                          
2025-01-04 00:12:41.373  |___  /                 | |                                         
2025-01-04 00:12:41.373     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __   
2025-01-04 00:12:41.373    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__|
2025-01-04 00:12:41.373   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |    
2025-01-04 00:12:41.373  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_|
2025-01-04 00:12:41.373                                               | |                     
2025-01-04 00:12:41.373                                               |_|                     
2025-01-04 00:12:41.373 
2025-01-04 00:12:41.375 Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT
2025-01-04 00:12:41.375 Server environment:host.name=host.docker.internal
2025-01-04 00:12:41.375 Server environment:java.version=17.0.12
2025-01-04 00:12:41.375 Server environment:java.vendor=Oracle Corporation
2025-01-04 00:12:41.375 Server environment:java.home=C:\work\jdk-17
2025-01-04 00:12:41.377 Server environment:java.class.path=C:\code\hsbc\demo\pong\target\test-classes;C:\code\hsbc\demo\pong\target\classes;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-webflux\3.1.4\spring-boot-starter-webflux-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter\3.1.4\spring-boot-starter-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot\3.1.4\spring-boot-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-autoconfigure\3.1.4\spring-boot-autoconfigure-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-logging\3.1.4\spring-boot-starter-logging-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\ch\qos\logback\logback-classic\1.4.11\logback-classic-1.4.11.jar;C:\work\apache-maven-3.8.8\repo\ch\qos\logback\logback-core\1.4.11\logback-core-1.4.11.jar;C:\work\apache-maven-3.8.8\repo\org\apache\logging\log4j\log4j-to-slf4j\2.20.0\log4j-to-slf4j-2.20.0.jar;C:\work\apache-maven-3.8.8\repo\org\apache\logging\log4j\log4j-api\2.20.0\log4j-api-2.20.0.jar;C:\work\apache-maven-3.8.8\repo\org\slf4j\jul-to-slf4j\2.0.9\jul-to-slf4j-2.0.9.jar;C:\work\apache-maven-3.8.8\repo\jakarta\annotation\jakarta.annotation-api\2.1.1\jakarta.annotation-api-2.1.1.jar;C:\work\apache-maven-3.8.8\repo\org\yaml\snakeyaml\1.33\snakeyaml-1.33.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-json\3.1.4\spring-boot-starter-json-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-databind\2.15.2\jackson-databind-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-annotations\2.15.2\jackson-annotations-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-core\2.15.2\jackson-core-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.15.2\jackson-datatype-jdk8-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.15.2\jackson-datatype-jsr310-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\module\jackson-module-parameter-names\2.15.2\jackson-module-parameter-names-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-reactor-netty\3.1.4\spring-boot-starter-reactor-netty-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\netty\reactor-netty-http\1.1.11\reactor-netty-http-1.1.11.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-http\4.1.97.Final\netty-codec-http-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-http2\4.1.97.Final\netty-codec-http2-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns\4.1.97.Final\netty-resolver-dns-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-dns\4.1.97.Final\netty-codec-dns-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns-native-macos\4.1.97.Final\netty-resolver-dns-native-macos-4.1.97.Final-osx-x86_64.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns-classes-macos\4.1.97.Final\netty-resolver-dns-classes-macos-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final-linux-x86_64.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\netty\reactor-netty-core\1.1.11\reactor-netty-core-1.1.11.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-handler-proxy\4.1.97.Final\netty-handler-proxy-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-socks\4.1.97.Final\netty-codec-socks-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-web\6.0.12\spring-web-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-beans\6.0.12\spring-beans-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-webflux\6.0.12\spring-webflux-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\reactor-core\3.5.10\reactor-core-3.5.10.jar;C:\work\apache-maven-3.8.8\repo\org\reactivestreams\reactive-streams\1.0.4\reactive-streams-1.0.4.jar;C:\work\apache-maven-3.8.8\repo\com\google\guava\guava\19.0\guava-19.0.jar;C:\work\apache-maven-3.8.8\repo\commons-io\commons-io\2.11.0\commons-io-2.11.0.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-data-redis\3.1.4\spring-boot-starter-data-redis-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-redis\3.1.4\spring-data-redis-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-keyvalue\3.1.4\spring-data-keyvalue-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-oxm\6.0.12\spring-oxm-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-aop\6.0.12\spring-aop-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-context-support\6.0.12\spring-context-support-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\io\lettuce\lettuce-core\6.2.6.RELEASE\lettuce-core-6.2.6.RELEASE.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-common\4.1.97.Final\netty-common-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-handler\4.1.97.Final\netty-handler-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver\4.1.97.Final\netty-resolver-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-buffer\4.1.97.Final\netty-buffer-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-unix-common\4.1.97.Final\netty-transport-native-unix-common-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec\4.1.97.Final\netty-codec-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport\4.1.97.Final\netty-transport-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-data-jpa\3.1.4\spring-boot-starter-data-jpa-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-aop\3.1.4\spring-boot-starter-aop-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\aspectj\aspectjweaver\1.9.20\aspectjweaver-1.9.20.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-jdbc\3.1.4\spring-boot-starter-jdbc-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\zaxxer\HikariCP\5.0.1\HikariCP-5.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-jdbc\6.0.12\spring-jdbc-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\hibernate\orm\hibernate-core\6.2.9.Final\hibernate-core-6.2.9.Final.jar;C:\work\apache-maven-3.8.8\repo\jakarta\persistence\jakarta.persistence-api\3.1.0\jakarta.persistence-api-3.1.0.jar;C:\work\apache-maven-3.8.8\repo\jakarta\transaction\jakarta.transaction-api\2.0.1\jakarta.transaction-api-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\jboss\logging\jboss-logging\3.5.3.Final\jboss-logging-3.5.3.Final.jar;C:\work\apache-maven-3.8.8\repo\org\hibernate\common\hibernate-commons-annotations\6.0.6.Final\hibernate-commons-annotations-6.0.6.Final.jar;C:\work\apache-maven-3.8.8\repo\io\smallrye\jandex\3.0.5\jandex-3.0.5.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\classmate\1.5.1\classmate-1.5.1.jar;C:\work\apache-maven-3.8.8\repo\net\bytebuddy\byte-buddy\1.14.8\byte-buddy-1.14.8.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\jaxb-runtime\4.0.3\jaxb-runtime-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\jaxb-core\4.0.3\jaxb-core-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\eclipse\angus\angus-activation\2.0.1\angus-activation-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\txw2\4.0.3\txw2-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\com\sun\istack\istack-commons-runtime\4.1.2\istack-commons-runtime-4.1.2.jar;C:\work\apache-maven-3.8.8\repo\jakarta\inject\jakarta.inject-api\2.0.1\jakarta.inject-api-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\antlr\antlr4-runtime\4.10.1\antlr4-runtime-4.10.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-jpa\3.1.4\spring-data-jpa-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-commons\3.1.4\spring-data-commons-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-orm\6.0.12\spring-orm-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-aspects\6.0.12\spring-aspects-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\postgresql\postgresql\42.6.0\postgresql-42.6.0.jar;C:\work\apache-maven-3.8.8\repo\org\checkerframework\checker-qual\3.31.0\checker-qual-3.31.0.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\kafka\spring-kafka\3.0.11\spring-kafka-3.0.11.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-context\6.0.12\spring-context-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-expression\6.0.12\spring-expression-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-messaging\6.0.12\spring-messaging-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-tx\6.0.12\spring-tx-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\retry\spring-retry\2.0.3\spring-retry-2.0.3.jar;C:\work\apache-maven-3.8.8\repo\io\micrometer\micrometer-observation\1.11.4\micrometer-observation-1.11.4.jar;C:\work\apache-maven-3.8.8\repo\io\micrometer\micrometer-commons\1.11.4\micrometer-commons-1.11.4.jar;C:\work\apache-maven-3.8.8\repo\com\google\code\findbugs\jsr305\3.0.2\jsr305-3.0.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\com\github\luben\zstd-jni\1.5.2-1\zstd-jni-1.5.2-1.jar;C:\work\apache-maven-3.8.8\repo\org\lz4\lz4-java\1.8.0\lz4-java-1.8.0.jar;C:\work\apache-maven-3.8.8\repo\org\xerial\snappy\snappy-java\1.1.8.4\snappy-java-1.1.8.4.jar;C:\work\apache-maven-3.8.8\repo\org\slf4j\slf4j-api\2.0.9\slf4j-api-2.0.9.jar;C:\work\apache-maven-3.8.8\repo\com\h2database\h2\1.4.200\h2-1.4.200.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-test\3.1.4\spring-boot-starter-test-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-test\3.1.4\spring-boot-test-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-test-autoconfigure\3.1.4\spring-boot-test-autoconfigure-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\jayway\jsonpath\json-path\2.8.0\json-path-2.8.0.jar;C:\work\apache-maven-3.8.8\repo\jakarta\xml\bind\jakarta.xml.bind-api\4.0.1\jakarta.xml.bind-api-4.0.1.jar;C:\work\apache-maven-3.8.8\repo\jakarta\activation\jakarta.activation-api\2.1.2\jakarta.activation-api-2.1.2.jar;C:\work\apache-maven-3.8.8\repo\net\minidev\json-smart\2.4.11\json-smart-2.4.11.jar;C:\work\apache-maven-3.8.8\repo\net\minidev\accessors-smart\2.4.11\accessors-smart-2.4.11.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm\9.3\asm-9.3.jar;C:\work\apache-maven-3.8.8\repo\org\assertj\assertj-core\3.24.2\assertj-core-3.24.2.jar;C:\work\apache-maven-3.8.8\repo\org\hamcrest\hamcrest\2.2\hamcrest-2.2.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter\5.9.3\junit-jupiter-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-params\5.9.3\junit-jupiter-params-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-engine\5.9.3\junit-jupiter-engine-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\mockito\mockito-core\5.3.1\mockito-core-5.3.1.jar;C:\work\apache-maven-3.8.8\repo\net\bytebuddy\byte-buddy-agent\1.14.8\byte-buddy-agent-1.14.8.jar;C:\work\apache-maven-3.8.8\repo\org\objenesis\objenesis\3.3\objenesis-3.3.jar;C:\work\apache-maven-3.8.8\repo\org\mockito\mockito-junit-jupiter\5.3.1\mockito-junit-jupiter-5.3.1.jar;C:\work\apache-maven-3.8.8\repo\org\skyscreamer\jsonassert\1.5.1\jsonassert-1.5.1.jar;C:\work\apache-maven-3.8.8\repo\com\vaadin\external\google\android-json\0.0.20131108.vaadin1\android-json-0.0.20131108.vaadin1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-core\6.0.12\spring-core-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-jcl\6.0.12\spring-jcl-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-test\6.0.12\spring-test-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\xmlunit\xmlunit-core\2.9.1\xmlunit-core-2.9.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy\4.0.15\groovy-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-ant\4.0.15\groovy-ant-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant\1.10.14\ant-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-junit\1.10.14\ant-junit-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-launcher\1.10.14\ant-launcher-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-antlr\1.10.14\ant-antlr-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-cli-picocli\4.0.15\groovy-cli-picocli-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\info\picocli\picocli\4.7.5\picocli-4.7.5.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-console\4.0.15\groovy-console-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\github\javaparser\javaparser-core\3.25.5\javaparser-core-3.25.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-util\9.5\asm-util-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-tree\9.5\asm-tree-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-analysis\9.5\asm-analysis-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\abego\treelayout\org.abego.treelayout.core\1.0.3\org.abego.treelayout.core-1.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ivy\ivy\2.5.2\ivy-2.5.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-datetime\4.0.15\groovy-datetime-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-docgenerator\4.0.15\groovy-docgenerator-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\thoughtworks\qdox\qdox\1.12.1\qdox-1.12.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-groovydoc\4.0.15\groovy-groovydoc-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-groovysh\4.0.15\groovy-groovysh-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\jline\jline\2.14.6\jline-2.14.6.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-jmx\4.0.15\groovy-jmx-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-json\4.0.15\groovy-json-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-jsr223\4.0.15\groovy-jsr223-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-macro\4.0.15\groovy-macro-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-nio\4.0.15\groovy-nio-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-servlet\4.0.15\groovy-servlet-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-sql\4.0.15\groovy-sql-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-swing\4.0.15\groovy-swing-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-templates\4.0.15\groovy-templates-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-test\4.0.15\groovy-test-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\junit\junit\4.13.2\junit-4.13.2.jar;C:\work\apache-maven-3.8.8\repo\org\hamcrest\hamcrest-core\2.2\hamcrest-core-2.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-test-junit5\4.0.15\groovy-test-junit5-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-xml\4.0.15\groovy-xml-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-yaml\4.0.15\groovy-yaml-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\dataformat\jackson-dataformat-yaml\2.15.2\jackson-dataformat-yaml-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\org\spockframework\spock-core\2.4-M1-groovy-4.0\spock-core-2.4-M1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-engine\1.9.3\junit-platform-engine-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\opentest4j\opentest4j\1.2.0\opentest4j-1.2.0.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-commons\1.9.3\junit-platform-commons-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\apiguardian\apiguardian-api\1.1.2\apiguardian-api-1.1.2.jar;C:\work\apache-maven-3.8.8\repo\org\spockframework\spock-spring\2.4-M1-groovy-4.0\spock-spring-2.4-M1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\com\athaydes\spock-reports\2.5.1-groovy-4.0\spock-reports-2.5.1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\com\github\codemonstur\embedded-redis\1.4.2\embedded-redis-1.4.2.jar;C:\work\apache-maven-3.8.8\repo\redis\clients\jedis\4.3.2\jedis-4.3.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\commons\commons-pool2\2.11.1\commons-pool2-2.11.1.jar;C:\work\apache-maven-3.8.8\repo\org\json\json\20220320\json-20220320.jar;C:\work\apache-maven-3.8.8\repo\com\google\code\gson\gson\2.10.1\gson-2.10.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\kafka\spring-kafka-test\3.0.11\spring-kafka-test-3.0.11.jar;C:\work\apache-maven-3.8.8\repo\org\apache\zookeeper\zookeeper\3.6.3\zookeeper-3.6.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\zookeeper\zookeeper-jute\3.6.3\zookeeper-jute-3.6.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-classes-epoll\4.1.97.Final\netty-transport-classes-epoll-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1-test.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-metadata\3.4.1\kafka-metadata-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-server-common\3.4.1\kafka-server-common-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-raft\3.4.1\kafka-raft-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-streams-test-utils\3.4.1\kafka-streams-test-utils-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-streams\3.4.1\kafka-streams-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\rocksdb\rocksdbjni\7.1.2\rocksdbjni-7.1.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\scala-library\2.13.10\scala-library-2.13.10.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-group-coordinator\3.4.1\kafka-group-coordinator-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-storage\3.4.1\kafka-storage-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-storage-api\3.4.1\kafka-storage-api-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\net\sourceforge\argparse4j\argparse4j\0.7.0\argparse4j-0.7.0.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\module\jackson-module-scala_2.13\2.15.2\jackson-module-scala_2.13-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\thoughtworks\paranamer\paranamer\2.8\paranamer-2.8.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\dataformat\jackson-dataformat-csv\2.15.2\jackson-dataformat-csv-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\net\sf\jopt-simple\jopt-simple\5.0.4\jopt-simple-5.0.4.jar;C:\work\apache-maven-3.8.8\repo\org\bitbucket\b_c\jose4j\0.9.3\jose4j-0.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\modules\scala-collection-compat_2.13\2.10.0\scala-collection-compat_2.13-2.10.0.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\modules\scala-java8-compat_2.13\1.0.2\scala-java8-compat_2.13-1.0.2.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\scala-reflect\2.13.10\scala-reflect-2.13.10.jar;C:\work\apache-maven-3.8.8\repo\com\typesafe\scala-logging\scala-logging_2.13\3.9.4\scala-logging_2.13-3.9.4.jar;C:\work\apache-maven-3.8.8\repo\io\dropwizard\metrics\metrics-core\4.2.19\metrics-core-4.2.19.jar;C:\work\apache-maven-3.8.8\repo\commons-cli\commons-cli\1.4\commons-cli-1.4.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1-test.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-api\5.9.3\junit-jupiter-api-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-launcher\1.9.3\junit-platform-launcher-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\awaitility\awaitility\4.2.0\awaitility-4.2.0.jar;
2025-01-04 00:12:41.378 Server environment:java.library.path=C:\work\jdk-17\bin;C:\windows\Sun\Java\bin;C:\windows\system32;C:\windows;C:\work\python312\Scripts\;C:\work\python312\;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program\Git\cmd;C:\Program\PowerShell\7\;C:\Program Files\dotnet\;;C:\Program Files\Docker\Docker\resources\bin;C:\Users\joech\AppData\Local\Microsoft\WindowsApps;C:\Users\joech\AppData\Local\GitHubDesktop\bin;C:\Program\Microsoft VS Code\bin;C:\work\apache-maven-3.8.8\bin;C:\Program Files\Tesseract-OCR;C:\work\jdk-17\bin;;.
2025-01-04 00:12:41.378 Server environment:java.io.tmpdir=C:\Users\joech\AppData\Local\Temp\
2025-01-04 00:12:41.378 Server environment:java.compiler=<NA>
2025-01-04 00:12:41.378 Server environment:os.name=Windows 11
2025-01-04 00:12:41.378 Server environment:os.arch=amd64
2025-01-04 00:12:41.378 Server environment:os.version=10.0
2025-01-04 00:12:41.378 Server environment:user.name=joech
2025-01-04 00:12:41.378 Server environment:user.home=C:\Users\joech
2025-01-04 00:12:41.378 Server environment:user.dir=C:\code\hsbc\demo\pong
2025-01-04 00:12:41.378 Server environment:os.memory.free=398MB
2025-01-04 00:12:41.378 Server environment:os.memory.max=15816MB
2025-01-04 00:12:41.378 Server environment:os.memory.total=568MB
2025-01-04 00:12:41.378 zookeeper.enableEagerACLCheck = false
2025-01-04 00:12:41.380 zookeeper.digest.enabled = true
2025-01-04 00:12:41.380 zookeeper.closeSessionTxn.enabled = true
2025-01-04 00:12:41.381 zookeeper.flushDelay=0
2025-01-04 00:12:41.381 zookeeper.maxWriteQueuePollTime=0
2025-01-04 00:12:41.381 zookeeper.maxBatchSize=1000
2025-01-04 00:12:41.381 zookeeper.intBufferStartingSizeBytes = 1024
2025-01-04 00:12:41.383 zookeeper.snapshot.trust.empty : false
2025-01-04 00:12:41.412 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2025-01-04 00:12:41.413 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2025-01-04 00:12:41.413 zookeeper.snapshotSizeFactor = 0.33
2025-01-04 00:12:41.413 zookeeper.commitLogCount=500
2025-01-04 00:12:41.416 Weighed connection throttling is disabled
2025-01-04 00:12:41.418 minSessionTimeout set to 1600
2025-01-04 00:12:41.418 maxSessionTimeout set to 16000
2025-01-04 00:12:41.419 Response cache size is initialized with value 400.
2025-01-04 00:12:41.419 Response cache size is initialized with value 400.
2025-01-04 00:12:41.420 zookeeper.pathStats.slotCapacity = 60
2025-01-04 00:12:41.420 zookeeper.pathStats.slotDuration = 15
2025-01-04 00:12:41.420 zookeeper.pathStats.maxDepth = 6
2025-01-04 00:12:41.420 zookeeper.pathStats.initialDelay = 5
2025-01-04 00:12:41.420 zookeeper.pathStats.delay = 5
2025-01-04 00:12:41.420 zookeeper.pathStats.enabled = false
2025-01-04 00:12:41.423 The max bytes for all large requests are set to 104857600
2025-01-04 00:12:41.423 The large request threshold is set to -1
2025-01-04 00:12:41.423 Created server with tickTime 800 minSessionTimeout 1600 maxSessionTimeout 16000 clientPortListenBacklog -1 datadir C:\Users\joech\AppData\Local\Temp\kafka-11657351825217993419\version-2 snapdir C:\Users\joech\AppData\Local\Temp\kafka-17337524083912526653\version-2
2025-01-04 00:12:41.464 maxCnxns is not configured, using default value 0.
2025-01-04 00:12:41.466 Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers.
2025-01-04 00:12:41.471 binding to port /127.0.0.1:0
2025-01-04 00:12:41.490 zookeeper.snapshot.compression.method = CHECKED
2025-01-04 00:12:41.490 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-17337524083912526653\version-2\snapshot.0
2025-01-04 00:12:41.495 Snapshot loaded in 18 ms, highest zxid is 0x0, digest is 1371985504
2025-01-04 00:12:41.495 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-17337524083912526653\version-2\snapshot.0
2025-01-04 00:12:41.495 Snapshot taken in 0 ms
2025-01-04 00:12:41.507 PrepRequestProcessor (sid:0) started, reconfigEnabled=false
2025-01-04 00:12:41.507 zookeeper.request_throttler.shutdownTimeout = 10000
2025-01-04 00:12:41.740 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.0894f3ab-bdbd-4f53-bba2-9187f81f1b2315892691390016550463
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:51182
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2025-01-04 00:12:41.782 Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
2025-01-04 00:12:41.860 starting
2025-01-04 00:12:41.861 Connecting to zookeeper on 127.0.0.1:51182
2025-01-04 00:12:41.879 [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:51182.
2025-01-04 00:12:41.884 Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT
2025-01-04 00:12:41.884 Client environment:host.name=host.docker.internal
2025-01-04 00:12:41.884 Client environment:java.version=17.0.12
2025-01-04 00:12:41.884 Client environment:java.vendor=Oracle Corporation
2025-01-04 00:12:41.884 Client environment:java.home=C:\work\jdk-17
2025-01-04 00:12:41.884 Client environment:java.class.path=C:\code\hsbc\demo\pong\target\test-classes;C:\code\hsbc\demo\pong\target\classes;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-webflux\3.1.4\spring-boot-starter-webflux-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter\3.1.4\spring-boot-starter-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot\3.1.4\spring-boot-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-autoconfigure\3.1.4\spring-boot-autoconfigure-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-logging\3.1.4\spring-boot-starter-logging-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\ch\qos\logback\logback-classic\1.4.11\logback-classic-1.4.11.jar;C:\work\apache-maven-3.8.8\repo\ch\qos\logback\logback-core\1.4.11\logback-core-1.4.11.jar;C:\work\apache-maven-3.8.8\repo\org\apache\logging\log4j\log4j-to-slf4j\2.20.0\log4j-to-slf4j-2.20.0.jar;C:\work\apache-maven-3.8.8\repo\org\apache\logging\log4j\log4j-api\2.20.0\log4j-api-2.20.0.jar;C:\work\apache-maven-3.8.8\repo\org\slf4j\jul-to-slf4j\2.0.9\jul-to-slf4j-2.0.9.jar;C:\work\apache-maven-3.8.8\repo\jakarta\annotation\jakarta.annotation-api\2.1.1\jakarta.annotation-api-2.1.1.jar;C:\work\apache-maven-3.8.8\repo\org\yaml\snakeyaml\1.33\snakeyaml-1.33.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-json\3.1.4\spring-boot-starter-json-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-databind\2.15.2\jackson-databind-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-annotations\2.15.2\jackson-annotations-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\core\jackson-core\2.15.2\jackson-core-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.15.2\jackson-datatype-jdk8-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.15.2\jackson-datatype-jsr310-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\module\jackson-module-parameter-names\2.15.2\jackson-module-parameter-names-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-reactor-netty\3.1.4\spring-boot-starter-reactor-netty-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\netty\reactor-netty-http\1.1.11\reactor-netty-http-1.1.11.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-http\4.1.97.Final\netty-codec-http-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-http2\4.1.97.Final\netty-codec-http2-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns\4.1.97.Final\netty-resolver-dns-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-dns\4.1.97.Final\netty-codec-dns-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns-native-macos\4.1.97.Final\netty-resolver-dns-native-macos-4.1.97.Final-osx-x86_64.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver-dns-classes-macos\4.1.97.Final\netty-resolver-dns-classes-macos-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final-linux-x86_64.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\netty\reactor-netty-core\1.1.11\reactor-netty-core-1.1.11.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-handler-proxy\4.1.97.Final\netty-handler-proxy-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec-socks\4.1.97.Final\netty-codec-socks-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-web\6.0.12\spring-web-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-beans\6.0.12\spring-beans-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-webflux\6.0.12\spring-webflux-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\io\projectreactor\reactor-core\3.5.10\reactor-core-3.5.10.jar;C:\work\apache-maven-3.8.8\repo\org\reactivestreams\reactive-streams\1.0.4\reactive-streams-1.0.4.jar;C:\work\apache-maven-3.8.8\repo\com\google\guava\guava\19.0\guava-19.0.jar;C:\work\apache-maven-3.8.8\repo\commons-io\commons-io\2.11.0\commons-io-2.11.0.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-data-redis\3.1.4\spring-boot-starter-data-redis-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-redis\3.1.4\spring-data-redis-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-keyvalue\3.1.4\spring-data-keyvalue-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-oxm\6.0.12\spring-oxm-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-aop\6.0.12\spring-aop-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-context-support\6.0.12\spring-context-support-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\io\lettuce\lettuce-core\6.2.6.RELEASE\lettuce-core-6.2.6.RELEASE.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-common\4.1.97.Final\netty-common-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-handler\4.1.97.Final\netty-handler-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-resolver\4.1.97.Final\netty-resolver-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-buffer\4.1.97.Final\netty-buffer-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-unix-common\4.1.97.Final\netty-transport-native-unix-common-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-codec\4.1.97.Final\netty-codec-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport\4.1.97.Final\netty-transport-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-data-jpa\3.1.4\spring-boot-starter-data-jpa-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-aop\3.1.4\spring-boot-starter-aop-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\aspectj\aspectjweaver\1.9.20\aspectjweaver-1.9.20.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-jdbc\3.1.4\spring-boot-starter-jdbc-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\zaxxer\HikariCP\5.0.1\HikariCP-5.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-jdbc\6.0.12\spring-jdbc-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\hibernate\orm\hibernate-core\6.2.9.Final\hibernate-core-6.2.9.Final.jar;C:\work\apache-maven-3.8.8\repo\jakarta\persistence\jakarta.persistence-api\3.1.0\jakarta.persistence-api-3.1.0.jar;C:\work\apache-maven-3.8.8\repo\jakarta\transaction\jakarta.transaction-api\2.0.1\jakarta.transaction-api-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\jboss\logging\jboss-logging\3.5.3.Final\jboss-logging-3.5.3.Final.jar;C:\work\apache-maven-3.8.8\repo\org\hibernate\common\hibernate-commons-annotations\6.0.6.Final\hibernate-commons-annotations-6.0.6.Final.jar;C:\work\apache-maven-3.8.8\repo\io\smallrye\jandex\3.0.5\jandex-3.0.5.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\classmate\1.5.1\classmate-1.5.1.jar;C:\work\apache-maven-3.8.8\repo\net\bytebuddy\byte-buddy\1.14.8\byte-buddy-1.14.8.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\jaxb-runtime\4.0.3\jaxb-runtime-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\jaxb-core\4.0.3\jaxb-core-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\eclipse\angus\angus-activation\2.0.1\angus-activation-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\glassfish\jaxb\txw2\4.0.3\txw2-4.0.3.jar;C:\work\apache-maven-3.8.8\repo\com\sun\istack\istack-commons-runtime\4.1.2\istack-commons-runtime-4.1.2.jar;C:\work\apache-maven-3.8.8\repo\jakarta\inject\jakarta.inject-api\2.0.1\jakarta.inject-api-2.0.1.jar;C:\work\apache-maven-3.8.8\repo\org\antlr\antlr4-runtime\4.10.1\antlr4-runtime-4.10.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-jpa\3.1.4\spring-data-jpa-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\data\spring-data-commons\3.1.4\spring-data-commons-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-orm\6.0.12\spring-orm-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-aspects\6.0.12\spring-aspects-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\postgresql\postgresql\42.6.0\postgresql-42.6.0.jar;C:\work\apache-maven-3.8.8\repo\org\checkerframework\checker-qual\3.31.0\checker-qual-3.31.0.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\kafka\spring-kafka\3.0.11\spring-kafka-3.0.11.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-context\6.0.12\spring-context-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-expression\6.0.12\spring-expression-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-messaging\6.0.12\spring-messaging-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-tx\6.0.12\spring-tx-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\retry\spring-retry\2.0.3\spring-retry-2.0.3.jar;C:\work\apache-maven-3.8.8\repo\io\micrometer\micrometer-observation\1.11.4\micrometer-observation-1.11.4.jar;C:\work\apache-maven-3.8.8\repo\io\micrometer\micrometer-commons\1.11.4\micrometer-commons-1.11.4.jar;C:\work\apache-maven-3.8.8\repo\com\google\code\findbugs\jsr305\3.0.2\jsr305-3.0.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\com\github\luben\zstd-jni\1.5.2-1\zstd-jni-1.5.2-1.jar;C:\work\apache-maven-3.8.8\repo\org\lz4\lz4-java\1.8.0\lz4-java-1.8.0.jar;C:\work\apache-maven-3.8.8\repo\org\xerial\snappy\snappy-java\1.1.8.4\snappy-java-1.1.8.4.jar;C:\work\apache-maven-3.8.8\repo\org\slf4j\slf4j-api\2.0.9\slf4j-api-2.0.9.jar;C:\work\apache-maven-3.8.8\repo\com\h2database\h2\1.4.200\h2-1.4.200.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-starter-test\3.1.4\spring-boot-starter-test-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-test\3.1.4\spring-boot-test-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\boot\spring-boot-test-autoconfigure\3.1.4\spring-boot-test-autoconfigure-3.1.4.jar;C:\work\apache-maven-3.8.8\repo\com\jayway\jsonpath\json-path\2.8.0\json-path-2.8.0.jar;C:\work\apache-maven-3.8.8\repo\jakarta\xml\bind\jakarta.xml.bind-api\4.0.1\jakarta.xml.bind-api-4.0.1.jar;C:\work\apache-maven-3.8.8\repo\jakarta\activation\jakarta.activation-api\2.1.2\jakarta.activation-api-2.1.2.jar;C:\work\apache-maven-3.8.8\repo\net\minidev\json-smart\2.4.11\json-smart-2.4.11.jar;C:\work\apache-maven-3.8.8\repo\net\minidev\accessors-smart\2.4.11\accessors-smart-2.4.11.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm\9.3\asm-9.3.jar;C:\work\apache-maven-3.8.8\repo\org\assertj\assertj-core\3.24.2\assertj-core-3.24.2.jar;C:\work\apache-maven-3.8.8\repo\org\hamcrest\hamcrest\2.2\hamcrest-2.2.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter\5.9.3\junit-jupiter-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-params\5.9.3\junit-jupiter-params-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-engine\5.9.3\junit-jupiter-engine-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\mockito\mockito-core\5.3.1\mockito-core-5.3.1.jar;C:\work\apache-maven-3.8.8\repo\net\bytebuddy\byte-buddy-agent\1.14.8\byte-buddy-agent-1.14.8.jar;C:\work\apache-maven-3.8.8\repo\org\objenesis\objenesis\3.3\objenesis-3.3.jar;C:\work\apache-maven-3.8.8\repo\org\mockito\mockito-junit-jupiter\5.3.1\mockito-junit-jupiter-5.3.1.jar;C:\work\apache-maven-3.8.8\repo\org\skyscreamer\jsonassert\1.5.1\jsonassert-1.5.1.jar;C:\work\apache-maven-3.8.8\repo\com\vaadin\external\google\android-json\0.0.20131108.vaadin1\android-json-0.0.20131108.vaadin1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-core\6.0.12\spring-core-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-jcl\6.0.12\spring-jcl-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\spring-test\6.0.12\spring-test-6.0.12.jar;C:\work\apache-maven-3.8.8\repo\org\xmlunit\xmlunit-core\2.9.1\xmlunit-core-2.9.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy\4.0.15\groovy-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-ant\4.0.15\groovy-ant-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant\1.10.14\ant-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-junit\1.10.14\ant-junit-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-launcher\1.10.14\ant-launcher-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ant\ant-antlr\1.10.14\ant-antlr-1.10.14.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-cli-picocli\4.0.15\groovy-cli-picocli-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\info\picocli\picocli\4.7.5\picocli-4.7.5.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-console\4.0.15\groovy-console-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\github\javaparser\javaparser-core\3.25.5\javaparser-core-3.25.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-util\9.5\asm-util-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-tree\9.5\asm-tree-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\ow2\asm\asm-analysis\9.5\asm-analysis-9.5.jar;C:\work\apache-maven-3.8.8\repo\org\abego\treelayout\org.abego.treelayout.core\1.0.3\org.abego.treelayout.core-1.0.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\ivy\ivy\2.5.2\ivy-2.5.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-datetime\4.0.15\groovy-datetime-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-docgenerator\4.0.15\groovy-docgenerator-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\thoughtworks\qdox\qdox\1.12.1\qdox-1.12.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-groovydoc\4.0.15\groovy-groovydoc-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-groovysh\4.0.15\groovy-groovysh-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\jline\jline\2.14.6\jline-2.14.6.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-jmx\4.0.15\groovy-jmx-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-json\4.0.15\groovy-json-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-jsr223\4.0.15\groovy-jsr223-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-macro\4.0.15\groovy-macro-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-nio\4.0.15\groovy-nio-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-servlet\4.0.15\groovy-servlet-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-sql\4.0.15\groovy-sql-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-swing\4.0.15\groovy-swing-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-templates\4.0.15\groovy-templates-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-test\4.0.15\groovy-test-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\junit\junit\4.13.2\junit-4.13.2.jar;C:\work\apache-maven-3.8.8\repo\org\hamcrest\hamcrest-core\2.2\hamcrest-core-2.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-test-junit5\4.0.15\groovy-test-junit5-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-xml\4.0.15\groovy-xml-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\org\apache\groovy\groovy-yaml\4.0.15\groovy-yaml-4.0.15.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\dataformat\jackson-dataformat-yaml\2.15.2\jackson-dataformat-yaml-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\org\spockframework\spock-core\2.4-M1-groovy-4.0\spock-core-2.4-M1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-engine\1.9.3\junit-platform-engine-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\opentest4j\opentest4j\1.2.0\opentest4j-1.2.0.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-commons\1.9.3\junit-platform-commons-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\apiguardian\apiguardian-api\1.1.2\apiguardian-api-1.1.2.jar;C:\work\apache-maven-3.8.8\repo\org\spockframework\spock-spring\2.4-M1-groovy-4.0\spock-spring-2.4-M1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\com\athaydes\spock-reports\2.5.1-groovy-4.0\spock-reports-2.5.1-groovy-4.0.jar;C:\work\apache-maven-3.8.8\repo\com\github\codemonstur\embedded-redis\1.4.2\embedded-redis-1.4.2.jar;C:\work\apache-maven-3.8.8\repo\redis\clients\jedis\4.3.2\jedis-4.3.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\commons\commons-pool2\2.11.1\commons-pool2-2.11.1.jar;C:\work\apache-maven-3.8.8\repo\org\json\json\20220320\json-20220320.jar;C:\work\apache-maven-3.8.8\repo\com\google\code\gson\gson\2.10.1\gson-2.10.1.jar;C:\work\apache-maven-3.8.8\repo\org\springframework\kafka\spring-kafka-test\3.0.11\spring-kafka-test-3.0.11.jar;C:\work\apache-maven-3.8.8\repo\org\apache\zookeeper\zookeeper\3.6.3\zookeeper-3.6.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\zookeeper\zookeeper-jute\3.6.3\zookeeper-jute-3.6.3.jar;C:\work\apache-maven-3.8.8\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-native-epoll\4.1.97.Final\netty-transport-native-epoll-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\io\netty\netty-transport-classes-epoll\4.1.97.Final\netty-transport-classes-epoll-4.1.97.Final.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-clients\3.4.1\kafka-clients-3.4.1-test.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-metadata\3.4.1\kafka-metadata-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-server-common\3.4.1\kafka-server-common-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-raft\3.4.1\kafka-raft-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-streams-test-utils\3.4.1\kafka-streams-test-utils-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-streams\3.4.1\kafka-streams-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\rocksdb\rocksdbjni\7.1.2\rocksdbjni-7.1.2.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\scala-library\2.13.10\scala-library-2.13.10.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-group-coordinator\3.4.1\kafka-group-coordinator-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-storage\3.4.1\kafka-storage-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka-storage-api\3.4.1\kafka-storage-api-3.4.1.jar;C:\work\apache-maven-3.8.8\repo\net\sourceforge\argparse4j\argparse4j\0.7.0\argparse4j-0.7.0.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\module\jackson-module-scala_2.13\2.15.2\jackson-module-scala_2.13-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\com\thoughtworks\paranamer\paranamer\2.8\paranamer-2.8.jar;C:\work\apache-maven-3.8.8\repo\com\fasterxml\jackson\dataformat\jackson-dataformat-csv\2.15.2\jackson-dataformat-csv-2.15.2.jar;C:\work\apache-maven-3.8.8\repo\net\sf\jopt-simple\jopt-simple\5.0.4\jopt-simple-5.0.4.jar;C:\work\apache-maven-3.8.8\repo\org\bitbucket\b_c\jose4j\0.9.3\jose4j-0.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\modules\scala-collection-compat_2.13\2.10.0\scala-collection-compat_2.13-2.10.0.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\modules\scala-java8-compat_2.13\1.0.2\scala-java8-compat_2.13-1.0.2.jar;C:\work\apache-maven-3.8.8\repo\org\scala-lang\scala-reflect\2.13.10\scala-reflect-2.13.10.jar;C:\work\apache-maven-3.8.8\repo\com\typesafe\scala-logging\scala-logging_2.13\3.9.4\scala-logging_2.13-3.9.4.jar;C:\work\apache-maven-3.8.8\repo\io\dropwizard\metrics\metrics-core\4.2.19\metrics-core-4.2.19.jar;C:\work\apache-maven-3.8.8\repo\commons-cli\commons-cli\1.4\commons-cli-1.4.jar;C:\work\apache-maven-3.8.8\repo\org\apache\kafka\kafka_2.13\3.4.1\kafka_2.13-3.4.1-test.jar;C:\work\apache-maven-3.8.8\repo\org\junit\jupiter\junit-jupiter-api\5.9.3\junit-jupiter-api-5.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\junit\platform\junit-platform-launcher\1.9.3\junit-platform-launcher-1.9.3.jar;C:\work\apache-maven-3.8.8\repo\org\awaitility\awaitility\4.2.0\awaitility-4.2.0.jar;
2025-01-04 00:12:41.885 Client environment:java.library.path=C:\work\jdk-17\bin;C:\windows\Sun\Java\bin;C:\windows\system32;C:\windows;C:\work\python312\Scripts\;C:\work\python312\;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program\Git\cmd;C:\Program\PowerShell\7\;C:\Program Files\dotnet\;;C:\Program Files\Docker\Docker\resources\bin;C:\Users\joech\AppData\Local\Microsoft\WindowsApps;C:\Users\joech\AppData\Local\GitHubDesktop\bin;C:\Program\Microsoft VS Code\bin;C:\work\apache-maven-3.8.8\bin;C:\Program Files\Tesseract-OCR;C:\work\jdk-17\bin;;.
2025-01-04 00:12:41.885 Client environment:java.io.tmpdir=C:\Users\joech\AppData\Local\Temp\
2025-01-04 00:12:41.885 Client environment:java.compiler=<NA>
2025-01-04 00:12:41.885 Client environment:os.name=Windows 11
2025-01-04 00:12:41.885 Client environment:os.arch=amd64
2025-01-04 00:12:41.885 Client environment:os.version=10.0
2025-01-04 00:12:41.885 Client environment:user.name=joech
2025-01-04 00:12:41.885 Client environment:user.home=C:\Users\joech
2025-01-04 00:12:41.885 Client environment:user.dir=C:\code\hsbc\demo\pong
2025-01-04 00:12:41.885 Client environment:os.memory.free=88MB
2025-01-04 00:12:41.885 Client environment:os.memory.max=15816MB
2025-01-04 00:12:41.885 Client environment:os.memory.total=160MB
2025-01-04 00:12:41.891 Initiating client connection, connectString=127.0.0.1:51182 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@14d3bee8
2025-01-04 00:12:41.898 jute.maxbuffer value is 4194304 Bytes
2025-01-04 00:12:41.905 zookeeper.request.timeout value is 0. feature enabled=false
2025-01-04 00:12:41.907 [ZooKeeperClient Kafka server] Waiting until connected.
2025-01-04 00:12:41.907 Opening socket connection to server /127.0.0.1:51182.
2025-01-04 00:12:41.909 Socket connection established, initiating session, client: /127.0.0.1:51184, server: /127.0.0.1:51182
2025-01-04 00:12:41.919 Creating new log file: log.1
2025-01-04 00:12:41.928 ZooKeeper audit is disabled.
2025-01-04 00:12:41.932 Session establishment complete on server /127.0.0.1:51182, session id = 0x1000a9d425f0000, negotiated timeout = 16000
2025-01-04 00:12:41.936 [ZooKeeperClient Kafka server] Connected.
2025-01-04 00:12:42.367 Cluster ID = QpV6DlF0Qye3mXfS5eVBNg
2025-01-04 00:12:42.370 No meta.properties file under dir C:\Users\joech\AppData\Local\Temp\spring.kafka.0894f3ab-bdbd-4f53-bba2-9187f81f1b2315892691390016550463\meta.properties
2025-01-04 00:12:42.422 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.0894f3ab-bdbd-4f53-bba2-9187f81f1b2315892691390016550463
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:51182
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2025-01-04 00:12:42.460 [ThrottledChannelReaper-Fetch]: Starting
2025-01-04 00:12:42.461 [ThrottledChannelReaper-Produce]: Starting
2025-01-04 00:12:42.463 [ThrottledChannelReaper-Request]: Starting
2025-01-04 00:12:42.467 [ThrottledChannelReaper-ControllerMutation]: Starting
2025-01-04 00:12:42.499 Loading logs from log dirs ArraySeq(C:\Users\joech\AppData\Local\Temp\spring.kafka.0894f3ab-bdbd-4f53-bba2-9187f81f1b2315892691390016550463)
2025-01-04 00:12:42.518 Attempting recovery for all logs in C:\Users\joech\AppData\Local\Temp\spring.kafka.0894f3ab-bdbd-4f53-bba2-9187f81f1b2315892691390016550463 since no clean shutdown file was found
2025-01-04 00:12:42.531 Loaded 0 logs in 31ms.
2025-01-04 00:12:42.531 Starting log cleanup with a period of 300000 ms.
2025-01-04 00:12:42.534 Starting log flusher with a default period of 9223372036854775807 ms.
2025-01-04 00:12:42.549 Starting the log cleaner
2025-01-04 00:12:42.560 [kafka-log-cleaner-thread-0]: Starting
2025-01-04 00:12:42.575 [feature-zk-node-event-process-thread]: Starting
2025-01-04 00:12:42.587 Feature ZK node at path: /feature does not exist
2025-01-04 00:12:42.615 [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting
2025-01-04 00:12:42.968 Updated connection-accept-rate max connection creation rate to 2147483647
2025-01-04 00:12:42.974 Awaiting socket connections on localhost:51186.
2025-01-04 00:12:43.002 [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT)
2025-01-04 00:12:43.012 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Starting
2025-01-04 00:12:43.027 [ExpirationReaper-0-Produce]: Starting
2025-01-04 00:12:43.028 [ExpirationReaper-0-Fetch]: Starting
2025-01-04 00:12:43.028 [ExpirationReaper-0-DeleteRecords]: Starting
2025-01-04 00:12:43.030 [ExpirationReaper-0-ElectLeader]: Starting
2025-01-04 00:12:43.044 [LogDirFailureHandler]: Starting
2025-01-04 00:12:43.064 Creating /brokers/ids/0 (is it secure? false)
2025-01-04 00:12:43.081 Stat of the created znode at /brokers/ids/0 is: 25,25,1735920763075,1735920763075,1,0,0,72069264577593344,204,0,25

2025-01-04 00:12:43.081 Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:51186, czxid (broker epoch): 25
2025-01-04 00:12:43.131 [ControllerEventThread controllerId=0] Starting
2025-01-04 00:12:43.135 [ExpirationReaper-0-topic]: Starting
2025-01-04 00:12:43.146 [ExpirationReaper-0-Heartbeat]: Starting
2025-01-04 00:12:43.146 [ExpirationReaper-0-Rebalance]: Starting
2025-01-04 00:12:43.158 Successfully created /controller_epoch with initial epoch 0
2025-01-04 00:12:43.167 [Controller id=0] 0 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1
2025-01-04 00:12:43.173 [Controller id=0] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map())
2025-01-04 00:12:43.173 [GroupCoordinator 0]: Starting up.
2025-01-04 00:12:43.176 Feature ZK node created at path: /feature
2025-01-04 00:12:43.180 [GroupCoordinator 0]: Startup complete.
2025-01-04 00:12:43.202 [TransactionCoordinator id=0] Starting up.
2025-01-04 00:12:43.206 [Transaction Marker Channel Manager 0]: Starting
2025-01-04 00:12:43.206 [TransactionCoordinator id=0] Startup complete.
2025-01-04 00:12:43.224 [Controller id=0] Registering handlers
2025-01-04 00:12:43.224 [MetadataCache brokerId=0] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0).
2025-01-04 00:12:43.228 [Controller id=0] Deleting log dir event notifications
2025-01-04 00:12:43.230 [Controller id=0] Deleting isr change notifications
2025-01-04 00:12:43.233 [Controller id=0] Initializing controller context
2025-01-04 00:12:43.250 [ExpirationReaper-0-AlterAcls]: Starting
2025-01-04 00:12:43.254 [Controller id=0] Initialized broker epochs cache: HashMap(0 -> 25)
2025-01-04 00:12:43.297 [RequestSendThread controllerId=0] Starting
2025-01-04 00:12:43.299 [Controller id=0] Currently active brokers in the cluster: Set(0)
2025-01-04 00:12:43.301 [Controller id=0] Currently shutting brokers in the cluster: HashSet()
2025-01-04 00:12:43.301 [Controller id=0] Current list of topics in the cluster: HashSet()
2025-01-04 00:12:43.301 [Controller id=0] Fetching topic deletions in progress
2025-01-04 00:12:43.303 [/config/changes-event-process-thread]: Starting
2025-01-04 00:12:43.307 [Controller id=0] List of topics to be deleted: 
2025-01-04 00:12:43.308 [Controller id=0] List of topics ineligible for deletion: 
2025-01-04 00:12:43.309 [Controller id=0] Initializing topic deletion manager
2025-01-04 00:12:43.310 [Topic Deletion Manager 0] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet()
2025-01-04 00:12:43.314 [Controller id=0] Sending update metadata request
2025-01-04 00:12:43.317 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions
2025-01-04 00:12:43.318 [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing.
2025-01-04 00:12:43.323 Kafka version: 3.4.1
2025-01-04 00:12:43.323 Kafka commitId: 8a516edc2755df89
2025-01-04 00:12:43.323 Kafka startTimeMs: 1735920763320
2025-01-04 00:12:43.324 [ReplicaStateMachine controllerId=0] Initializing replica state
2025-01-04 00:12:43.324 [KafkaServer id=0] started
2025-01-04 00:12:43.325 [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2025-01-04 00:12:43.332 [ReplicaStateMachine controllerId=0] Triggering offline replica state changes
2025-01-04 00:12:43.333 AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [127.0.0.1:51186]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-01-04 00:12:43.333 [PartitionStateMachine controllerId=0] Initializing partition state
2025-01-04 00:12:43.333 [RequestSendThread controllerId=0] Controller 0 connected to localhost:51186 (id: 0 rack: null) for sending state change requests
2025-01-04 00:12:43.334 [PartitionStateMachine controllerId=0] Triggering online partition state changes
2025-01-04 00:12:43.340 [Controller id=0] Ready to serve as the new controller with epoch 1
2025-01-04 00:12:43.346 [Controller id=0] Partitions undergoing preferred replica election: 
2025-01-04 00:12:43.346 [Controller id=0] Partitions that completed preferred replica election: 
2025-01-04 00:12:43.348 [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2025-01-04 00:12:43.348 [Controller id=0] Resuming preferred replica election for partitions: 
2025-01-04 00:12:43.349 [Controller id=0] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered
2025-01-04 00:12:43.364 [Controller id=0] Starting the controller scheduler
2025-01-04 00:12:43.374 Kafka version: 3.4.1
2025-01-04 00:12:43.374 Kafka commitId: 8a516edc2755df89
2025-01-04 00:12:43.375 Kafka startTimeMs: 1735920763374
2025-01-04 00:12:43.439 [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use node localhost:51186 (id: 0 rack: null)
2025-01-04 00:12:43.439 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Recorded new controller, from now on will use node localhost:51186 (id: 0 rack: null)
2025-01-04 00:12:43.465 Creating topic pong-message-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0))
2025-01-04 00:12:43.479 [Controller id=0] New topics: [Set(pong-message-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(pong-message-topic,Some(3J0lYNQ6Sf-FuzAIfVnz8g),Map(pong-message-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), pong-message-topic-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-01-04 00:12:43.481 [Controller id=0] New partition creation callback for pong-message-topic-0,pong-message-topic-1
2025-01-04 00:12:43.483 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-04 00:12:43.483 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-04 00:12:43.483 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:12:43.485 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:12:43.501 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-04 00:12:43.501 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-04 00:12:43.502 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2025-01-04 00:12:43.504 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2025-01-04 00:12:43.505 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:12:43.508 [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 for 2 partitions
2025-01-04 00:12:43.534 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(pong-message-topic-0, pong-message-topic-1)
2025-01-04 00:12:43.535 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2025-01-04 00:12:43.594 [LogLoader partition=pong-message-topic-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.0894f3ab-bdbd-4f53-bba2-9187f81f1b2315892691390016550463] Loading producer state till offset 0 with message format version 2
2025-01-04 00:12:43.607 Created log for partition pong-message-topic-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.0894f3ab-bdbd-4f53-bba2-9187f81f1b2315892691390016550463\pong-message-topic-0 with properties {}
2025-01-04 00:12:43.608 [Partition pong-message-topic-0 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-0
2025-01-04 00:12:43.608 [Partition pong-message-topic-0 broker=0] Log loaded for partition pong-message-topic-0 with initial high watermark 0
2025-01-04 00:12:43.609 [Broker id=0] Leader pong-message-topic-0 with topic id Some(3J0lYNQ6Sf-FuzAIfVnz8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2025-01-04 00:12:43.624 [LogLoader partition=pong-message-topic-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.0894f3ab-bdbd-4f53-bba2-9187f81f1b2315892691390016550463] Loading producer state till offset 0 with message format version 2
2025-01-04 00:12:43.626 Created log for partition pong-message-topic-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.0894f3ab-bdbd-4f53-bba2-9187f81f1b2315892691390016550463\pong-message-topic-1 with properties {}
2025-01-04 00:12:43.626 [Partition pong-message-topic-1 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-1
2025-01-04 00:12:43.626 [Partition pong-message-topic-1 broker=0] Log loaded for partition pong-message-topic-1 with initial high watermark 0
2025-01-04 00:12:43.626 [Broker id=0] Leader pong-message-topic-1 with topic id Some(3J0lYNQ6Sf-FuzAIfVnz8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2025-01-04 00:12:43.633 [Broker id=0] Finished LeaderAndIsr request in 126ms correlationId 1 from controller 0 for 2 partitions
2025-01-04 00:12:43.639 [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2
2025-01-04 00:12:43.644 App info kafka.admin.client for adminclient-1 unregistered
2025-01-04 00:12:43.647 Metrics scheduler closed
2025-01-04 00:12:43.647 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-04 00:12:43.647 Metrics reporters closed
2025-01-04 00:12:43.903 

Found multiple occurrences of org.json.JSONObject on the class path:

	jar:file:/C:/work/apache-maven-3.8.8/repo/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar!/org/json/JSONObject.class
	jar:file:/C:/work/apache-maven-3.8.8/repo/org/json/json/20220320/json-20220320.jar!/org/json/JSONObject.class

You may wish to exclude one of them to ensure predictable runtime behavior

2025-01-04 00:12:43.924 Starting KafkaSpec using Java 17.0.12 with PID 10572 (started by joech in C:\code\hsbc\demo\pong)
2025-01-04 00:12:43.925 No active profile set, falling back to 1 default profile: "default"
2025-01-04 00:12:44.639 Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-04 00:12:44.639 Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-04 00:12:44.776 Finished Spring Data repository scanning in 128 ms. Found 1 JPA repository interfaces.
2025-01-04 00:12:44.796 Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-04 00:12:44.797 Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-04 00:12:44.812 Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.demo.dao.MessageRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-04 00:12:44.813 Finished Spring Data repository scanning in 5 ms. Found 0 Redis repository interfaces.
2025-01-04 00:12:45.352 HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-04 00:12:45.443 HHH000412: Hibernate ORM core version 6.2.9.Final
2025-01-04 00:12:45.446 HHH000406: Using bytecode reflection optimizer
2025-01-04 00:12:45.645 HHH000021: Bytecode provider name : bytebuddy
2025-01-04 00:12:45.791 No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-04 00:12:45.811 HikariPool-1 - Starting...
2025-01-04 00:12:46.156 HikariPool-1 - Added connection conn0: url=jdbc:h2:mem:testdb user=SA
2025-01-04 00:12:46.158 HikariPool-1 - Start completed.
2025-01-04 00:12:46.472 HHH000021: Bytecode provider name : bytebuddy
2025-01-04 00:12:47.285 HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2025-01-04 00:12:47.377 Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-04 00:12:48.379 [Controller id=0] Processing automatic preferred replica leader election
2025-01-04 00:12:48.825 ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:51186]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-pong-service-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = pong-service
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-04 00:12:48.868 These configurations '[spring.json.trusted.packages]' were supplied but are not used yet.
2025-01-04 00:12:48.868 Kafka version: 3.4.1
2025-01-04 00:12:48.868 Kafka commitId: 8a516edc2755df89
2025-01-04 00:12:48.868 Kafka startTimeMs: 1735920768868
2025-01-04 00:12:48.870 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Subscribed to topic(s): pong-message-topic
2025-01-04 00:12:48.883 Started KafkaSpec in 5.206 seconds (process running for 11.605)
2025-01-04 00:12:48.896 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting the last seen epoch of partition pong-message-topic-0 to 0 since the associated topicId changed from null to 3J0lYNQ6Sf-FuzAIfVnz8g
2025-01-04 00:12:48.896 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting the last seen epoch of partition pong-message-topic-1 to 0 since the associated topicId changed from null to 3J0lYNQ6Sf-FuzAIfVnz8g
2025-01-04 00:12:48.900 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Cluster ID: QpV6DlF0Qye3mXfS5eVBNg
2025-01-04 00:12:48.901 Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0))
2025-01-04 00:12:48.908 [Controller id=0] New topics: [Set(__consumer_offsets)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(__consumer_offsets,Some(833ovcegTxm5R2WUUZZA3A),HashMap(__consumer_offsets-4 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-3 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-2 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-01-04 00:12:48.908 [Controller id=0] New partition creation callback for __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2025-01-04 00:12:48.908 [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-04 00:12:48.908 [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-04 00:12:48.908 [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-04 00:12:48.908 [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-04 00:12:48.908 [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-04 00:12:48.908 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:12:48.909 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:12:48.916 [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-04 00:12:48.916 [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-04 00:12:48.916 [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-04 00:12:48.916 [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-04 00:12:48.916 [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-04 00:12:48.917 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 5 become-leader and 0 become-follower partitions
2025-01-04 00:12:48.917 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 5 partitions
2025-01-04 00:12:48.917 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:12:48.917 [Broker id=0] Handling LeaderAndIsr request correlationId 3 from controller 0 for 5 partitions
2025-01-04 00:12:48.920 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-4, __consumer_offsets-3, __consumer_offsets-2, __consumer_offsets-0, __consumer_offsets-1)
2025-01-04 00:12:48.920 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 3 from controller 0 epoch 1 as part of the become-leader transition for 5 partitions
2025-01-04 00:12:48.928 [LogLoader partition=__consumer_offsets-3, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.0894f3ab-bdbd-4f53-bba2-9187f81f1b2315892691390016550463] Loading producer state till offset 0 with message format version 2
2025-01-04 00:12:48.929 Created log for partition __consumer_offsets-3 in C:\Users\joech\AppData\Local\Temp\spring.kafka.0894f3ab-bdbd-4f53-bba2-9187f81f1b2315892691390016550463\__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-01-04 00:12:48.931 [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
2025-01-04 00:12:48.931 [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0
2025-01-04 00:12:48.931 [Broker id=0] Leader __consumer_offsets-3 with topic id Some(833ovcegTxm5R2WUUZZA3A) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2025-01-04 00:12:48.939 [LogLoader partition=__consumer_offsets-2, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.0894f3ab-bdbd-4f53-bba2-9187f81f1b2315892691390016550463] Loading producer state till offset 0 with message format version 2
2025-01-04 00:12:48.940 Created log for partition __consumer_offsets-2 in C:\Users\joech\AppData\Local\Temp\spring.kafka.0894f3ab-bdbd-4f53-bba2-9187f81f1b2315892691390016550463\__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-01-04 00:12:48.941 [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
2025-01-04 00:12:48.941 [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0
2025-01-04 00:12:48.941 [Broker id=0] Leader __consumer_offsets-2 with topic id Some(833ovcegTxm5R2WUUZZA3A) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2025-01-04 00:12:48.948 [LogLoader partition=__consumer_offsets-4, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.0894f3ab-bdbd-4f53-bba2-9187f81f1b2315892691390016550463] Loading producer state till offset 0 with message format version 2
2025-01-04 00:12:48.950 Created log for partition __consumer_offsets-4 in C:\Users\joech\AppData\Local\Temp\spring.kafka.0894f3ab-bdbd-4f53-bba2-9187f81f1b2315892691390016550463\__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-01-04 00:12:48.951 [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
2025-01-04 00:12:48.951 [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0
2025-01-04 00:12:48.951 [Broker id=0] Leader __consumer_offsets-4 with topic id Some(833ovcegTxm5R2WUUZZA3A) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2025-01-04 00:12:48.958 [LogLoader partition=__consumer_offsets-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.0894f3ab-bdbd-4f53-bba2-9187f81f1b2315892691390016550463] Loading producer state till offset 0 with message format version 2
2025-01-04 00:12:48.959 Created log for partition __consumer_offsets-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.0894f3ab-bdbd-4f53-bba2-9187f81f1b2315892691390016550463\__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-01-04 00:12:48.959 [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
2025-01-04 00:12:48.959 [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0
2025-01-04 00:12:48.959 [Broker id=0] Leader __consumer_offsets-1 with topic id Some(833ovcegTxm5R2WUUZZA3A) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2025-01-04 00:12:48.967 [LogLoader partition=__consumer_offsets-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.0894f3ab-bdbd-4f53-bba2-9187f81f1b2315892691390016550463] Loading producer state till offset 0 with message format version 2
2025-01-04 00:12:48.969 Created log for partition __consumer_offsets-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.0894f3ab-bdbd-4f53-bba2-9187f81f1b2315892691390016550463\__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-01-04 00:12:48.969 [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
2025-01-04 00:12:48.969 [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0
2025-01-04 00:12:48.969 [Broker id=0] Leader __consumer_offsets-0 with topic id Some(833ovcegTxm5R2WUUZZA3A) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2025-01-04 00:12:48.972 [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 0
2025-01-04 00:12:48.973 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0
2025-01-04 00:12:48.974 [GroupCoordinator 0]: Elected as the group coordinator for partition 2 in epoch 0
2025-01-04 00:12:48.974 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0
2025-01-04 00:12:48.975 [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 0
2025-01-04 00:12:48.975 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0
2025-01-04 00:12:48.975 [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 0
2025-01-04 00:12:48.975 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0
2025-01-04 00:12:48.975 [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 0
2025-01-04 00:12:48.975 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0
2025-01-04 00:12:48.975 [Broker id=0] Finished LeaderAndIsr request in 58ms correlationId 3 from controller 0 for 5 partitions
2025-01-04 00:12:48.976 [Broker id=0] Add 5 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 4
2025-01-04 00:12:48.978 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 4 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler.
2025-01-04 00:12:48.978 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 3 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler.
2025-01-04 00:12:48.978 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 3 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler.
2025-01-04 00:12:48.979 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 3 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler.
2025-01-04 00:12:48.979 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler.
2025-01-04 00:12:49.007 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Discovered group coordinator localhost:51186 (id: 2147483647 rack: null)
2025-01-04 00:12:49.009 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] (Re-)joining group
2025-01-04 00:12:49.025 [GroupCoordinator 0]: Dynamic member with unknown member id joins group pong-service in Empty state. Created a new member id consumer-pong-service-1-12de9859-5e05-4753-b4b4-41501be2c20b and request the member to rejoin with this id.
2025-01-04 00:12:49.029 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: need to re-join with the given member-id: consumer-pong-service-1-12de9859-5e05-4753-b4b4-41501be2c20b
2025-01-04 00:12:49.029 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2025-01-04 00:12:49.029 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] (Re-)joining group
2025-01-04 00:12:49.035 [GroupCoordinator 0]: Preparing to rebalance group pong-service in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-pong-service-1-12de9859-5e05-4753-b4b4-41501be2c20b with group instance id None; client reason: rebalance failed due to MemberIdRequiredException)
2025-01-04 00:12:49.039 [GroupCoordinator 0]: Stabilized group pong-service generation 1 (__consumer_offsets-2) with 1 members
2025-01-04 00:12:49.041 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Successfully joined group with generation Generation{generationId=1, memberId='consumer-pong-service-1-12de9859-5e05-4753-b4b4-41501be2c20b', protocol='range'}
2025-01-04 00:12:49.043 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Finished assignment for group at generation 1: {consumer-pong-service-1-12de9859-5e05-4753-b4b4-41501be2c20b=Assignment(partitions=[pong-message-topic-0, pong-message-topic-1])}
2025-01-04 00:12:49.050 [GroupCoordinator 0]: Assignment received from leader consumer-pong-service-1-12de9859-5e05-4753-b4b4-41501be2c20b for group pong-service for generation 1. The group has 1 members, 0 of which are static.
2025-01-04 00:12:49.099 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Successfully synced group in generation Generation{generationId=1, memberId='consumer-pong-service-1-12de9859-5e05-4753-b4b4-41501be2c20b', protocol='range'}
2025-01-04 00:12:49.100 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Notifying assignor about the new Assignment(partitions=[pong-message-topic-0, pong-message-topic-1])
2025-01-04 00:12:49.102 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Adding newly assigned partitions: pong-message-topic-0, pong-message-topic-1
2025-01-04 00:12:49.113 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-0
2025-01-04 00:12:49.113 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-1
2025-01-04 00:12:49.116 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-0
2025-01-04 00:12:49.116 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Found no committed offset for partition pong-message-topic-1
2025-01-04 00:12:49.127 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting offset for partition pong-message-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:51186 (id: 0 rack: null)], epoch=0}}.
2025-01-04 00:12:49.131 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting offset for partition pong-message-topic-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:51186 (id: 0 rack: null)], epoch=0}}.
2025-01-04 00:12:49.148 pong-service: partitions assigned: [pong-message-topic-0, pong-message-topic-1]
2025-01-04 00:12:49.471 Idempotence will be disabled because acks is set to 0, not set to 'all'.
2025-01-04 00:12:49.471 ProducerConfig values: 
	acks = 0
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:51186]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2025-01-04 00:12:49.496 Kafka version: 3.4.1
2025-01-04 00:12:49.497 Kafka commitId: 8a516edc2755df89
2025-01-04 00:12:49.497 Kafka startTimeMs: 1735920769496
2025-01-04 00:12:49.501 [Producer clientId=producer-1] Resetting the last seen epoch of partition pong-message-topic-0 to 0 since the associated topicId changed from null to 3J0lYNQ6Sf-FuzAIfVnz8g
2025-01-04 00:12:49.501 [Producer clientId=producer-1] Resetting the last seen epoch of partition pong-message-topic-1 to 0 since the associated topicId changed from null to 3J0lYNQ6Sf-FuzAIfVnz8g
2025-01-04 00:12:49.501 [Producer clientId=producer-1] Cluster ID: QpV6DlF0Qye3mXfS5eVBNg
2025-01-04 00:12:49.669 [KafkaServer id=0] shutting down
2025-01-04 00:12:49.670 [KafkaServer id=0] Starting controlled shutdown
2025-01-04 00:12:49.674 [Controller id=0] Shutting down broker 0
2025-01-04 00:12:49.677 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:12:49.679 [KafkaServer id=0] Controlled shutdown request returned successfully after 6ms
2025-01-04 00:12:49.681 [/config/changes-event-process-thread]: Shutting down
2025-01-04 00:12:49.681 [/config/changes-event-process-thread]: Shutdown completed
2025-01-04 00:12:49.681 [/config/changes-event-process-thread]: Stopped
2025-01-04 00:12:49.681 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
2025-01-04 00:12:49.684 [Producer clientId=producer-1] Node 0 disconnected.
2025-01-04 00:12:49.684 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 2147483647 disconnected.
2025-01-04 00:12:49.685 [Producer clientId=producer-1] Node -1 disconnected.
2025-01-04 00:12:49.685 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 0 disconnected.
2025-01-04 00:12:49.685 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Cancelled in-flight FETCH request with correlation id 15 due to node 0 being disconnected (elapsed time since creation: 135ms, elapsed time since send: 135ms, request timeout: 30000ms)
2025-01-04 00:12:49.685 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Cancelled in-flight METADATA request with correlation id 17 due to node 0 being disconnected (elapsed time since creation: 39ms, elapsed time since send: 39ms, request timeout: 30000ms)
2025-01-04 00:12:49.685 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node -1 disconnected.
2025-01-04 00:12:49.686 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors
2025-01-04 00:12:49.687 [data-plane Kafka Request Handler on Broker 0], shutting down
2025-01-04 00:12:49.691 [data-plane Kafka Request Handler on Broker 0], shut down completely
2025-01-04 00:12:49.685 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Error sending fetch request (sessionId=205216537, epoch=1) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2025-01-04 00:12:49.691 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Group coordinator localhost:51186 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
2025-01-04 00:12:49.691 [ExpirationReaper-0-AlterAcls]: Shutting down
2025-01-04 00:12:49.694 [ExpirationReaper-0-AlterAcls]: Stopped
2025-01-04 00:12:49.694 [ExpirationReaper-0-AlterAcls]: Shutdown completed
2025-01-04 00:12:49.695 [KafkaApi-0] Shutdown complete.
2025-01-04 00:12:49.696 [ExpirationReaper-0-topic]: Shutting down
2025-01-04 00:12:49.696 [ExpirationReaper-0-topic]: Stopped
2025-01-04 00:12:49.696 [ExpirationReaper-0-topic]: Shutdown completed
2025-01-04 00:12:49.696 [TransactionCoordinator id=0] Shutting down.
2025-01-04 00:12:49.696 [Transaction State Manager 0]: Shutdown complete
2025-01-04 00:12:49.696 [Transaction Marker Channel Manager 0]: Shutting down
2025-01-04 00:12:49.698 [Transaction Marker Channel Manager 0]: Stopped
2025-01-04 00:12:49.698 [Transaction Marker Channel Manager 0]: Shutdown completed
2025-01-04 00:12:49.698 [TransactionCoordinator id=0] Shutdown complete.
2025-01-04 00:12:49.698 [GroupCoordinator 0]: Shutting down.
2025-01-04 00:12:49.699 [ExpirationReaper-0-Heartbeat]: Shutting down
2025-01-04 00:12:49.699 [ExpirationReaper-0-Heartbeat]: Shutdown completed
2025-01-04 00:12:49.699 [ExpirationReaper-0-Heartbeat]: Stopped
2025-01-04 00:12:49.699 [ExpirationReaper-0-Rebalance]: Shutting down
2025-01-04 00:12:49.700 [ExpirationReaper-0-Rebalance]: Stopped
2025-01-04 00:12:49.700 [ExpirationReaper-0-Rebalance]: Shutdown completed
2025-01-04 00:12:49.700 [GroupCoordinator 0]: Shutdown complete.
2025-01-04 00:12:49.700 [ReplicaManager broker=0] Shutting down
2025-01-04 00:12:49.701 [LogDirFailureHandler]: Shutting down
2025-01-04 00:12:49.701 [LogDirFailureHandler]: Stopped
2025-01-04 00:12:49.701 [LogDirFailureHandler]: Shutdown completed
2025-01-04 00:12:49.701 [ReplicaFetcherManager on broker 0] shutting down
2025-01-04 00:12:49.701 [ReplicaFetcherManager on broker 0] shutdown completed
2025-01-04 00:12:49.701 [ReplicaAlterLogDirsManager on broker 0] shutting down
2025-01-04 00:12:49.701 [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2025-01-04 00:12:49.701 [ExpirationReaper-0-Fetch]: Shutting down
2025-01-04 00:12:49.703 [ExpirationReaper-0-Fetch]: Shutdown completed
2025-01-04 00:12:49.703 [ExpirationReaper-0-Fetch]: Stopped
2025-01-04 00:12:49.703 [ExpirationReaper-0-Produce]: Shutting down
2025-01-04 00:12:49.703 [ExpirationReaper-0-Produce]: Stopped
2025-01-04 00:12:49.703 [ExpirationReaper-0-Produce]: Shutdown completed
2025-01-04 00:12:49.703 [ExpirationReaper-0-DeleteRecords]: Shutting down
2025-01-04 00:12:49.704 [ExpirationReaper-0-DeleteRecords]: Stopped
2025-01-04 00:12:49.704 [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2025-01-04 00:12:49.704 [ExpirationReaper-0-ElectLeader]: Shutting down
2025-01-04 00:12:49.704 [ExpirationReaper-0-ElectLeader]: Stopped
2025-01-04 00:12:49.704 [ExpirationReaper-0-ElectLeader]: Shutdown completed
2025-01-04 00:12:49.708 [ReplicaManager broker=0] Shut down completely
2025-01-04 00:12:49.708 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutting down
2025-01-04 00:12:49.708 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Stopped
2025-01-04 00:12:49.708 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutdown completed
2025-01-04 00:12:49.709 Broker to controller channel manager for alterPartition shutdown
2025-01-04 00:12:49.709 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down
2025-01-04 00:12:49.709 [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped
2025-01-04 00:12:49.709 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed
2025-01-04 00:12:49.709 Broker to controller channel manager for forwarding shutdown
2025-01-04 00:12:49.709 Shutting down.
2025-01-04 00:12:49.711 Shutting down the log cleaner.
2025-01-04 00:12:49.711 [kafka-log-cleaner-thread-0]: Shutting down
2025-01-04 00:12:49.711 [kafka-log-cleaner-thread-0]: Stopped
2025-01-04 00:12:49.711 [kafka-log-cleaner-thread-0]: Shutdown completed
2025-01-04 00:12:49.739 [ProducerStateManager partition=pong-message-topic-1] Wrote producer snapshot at offset 1 with 0 producer ids in 3 ms.
2025-01-04 00:12:49.748 [ProducerStateManager partition=__consumer_offsets-2] Wrote producer snapshot at offset 4 with 0 producer ids in 2 ms.
2025-01-04 00:12:49.757 Shutdown complete.
2025-01-04 00:12:49.757 [ControllerEventThread controllerId=0] Shutting down
2025-01-04 00:12:49.759 [ControllerEventThread controllerId=0] Stopped
2025-01-04 00:12:49.759 [ControllerEventThread controllerId=0] Shutdown completed
2025-01-04 00:12:49.760 [PartitionStateMachine controllerId=0] Stopped partition state machine
2025-01-04 00:12:49.760 [ReplicaStateMachine controllerId=0] Stopped replica state machine
2025-01-04 00:12:49.760 [RequestSendThread controllerId=0] Shutting down
2025-01-04 00:12:49.762 [RequestSendThread controllerId=0] Shutdown completed
2025-01-04 00:12:49.762 [RequestSendThread controllerId=0] Stopped
2025-01-04 00:12:49.763 [Controller id=0] Resigned
2025-01-04 00:12:49.763 [feature-zk-node-event-process-thread]: Shutting down
2025-01-04 00:12:49.763 [feature-zk-node-event-process-thread]: Shutdown completed
2025-01-04 00:12:49.763 [feature-zk-node-event-process-thread]: Stopped
2025-01-04 00:12:49.764 [ZooKeeperClient Kafka server] Closing.
2025-01-04 00:12:49.787 [Producer clientId=producer-1] Node 0 disconnected.
2025-01-04 00:12:49.787 [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:51186) could not be established. Broker may not be available.
2025-01-04 00:12:49.795 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 0 disconnected.
2025-01-04 00:12:49.795 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node 0 (localhost/127.0.0.1:51186) could not be established. Broker may not be available.
2025-01-04 00:12:49.874 Session: 0x1000a9d425f0000 closed
2025-01-04 00:12:49.874 EventThread shut down for session: 0x1000a9d425f0000
2025-01-04 00:12:49.876 [ZooKeeperClient Kafka server] Closed.
2025-01-04 00:12:49.876 [ThrottledChannelReaper-Fetch]: Shutting down
2025-01-04 00:12:49.878 [ThrottledChannelReaper-Fetch]: Stopped
2025-01-04 00:12:49.878 [ThrottledChannelReaper-Fetch]: Shutdown completed
2025-01-04 00:12:49.878 [ThrottledChannelReaper-Produce]: Shutting down
2025-01-04 00:12:49.879 [ThrottledChannelReaper-Produce]: Stopped
2025-01-04 00:12:49.879 [ThrottledChannelReaper-Produce]: Shutdown completed
2025-01-04 00:12:49.879 [ThrottledChannelReaper-Request]: Shutting down
2025-01-04 00:12:49.879 [ThrottledChannelReaper-Request]: Stopped
2025-01-04 00:12:49.879 [ThrottledChannelReaper-Request]: Shutdown completed
2025-01-04 00:12:49.879 [ThrottledChannelReaper-ControllerMutation]: Shutting down
2025-01-04 00:12:49.879 [ThrottledChannelReaper-ControllerMutation]: Shutdown completed
2025-01-04 00:12:49.879 [ThrottledChannelReaper-ControllerMutation]: Stopped
2025-01-04 00:12:49.880 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server
2025-01-04 00:12:49.891 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed
2025-01-04 00:12:49.891 Metrics scheduler closed
2025-01-04 00:12:49.891 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-04 00:12:49.891 Metrics reporters closed
2025-01-04 00:12:49.894 Broker and topic stats closed
2025-01-04 00:12:49.894 App info kafka.server for 0 unregistered
2025-01-04 00:12:49.894 [KafkaServer id=0] shut down completed
2025-01-04 00:12:49.903 [Producer clientId=producer-1] Node 0 disconnected.
2025-01-04 00:12:49.903 [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:51186) could not be established. Broker may not be available.
2025-01-04 00:12:49.903 ConnnectionExpirerThread interrupted
2025-01-04 00:12:49.903 selector thread exitted run method
2025-01-04 00:12:49.904 accept thread exitted run method
2025-01-04 00:12:49.904 selector thread exitted run method
2025-01-04 00:12:49.904 shutting down
2025-01-04 00:12:49.905 Shutting down
2025-01-04 00:12:49.905 Draining request throttler queue
2025-01-04 00:12:49.905 RequestThrottler shutdown. Dropped 0 requests
2025-01-04 00:12:49.905 Shutting down
2025-01-04 00:12:49.905 Shutting down
2025-01-04 00:12:49.905 Shutting down
2025-01-04 00:12:49.905 PrepRequestProcessor exited loop!
2025-01-04 00:12:49.905 SyncRequestProcessor exited!
2025-01-04 00:12:49.905 shutdown of request processor complete
2025-01-04 00:12:49.930 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Node 0 disconnected.
2025-01-04 00:12:49.930 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Connection to node 0 (localhost/127.0.0.1:51186) could not be established. Broker may not be available.
2025-01-04 00:12:49.930 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Revoke previously assigned partitions pong-message-topic-0, pong-message-topic-1
2025-01-04 00:12:49.930 pong-service: partitions revoked: [pong-message-topic-0, pong-message-topic-1]
2025-01-04 00:12:49.931 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-04 00:12:49.931 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2025-01-04 00:12:49.931 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Unsubscribed all topics or patterns and assigned partitions
2025-01-04 00:12:49.931 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-04 00:12:49.931 [Consumer clientId=consumer-pong-service-1, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2025-01-04 00:12:49.931 Metrics scheduler closed
2025-01-04 00:12:49.931 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-04 00:12:49.931 Metrics reporters closed
2025-01-04 00:12:49.933 App info kafka.consumer for consumer-pong-service-1 unregistered
2025-01-04 00:12:49.933 pong-service: Consumer stopped
2025-01-04 00:12:49.934 [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2025-01-04 00:12:49.935 Metrics scheduler closed
2025-01-04 00:12:49.935 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-04 00:12:49.935 Metrics reporters closed
2025-01-04 00:12:49.935 App info kafka.producer for producer-1 unregistered
2025-01-04 00:12:49.957 Closing JPA EntityManagerFactory for persistence unit 'default'
2025-01-04 00:12:49.960 HikariPool-1 - Shutdown initiated...
2025-01-04 00:12:49.961 HikariPool-1 - Shutdown completed.
2025-01-04 00:12:50.004 

Found multiple occurrences of org.json.JSONObject on the class path:

	jar:file:/C:/work/apache-maven-3.8.8/repo/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar!/org/json/JSONObject.class
	jar:file:/C:/work/apache-maven-3.8.8/repo/org/json/json/20220320/json-20220320.jar!/org/json/JSONObject.class

You may wish to exclude one of them to ensure predictable runtime behavior

2025-01-04 00:12:50.006 Starting MessageRepositorySpec using Java 17.0.12 with PID 10572 (started by joech in C:\code\hsbc\demo\pong)
2025-01-04 00:12:50.006 No active profile set, falling back to 1 default profile: "default"
2025-01-04 00:12:50.121 Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-04 00:12:50.121 Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-04 00:12:50.132 Finished Spring Data repository scanning in 11 ms. Found 1 JPA repository interfaces.
2025-01-04 00:12:50.137 Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-04 00:12:50.137 Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-04 00:12:50.143 Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.demo.dao.MessageRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-04 00:12:50.143 Finished Spring Data repository scanning in 5 ms. Found 0 Redis repository interfaces.
2025-01-04 00:12:50.211 HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-04 00:12:50.216 HHH000021: Bytecode provider name : bytebuddy
2025-01-04 00:12:50.216 No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-04 00:12:50.217 HikariPool-2 - Starting...
2025-01-04 00:12:50.220 HikariPool-2 - Added connection conn10: url=jdbc:h2:mem:testdb user=SA
2025-01-04 00:12:50.220 HikariPool-2 - Start completed.
2025-01-04 00:12:50.226 HHH000021: Bytecode provider name : bytebuddy
2025-01-04 00:12:50.245 HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2025-01-04 00:12:50.258 Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-04 00:12:50.404 SessionTrackerImpl exited loop!
2025-01-04 00:12:50.418 ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:51186]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-pong-service-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = pong-service
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-04 00:12:50.422 These configurations '[spring.json.trusted.packages]' were supplied but are not used yet.
2025-01-04 00:12:50.422 Kafka version: 3.4.1
2025-01-04 00:12:50.422 Kafka commitId: 8a516edc2755df89
2025-01-04 00:12:50.422 Kafka startTimeMs: 1735920770422
2025-01-04 00:12:50.422 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Subscribed to topic(s): pong-message-topic
2025-01-04 00:12:50.424 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Node -1 disconnected.
2025-01-04 00:12:50.424 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Connection to node -1 (/127.0.0.1:51186) could not be established. Broker may not be available.
2025-01-04 00:12:50.424 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Bootstrap broker 127.0.0.1:51186 (id: -1 rack: null) disconnected
2025-01-04 00:12:50.424 Started MessageRepositorySpec in 0.445 seconds (process running for 13.146)
2025-01-04 00:12:50.461 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-04 00:12:50.461 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2025-01-04 00:12:50.461 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Unsubscribed all topics or patterns and assigned partitions
2025-01-04 00:12:50.461 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-04 00:12:50.461 [Consumer clientId=consumer-pong-service-2, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2025-01-04 00:12:50.462 Metrics scheduler closed
2025-01-04 00:12:50.462 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-04 00:12:50.462 Metrics reporters closed
2025-01-04 00:12:50.462 App info kafka.consumer for consumer-pong-service-2 unregistered
2025-01-04 00:12:50.462 pong-service: Consumer stopped
2025-01-04 00:12:50.466 Closing JPA EntityManagerFactory for persistence unit 'default'
2025-01-04 00:12:50.466 HikariPool-2 - Shutdown initiated...
2025-01-04 00:12:50.468 HikariPool-2 - Shutdown completed.
2025-01-04 00:12:50.486 zookeeper.snapshot.trust.empty : false
2025-01-04 00:12:50.487 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2025-01-04 00:12:50.487 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2025-01-04 00:12:50.487 zookeeper.snapshotSizeFactor = 0.33
2025-01-04 00:12:50.487 zookeeper.commitLogCount=500
2025-01-04 00:12:50.487 minSessionTimeout set to 1600
2025-01-04 00:12:50.487 maxSessionTimeout set to 16000
2025-01-04 00:12:50.487 Response cache size is initialized with value 400.
2025-01-04 00:12:50.487 Response cache size is initialized with value 400.
2025-01-04 00:12:50.487 zookeeper.pathStats.slotCapacity = 60
2025-01-04 00:12:50.487 zookeeper.pathStats.slotDuration = 15
2025-01-04 00:12:50.487 zookeeper.pathStats.maxDepth = 6
2025-01-04 00:12:50.487 zookeeper.pathStats.initialDelay = 5
2025-01-04 00:12:50.487 zookeeper.pathStats.delay = 5
2025-01-04 00:12:50.487 zookeeper.pathStats.enabled = false
2025-01-04 00:12:50.487 The max bytes for all large requests are set to 104857600
2025-01-04 00:12:50.487 The large request threshold is set to -1
2025-01-04 00:12:50.488 Created server with tickTime 800 minSessionTimeout 1600 maxSessionTimeout 16000 clientPortListenBacklog -1 datadir C:\Users\joech\AppData\Local\Temp\kafka-10756757593901107356\version-2 snapdir C:\Users\joech\AppData\Local\Temp\kafka-8279849800800756733\version-2
2025-01-04 00:12:50.488 maxCnxns is not configured, using default value 0.
2025-01-04 00:12:50.488 Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers.
2025-01-04 00:12:50.491 binding to port /127.0.0.1:0
2025-01-04 00:12:50.494 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-8279849800800756733\version-2\snapshot.0
2025-01-04 00:12:50.494 Snapshot loaded in 1 ms, highest zxid is 0x0, digest is 1371985504
2025-01-04 00:12:50.494 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-8279849800800756733\version-2\snapshot.0
2025-01-04 00:12:50.494 Snapshot taken in 0 ms
2025-01-04 00:12:50.495 PrepRequestProcessor (sid:0) started, reconfigEnabled=false
2025-01-04 00:12:50.497 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.a68a358b-4c66-4881-85c5-3d5c451ad0ab8865735822486362518
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:51203
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2025-01-04 00:12:50.501 starting
2025-01-04 00:12:50.501 Connecting to zookeeper on 127.0.0.1:51203
2025-01-04 00:12:50.502 [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:51203.
2025-01-04 00:12:50.502 Initiating client connection, connectString=127.0.0.1:51203 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4389c18f
2025-01-04 00:12:50.504 jute.maxbuffer value is 4194304 Bytes
2025-01-04 00:12:50.505 zookeeper.request.timeout value is 0. feature enabled=false
2025-01-04 00:12:50.505 [ZooKeeperClient Kafka server] Waiting until connected.
2025-01-04 00:12:50.505 Opening socket connection to server /127.0.0.1:51203.
2025-01-04 00:12:50.506 Socket connection established, initiating session, client: /127.0.0.1:51204, server: /127.0.0.1:51203
2025-01-04 00:12:50.507 Creating new log file: log.1
2025-01-04 00:12:50.512 Session establishment complete on server /127.0.0.1:51203, session id = 0x1000a9d65840000, negotiated timeout = 16000
2025-01-04 00:12:50.512 [ZooKeeperClient Kafka server] Connected.
2025-01-04 00:12:50.550 Cluster ID = g4S3f1T9TLKvdGbqnAR4LQ
2025-01-04 00:12:50.551 No meta.properties file under dir C:\Users\joech\AppData\Local\Temp\spring.kafka.a68a358b-4c66-4881-85c5-3d5c451ad0ab8865735822486362518\meta.properties
2025-01-04 00:12:50.557 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.a68a358b-4c66-4881-85c5-3d5c451ad0ab8865735822486362518
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:51203
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2025-01-04 00:12:50.561 [ThrottledChannelReaper-Fetch]: Starting
2025-01-04 00:12:50.561 [ThrottledChannelReaper-Produce]: Starting
2025-01-04 00:12:50.562 [ThrottledChannelReaper-Request]: Starting
2025-01-04 00:12:50.562 [ThrottledChannelReaper-ControllerMutation]: Starting
2025-01-04 00:12:50.565 Loading logs from log dirs ArraySeq(C:\Users\joech\AppData\Local\Temp\spring.kafka.a68a358b-4c66-4881-85c5-3d5c451ad0ab8865735822486362518)
2025-01-04 00:12:50.566 Attempting recovery for all logs in C:\Users\joech\AppData\Local\Temp\spring.kafka.a68a358b-4c66-4881-85c5-3d5c451ad0ab8865735822486362518 since no clean shutdown file was found
2025-01-04 00:12:50.566 Loaded 0 logs in 1ms.
2025-01-04 00:12:50.566 Starting log cleanup with a period of 300000 ms.
2025-01-04 00:12:50.568 Starting log flusher with a default period of 9223372036854775807 ms.
2025-01-04 00:12:50.569 Starting the log cleaner
2025-01-04 00:12:50.570 [kafka-log-cleaner-thread-0]: Starting
2025-01-04 00:12:50.570 [feature-zk-node-event-process-thread]: Starting
2025-01-04 00:12:50.572 Feature ZK node at path: /feature does not exist
2025-01-04 00:12:50.574 [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting
2025-01-04 00:12:50.584 Updated connection-accept-rate max connection creation rate to 2147483647
2025-01-04 00:12:50.586 Awaiting socket connections on localhost:51205.
2025-01-04 00:12:50.595 [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT)
2025-01-04 00:12:50.596 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Starting
2025-01-04 00:12:50.597 [ExpirationReaper-0-Produce]: Starting
2025-01-04 00:12:50.597 [ExpirationReaper-0-Fetch]: Starting
2025-01-04 00:12:50.597 [ExpirationReaper-0-DeleteRecords]: Starting
2025-01-04 00:12:50.597 [ExpirationReaper-0-ElectLeader]: Starting
2025-01-04 00:12:50.599 [LogDirFailureHandler]: Starting
2025-01-04 00:12:50.601 Creating /brokers/ids/0 (is it secure? false)
2025-01-04 00:12:50.602 Stat of the created znode at /brokers/ids/0 is: 25,25,1735920770601,1735920770601,1,0,0,72069265167220736,204,0,25

2025-01-04 00:12:50.602 Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:51205, czxid (broker epoch): 25
2025-01-04 00:12:50.605 [ControllerEventThread controllerId=0] Starting
2025-01-04 00:12:50.607 [ExpirationReaper-0-topic]: Starting
2025-01-04 00:12:50.607 [ExpirationReaper-0-Heartbeat]: Starting
2025-01-04 00:12:50.608 [ExpirationReaper-0-Rebalance]: Starting
2025-01-04 00:12:50.608 [GroupCoordinator 0]: Starting up.
2025-01-04 00:12:50.608 [GroupCoordinator 0]: Startup complete.
2025-01-04 00:12:50.610 Successfully created /controller_epoch with initial epoch 0
2025-01-04 00:12:50.611 [TransactionCoordinator id=0] Starting up.
2025-01-04 00:12:50.612 [Controller id=0] 0 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1
2025-01-04 00:12:50.612 [TransactionCoordinator id=0] Startup complete.
2025-01-04 00:12:50.612 [Transaction Marker Channel Manager 0]: Starting
2025-01-04 00:12:50.612 [Controller id=0] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map())
2025-01-04 00:12:50.614 [ExpirationReaper-0-AlterAcls]: Starting
2025-01-04 00:12:50.614 Feature ZK node created at path: /feature
2025-01-04 00:12:50.615 [MetadataCache brokerId=0] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0).
2025-01-04 00:12:50.615 [Controller id=0] Registering handlers
2025-01-04 00:12:50.615 [Controller id=0] Deleting log dir event notifications
2025-01-04 00:12:50.616 [Controller id=0] Deleting isr change notifications
2025-01-04 00:12:50.616 [/config/changes-event-process-thread]: Starting
2025-01-04 00:12:50.616 [Controller id=0] Initializing controller context
2025-01-04 00:12:50.619 [Controller id=0] Initialized broker epochs cache: HashMap(0 -> 25)
2025-01-04 00:12:50.619 [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing.
2025-01-04 00:12:50.620 Kafka version: 3.4.1
2025-01-04 00:12:50.620 Kafka commitId: 8a516edc2755df89
2025-01-04 00:12:50.620 Kafka startTimeMs: 1735920770620
2025-01-04 00:12:50.620 [KafkaServer id=0] started
2025-01-04 00:12:50.620 AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [127.0.0.1:51205]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-01-04 00:12:50.623 [Controller id=0] Currently active brokers in the cluster: Set(0)
2025-01-04 00:12:50.623 [RequestSendThread controllerId=0] Starting
2025-01-04 00:12:50.623 [Controller id=0] Currently shutting brokers in the cluster: HashSet()
2025-01-04 00:12:50.623 [Controller id=0] Current list of topics in the cluster: HashSet()
2025-01-04 00:12:50.623 [Controller id=0] Fetching topic deletions in progress
2025-01-04 00:12:50.623 Kafka version: 3.4.1
2025-01-04 00:12:50.623 Kafka commitId: 8a516edc2755df89
2025-01-04 00:12:50.623 Kafka startTimeMs: 1735920770623
2025-01-04 00:12:50.624 [Controller id=0] List of topics to be deleted: 
2025-01-04 00:12:50.624 [Controller id=0] List of topics ineligible for deletion: 
2025-01-04 00:12:50.624 [Controller id=0] Initializing topic deletion manager
2025-01-04 00:12:50.624 [Topic Deletion Manager 0] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet()
2025-01-04 00:12:50.624 [Controller id=0] Sending update metadata request
2025-01-04 00:12:50.624 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions
2025-01-04 00:12:50.624 [ReplicaStateMachine controllerId=0] Initializing replica state
2025-01-04 00:12:50.624 [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2025-01-04 00:12:50.624 [ReplicaStateMachine controllerId=0] Triggering offline replica state changes
2025-01-04 00:12:50.624 [PartitionStateMachine controllerId=0] Initializing partition state
2025-01-04 00:12:50.624 [PartitionStateMachine controllerId=0] Triggering online partition state changes
2025-01-04 00:12:50.624 [Controller id=0] Ready to serve as the new controller with epoch 1
2025-01-04 00:12:50.626 [RequestSendThread controllerId=0] Controller 0 connected to localhost:51205 (id: 0 rack: null) for sending state change requests
2025-01-04 00:12:50.627 [Controller id=0] Partitions undergoing preferred replica election: 
2025-01-04 00:12:50.627 [Controller id=0] Partitions that completed preferred replica election: 
2025-01-04 00:12:50.627 [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2025-01-04 00:12:50.627 [Controller id=0] Resuming preferred replica election for partitions: 
2025-01-04 00:12:50.627 [Controller id=0] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered
2025-01-04 00:12:50.628 [Controller id=0] Starting the controller scheduler
2025-01-04 00:12:50.632 Creating topic pong-message-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0))
2025-01-04 00:12:50.637 [Controller id=0] New topics: [Set(pong-message-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(pong-message-topic,Some(1ueuB_1OSHCWpikvBBJD-g),Map(pong-message-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), pong-message-topic-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-01-04 00:12:50.637 [Controller id=0] New partition creation callback for pong-message-topic-0,pong-message-topic-1
2025-01-04 00:12:50.637 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-04 00:12:50.637 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-04 00:12:50.637 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:12:50.639 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:12:50.643 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-04 00:12:50.643 [Controller id=0 epoch=1] Changed partition pong-message-topic-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-04 00:12:50.645 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 0 become-follower partitions
2025-01-04 00:12:50.645 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 2 partitions
2025-01-04 00:12:50.645 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:12:50.646 [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 for 2 partitions
2025-01-04 00:12:50.646 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(pong-message-topic-0, pong-message-topic-1)
2025-01-04 00:12:50.646 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions
2025-01-04 00:12:50.652 [LogLoader partition=pong-message-topic-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.a68a358b-4c66-4881-85c5-3d5c451ad0ab8865735822486362518] Loading producer state till offset 0 with message format version 2
2025-01-04 00:12:50.652 Created log for partition pong-message-topic-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.a68a358b-4c66-4881-85c5-3d5c451ad0ab8865735822486362518\pong-message-topic-0 with properties {}
2025-01-04 00:12:50.653 [Partition pong-message-topic-0 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-0
2025-01-04 00:12:50.653 [Partition pong-message-topic-0 broker=0] Log loaded for partition pong-message-topic-0 with initial high watermark 0
2025-01-04 00:12:50.653 [Broker id=0] Leader pong-message-topic-0 with topic id Some(1ueuB_1OSHCWpikvBBJD-g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2025-01-04 00:12:50.663 [LogLoader partition=pong-message-topic-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.a68a358b-4c66-4881-85c5-3d5c451ad0ab8865735822486362518] Loading producer state till offset 0 with message format version 2
2025-01-04 00:12:50.664 Created log for partition pong-message-topic-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.a68a358b-4c66-4881-85c5-3d5c451ad0ab8865735822486362518\pong-message-topic-1 with properties {}
2025-01-04 00:12:50.664 [Partition pong-message-topic-1 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-1
2025-01-04 00:12:50.664 [Partition pong-message-topic-1 broker=0] Log loaded for partition pong-message-topic-1 with initial high watermark 0
2025-01-04 00:12:50.664 [Broker id=0] Leader pong-message-topic-1 with topic id Some(1ueuB_1OSHCWpikvBBJD-g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2025-01-04 00:12:50.667 [Broker id=0] Finished LeaderAndIsr request in 22ms correlationId 1 from controller 0 for 2 partitions
2025-01-04 00:12:50.670 [Broker id=0] Add 2 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2
2025-01-04 00:12:50.671 App info kafka.admin.client for adminclient-2 unregistered
2025-01-04 00:12:50.673 Metrics scheduler closed
2025-01-04 00:12:50.673 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-04 00:12:50.673 Metrics reporters closed
2025-01-04 00:12:50.675 [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use node localhost:51205 (id: 0 rack: null)
2025-01-04 00:12:50.730 

Found multiple occurrences of org.json.JSONObject on the class path:

	jar:file:/C:/work/apache-maven-3.8.8/repo/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar!/org/json/JSONObject.class
	jar:file:/C:/work/apache-maven-3.8.8/repo/org/json/json/20220320/json-20220320.jar!/org/json/JSONObject.class

You may wish to exclude one of them to ensure predictable runtime behavior

2025-01-04 00:12:50.739 zookeeper.snapshot.trust.empty : false
2025-01-04 00:12:50.740 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2025-01-04 00:12:50.740 Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2025-01-04 00:12:50.740 zookeeper.snapshotSizeFactor = 0.33
2025-01-04 00:12:50.740 zookeeper.commitLogCount=500
2025-01-04 00:12:50.740 minSessionTimeout set to 1600
2025-01-04 00:12:50.740 maxSessionTimeout set to 16000
2025-01-04 00:12:50.740 Response cache size is initialized with value 400.
2025-01-04 00:12:50.740 Response cache size is initialized with value 400.
2025-01-04 00:12:50.740 zookeeper.pathStats.slotCapacity = 60
2025-01-04 00:12:50.740 zookeeper.pathStats.slotDuration = 15
2025-01-04 00:12:50.740 zookeeper.pathStats.maxDepth = 6
2025-01-04 00:12:50.740 zookeeper.pathStats.initialDelay = 5
2025-01-04 00:12:50.740 zookeeper.pathStats.delay = 5
2025-01-04 00:12:50.740 zookeeper.pathStats.enabled = false
2025-01-04 00:12:50.740 The max bytes for all large requests are set to 104857600
2025-01-04 00:12:50.740 The large request threshold is set to -1
2025-01-04 00:12:50.740 Created server with tickTime 800 minSessionTimeout 1600 maxSessionTimeout 16000 clientPortListenBacklog -1 datadir C:\Users\joech\AppData\Local\Temp\kafka-17495930425397362672\version-2 snapdir C:\Users\joech\AppData\Local\Temp\kafka-3257652017959351268\version-2
2025-01-04 00:12:50.740 maxCnxns is not configured, using default value 0.
2025-01-04 00:12:50.740 Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers.
2025-01-04 00:12:50.743 binding to port /127.0.0.1:0
2025-01-04 00:12:50.746 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-3257652017959351268\version-2\snapshot.0
2025-01-04 00:12:50.747 Snapshot loaded in 1 ms, highest zxid is 0x0, digest is 1371985504
2025-01-04 00:12:50.747 Snapshotting: 0x0 to C:\Users\joech\AppData\Local\Temp\kafka-3257652017959351268\version-2\snapshot.0
2025-01-04 00:12:50.747 Snapshot taken in 1 ms
2025-01-04 00:12:50.748 PrepRequestProcessor (sid:0) started, reconfigEnabled=false
2025-01-04 00:12:50.750 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.358f9ed1-2460-4fd8-b26c-46ce59d663fe5754759066350150320
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:51209
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2025-01-04 00:12:50.753 starting
2025-01-04 00:12:50.753 Connecting to zookeeper on 127.0.0.1:51209
2025-01-04 00:12:50.753 [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:51209.
2025-01-04 00:12:50.753 Initiating client connection, connectString=127.0.0.1:51209 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@4dc66273
2025-01-04 00:12:50.756 jute.maxbuffer value is 4194304 Bytes
2025-01-04 00:12:50.757 zookeeper.request.timeout value is 0. feature enabled=false
2025-01-04 00:12:50.757 [ZooKeeperClient Kafka server] Waiting until connected.
2025-01-04 00:12:50.757 Opening socket connection to server /127.0.0.1:51209.
2025-01-04 00:12:50.757 Socket connection established, initiating session, client: /127.0.0.1:51210, server: /127.0.0.1:51209
2025-01-04 00:12:50.758 Creating new log file: log.1
2025-01-04 00:12:50.761 Session establishment complete on server /127.0.0.1:51209, session id = 0x1000a9d66810000, negotiated timeout = 16000
2025-01-04 00:12:50.761 [ZooKeeperClient Kafka server] Connected.
2025-01-04 00:12:50.793 Cluster ID = dYyYEv4_QuG4E2xr_Il6Fw
2025-01-04 00:12:50.793 No meta.properties file under dir C:\Users\joech\AppData\Local\Temp\spring.kafka.358f9ed1-2460-4fd8-b26c-46ce59d663fe5754759066350150320\meta.properties
2025-01-04 00:12:50.800 KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.4-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\joech\AppData\Local\Temp\spring.kafka.358f9ed1-2460-4fd8-b26c-46ce59d663fe5754759066350150320
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:51209
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2025-01-04 00:12:50.809 [ThrottledChannelReaper-Fetch]: Starting
2025-01-04 00:12:50.809 [ThrottledChannelReaper-Produce]: Starting
2025-01-04 00:12:50.809 [ThrottledChannelReaper-Request]: Starting
2025-01-04 00:12:50.810 [ThrottledChannelReaper-ControllerMutation]: Starting
2025-01-04 00:12:50.813 Loading logs from log dirs ArraySeq(C:\Users\joech\AppData\Local\Temp\spring.kafka.358f9ed1-2460-4fd8-b26c-46ce59d663fe5754759066350150320)
2025-01-04 00:12:50.813 Attempting recovery for all logs in C:\Users\joech\AppData\Local\Temp\spring.kafka.358f9ed1-2460-4fd8-b26c-46ce59d663fe5754759066350150320 since no clean shutdown file was found
2025-01-04 00:12:50.814 Loaded 0 logs in 1ms.
2025-01-04 00:12:50.814 Starting log cleanup with a period of 300000 ms.
2025-01-04 00:12:50.815 Starting log flusher with a default period of 9223372036854775807 ms.
2025-01-04 00:12:50.817 Starting the log cleaner
2025-01-04 00:12:50.817 [kafka-log-cleaner-thread-0]: Starting
2025-01-04 00:12:50.817 [feature-zk-node-event-process-thread]: Starting
2025-01-04 00:12:50.820 Feature ZK node at path: /feature does not exist
2025-01-04 00:12:50.821 [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting
2025-01-04 00:12:50.829 Updated connection-accept-rate max connection creation rate to 2147483647
2025-01-04 00:12:50.830 Awaiting socket connections on localhost:51211.
2025-01-04 00:12:50.835 [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT)
2025-01-04 00:12:50.837 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Starting
2025-01-04 00:12:50.837 [ExpirationReaper-0-Produce]: Starting
2025-01-04 00:12:50.838 [ExpirationReaper-0-Fetch]: Starting
2025-01-04 00:12:50.838 [ExpirationReaper-0-DeleteRecords]: Starting
2025-01-04 00:12:50.838 [ExpirationReaper-0-ElectLeader]: Starting
2025-01-04 00:12:50.839 [LogDirFailureHandler]: Starting
2025-01-04 00:12:50.842 Creating /brokers/ids/0 (is it secure? false)
2025-01-04 00:12:50.843 Stat of the created znode at /brokers/ids/0 is: 25,25,1735920770842,1735920770842,1,0,0,72069265183801344,204,0,25

2025-01-04 00:12:50.843 Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:51211, czxid (broker epoch): 25
2025-01-04 00:12:50.847 [ControllerEventThread controllerId=0] Starting
2025-01-04 00:12:50.849 [ExpirationReaper-0-topic]: Starting
2025-01-04 00:12:50.849 [ExpirationReaper-0-Heartbeat]: Starting
2025-01-04 00:12:50.849 [ExpirationReaper-0-Rebalance]: Starting
2025-01-04 00:12:50.849 [GroupCoordinator 0]: Starting up.
2025-01-04 00:12:50.850 Successfully created /controller_epoch with initial epoch 0
2025-01-04 00:12:50.850 [GroupCoordinator 0]: Startup complete.
2025-01-04 00:12:50.851 [Controller id=0] 0 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1
2025-01-04 00:12:50.851 [TransactionCoordinator id=0] Starting up.
2025-01-04 00:12:50.851 [Controller id=0] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map())
2025-01-04 00:12:50.852 Feature ZK node created at path: /feature
2025-01-04 00:12:50.852 [TransactionCoordinator id=0] Startup complete.
2025-01-04 00:12:50.854 [Transaction Marker Channel Manager 0]: Starting
2025-01-04 00:12:50.854 [MetadataCache brokerId=0] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0).
2025-01-04 00:12:50.854 [Controller id=0] Registering handlers
2025-01-04 00:12:50.854 [ExpirationReaper-0-AlterAcls]: Starting
2025-01-04 00:12:50.855 [Controller id=0] Deleting log dir event notifications
2025-01-04 00:12:50.856 [Controller id=0] Deleting isr change notifications
2025-01-04 00:12:50.856 [Controller id=0] Initializing controller context
2025-01-04 00:12:50.857 [/config/changes-event-process-thread]: Starting
2025-01-04 00:12:50.859 [Controller id=0] Initialized broker epochs cache: HashMap(0 -> 25)
2025-01-04 00:12:50.861 [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing.
2025-01-04 00:12:50.862 Kafka version: 3.4.1
2025-01-04 00:12:50.862 Kafka commitId: 8a516edc2755df89
2025-01-04 00:12:50.862 Kafka startTimeMs: 1735920770862
2025-01-04 00:12:50.862 [RequestSendThread controllerId=0] Starting
2025-01-04 00:12:50.862 [Controller id=0] Currently active brokers in the cluster: Set(0)
2025-01-04 00:12:50.862 [Controller id=0] Currently shutting brokers in the cluster: HashSet()
2025-01-04 00:12:50.862 [Controller id=0] Current list of topics in the cluster: HashSet()
2025-01-04 00:12:50.862 [Controller id=0] Fetching topic deletions in progress
2025-01-04 00:12:50.863 [Controller id=0] List of topics to be deleted: 
2025-01-04 00:12:50.863 [Controller id=0] List of topics ineligible for deletion: 
2025-01-04 00:12:50.863 [Controller id=0] Initializing topic deletion manager
2025-01-04 00:12:50.863 [Topic Deletion Manager 0] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet()
2025-01-04 00:12:50.863 [Controller id=0] Sending update metadata request
2025-01-04 00:12:50.863 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions
2025-01-04 00:12:50.863 [ReplicaStateMachine controllerId=0] Initializing replica state
2025-01-04 00:12:50.863 [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2025-01-04 00:12:50.863 [ReplicaStateMachine controllerId=0] Triggering offline replica state changes
2025-01-04 00:12:50.863 [PartitionStateMachine controllerId=0] Initializing partition state
2025-01-04 00:12:50.863 [PartitionStateMachine controllerId=0] Triggering online partition state changes
2025-01-04 00:12:50.863 [Controller id=0] Ready to serve as the new controller with epoch 1
2025-01-04 00:12:50.864 [RequestSendThread controllerId=0] Controller 0 connected to localhost:51211 (id: 0 rack: null) for sending state change requests
2025-01-04 00:12:50.865 [Controller id=0] Partitions undergoing preferred replica election: 
2025-01-04 00:12:50.865 [Controller id=0] Partitions that completed preferred replica election: 
2025-01-04 00:12:50.865 [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2025-01-04 00:12:50.865 [Controller id=0] Resuming preferred replica election for partitions: 
2025-01-04 00:12:50.865 [Controller id=0] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered
2025-01-04 00:12:50.862 Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.server:type=app-info,id=0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1865)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:960)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:895)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:523)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:563)
	at kafka.utils.TestUtils$.createServer(TestUtils.scala:188)
	at kafka.utils.TestUtils$.createServer(TestUtils.scala:182)
	at kafka.utils.TestUtils.createServer(TestUtils.scala)
	at org.springframework.kafka.test.EmbeddedKafkaBroker.afterPropertiesSet(EmbeddedKafkaBroker.java:369)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1817)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1766)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:410)
	at org.springframework.kafka.test.context.EmbeddedKafkaContextCustomizer.customizeContext(EmbeddedKafkaContextCustomizer.java:116)
	at org.springframework.boot.test.context.SpringBootContextLoader$ContextCustomizerAdapter.initialize(SpringBootContextLoader.java:435)
	at org.springframework.boot.SpringApplication.applyInitializers(SpringApplication.java:610)
	at org.springframework.boot.SpringApplication.prepareContext(SpringApplication.java:390)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:314)
	at org.springframework.boot.test.context.SpringBootContextLoader.lambda$loadContext$3(SpringBootContextLoader.java:137)
	at org.springframework.util.function.ThrowingSupplier.get(ThrowingSupplier.java:58)
	at org.springframework.util.function.ThrowingSupplier.get(ThrowingSupplier.java:46)
	at org.springframework.boot.SpringApplication.withHook(SpringApplication.java:1409)
	at org.springframework.boot.test.context.SpringBootContextLoader$ContextLoaderHook.run(SpringBootContextLoader.java:545)
	at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:137)
	at org.springframework.boot.test.context.SpringBootContextLoader.loadContext(SpringBootContextLoader.java:108)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContextInternal(DefaultCacheAwareContextLoaderDelegate.java:187)
	at org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:119)
	at org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:127)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.injectDependencies(DependencyInjectionTestExecutionListener.java:141)
	at org.springframework.test.context.support.DependencyInjectionTestExecutionListener.prepareTestInstance(DependencyInjectionTestExecutionListener.java:97)
	at org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:241)
	at org.spockframework.spring.SpringTestContextManager.prepareTestInstance(SpringTestContextManager.java:56)
	at org.spockframework.spring.SpringInterceptor.interceptInitializerMethod(SpringInterceptor.java:46)
	at org.spockframework.runtime.extension.AbstractMethodInterceptor.intercept(AbstractMethodInterceptor.java:24)
	at org.spockframework.runtime.extension.MethodInvocation.proceed(MethodInvocation.java:101)
	at org.spockframework.runtime.PlatformSpecRunner.invoke(PlatformSpecRunner.java:398)
	at org.spockframework.runtime.PlatformSpecRunner.runInitializer(PlatformSpecRunner.java:259)
	at org.spockframework.runtime.PlatformSpecRunner.runInitializer(PlatformSpecRunner.java:254)
	at org.spockframework.runtime.IterationNode.prepare(IterationNode.java:31)
	at org.spockframework.runtime.IterationNode.prepare(IterationNode.java:13)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$prepare$2(NodeTestTask.java:123)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.prepare(NodeTestTask.java:123)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:90)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:226)
	at org.spockframework.runtime.ParameterizedFeatureChildExecutor.execute(ParameterizedFeatureChildExecutor.java:104)
	at org.spockframework.runtime.PlatformParameterizedSpecRunner$1.runIteration(PlatformParameterizedSpecRunner.java:72)
	at org.spockframework.runtime.extension.IDataDriver.lambda$static$0(IDataDriver.java:37)
	at org.spockframework.runtime.PlatformParameterizedSpecRunner.runParameterizedFeature(PlatformParameterizedSpecRunner.java:47)
	at org.spockframework.runtime.ParameterizedFeatureNode.execute(ParameterizedFeatureNode.java:40)
	at org.spockframework.runtime.ParameterizedFeatureNode.execute(ParameterizedFeatureNode.java:16)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.spockframework.runtime.SpockNode.sneakyInvoke(SpockNode.java:40)
	at org.spockframework.runtime.FeatureNode.lambda$around$0(FeatureNode.java:41)
	at org.spockframework.runtime.PlatformSpecRunner.lambda$createMethodInfoForDoRunFeature$4(PlatformSpecRunner.java:199)
	at org.spockframework.runtime.model.MethodInfo.invoke(MethodInfo.java:156)
	at org.spockframework.runtime.PlatformSpecRunner.invokeRaw(PlatformSpecRunner.java:407)
	at org.spockframework.runtime.PlatformSpecRunner.invoke(PlatformSpecRunner.java:390)
	at org.spockframework.runtime.PlatformSpecRunner.runFeature(PlatformSpecRunner.java:192)
	at org.spockframework.runtime.FeatureNode.around(FeatureNode.java:41)
	at org.spockframework.runtime.FeatureNode.around(FeatureNode.java:12)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1511)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.spockframework.runtime.SpockNode.sneakyInvoke(SpockNode.java:40)
	at org.spockframework.runtime.SpecNode.lambda$around$0(SpecNode.java:63)
	at org.spockframework.runtime.PlatformSpecRunner.lambda$createMethodInfoForDoRunSpec$0(PlatformSpecRunner.java:61)
	at org.spockframework.runtime.model.MethodInfo.invoke(MethodInfo.java:156)
	at org.spockframework.runtime.PlatformSpecRunner.invokeRaw(PlatformSpecRunner.java:407)
	at org.spockframework.runtime.PlatformSpecRunner.invoke(PlatformSpecRunner.java:390)
	at org.spockframework.runtime.PlatformSpecRunner.runSpec(PlatformSpecRunner.java:55)
	at org.spockframework.runtime.SpecNode.around(SpecNode.java:63)
	at org.spockframework.runtime.SpecNode.around(SpecNode.java:11)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1511)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:147)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:127)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:90)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:55)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:102)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:150)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2025-01-04 00:12:50.865 [KafkaServer id=0] started
2025-01-04 00:12:50.865 AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [127.0.0.1:51211]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-01-04 00:12:50.866 [Controller id=0] Starting the controller scheduler
2025-01-04 00:12:50.868 Kafka version: 3.4.1
2025-01-04 00:12:50.868 Kafka commitId: 8a516edc2755df89
2025-01-04 00:12:50.868 Kafka startTimeMs: 1735920770868
2025-01-04 00:12:50.878 Creating topic pong-message-topic with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-01-04 00:12:50.885 [Controller id=0] New topics: [Set(pong-message-topic)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(pong-message-topic,Some(4m4Cn_6sQCqBaRjdL4JK9g),Map(pong-message-topic-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-01-04 00:12:50.885 [Controller id=0] New partition creation callback for pong-message-topic-0
2025-01-04 00:12:50.885 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-04 00:12:50.885 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:12:50.885 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:12:50.891 [Controller id=0 epoch=1] Changed partition pong-message-topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-04 00:12:50.891 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions
2025-01-04 00:12:50.891 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 1 partitions
2025-01-04 00:12:50.892 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:12:50.892 [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 for 1 partitions
2025-01-04 00:12:50.894 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(pong-message-topic-0)
2025-01-04 00:12:50.894 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions
2025-01-04 00:12:50.899 [LogLoader partition=pong-message-topic-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.358f9ed1-2460-4fd8-b26c-46ce59d663fe5754759066350150320] Loading producer state till offset 0 with message format version 2
2025-01-04 00:12:50.899 Created log for partition pong-message-topic-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.358f9ed1-2460-4fd8-b26c-46ce59d663fe5754759066350150320\pong-message-topic-0 with properties {}
2025-01-04 00:12:50.901 [Partition pong-message-topic-0 broker=0] No checkpointed highwatermark is found for partition pong-message-topic-0
2025-01-04 00:12:50.901 [Partition pong-message-topic-0 broker=0] Log loaded for partition pong-message-topic-0 with initial high watermark 0
2025-01-04 00:12:50.901 [Broker id=0] Leader pong-message-topic-0 with topic id Some(4m4Cn_6sQCqBaRjdL4JK9g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2025-01-04 00:12:50.903 [Broker id=0] Finished LeaderAndIsr request in 11ms correlationId 1 from controller 0 for 1 partitions
2025-01-04 00:12:50.905 [Broker id=0] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2
2025-01-04 00:12:50.906 App info kafka.admin.client for adminclient-3 unregistered
2025-01-04 00:12:50.907 Metrics scheduler closed
2025-01-04 00:12:50.907 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-04 00:12:50.907 Metrics reporters closed
2025-01-04 00:12:50.908 Starting PongControllerSpec using Java 17.0.12 with PID 10572 (started by joech in C:\code\hsbc\demo\pong)
2025-01-04 00:12:50.908 No active profile set, falling back to 1 default profile: "default"
2025-01-04 00:12:50.923 [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use node localhost:51211 (id: 0 rack: null)
2025-01-04 00:12:50.937 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Recorded new controller, from now on will use node localhost:51211 (id: 0 rack: null)
2025-01-04 00:12:51.010 Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-04 00:12:51.011 Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-01-04 00:12:51.021 Finished Spring Data repository scanning in 9 ms. Found 1 JPA repository interfaces.
2025-01-04 00:12:51.024 Multiple Spring Data modules found, entering strict repository configuration mode
2025-01-04 00:12:51.024 Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-01-04 00:12:51.027 Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.demo.dao.MessageRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-01-04 00:12:51.027 Finished Spring Data repository scanning in 2 ms. Found 0 Redis repository interfaces.
2025-01-04 00:12:51.198 HHH000204: Processing PersistenceUnitInfo [name: default]
2025-01-04 00:12:51.205 HHH000021: Bytecode provider name : bytebuddy
2025-01-04 00:12:51.205 No LoadTimeWeaver setup: ignoring JPA class transformer
2025-01-04 00:12:51.207 HikariPool-3 - Starting...
2025-01-04 00:12:51.209 HikariPool-3 - Added connection conn20: url=jdbc:h2:mem:testdb user=SA
2025-01-04 00:12:51.209 HikariPool-3 - Start completed.
2025-01-04 00:12:51.221 HHH000021: Bytecode provider name : bytebuddy
2025-01-04 00:12:51.243 HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2025-01-04 00:12:51.260 Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-01-04 00:12:51.545 Netty started on port 51216
2025-01-04 00:12:51.548 ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:51205]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-pong-service-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = pong-service
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-01-04 00:12:51.551 These configurations '[spring.json.trusted.packages]' were supplied but are not used yet.
2025-01-04 00:12:51.551 Kafka version: 3.4.1
2025-01-04 00:12:51.551 Kafka commitId: 8a516edc2755df89
2025-01-04 00:12:51.551 Kafka startTimeMs: 1735920771551
2025-01-04 00:12:51.551 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Subscribed to topic(s): pong-message-topic
2025-01-04 00:12:51.554 Started PongControllerSpec in 0.858 seconds (process running for 14.275)
2025-01-04 00:12:51.558 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting the last seen epoch of partition pong-message-topic-0 to 0 since the associated topicId changed from null to 1ueuB_1OSHCWpikvBBJD-g
2025-01-04 00:12:51.559 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting the last seen epoch of partition pong-message-topic-1 to 0 since the associated topicId changed from null to 1ueuB_1OSHCWpikvBBJD-g
2025-01-04 00:12:51.559 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Cluster ID: g4S3f1T9TLKvdGbqnAR4LQ
2025-01-04 00:12:51.563 Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0))
2025-01-04 00:12:51.576 [Controller id=0] New topics: [Set(__consumer_offsets)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(__consumer_offsets,Some(tO3upDJMT5uYFtsthmublg),HashMap(__consumer_offsets-4 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-3 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-2 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-01-04 00:12:51.576 [Controller id=0] New partition creation callback for __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2025-01-04 00:12:51.576 [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-04 00:12:51.576 [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-04 00:12:51.576 [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-04 00:12:51.576 [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-04 00:12:51.576 [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-04 00:12:51.577 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:12:51.578 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:12:51.586 [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-04 00:12:51.586 [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-04 00:12:51.586 [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-04 00:12:51.586 [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-04 00:12:51.586 [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-04 00:12:51.586 [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 5 become-leader and 0 become-follower partitions
2025-01-04 00:12:51.586 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 5 partitions
2025-01-04 00:12:51.588 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:12:51.588 [Broker id=0] Handling LeaderAndIsr request correlationId 3 from controller 0 for 5 partitions
2025-01-04 00:12:51.589 [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-4, __consumer_offsets-3, __consumer_offsets-2, __consumer_offsets-0, __consumer_offsets-1)
2025-01-04 00:12:51.589 [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 3 from controller 0 epoch 1 as part of the become-leader transition for 5 partitions
2025-01-04 00:12:51.596 [LogLoader partition=__consumer_offsets-3, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.a68a358b-4c66-4881-85c5-3d5c451ad0ab8865735822486362518] Loading producer state till offset 0 with message format version 2
2025-01-04 00:12:51.596 Created log for partition __consumer_offsets-3 in C:\Users\joech\AppData\Local\Temp\spring.kafka.a68a358b-4c66-4881-85c5-3d5c451ad0ab8865735822486362518\__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-01-04 00:12:51.598 [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
2025-01-04 00:12:51.599 [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0
2025-01-04 00:12:51.599 [Broker id=0] Leader __consumer_offsets-3 with topic id Some(tO3upDJMT5uYFtsthmublg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2025-01-04 00:12:51.608 [LogLoader partition=__consumer_offsets-2, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.a68a358b-4c66-4881-85c5-3d5c451ad0ab8865735822486362518] Loading producer state till offset 0 with message format version 2
2025-01-04 00:12:51.608 Created log for partition __consumer_offsets-2 in C:\Users\joech\AppData\Local\Temp\spring.kafka.a68a358b-4c66-4881-85c5-3d5c451ad0ab8865735822486362518\__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-01-04 00:12:51.608 [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
2025-01-04 00:12:51.609 [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0
2025-01-04 00:12:51.609 [Broker id=0] Leader __consumer_offsets-2 with topic id Some(tO3upDJMT5uYFtsthmublg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2025-01-04 00:12:51.617 [LogLoader partition=__consumer_offsets-4, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.a68a358b-4c66-4881-85c5-3d5c451ad0ab8865735822486362518] Loading producer state till offset 0 with message format version 2
2025-01-04 00:12:51.618 Created log for partition __consumer_offsets-4 in C:\Users\joech\AppData\Local\Temp\spring.kafka.a68a358b-4c66-4881-85c5-3d5c451ad0ab8865735822486362518\__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-01-04 00:12:51.618 [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
2025-01-04 00:12:51.618 [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0
2025-01-04 00:12:51.618 [Broker id=0] Leader __consumer_offsets-4 with topic id Some(tO3upDJMT5uYFtsthmublg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2025-01-04 00:12:51.627 [LogLoader partition=__consumer_offsets-1, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.a68a358b-4c66-4881-85c5-3d5c451ad0ab8865735822486362518] Loading producer state till offset 0 with message format version 2
2025-01-04 00:12:51.627 Created log for partition __consumer_offsets-1 in C:\Users\joech\AppData\Local\Temp\spring.kafka.a68a358b-4c66-4881-85c5-3d5c451ad0ab8865735822486362518\__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-01-04 00:12:51.627 [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
2025-01-04 00:12:51.627 [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0
2025-01-04 00:12:51.627 [Broker id=0] Leader __consumer_offsets-1 with topic id Some(tO3upDJMT5uYFtsthmublg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2025-01-04 00:12:51.636 [LogLoader partition=__consumer_offsets-0, dir=C:\Users\joech\AppData\Local\Temp\spring.kafka.a68a358b-4c66-4881-85c5-3d5c451ad0ab8865735822486362518] Loading producer state till offset 0 with message format version 2
2025-01-04 00:12:51.637 Created log for partition __consumer_offsets-0 in C:\Users\joech\AppData\Local\Temp\spring.kafka.a68a358b-4c66-4881-85c5-3d5c451ad0ab8865735822486362518\__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-01-04 00:12:51.637 [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
2025-01-04 00:12:51.637 [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0
2025-01-04 00:12:51.637 [Broker id=0] Leader __consumer_offsets-0 with topic id Some(tO3upDJMT5uYFtsthmublg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas []. Previous leader epoch was -1.
2025-01-04 00:12:51.640 [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 0
2025-01-04 00:12:51.640 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0
2025-01-04 00:12:51.640 [GroupCoordinator 0]: Elected as the group coordinator for partition 2 in epoch 0
2025-01-04 00:12:51.640 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0
2025-01-04 00:12:51.640 [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 0
2025-01-04 00:12:51.641 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0
2025-01-04 00:12:51.641 [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 0
2025-01-04 00:12:51.641 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0
2025-01-04 00:12:51.641 [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 0
2025-01-04 00:12:51.641 [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0
2025-01-04 00:12:51.641 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 1 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler.
2025-01-04 00:12:51.641 [Broker id=0] Finished LeaderAndIsr request in 53ms correlationId 3 from controller 0 for 5 partitions
2025-01-04 00:12:51.641 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler.
2025-01-04 00:12:51.641 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler.
2025-01-04 00:12:51.641 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler.
2025-01-04 00:12:51.641 [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler.
2025-01-04 00:12:51.643 [Broker id=0] Add 5 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 4
2025-01-04 00:12:51.664 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Discovered group coordinator localhost:51205 (id: 2147483647 rack: null)
2025-01-04 00:12:51.664 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] (Re-)joining group
2025-01-04 00:12:51.667 [GroupCoordinator 0]: Dynamic member with unknown member id joins group pong-service in Empty state. Created a new member id consumer-pong-service-3-231b91f5-f1a2-4557-90a3-66cf7dd961e0 and request the member to rejoin with this id.
2025-01-04 00:12:51.668 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Request joining group due to: need to re-join with the given member-id: consumer-pong-service-3-231b91f5-f1a2-4557-90a3-66cf7dd961e0
2025-01-04 00:12:51.668 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
2025-01-04 00:12:51.668 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] (Re-)joining group
2025-01-04 00:12:51.670 [GroupCoordinator 0]: Preparing to rebalance group pong-service in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-pong-service-3-231b91f5-f1a2-4557-90a3-66cf7dd961e0 with group instance id None; client reason: rebalance failed due to MemberIdRequiredException)
2025-01-04 00:12:51.671 [GroupCoordinator 0]: Stabilized group pong-service generation 1 (__consumer_offsets-2) with 1 members
2025-01-04 00:12:51.672 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Successfully joined group with generation Generation{generationId=1, memberId='consumer-pong-service-3-231b91f5-f1a2-4557-90a3-66cf7dd961e0', protocol='range'}
2025-01-04 00:12:51.672 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Finished assignment for group at generation 1: {consumer-pong-service-3-231b91f5-f1a2-4557-90a3-66cf7dd961e0=Assignment(partitions=[pong-message-topic-0, pong-message-topic-1])}
2025-01-04 00:12:51.674 [GroupCoordinator 0]: Assignment received from leader consumer-pong-service-3-231b91f5-f1a2-4557-90a3-66cf7dd961e0 for group pong-service for generation 1. The group has 1 members, 0 of which are static.
2025-01-04 00:12:51.677 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Successfully synced group in generation Generation{generationId=1, memberId='consumer-pong-service-3-231b91f5-f1a2-4557-90a3-66cf7dd961e0', protocol='range'}
2025-01-04 00:12:51.677 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Notifying assignor about the new Assignment(partitions=[pong-message-topic-0, pong-message-topic-1])
2025-01-04 00:12:51.677 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Adding newly assigned partitions: pong-message-topic-0, pong-message-topic-1
2025-01-04 00:12:51.678 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Found no committed offset for partition pong-message-topic-0
2025-01-04 00:12:51.679 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Found no committed offset for partition pong-message-topic-1
2025-01-04 00:12:51.680 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Found no committed offset for partition pong-message-topic-0
2025-01-04 00:12:51.680 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Found no committed offset for partition pong-message-topic-1
2025-01-04 00:12:51.682 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting offset for partition pong-message-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:51205 (id: 0 rack: null)], epoch=0}}.
2025-01-04 00:12:51.682 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting offset for partition pong-message-topic-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:51205 (id: 0 rack: null)], epoch=0}}.
2025-01-04 00:12:51.685 pong-service: partitions assigned: [pong-message-topic-0, pong-message-topic-1]
2025-01-04 00:12:52.020 Ping success, handling ping message: Hello
2025-01-04 00:12:52.020 Idempotence will be disabled because acks is set to 0, not set to 'all'.
2025-01-04 00:12:52.020 ProducerConfig values: 
	acks = 0
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:51205]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2025-01-04 00:12:52.026 Kafka version: 3.4.1
2025-01-04 00:12:52.026 Kafka commitId: 8a516edc2755df89
2025-01-04 00:12:52.026 Kafka startTimeMs: 1735920772026
2025-01-04 00:12:52.033 [Producer clientId=producer-2] Resetting the last seen epoch of partition pong-message-topic-0 to 0 since the associated topicId changed from null to 1ueuB_1OSHCWpikvBBJD-g
2025-01-04 00:12:52.033 [Producer clientId=producer-2] Resetting the last seen epoch of partition pong-message-topic-1 to 0 since the associated topicId changed from null to 1ueuB_1OSHCWpikvBBJD-g
2025-01-04 00:12:52.034 [Producer clientId=producer-2] Cluster ID: g4S3f1T9TLKvdGbqnAR4LQ
2025-01-04 00:12:53.251 Ping success, handling ping message: Hello
2025-01-04 00:12:53.255 Throttling request as too many requests in the same second
2025-01-04 00:12:53.255 Throttling request as too many requests in the same second
2025-01-04 00:12:53.297 [KafkaServer id=0] shutting down
2025-01-04 00:12:53.298 [KafkaServer id=0] Starting controlled shutdown
2025-01-04 00:12:53.301 [Controller id=0] Shutting down broker 0
2025-01-04 00:12:53.302 [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-04 00:12:53.302 [KafkaServer id=0] Controlled shutdown request returned successfully after 1ms
2025-01-04 00:12:53.303 [/config/changes-event-process-thread]: Shutting down
2025-01-04 00:12:53.303 [/config/changes-event-process-thread]: Stopped
2025-01-04 00:12:53.303 [/config/changes-event-process-thread]: Shutdown completed
2025-01-04 00:12:53.303 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
2025-01-04 00:12:53.304 [Producer clientId=producer-2] Node -1 disconnected.
2025-01-04 00:12:53.304 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node 2147483647 disconnected.
2025-01-04 00:12:53.304 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node -1 disconnected.
2025-01-04 00:12:53.304 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Group coordinator localhost:51205 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
2025-01-04 00:12:53.306 [Producer clientId=producer-2] Node 0 disconnected.
2025-01-04 00:12:53.306 [Producer clientId=producer-2] Cancelled in-flight METADATA request with correlation id 5 due to node 0 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
2025-01-04 00:12:53.306 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node 0 disconnected.
2025-01-04 00:12:53.306 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Cancelled in-flight FETCH request with correlation id 19 due to node 0 being disconnected (elapsed time since creation: 48ms, elapsed time since send: 48ms, request timeout: 30000ms)
2025-01-04 00:12:53.306 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Cancelled in-flight FIND_COORDINATOR request with correlation id 21 due to node 0 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
2025-01-04 00:12:53.306 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors
2025-01-04 00:12:53.306 [data-plane Kafka Request Handler on Broker 0], shutting down
2025-01-04 00:12:53.306 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Error sending fetch request (sessionId=1363167068, epoch=4) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2025-01-04 00:12:53.306 [data-plane Kafka Request Handler on Broker 0], shut down completely
2025-01-04 00:12:53.307 [ExpirationReaper-0-AlterAcls]: Shutting down
2025-01-04 00:12:53.308 [ExpirationReaper-0-AlterAcls]: Shutdown completed
2025-01-04 00:12:53.308 [ExpirationReaper-0-AlterAcls]: Stopped
2025-01-04 00:12:53.308 [KafkaApi-0] Shutdown complete.
2025-01-04 00:12:53.308 [ExpirationReaper-0-topic]: Shutting down
2025-01-04 00:12:53.309 [ExpirationReaper-0-topic]: Stopped
2025-01-04 00:12:53.309 [ExpirationReaper-0-topic]: Shutdown completed
2025-01-04 00:12:53.309 [TransactionCoordinator id=0] Shutting down.
2025-01-04 00:12:53.309 [Transaction State Manager 0]: Shutdown complete
2025-01-04 00:12:53.309 [Transaction Marker Channel Manager 0]: Shutting down
2025-01-04 00:12:53.309 [Transaction Marker Channel Manager 0]: Stopped
2025-01-04 00:12:53.309 [Transaction Marker Channel Manager 0]: Shutdown completed
2025-01-04 00:12:53.309 [TransactionCoordinator id=0] Shutdown complete.
2025-01-04 00:12:53.310 [GroupCoordinator 0]: Shutting down.
2025-01-04 00:12:53.310 [ExpirationReaper-0-Heartbeat]: Shutting down
2025-01-04 00:12:53.310 [ExpirationReaper-0-Heartbeat]: Stopped
2025-01-04 00:12:53.310 [ExpirationReaper-0-Heartbeat]: Shutdown completed
2025-01-04 00:12:53.310 [ExpirationReaper-0-Rebalance]: Shutting down
2025-01-04 00:12:53.310 [ExpirationReaper-0-Rebalance]: Stopped
2025-01-04 00:12:53.310 [ExpirationReaper-0-Rebalance]: Shutdown completed
2025-01-04 00:12:53.310 [GroupCoordinator 0]: Shutdown complete.
2025-01-04 00:12:53.311 [ReplicaManager broker=0] Shutting down
2025-01-04 00:12:53.311 [LogDirFailureHandler]: Shutting down
2025-01-04 00:12:53.311 [LogDirFailureHandler]: Shutdown completed
2025-01-04 00:12:53.311 [LogDirFailureHandler]: Stopped
2025-01-04 00:12:53.311 [ReplicaFetcherManager on broker 0] shutting down
2025-01-04 00:12:53.311 [ReplicaFetcherManager on broker 0] shutdown completed
2025-01-04 00:12:53.311 [ReplicaAlterLogDirsManager on broker 0] shutting down
2025-01-04 00:12:53.311 [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2025-01-04 00:12:53.311 [ExpirationReaper-0-Fetch]: Shutting down
2025-01-04 00:12:53.311 [ExpirationReaper-0-Fetch]: Stopped
2025-01-04 00:12:53.311 [ExpirationReaper-0-Fetch]: Shutdown completed
2025-01-04 00:12:53.311 [ExpirationReaper-0-Produce]: Shutting down
2025-01-04 00:12:53.311 [ExpirationReaper-0-Produce]: Stopped
2025-01-04 00:12:53.311 [ExpirationReaper-0-Produce]: Shutdown completed
2025-01-04 00:12:53.312 [ExpirationReaper-0-DeleteRecords]: Shutting down
2025-01-04 00:12:53.312 [ExpirationReaper-0-DeleteRecords]: Stopped
2025-01-04 00:12:53.312 [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2025-01-04 00:12:53.312 [ExpirationReaper-0-ElectLeader]: Shutting down
2025-01-04 00:12:53.312 [ExpirationReaper-0-ElectLeader]: Stopped
2025-01-04 00:12:53.312 [ExpirationReaper-0-ElectLeader]: Shutdown completed
2025-01-04 00:12:53.315 [ReplicaManager broker=0] Shut down completely
2025-01-04 00:12:53.316 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutting down
2025-01-04 00:12:53.316 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Stopped
2025-01-04 00:12:53.316 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutdown completed
2025-01-04 00:12:53.316 Broker to controller channel manager for alterPartition shutdown
2025-01-04 00:12:53.316 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down
2025-01-04 00:12:53.316 [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped
2025-01-04 00:12:53.316 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed
2025-01-04 00:12:53.316 Broker to controller channel manager for forwarding shutdown
2025-01-04 00:12:53.316 Shutting down.
2025-01-04 00:12:53.316 Shutting down the log cleaner.
2025-01-04 00:12:53.316 [kafka-log-cleaner-thread-0]: Shutting down
2025-01-04 00:12:53.318 [kafka-log-cleaner-thread-0]: Shutdown completed
2025-01-04 00:12:53.318 [kafka-log-cleaner-thread-0]: Stopped
2025-01-04 00:12:53.334 [ProducerStateManager partition=pong-message-topic-1] Wrote producer snapshot at offset 2 with 0 producer ids in 2 ms.
2025-01-04 00:12:53.341 [ProducerStateManager partition=__consumer_offsets-2] Wrote producer snapshot at offset 5 with 0 producer ids in 2 ms.
2025-01-04 00:12:53.348 Shutdown complete.
2025-01-04 00:12:53.348 [ControllerEventThread controllerId=0] Shutting down
2025-01-04 00:12:53.348 [ControllerEventThread controllerId=0] Shutdown completed
2025-01-04 00:12:53.348 [ControllerEventThread controllerId=0] Stopped
2025-01-04 00:12:53.349 [PartitionStateMachine controllerId=0] Stopped partition state machine
2025-01-04 00:12:53.349 [ReplicaStateMachine controllerId=0] Stopped replica state machine
2025-01-04 00:12:53.349 [RequestSendThread controllerId=0] Shutting down
2025-01-04 00:12:53.349 [RequestSendThread controllerId=0] Shutdown completed
2025-01-04 00:12:53.349 [RequestSendThread controllerId=0] Stopped
2025-01-04 00:12:53.350 [Controller id=0] Resigned
2025-01-04 00:12:53.350 [feature-zk-node-event-process-thread]: Shutting down
2025-01-04 00:12:53.350 [feature-zk-node-event-process-thread]: Stopped
2025-01-04 00:12:53.350 [feature-zk-node-event-process-thread]: Shutdown completed
2025-01-04 00:12:53.350 [ZooKeeperClient Kafka server] Closing.
2025-01-04 00:12:53.405 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Node 0 disconnected.
2025-01-04 00:12:53.405 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Connection to node 0 (localhost/127.0.0.1:51205) could not be established. Broker may not be available.
2025-01-04 00:12:53.407 [Producer clientId=producer-2] Node 0 disconnected.
2025-01-04 00:12:53.407 [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:51205) could not be established. Broker may not be available.
2025-01-04 00:12:53.454 Session: 0x1000a9d65840000 closed
2025-01-04 00:12:53.454 EventThread shut down for session: 0x1000a9d65840000
2025-01-04 00:12:53.455 [ZooKeeperClient Kafka server] Closed.
2025-01-04 00:12:53.455 [ThrottledChannelReaper-Fetch]: Shutting down
2025-01-04 00:12:53.455 [ThrottledChannelReaper-Fetch]: Shutdown completed
2025-01-04 00:12:53.455 [ThrottledChannelReaper-Fetch]: Stopped
2025-01-04 00:12:53.455 [ThrottledChannelReaper-Produce]: Shutting down
2025-01-04 00:12:53.455 [ThrottledChannelReaper-Produce]: Stopped
2025-01-04 00:12:53.455 [ThrottledChannelReaper-Produce]: Shutdown completed
2025-01-04 00:12:53.455 [ThrottledChannelReaper-Request]: Shutting down
2025-01-04 00:12:53.455 [ThrottledChannelReaper-Request]: Stopped
2025-01-04 00:12:53.455 [ThrottledChannelReaper-Request]: Shutdown completed
2025-01-04 00:12:53.455 [ThrottledChannelReaper-ControllerMutation]: Shutting down
2025-01-04 00:12:53.455 [ThrottledChannelReaper-ControllerMutation]: Shutdown completed
2025-01-04 00:12:53.455 [ThrottledChannelReaper-ControllerMutation]: Stopped
2025-01-04 00:12:53.456 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server
2025-01-04 00:12:53.461 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed
2025-01-04 00:12:53.461 Metrics scheduler closed
2025-01-04 00:12:53.461 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-04 00:12:53.461 Metrics reporters closed
2025-01-04 00:12:53.461 Broker and topic stats closed
2025-01-04 00:12:53.461 App info kafka.server for 0 unregistered
2025-01-04 00:12:53.461 [KafkaServer id=0] shut down completed
2025-01-04 00:12:53.468 ConnnectionExpirerThread interrupted
2025-01-04 00:12:53.468 selector thread exitted run method
2025-01-04 00:12:53.469 accept thread exitted run method
2025-01-04 00:12:53.469 selector thread exitted run method
2025-01-04 00:12:53.469 shutting down
2025-01-04 00:12:53.469 Shutting down
2025-01-04 00:12:53.469 Draining request throttler queue
2025-01-04 00:12:53.469 RequestThrottler shutdown. Dropped 0 requests
2025-01-04 00:12:53.469 Shutting down
2025-01-04 00:12:53.469 Shutting down
2025-01-04 00:12:53.469 Shutting down
2025-01-04 00:12:53.469 PrepRequestProcessor exited loop!
2025-01-04 00:12:53.469 SyncRequestProcessor exited!
2025-01-04 00:12:53.469 shutdown of request processor complete
2025-01-04 00:12:53.483 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Revoke previously assigned partitions pong-message-topic-0, pong-message-topic-1
2025-01-04 00:12:53.483 pong-service: partitions revoked: [pong-message-topic-0, pong-message-topic-1]
2025-01-04 00:12:53.483 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-04 00:12:53.483 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2025-01-04 00:12:53.483 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Unsubscribed all topics or patterns and assigned partitions
2025-01-04 00:12:53.484 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-04 00:12:53.484 [Consumer clientId=consumer-pong-service-3, groupId=pong-service] Request joining group due to: consumer pro-actively leaving the group
2025-01-04 00:12:53.484 Metrics scheduler closed
2025-01-04 00:12:53.484 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-04 00:12:53.484 Metrics reporters closed
2025-01-04 00:12:53.484 App info kafka.consumer for consumer-pong-service-3 unregistered
2025-01-04 00:12:53.484 pong-service: Consumer stopped
2025-01-04 00:12:53.487 [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 30000 ms.
2025-01-04 00:12:53.487 Metrics scheduler closed
2025-01-04 00:12:53.487 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-04 00:12:53.487 Metrics reporters closed
2025-01-04 00:12:53.487 App info kafka.producer for producer-2 unregistered
2025-01-04 00:12:53.490 Closing JPA EntityManagerFactory for persistence unit 'default'
2025-01-04 00:12:53.491 HikariPool-3 - Shutdown initiated...
2025-01-04 00:12:53.493 HikariPool-3 - Shutdown completed.
2025-01-04 00:12:53.595 SessionTrackerImpl exited loop!
2025-01-04 00:12:55.507 [KafkaServer id=0] shutting down
2025-01-04 00:12:55.507 [/config/changes-event-process-thread]: Shutting down
2025-01-04 00:12:55.507 [/config/changes-event-process-thread]: Stopped
2025-01-04 00:12:55.507 [/config/changes-event-process-thread]: Shutdown completed
2025-01-04 00:12:55.508 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
2025-01-04 00:12:55.508 [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors
2025-01-04 00:12:55.508 [data-plane Kafka Request Handler on Broker 0], shutting down
2025-01-04 00:12:55.509 [data-plane Kafka Request Handler on Broker 0], shut down completely
2025-01-04 00:12:55.509 [ExpirationReaper-0-AlterAcls]: Shutting down
2025-01-04 00:12:55.509 [ExpirationReaper-0-AlterAcls]: Stopped
2025-01-04 00:12:55.509 [ExpirationReaper-0-AlterAcls]: Shutdown completed
2025-01-04 00:12:55.511 [KafkaApi-0] Shutdown complete.
2025-01-04 00:12:55.511 [ExpirationReaper-0-topic]: Shutting down
2025-01-04 00:12:55.511 [ExpirationReaper-0-topic]: Stopped
2025-01-04 00:12:55.511 [ExpirationReaper-0-topic]: Shutdown completed
2025-01-04 00:12:55.511 [TransactionCoordinator id=0] Shutting down.
2025-01-04 00:12:55.511 [Transaction State Manager 0]: Shutdown complete
2025-01-04 00:12:55.511 [Transaction Marker Channel Manager 0]: Shutting down
2025-01-04 00:12:55.511 [Transaction Marker Channel Manager 0]: Stopped
2025-01-04 00:12:55.511 [Transaction Marker Channel Manager 0]: Shutdown completed
2025-01-04 00:12:55.511 [TransactionCoordinator id=0] Shutdown complete.
2025-01-04 00:12:55.511 [GroupCoordinator 0]: Shutting down.
2025-01-04 00:12:55.511 [ExpirationReaper-0-Heartbeat]: Shutting down
2025-01-04 00:12:55.512 [ExpirationReaper-0-Heartbeat]: Shutdown completed
2025-01-04 00:12:55.512 [ExpirationReaper-0-Heartbeat]: Stopped
2025-01-04 00:12:55.512 [ExpirationReaper-0-Rebalance]: Shutting down
2025-01-04 00:12:55.512 [ExpirationReaper-0-Rebalance]: Stopped
2025-01-04 00:12:55.512 [ExpirationReaper-0-Rebalance]: Shutdown completed
2025-01-04 00:12:55.512 [GroupCoordinator 0]: Shutdown complete.
2025-01-04 00:12:55.512 [ReplicaManager broker=0] Shutting down
2025-01-04 00:12:55.512 [LogDirFailureHandler]: Shutting down
2025-01-04 00:12:55.512 [LogDirFailureHandler]: Stopped
2025-01-04 00:12:55.512 [LogDirFailureHandler]: Shutdown completed
2025-01-04 00:12:55.512 [ReplicaFetcherManager on broker 0] shutting down
2025-01-04 00:12:55.512 [ReplicaFetcherManager on broker 0] shutdown completed
2025-01-04 00:12:55.512 [ReplicaAlterLogDirsManager on broker 0] shutting down
2025-01-04 00:12:55.512 [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2025-01-04 00:12:55.512 [ExpirationReaper-0-Fetch]: Shutting down
2025-01-04 00:12:55.513 [ExpirationReaper-0-Fetch]: Shutdown completed
2025-01-04 00:12:55.513 [ExpirationReaper-0-Fetch]: Stopped
2025-01-04 00:12:55.513 [ExpirationReaper-0-Produce]: Shutting down
2025-01-04 00:12:55.513 [ExpirationReaper-0-Produce]: Stopped
2025-01-04 00:12:55.513 [ExpirationReaper-0-Produce]: Shutdown completed
2025-01-04 00:12:55.513 [ExpirationReaper-0-DeleteRecords]: Shutting down
2025-01-04 00:12:55.513 [ExpirationReaper-0-DeleteRecords]: Stopped
2025-01-04 00:12:55.513 [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2025-01-04 00:12:55.513 [ExpirationReaper-0-ElectLeader]: Shutting down
2025-01-04 00:12:55.513 [ExpirationReaper-0-ElectLeader]: Stopped
2025-01-04 00:12:55.513 [ExpirationReaper-0-ElectLeader]: Shutdown completed
2025-01-04 00:12:55.518 [ReplicaManager broker=0] Shut down completely
2025-01-04 00:12:55.518 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutting down
2025-01-04 00:12:55.518 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Stopped
2025-01-04 00:12:55.518 [BrokerToControllerChannelManager broker=0 name=alterPartition]: Shutdown completed
2025-01-04 00:12:55.519 Broker to controller channel manager for alterPartition shutdown
2025-01-04 00:12:55.519 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down
2025-01-04 00:12:55.519 [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped
2025-01-04 00:12:55.519 [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed
2025-01-04 00:12:55.519 Broker to controller channel manager for forwarding shutdown
2025-01-04 00:12:55.519 Shutting down.
2025-01-04 00:12:55.519 Shutting down the log cleaner.
2025-01-04 00:12:55.519 [kafka-log-cleaner-thread-0]: Shutting down
2025-01-04 00:12:55.519 [kafka-log-cleaner-thread-0]: Stopped
2025-01-04 00:12:55.519 [kafka-log-cleaner-thread-0]: Shutdown completed
2025-01-04 00:12:55.529 Shutdown complete.
2025-01-04 00:12:55.529 [ControllerEventThread controllerId=0] Shutting down
2025-01-04 00:12:55.529 [ControllerEventThread controllerId=0] Shutdown completed
2025-01-04 00:12:55.529 [ControllerEventThread controllerId=0] Stopped
2025-01-04 00:12:55.529 [PartitionStateMachine controllerId=0] Stopped partition state machine
2025-01-04 00:12:55.529 [ReplicaStateMachine controllerId=0] Stopped replica state machine
2025-01-04 00:12:55.529 [RequestSendThread controllerId=0] Shutting down
2025-01-04 00:12:55.529 [RequestSendThread controllerId=0] Shutdown completed
2025-01-04 00:12:55.529 [RequestSendThread controllerId=0] Stopped
2025-01-04 00:12:55.531 [Controller id=0] Resigned
2025-01-04 00:12:55.531 [feature-zk-node-event-process-thread]: Shutting down
2025-01-04 00:12:55.531 [feature-zk-node-event-process-thread]: Shutdown completed
2025-01-04 00:12:55.531 [feature-zk-node-event-process-thread]: Stopped
2025-01-04 00:12:55.532 [ZooKeeperClient Kafka server] Closing.
2025-01-04 00:12:55.633 Session: 0x1000a9d66810000 closed
2025-01-04 00:12:55.633 EventThread shut down for session: 0x1000a9d66810000
2025-01-04 00:12:55.633 [ZooKeeperClient Kafka server] Closed.
2025-01-04 00:12:55.633 [ThrottledChannelReaper-Fetch]: Shutting down
2025-01-04 00:12:55.633 [ThrottledChannelReaper-Fetch]: Stopped
2025-01-04 00:12:55.633 [ThrottledChannelReaper-Fetch]: Shutdown completed
2025-01-04 00:12:55.633 [ThrottledChannelReaper-Produce]: Shutting down
2025-01-04 00:12:55.633 [ThrottledChannelReaper-Produce]: Stopped
2025-01-04 00:12:55.633 [ThrottledChannelReaper-Produce]: Shutdown completed
2025-01-04 00:12:55.633 [ThrottledChannelReaper-Request]: Shutting down
2025-01-04 00:12:55.633 [ThrottledChannelReaper-Request]: Stopped
2025-01-04 00:12:55.633 [ThrottledChannelReaper-Request]: Shutdown completed
2025-01-04 00:12:55.633 [ThrottledChannelReaper-ControllerMutation]: Shutting down
2025-01-04 00:12:55.633 [ThrottledChannelReaper-ControllerMutation]: Stopped
2025-01-04 00:12:55.633 [ThrottledChannelReaper-ControllerMutation]: Shutdown completed
2025-01-04 00:12:55.635 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server
2025-01-04 00:12:55.639 [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed
2025-01-04 00:12:55.639 Metrics scheduler closed
2025-01-04 00:12:55.639 Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-04 00:12:55.639 Metrics reporters closed
2025-01-04 00:12:55.639 Broker and topic stats closed
2025-01-04 00:12:55.641 App info kafka.server for 0 unregistered
2025-01-04 00:12:55.641 [KafkaServer id=0] shut down completed
2025-01-04 00:12:55.643 ConnnectionExpirerThread interrupted
2025-01-04 00:12:55.643 accept thread exitted run method
2025-01-04 00:12:55.644 selector thread exitted run method
2025-01-04 00:12:55.644 selector thread exitted run method
2025-01-04 00:12:55.644 shutting down
2025-01-04 00:12:55.644 Shutting down
2025-01-04 00:12:55.645 Draining request throttler queue
2025-01-04 00:12:55.645 RequestThrottler shutdown. Dropped 0 requests
2025-01-04 00:12:55.645 Shutting down
2025-01-04 00:12:55.645 Shutting down
2025-01-04 00:12:55.645 Shutting down
2025-01-04 00:12:55.645 PrepRequestProcessor exited loop!
2025-01-04 00:12:55.645 SyncRequestProcessor exited!
2025-01-04 00:12:55.645 shutdown of request processor complete
